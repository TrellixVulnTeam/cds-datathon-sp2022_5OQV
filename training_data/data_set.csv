contents,language
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*                               Leo White                                *)
(*                                                                        *)
(*   Copyright 1996 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(** Documentation comments

  {b Warning:} this module is unstable and part of
  {{!Compiler_libs}compiler-libs}.

*)

(** (Re)Initialise all docstring state *)
val init : unit -> unit

(** Emit warnings for unattached and ambiguous docstrings *)
val warn_bad_docstrings : unit -> unit

(** {2 Docstrings} *)

(** Documentation comments *)
type docstring

(** Create a docstring *)
val docstring : string -> Location.t -> docstring

(** Register a docstring *)
val register : docstring -> unit

(** Get the text of a docstring *)
val docstring_body : docstring -> string

(** Get the location of a docstring *)
val docstring_loc : docstring -> Location.t

(** {2 Set functions}

   These functions are used by the lexer to associate docstrings to
   the locations of tokens. *)

(** Docstrings immediately preceding a token *)
val set_pre_docstrings : Lexing.position -> docstring list -> unit

(** Docstrings immediately following a token *)
val set_post_docstrings : Lexing.position -> docstring list -> unit

(** Docstrings not immediately adjacent to a token *)
val set_floating_docstrings : Lexing.position -> docstring list -> unit

(** Docstrings immediately following the token which precedes this one *)
val set_pre_extra_docstrings : Lexing.position -> docstring list -> unit

(** Docstrings immediately preceding the token which follows this one *)
val set_post_extra_docstrings : Lexing.position -> docstring list -> unit

(** {2 Items}

    The {!docs} type represents documentation attached to an item. *)

type docs =
  { docs_pre: docstring option;
    docs_post: docstring option; }

val empty_docs : docs

val docs_attr : docstring -> Parsetree.attribute

(** Convert item documentation to attributes and add them to an
    attribute list *)
val add_docs_attrs : docs -> Parsetree.attributes -> Parsetree.attributes

(** Fetch the item documentation for the current symbol. This also
    marks this documentation (for ambiguity warnings). *)
val symbol_docs : unit -> docs
val symbol_docs_lazy : unit -> docs Lazy.t

(** Fetch the item documentation for the symbols between two
    positions. This also marks this documentation (for ambiguity
    warnings). *)
val rhs_docs : int -> int -> docs
val rhs_docs_lazy : int -> int -> docs Lazy.t

(** Mark the item documentation for the current symbol (for ambiguity
    warnings). *)
val mark_symbol_docs : unit -> unit

(** Mark as associated the item documentation for the symbols between
    two positions (for ambiguity warnings) *)
val mark_rhs_docs : int -> int -> unit

(** {2 Fields and constructors}

    The {!info} type represents documentation attached to a field or
    constructor. *)

type info = docstring option

val empty_info : info

val info_attr : docstring -> Parsetree.attribute

(** Convert field info to attributes and add them to an
    attribute list *)
val add_info_attrs : info -> Parsetree.attributes -> Parsetree.attributes

(** Fetch the field info for the current symbol. *)
val symbol_info : unit -> info

(** Fetch the field info following the symbol at a given position. *)
val rhs_info : int -> info

(** {2 Unattached comments}

    The {!text} type represents documentation which is not attached to
    anything. *)

type text = docstring list

val empty_text : text
val empty_text_lazy : text Lazy.t

val text_attr : docstring -> Parsetree.attribute

(** Convert text to attributes and add them to an attribute list *)
val add_text_attrs : text -> Parsetree.attributes -> Parsetree.attributes

(** Fetch the text preceding the current symbol. *)
val symbol_text : unit -> text
val symbol_text_lazy : unit -> text Lazy.t

(** Fetch the text preceding the symbol at the given position. *)
val rhs_text : int -> text
val rhs_text_lazy : int -> text Lazy.t

(** {2 Extra text}

    There may be additional text attached to the delimiters of a block
    (e.g. [struct] and [end]). This is fetched by the following
    functions, which are applied to the contents of the block rather
    than the delimiters. *)

(** Fetch additional text preceding the current symbol *)
val symbol_pre_extra_text : unit -> text

(** Fetch additional text following the current symbol *)
val symbol_post_extra_text : unit -> text

(** Fetch additional text preceding the symbol at the given position *)
val rhs_pre_extra_text : int -> text

(** Fetch additional text following the symbol at the given position *)
val rhs_post_extra_text : int -> text

(** Fetch text following the symbol at the given position *)
val rhs_post_text : int -> text

module WithMenhir: sig
(** Fetch the item documentation for the current symbol. This also
    marks this documentation (for ambiguity warnings). *)
val symbol_docs : Lexing.position * Lexing.position -> docs
val symbol_docs_lazy : Lexing.position * Lexing.position -> docs Lazy.t

(** Fetch the item documentation for the symbols between two
    positions. This also marks this documentation (for ambiguity
    warnings). *)
val rhs_docs : Lexing.position -> Lexing.position -> docs
val rhs_docs_lazy : Lexing.position -> Lexing.position -> docs Lazy.t

(** Mark the item documentation for the current symbol (for ambiguity
    warnings). *)
val mark_symbol_docs : Lexing.position * Lexing.position -> unit

(** Mark as associated the item documentation for the symbols between
    two positions (for ambiguity warnings) *)
val mark_rhs_docs : Lexing.position -> Lexing.position -> unit

(** Fetch the field info for the current symbol. *)
val symbol_info : Lexing.position -> info

(** Fetch the field info following the symbol at a given position. *)
val rhs_info : Lexing.position -> info

(** Fetch the text preceding the current symbol. *)
val symbol_text : Lexing.position -> text
val symbol_text_lazy : Lexing.position -> text Lazy.t

(** Fetch the text preceding the symbol at the given position. *)
val rhs_text : Lexing.position -> text
val rhs_text_lazy : Lexing.position -> text Lazy.t

(** {3 Extra text}

    There may be additional text attached to the delimiters of a block
    (e.g. [struct] and [end]). This is fetched by the following
    functions, which are applied to the contents of the block rather
    than the delimiters. *)

(** Fetch additional text preceding the current symbol *)
val symbol_pre_extra_text : Lexing.position -> text

(** Fetch additional text following the current symbol *)
val symbol_post_extra_text : Lexing.position -> text

(** Fetch additional text preceding the symbol at the given position *)
val rhs_pre_extra_text : Lexing.position -> text

(** Fetch additional text following the symbol at the given position *)
val rhs_post_extra_text : Lexing.position -> text

(** Fetch text following the symbol at the given position *)
val rhs_post_text : Lexing.position -> text

end
",ocaml
,ocaml
"/**************************************************************************/
/*                                                                        */
/*                                 OCaml                                  */
/*                                                                        */
/*             Xavier Leroy, projet Cristal, INRIA Rocquencourt           */
/*                                                                        */
/*   Copyright 1996 Institut National de Recherche en Informatique et     */
/*     en Automatique.                                                    */
/*                                                                        */
/*   All rights reserved.  This file is distributed under the terms of    */
/*   the GNU Lesser General Public License version 2.1, with the          */
/*   special exception on linking described in the file LICENSE.          */
/*                                                                        */
/**************************************************************************/

/* The parser definition */

/* The commands [make list-parse-errors] and [make generate-parse-errors]
   run Menhir on a modified copy of the parser where every block of
   text comprised between the markers [BEGIN AVOID] and -----------
   [END AVOID] has been removed. This file should be formatted in
   such a way that this results in a clean removal of certain
   symbols, productions, or declarations. */

%{

open Asttypes
open Longident
open Parsetree
open Ast_helper
open Docstrings
open Docstrings.WithMenhir

let mkloc = Location.mkloc
let mknoloc = Location.mknoloc

let make_loc (startpos, endpos) = {
  Location.loc_start = startpos;
  Location.loc_end = endpos;
  Location.loc_ghost = false;
}

let ghost_loc (startpos, endpos) = {
  Location.loc_start = startpos;
  Location.loc_end = endpos;
  Location.loc_ghost = true;
}

let mktyp ~loc ?attrs d = Typ.mk ~loc:(make_loc loc) ?attrs d
let mkpat ~loc d = Pat.mk ~loc:(make_loc loc) d
let mkexp ~loc d = Exp.mk ~loc:(make_loc loc) d
let mkmty ~loc ?attrs d = Mty.mk ~loc:(make_loc loc) ?attrs d
let mksig ~loc d = Sig.mk ~loc:(make_loc loc) d
let mkmod ~loc ?attrs d = Mod.mk ~loc:(make_loc loc) ?attrs d
let mkstr ~loc d = Str.mk ~loc:(make_loc loc) d
let mkclass ~loc ?attrs d = Cl.mk ~loc:(make_loc loc) ?attrs d
let mkcty ~loc ?attrs d = Cty.mk ~loc:(make_loc loc) ?attrs d

let pstr_typext (te, ext) =
  (Pstr_typext te, ext)
let pstr_primitive (vd, ext) =
  (Pstr_primitive vd, ext)
let pstr_type ((nr, ext), tys) =
  (Pstr_type (nr, tys), ext)
let pstr_exception (te, ext) =
  (Pstr_exception te, ext)
let pstr_include (body, ext) =
  (Pstr_include body, ext)
let pstr_recmodule (ext, bindings) =
  (Pstr_recmodule bindings, ext)

let psig_typext (te, ext) =
  (Psig_typext te, ext)
let psig_value (vd, ext) =
  (Psig_value vd, ext)
let psig_type ((nr, ext), tys) =
  (Psig_type (nr, tys), ext)
let psig_typesubst ((nr, ext), tys) =
  assert (nr = Recursive); (* see [no_nonrec_flag] *)
  (Psig_typesubst tys, ext)
let psig_exception (te, ext) =
  (Psig_exception te, ext)
let psig_include (body, ext) =
  (Psig_include body, ext)

let mkctf ~loc ?attrs ?docs d =
  Ctf.mk ~loc:(make_loc loc) ?attrs ?docs d
let mkcf ~loc ?attrs ?docs d =
  Cf.mk ~loc:(make_loc loc) ?attrs ?docs d

let mkrhs rhs loc = mkloc rhs (make_loc loc)
let ghrhs rhs loc = mkloc rhs (ghost_loc loc)

let push_loc x acc =
  if x.Location.loc_ghost
  then acc
  else x :: acc

let reloc_pat ~loc x =
  { x with ppat_loc = make_loc loc;
           ppat_loc_stack = push_loc x.ppat_loc x.ppat_loc_stack }
let reloc_exp ~loc x =
  { x with pexp_loc = make_loc loc;
           pexp_loc_stack = push_loc x.pexp_loc x.pexp_loc_stack }
let reloc_typ ~loc x =
  { x with ptyp_loc = make_loc loc;
           ptyp_loc_stack = push_loc x.ptyp_loc x.ptyp_loc_stack }

let mkexpvar ~loc (name : string) =
  mkexp ~loc (Pexp_ident(mkrhs (Lident name) loc))

let mkoperator =
  mkexpvar

let mkpatvar ~loc name =
  mkpat ~loc (Ppat_var (mkrhs name loc))

(*
  Ghost expressions and patterns:
  expressions and patterns that do not appear explicitly in the
  source file they have the loc_ghost flag set to true.
  Then the profiler will not try to instrument them and the
  -annot option will not try to display their type.

  Every grammar rule that generates an element with a location must
  make at most one non-ghost element, the topmost one.

  How to tell whether your location must be ghost:
  A location corresponds to a range of characters in the source file.
  If the location contains a piece of code that is syntactically
  valid (according to the documentation), and corresponds to the
  AST node, then the location must be real; in all other cases,
  it must be ghost.
*)
let ghexp ~loc d = Exp.mk ~loc:(ghost_loc loc) d
let ghpat ~loc d = Pat.mk ~loc:(ghost_loc loc) d
let ghtyp ~loc d = Typ.mk ~loc:(ghost_loc loc) d
let ghloc ~loc d = { txt = d; loc = ghost_loc loc }
let ghstr ~loc d = Str.mk ~loc:(ghost_loc loc) d
let ghsig ~loc d = Sig.mk ~loc:(ghost_loc loc) d

let mkinfix arg1 op arg2 =
  Pexp_apply(op, [Nolabel, arg1; Nolabel, arg2])

let neg_string f =
  if String.length f > 0 && f.[0] = '-'
  then String.sub f 1 (String.length f - 1)
  else ""-"" ^ f

let mkuminus ~oploc name arg =
  match name, arg.pexp_desc with
  | ""-"", Pexp_constant(Pconst_integer (n,m)) ->
      Pexp_constant(Pconst_integer(neg_string n,m))
  | (""-"" | ""-.""), Pexp_constant(Pconst_float (f, m)) ->
      Pexp_constant(Pconst_float(neg_string f, m))
  | _ ->
      Pexp_apply(mkoperator ~loc:oploc (""~"" ^ name), [Nolabel, arg])

let mkuplus ~oploc name arg =
  let desc = arg.pexp_desc in
  match name, desc with
  | ""+"", Pexp_constant(Pconst_integer _)
  | (""+"" | ""+.""), Pexp_constant(Pconst_float _) -> desc
  | _ ->
      Pexp_apply(mkoperator ~loc:oploc (""~"" ^ name), [Nolabel, arg])

(* TODO define an abstraction boundary between locations-as-pairs
   and locations-as-Location.t; it should be clear when we move from
   one world to the other *)

let mkexp_cons_desc consloc args =
  Pexp_construct(mkrhs (Lident ""::"") consloc, Some args)
let mkexp_cons ~loc consloc args =
  mkexp ~loc (mkexp_cons_desc consloc args)

let mkpat_cons_desc consloc args =
  Ppat_construct(mkrhs (Lident ""::"") consloc, Some ([], args))
let mkpat_cons ~loc consloc args =
  mkpat ~loc (mkpat_cons_desc consloc args)

let ghexp_cons_desc consloc args =
  Pexp_construct(ghrhs (Lident ""::"") consloc, Some args)
let ghpat_cons_desc consloc args =
  Ppat_construct(ghrhs (Lident ""::"") consloc, Some ([], args))

let rec mktailexp nilloc = let open Location in function
    [] ->
      let nil = ghloc ~loc:nilloc (Lident ""[]"") in
      Pexp_construct (nil, None), nilloc
  | e1 :: el ->
      let exp_el, el_loc = mktailexp nilloc el in
      let loc = (e1.pexp_loc.loc_start, snd el_loc) in
      let arg = ghexp ~loc (Pexp_tuple [e1; ghexp ~loc:el_loc exp_el]) in
      ghexp_cons_desc loc arg, loc

let rec mktailpat nilloc = let open Location in function
    [] ->
      let nil = ghloc ~loc:nilloc (Lident ""[]"") in
      Ppat_construct (nil, None), nilloc
  | p1 :: pl ->
      let pat_pl, el_loc = mktailpat nilloc pl in
      let loc = (p1.ppat_loc.loc_start, snd el_loc) in
      let arg = ghpat ~loc (Ppat_tuple [p1; ghpat ~loc:el_loc pat_pl]) in
      ghpat_cons_desc loc arg, loc

let mkstrexp e attrs =
  { pstr_desc = Pstr_eval (e, attrs); pstr_loc = e.pexp_loc }

let mkexp_constraint ~loc e (t1, t2) =
  match t1, t2 with
  | Some t, None -> mkexp ~loc (Pexp_constraint(e, t))
  | _, Some t -> mkexp ~loc (Pexp_coerce(e, t1, t))
  | None, None -> assert false

let mkexp_opt_constraint ~loc e = function
  | None -> e
  | Some constraint_ -> mkexp_constraint ~loc e constraint_

let mkpat_opt_constraint ~loc p = function
  | None -> p
  | Some typ -> mkpat ~loc (Ppat_constraint(p, typ))

let syntax_error () =
  raise Syntaxerr.Escape_error

let unclosed opening_name opening_loc closing_name closing_loc =
  raise(Syntaxerr.Error(Syntaxerr.Unclosed(make_loc opening_loc, opening_name,
                                           make_loc closing_loc, closing_name)))

let expecting loc nonterm =
    raise Syntaxerr.(Error(Expecting(make_loc loc, nonterm)))

(* Using the function [not_expecting] in a semantic action means that this
   syntactic form is recognized by the parser but is in fact incorrect. This
   idiom is used in a few places to produce ad hoc syntax error messages. *)

(* This idiom should be used as little as possible, because it confuses the
   analyses performed by Menhir. Because Menhir views the semantic action as
   opaque, it believes that this syntactic form is correct. This can lead
   [make generate-parse-errors] to produce sentences that cause an early
   (unexpected) syntax error and do not achieve the desired effect. This could
   also lead a completion system to propose completions which in fact are
   incorrect. In order to avoid these problems, the productions that use
   [not_expecting] should be marked with AVOID. *)

let not_expecting loc nonterm =
    raise Syntaxerr.(Error(Not_expecting(make_loc loc, nonterm)))

(* Helper functions for desugaring array indexing operators *)
type paren_kind = Paren | Brace | Bracket

(* We classify the dimension of indices: Bigarray distinguishes
   indices of dimension 1,2,3, or more. Similarly, user-defined
   indexing operator behave differently for indices of dimension 1
   or more.
*)
type index_dim =
  | One
  | Two
  | Three
  | Many
type ('dot,'index) array_family = {

  name:
    Lexing.position * Lexing.position -> 'dot -> assign:bool -> paren_kind
  -> index_dim -> Longident.t Location.loc
  (*
    This functions computes the name of the explicit indexing operator
    associated with a sugared array indexing expression.

    For instance, for builtin arrays, if Clflags.unsafe is set,
    * [ a.[index] ]     =>  [String.unsafe_get]
    * [ a.{x,y} <- 1 ]  =>  [ Bigarray.Array2.unsafe_set]

    User-defined indexing operator follows a more local convention:
    * [ a .%(index)]     => [ (.%()) ]
    * [ a.![1;2] <- 0 ]  => [(.![;..]<-)]
    * [ a.My.Map.?(0) => [My.Map.(.?())]
  *);

  index:
    Lexing.position * Lexing.position -> paren_kind -> 'index
    -> index_dim * (arg_label * expression) list
   (*
     [index (start,stop) paren index] computes the dimension of the
     index argument and how it should be desugared when transformed
     to a list of arguments for the indexing operator.
     In particular, in both the Bigarray case and the user-defined case,
     beyond a certain dimension, multiple indices are packed into a single
     array argument:
     * [ a.(x) ]       => [ [One, [Nolabel, <<x>>] ]
     * [ a.{1,2} ]     => [ [Two, [Nolabel, <<1>>; Nolabel, <<2>>] ]
     * [ a.{1,2,3,4} ] => [ [Many, [Nolabel, <<[|1;2;3;4|]>>] ] ]
   *);

}

let bigarray_untuplify = function
    { pexp_desc = Pexp_tuple explist; pexp_loc = _ } -> explist
  | exp -> [exp]

let builtin_arraylike_name loc _ ~assign paren_kind n =
  let opname = if assign then ""set"" else ""get"" in
  let opname = if !Clflags.unsafe then ""unsafe_"" ^ opname else opname in
  let prefix = match paren_kind with
    | Paren -> Lident ""Array""
    | Bracket -> Lident ""String""
    | Brace ->
       let submodule_name = match n with
         | One -> ""Array1""
         | Two -> ""Array2""
         | Three -> ""Array3""
         | Many -> ""Genarray"" in
       Ldot(Lident ""Bigarray"", submodule_name) in
   ghloc ~loc (Ldot(prefix,opname))

let builtin_arraylike_index loc paren_kind index = match paren_kind with
    | Paren | Bracket -> One, [Nolabel, index]
    | Brace ->
       (* Multi-indices for bigarray are comma-separated ([a.{1,2,3,4}]) *)
       match bigarray_untuplify index with
     | [x] -> One, [Nolabel, x]
     | [x;y] -> Two, [Nolabel, x; Nolabel, y]
     | [x;y;z] -> Three, [Nolabel, x; Nolabel, y; Nolabel, z]
     | coords -> Many, [Nolabel, ghexp ~loc (Pexp_array coords)]

let builtin_indexing_operators : (unit, expression) array_family  =
  { index = builtin_arraylike_index; name = builtin_arraylike_name }

let paren_to_strings = function
  | Paren -> ""("", "")""
  | Bracket -> ""["", ""]""
  | Brace -> ""{"", ""}""

let user_indexing_operator_name loc (prefix,ext) ~assign paren_kind n =
  let name =
    let assign = if assign then ""<-"" else """" in
    let mid = match n with
        | Many | Three | Two  -> "";..""
        | One -> """" in
    let left, right = paren_to_strings paren_kind in
    String.concat """" ["".""; ext; left; mid; right; assign] in
  let lid = match prefix with
    | None -> Lident name
    | Some p -> Ldot(p,name) in
  ghloc ~loc lid

let user_index loc _ index =
  (* Multi-indices for user-defined operators are semicolon-separated
     ([a.%[1;2;3;4]]) *)
  match index with
    | [a] -> One, [Nolabel, a]
    | l -> Many, [Nolabel, mkexp ~loc (Pexp_array l)]

let user_indexing_operators:
      (Longident.t option * string, expression list) array_family
  = { index = user_index; name = user_indexing_operator_name }

let mk_indexop_expr array_indexing_operator ~loc
      (array,dot,paren,index,set_expr) =
  let assign = match set_expr with None -> false | Some _ -> true in
  let n, index = array_indexing_operator.index loc paren index in
  let fn = array_indexing_operator.name loc dot ~assign paren n in
  let set_arg = match set_expr with
    | None -> []
    | Some expr -> [Nolabel, expr] in
  let args = (Nolabel,array) :: index @ set_arg in
  mkexp ~loc (Pexp_apply(ghexp ~loc (Pexp_ident fn), args))

let indexop_unclosed_error loc_s s loc_e =
  let left, right = paren_to_strings s in
  unclosed left loc_s right loc_e

let lapply ~loc p1 p2 =
  if !Clflags.applicative_functors
  then Lapply(p1, p2)
  else raise (Syntaxerr.Error(
                  Syntaxerr.Applicative_path (make_loc loc)))

(* [loc_map] could be [Location.map]. *)
let loc_map (f : 'a -> 'b) (x : 'a Location.loc) : 'b Location.loc =
  { x with txt = f x.txt }

let make_ghost x = { x with loc = { x.loc with loc_ghost = true }}

let loc_last (id : Longident.t Location.loc) : string Location.loc =
  loc_map Longident.last id

let loc_lident (id : string Location.loc) : Longident.t Location.loc =
  loc_map (fun x -> Lident x) id

let exp_of_longident lid =
  let lid = loc_map (fun id -> Lident (Longident.last id)) lid in
  Exp.mk ~loc:lid.loc (Pexp_ident lid)

let exp_of_label lbl =
  Exp.mk ~loc:lbl.loc (Pexp_ident (loc_lident lbl))

let pat_of_label lbl =
  Pat.mk ~loc:lbl.loc  (Ppat_var (loc_last lbl))

let mk_newtypes ~loc newtypes exp =
  let mkexp = mkexp ~loc in
  List.fold_right (fun newtype exp -> mkexp (Pexp_newtype (newtype, exp)))
    newtypes exp

let wrap_type_annotation ~loc newtypes core_type body =
  let mkexp, ghtyp = mkexp ~loc, ghtyp ~loc in
  let mk_newtypes = mk_newtypes ~loc in
  let exp = mkexp(Pexp_constraint(body,core_type)) in
  let exp = mk_newtypes newtypes exp in
  (exp, ghtyp(Ptyp_poly(newtypes, Typ.varify_constructors newtypes core_type)))

let wrap_exp_attrs ~loc body (ext, attrs) =
  let ghexp = ghexp ~loc in
  (* todo: keep exact location for the entire attribute *)
  let body = {body with pexp_attributes = attrs @ body.pexp_attributes} in
  match ext with
  | None -> body
  | Some id -> ghexp(Pexp_extension (id, PStr [mkstrexp body []]))

let mkexp_attrs ~loc d attrs =
  wrap_exp_attrs ~loc (mkexp ~loc d) attrs

let wrap_typ_attrs ~loc typ (ext, attrs) =
  (* todo: keep exact location for the entire attribute *)
  let typ = {typ with ptyp_attributes = attrs @ typ.ptyp_attributes} in
  match ext with
  | None -> typ
  | Some id -> ghtyp ~loc (Ptyp_extension (id, PTyp typ))

let wrap_pat_attrs ~loc pat (ext, attrs) =
  (* todo: keep exact location for the entire attribute *)
  let pat = {pat with ppat_attributes = attrs @ pat.ppat_attributes} in
  match ext with
  | None -> pat
  | Some id -> ghpat ~loc (Ppat_extension (id, PPat (pat, None)))

let mkpat_attrs ~loc d attrs =
  wrap_pat_attrs ~loc (mkpat ~loc d) attrs

let wrap_class_attrs ~loc:_ body attrs =
  {body with pcl_attributes = attrs @ body.pcl_attributes}
let wrap_mod_attrs ~loc:_ attrs body =
  {body with pmod_attributes = attrs @ body.pmod_attributes}
let wrap_mty_attrs ~loc:_ attrs body =
  {body with pmty_attributes = attrs @ body.pmty_attributes}

let wrap_str_ext ~loc body ext =
  match ext with
  | None -> body
  | Some id -> ghstr ~loc (Pstr_extension ((id, PStr [body]), []))

let wrap_mkstr_ext ~loc (item, ext) =
  wrap_str_ext ~loc (mkstr ~loc item) ext

let wrap_sig_ext ~loc body ext =
  match ext with
  | None -> body
  | Some id -> ghsig ~loc (Psig_extension ((id, PSig [body]), []))

let wrap_mksig_ext ~loc (item, ext) =
  wrap_sig_ext ~loc (mksig ~loc item) ext

let mk_quotedext ~loc (id, idloc, str, strloc, delim) =
  let exp_id = mkloc id idloc in
  let e = ghexp ~loc (Pexp_constant (Pconst_string (str, strloc, delim))) in
  (exp_id, PStr [mkstrexp e []])

let text_str pos = Str.text (rhs_text pos)
let text_sig pos = Sig.text (rhs_text pos)
let text_cstr pos = Cf.text (rhs_text pos)
let text_csig pos = Ctf.text (rhs_text pos)
let text_def pos =
  List.map (fun def -> Ptop_def [def]) (Str.text (rhs_text pos))

let extra_text startpos endpos text items =
  match items with
  | [] ->
      let post = rhs_post_text endpos in
      let post_extras = rhs_post_extra_text endpos in
      text post @ text post_extras
  | _ :: _ ->
      let pre_extras = rhs_pre_extra_text startpos in
      let post_extras = rhs_post_extra_text endpos in
        text pre_extras @ items @ text post_extras

let extra_str p1 p2 items = extra_text p1 p2 Str.text items
let extra_sig p1 p2 items = extra_text p1 p2 Sig.text items
let extra_cstr p1 p2 items = extra_text p1 p2 Cf.text items
let extra_csig p1 p2 items = extra_text p1 p2 Ctf.text  items
let extra_def p1 p2 items =
  extra_text p1 p2
    (fun txt -> List.map (fun def -> Ptop_def [def]) (Str.text txt))
    items

let extra_rhs_core_type ct ~pos =
  let docs = rhs_info pos in
  { ct with ptyp_attributes = add_info_attrs docs ct.ptyp_attributes }

type let_binding =
  { lb_pattern: pattern;
    lb_expression: expression;
    lb_is_pun: bool;
    lb_attributes: attributes;
    lb_docs: docs Lazy.t;
    lb_text: text Lazy.t;
    lb_loc: Location.t; }

type let_bindings =
  { lbs_bindings: let_binding list;
    lbs_rec: rec_flag;
    lbs_extension: string Asttypes.loc option }

let mklb first ~loc (p, e, is_pun) attrs =
  {
    lb_pattern = p;
    lb_expression = e;
    lb_is_pun = is_pun;
    lb_attributes = attrs;
    lb_docs = symbol_docs_lazy loc;
    lb_text = (if first then empty_text_lazy
               else symbol_text_lazy (fst loc));
    lb_loc = make_loc loc;
  }

let addlb lbs lb =
  if lb.lb_is_pun && lbs.lbs_extension = None then syntax_error ();
  { lbs with lbs_bindings = lb :: lbs.lbs_bindings }

let mklbs ext rf lb =
  let lbs = {
    lbs_bindings = [];
    lbs_rec = rf;
    lbs_extension = ext;
  } in
  addlb lbs lb

let val_of_let_bindings ~loc lbs =
  let bindings =
    List.map
      (fun lb ->
         Vb.mk ~loc:lb.lb_loc ~attrs:lb.lb_attributes
           ~docs:(Lazy.force lb.lb_docs)
           ~text:(Lazy.force lb.lb_text)
           lb.lb_pattern lb.lb_expression)
      lbs.lbs_bindings
  in
  let str = mkstr ~loc (Pstr_value(lbs.lbs_rec, List.rev bindings)) in
  match lbs.lbs_extension with
  | None -> str
  | Some id -> ghstr ~loc (Pstr_extension((id, PStr [str]), []))

let expr_of_let_bindings ~loc lbs body =
  let bindings =
    List.map
      (fun lb ->
         Vb.mk ~loc:lb.lb_loc ~attrs:lb.lb_attributes
           lb.lb_pattern lb.lb_expression)
      lbs.lbs_bindings
  in
    mkexp_attrs ~loc (Pexp_let(lbs.lbs_rec, List.rev bindings, body))
      (lbs.lbs_extension, [])

let class_of_let_bindings ~loc lbs body =
  let bindings =
    List.map
      (fun lb ->
         Vb.mk ~loc:lb.lb_loc ~attrs:lb.lb_attributes
           lb.lb_pattern lb.lb_expression)
      lbs.lbs_bindings
  in
    (* Our use of let_bindings(no_ext) guarantees the following: *)
    assert (lbs.lbs_extension = None);
    mkclass ~loc (Pcl_let (lbs.lbs_rec, List.rev bindings, body))

(* Alternatively, we could keep the generic module type in the Parsetree
   and extract the package type during type-checking. In that case,
   the assertions below should be turned into explicit checks. *)
let package_type_of_module_type pmty =
  let err loc s =
    raise (Syntaxerr.Error (Syntaxerr.Invalid_package_type (loc, s)))
  in
  let map_cstr = function
    | Pwith_type (lid, ptyp) ->
        let loc = ptyp.ptype_loc in
        if ptyp.ptype_params <> [] then
          err loc ""parametrized types are not supported"";
        if ptyp.ptype_cstrs <> [] then
          err loc ""constrained types are not supported"";
        if ptyp.ptype_private <> Public then
          err loc ""private types are not supported"";

        (* restrictions below are checked by the 'with_constraint' rule *)
        assert (ptyp.ptype_kind = Ptype_abstract);
        assert (ptyp.ptype_attributes = []);
        let ty =
          match ptyp.ptype_manifest with
          | Some ty -> ty
          | None -> assert false
        in
        (lid, ty)
    | _ ->
        err pmty.pmty_loc ""only 'with type t =' constraints are supported""
  in
  match pmty with
  | {pmty_desc = Pmty_ident lid} -> (lid, [], pmty.pmty_attributes)
  | {pmty_desc = Pmty_with({pmty_desc = Pmty_ident lid}, cstrs)} ->
      (lid, List.map map_cstr cstrs, pmty.pmty_attributes)
  | _ ->
      err pmty.pmty_loc
        ""only module type identifier and 'with type' constraints are supported""

let mk_directive_arg ~loc k =
  { pdira_desc = k;
    pdira_loc = make_loc loc;
  }

let mk_directive ~loc name arg =
  Ptop_dir {
      pdir_name = name;
      pdir_arg = arg;
      pdir_loc = make_loc loc;
    }

%}

/* Tokens */

/* The alias that follows each token is used by Menhir when it needs to
   produce a sentence (that is, a sequence of tokens) in concrete syntax. */

/* Some tokens represent multiple concrete strings. In most cases, an
   arbitrary concrete string can be chosen. In a few cases, one must
   be careful: e.g., in PREFIXOP and INFIXOP2, one must choose a concrete
   string that will not trigger a syntax error; see how [not_expecting]
   is used in the definition of [type_variance]. */

%token AMPERAMPER             ""&&""
%token AMPERSAND              ""&""
%token AND                    ""and""
%token AS                     ""as""
%token ASSERT                 ""assert""
%token BACKQUOTE              ""`""
%token BANG                   ""!""
%token BAR                    ""|""
%token BARBAR                 ""||""
%token BARRBRACKET            ""|]""
%token BEGIN                  ""begin""
%token <char> CHAR            ""'a'"" (* just an example *)
%token CLASS                  ""class""
%token COLON                  "":""
%token COLONCOLON             ""::""
%token COLONEQUAL             "":=""
%token COLONGREATER           "":>""
%token COMMA                  "",""
%token CONSTRAINT             ""constraint""
%token DO                     ""do""
%token DONE                   ""done""
%token DOT                    "".""
%token DOTDOT                 ""..""
%token DOWNTO                 ""downto""
%token ELSE                   ""else""
%token END                    ""end""
%token EOF                    """"
%token EQUAL                  ""=""
%token EXCEPTION              ""exception""
%token EXTERNAL               ""external""
%token FALSE                  ""false""
%token <string * char option> FLOAT ""42.0"" (* just an example *)
%token FOR                    ""for""
%token FUN                    ""fun""
%token FUNCTION               ""function""
%token FUNCTOR                ""functor""
%token GREATER                "">""
%token GREATERRBRACE          "">}""
%token GREATERRBRACKET        "">]""
%token IF                     ""if""
%token IN                     ""in""
%token INCLUDE                ""include""
%token <string> INFIXOP0      ""!=""   (* just an example *)
%token <string> INFIXOP1      ""@""    (* just an example *)
%token <string> INFIXOP2      ""+!""   (* chosen with care; see above *)
%token <string> INFIXOP3      ""land"" (* just an example *)
%token <string> INFIXOP4      ""**""   (* just an example *)
%token <string> DOTOP         "".+""
%token <string> LETOP         ""let*"" (* just an example *)
%token <string> ANDOP         ""and*"" (* just an example *)
%token INHERIT                ""inherit""
%token INITIALIZER            ""initializer""
%token <string * char option> INT ""42""  (* just an example *)
%token <string> LABEL         ""~label:"" (* just an example *)
%token LAZY                   ""lazy""
%token LBRACE                 ""{""
%token LBRACELESS             ""{<""
%token LBRACKET               ""[""
%token LBRACKETBAR            ""[|""
%token LBRACKETLESS           ""[<""
%token LBRACKETGREATER        ""[>""
%token LBRACKETPERCENT        ""[%""
%token LBRACKETPERCENTPERCENT ""[%%""
%token LESS                   ""<""
%token LESSMINUS              ""<-""
%token LET                    ""let""
%token <string> LIDENT        ""lident"" (* just an example *)
%token LPAREN                 ""(""
%token LBRACKETAT             ""[@""
%token LBRACKETATAT           ""[@@""
%token LBRACKETATATAT         ""[@@@""
%token MATCH                  ""match""
%token METHOD                 ""method""
%token MINUS                  ""-""
%token MINUSDOT               ""-.""
%token MINUSGREATER           ""->""
%token MODULE                 ""module""
%token MUTABLE                ""mutable""
%token NEW                    ""new""
%token NONREC                 ""nonrec""
%token OBJECT                 ""object""
%token OF                     ""of""
%token OPEN                   ""open""
%token <string> OPTLABEL      ""?label:"" (* just an example *)
%token OR                     ""or""
/* %token PARSER              ""parser"" */
%token PERCENT                ""%""
%token PLUS                   ""+""
%token PLUSDOT                ""+.""
%token PLUSEQ                 ""+=""
%token <string> PREFIXOP      ""!+"" (* chosen with care; see above *)
%token PRIVATE                ""private""
%token QUESTION               ""?""
%token QUOTE                  ""'""
%token RBRACE                 ""}""
%token RBRACKET               ""]""
%token REC                    ""rec""
%token RPAREN                 "")""
%token SEMI                   "";""
%token SEMISEMI               "";;""
%token HASH                   ""#""
%token <string> HASHOP        ""##"" (* just an example *)
%token SIG                    ""sig""
%token STAR                   ""*""
%token <string * Location.t * string option>
       STRING                 ""\""hello\"""" (* just an example *)
%token <string * Location.t * string * Location.t * string option>
       QUOTED_STRING_EXPR     ""{%hello|world|}""  (* just an example *)
%token <string * Location.t * string * Location.t * string option>
       QUOTED_STRING_ITEM     ""{%%hello|world|}"" (* just an example *)
%token STRUCT                 ""struct""
%token THEN                   ""then""
%token TILDE                  ""~""
%token TO                     ""to""
%token TRUE                   ""true""
%token TRY                    ""try""
%token TYPE                   ""type""
%token <string> UIDENT        ""UIdent"" (* just an example *)
%token UNDERSCORE             ""_""
%token VAL                    ""val""
%token VIRTUAL                ""virtual""
%token WHEN                   ""when""
%token WHILE                  ""while""
%token WITH                   ""with""
%token <string * Location.t> COMMENT    ""(* comment *)""
%token <Docstrings.docstring> DOCSTRING ""(** documentation *)""

%token EOL                    ""\\n""      (* not great, but EOL is unused *)

/* Precedences and associativities.

Tokens and rules have precedences.  A reduce/reduce conflict is resolved
in favor of the first rule (in source file order).  A shift/reduce conflict
is resolved by comparing the precedence and associativity of the token to
be shifted with those of the rule to be reduced.

By default, a rule has the precedence of its rightmost terminal (if any).

When there is a shift/reduce conflict between a rule and a token that
have the same precedence, it is resolved using the associativity:
if the token is left-associative, the parser will reduce; if
right-associative, the parser will shift; if non-associative,
the parser will declare a syntax error.

We will only use associativities with operators of the kind  x * x -> x
for example, in the rules of the form    expr: expr BINOP expr
in all other cases, we define two precedences if needed to resolve
conflicts.

The precedences must be listed from low to high.
*/

%nonassoc IN
%nonassoc below_SEMI
%nonassoc SEMI                          /* below EQUAL ({lbl=...; lbl=...}) */
%nonassoc LET                           /* above SEMI ( ...; let ... in ...) */
%nonassoc below_WITH
%nonassoc FUNCTION WITH                 /* below BAR  (match ... with ...) */
%nonassoc AND             /* above WITH (module rec A: SIG with ... and ...) */
%nonassoc THEN                          /* below ELSE (if ... then ...) */
%nonassoc ELSE                          /* (if ... then ... else ...) */
%nonassoc LESSMINUS                     /* below COLONEQUAL (lbl <- x := e) */
%right    COLONEQUAL                    /* expr (e := e := e) */
%nonassoc AS
%left     BAR                           /* pattern (p|p|p) */
%nonassoc below_COMMA
%left     COMMA                         /* expr/expr_comma_list (e,e,e) */
%right    MINUSGREATER                  /* function_type (t -> t -> t) */
%right    OR BARBAR                     /* expr (e || e || e) */
%right    AMPERSAND AMPERAMPER          /* expr (e && e && e) */
%nonassoc below_EQUAL
%left     INFIXOP0 EQUAL LESS GREATER   /* expr (e OP e OP e) */
%right    INFIXOP1                      /* expr (e OP e OP e) */
%nonassoc below_LBRACKETAT
%nonassoc LBRACKETAT
%right    COLONCOLON                    /* expr (e :: e :: e) */
%left     INFIXOP2 PLUS PLUSDOT MINUS MINUSDOT PLUSEQ /* expr (e OP e OP e) */
%left     PERCENT INFIXOP3 STAR                 /* expr (e OP e OP e) */
%right    INFIXOP4                      /* expr (e OP e OP e) */
%nonassoc prec_unary_minus prec_unary_plus /* unary - */
%nonassoc prec_constant_constructor     /* cf. simple_expr (C versus C x) */
%nonassoc prec_constr_appl              /* above AS BAR COLONCOLON COMMA */
%nonassoc below_HASH
%nonassoc HASH                         /* simple_expr/toplevel_directive */
%left     HASHOP
%nonassoc below_DOT
%nonassoc DOT DOTOP
/* Finally, the first tokens of simple_expr are above everything else. */
%nonassoc BACKQUOTE BANG BEGIN CHAR FALSE FLOAT INT OBJECT
          LBRACE LBRACELESS LBRACKET LBRACKETBAR LIDENT LPAREN
          NEW PREFIXOP STRING TRUE UIDENT
          LBRACKETPERCENT QUOTED_STRING_EXPR


/* Entry points */

/* Several start symbols are marked with AVOID so that they are not used by
   [make generate-parse-errors]. The three start symbols that we keep are
   [implementation], [use_file], and [toplevel_phrase]. The latter two are
   of marginal importance; only [implementation] really matters, since most
   states in the automaton are reachable from it. */

%start implementation                   /* for implementation files */
%type <Parsetree.structure> implementation
/* BEGIN AVOID */
%start interface                        /* for interface files */
%type <Parsetree.signature> interface
/* END AVOID */
%start toplevel_phrase                  /* for interactive use */
%type <Parsetree.toplevel_phrase> toplevel_phrase
%start use_file                         /* for the #use directive */
%type <Parsetree.toplevel_phrase list> use_file
/* BEGIN AVOID */
%start parse_module_type
%type <Parsetree.module_type> parse_module_type
%start parse_module_expr
%type <Parsetree.module_expr> parse_module_expr
%start parse_core_type
%type <Parsetree.core_type> parse_core_type
%start parse_expression
%type <Parsetree.expression> parse_expression
%start parse_pattern
%type <Parsetree.pattern> parse_pattern
%start parse_constr_longident
%type <Longident.t> parse_constr_longident
%start parse_val_longident
%type <Longident.t> parse_val_longident
%start parse_mty_longident
%type <Longident.t> parse_mty_longident
%start parse_mod_ext_longident
%type <Longident.t> parse_mod_ext_longident
%start parse_mod_longident
%type <Longident.t> parse_mod_longident
%start parse_any_longident
%type <Longident.t> parse_any_longident
/* END AVOID */

%%

/* macros */
%inline extra_str(symb): symb { extra_str $startpos $endpos $1 };
%inline extra_sig(symb): symb { extra_sig $startpos $endpos $1 };
%inline extra_cstr(symb): symb { extra_cstr $startpos $endpos $1 };
%inline extra_csig(symb): symb { extra_csig $startpos $endpos $1 };
%inline extra_def(symb): symb { extra_def $startpos $endpos $1 };
%inline extra_text(symb): symb { extra_text $startpos $endpos $1 };
%inline extra_rhs(symb): symb { extra_rhs_core_type $1 ~pos:$endpos($1) };
%inline mkrhs(symb): symb
    { mkrhs $1 $sloc }
;

%inline text_str(symb): symb
  { text_str $startpos @ [$1] }
%inline text_str_SEMISEMI: SEMISEMI
  { text_str $startpos }
%inline text_sig(symb): symb
  { text_sig $startpos @ [$1] }
%inline text_sig_SEMISEMI: SEMISEMI
  { text_sig $startpos }
%inline text_def(symb): symb
  { text_def $startpos @ [$1] }
%inline top_def(symb): symb
  { Ptop_def [$1] }
%inline text_cstr(symb): symb
  { text_cstr $startpos @ [$1] }
%inline text_csig(symb): symb
  { text_csig $startpos @ [$1] }

(* Using this %inline definition means that we do not control precisely
   when [mark_rhs_docs] is called, but I don't think this matters. *)
%inline mark_rhs_docs(symb): symb
  { mark_rhs_docs $startpos $endpos;
    $1 }

%inline op(symb): symb
   { mkoperator ~loc:$sloc $1 }

%inline mkloc(symb): symb
    { mkloc $1 (make_loc $sloc) }

%inline mkexp(symb): symb
    { mkexp ~loc:$sloc $1 }
%inline mkpat(symb): symb
    { mkpat ~loc:$sloc $1 }
%inline mktyp(symb): symb
    { mktyp ~loc:$sloc $1 }
%inline mkstr(symb): symb
    { mkstr ~loc:$sloc $1 }
%inline mksig(symb): symb
    { mksig ~loc:$sloc $1 }
%inline mkmod(symb): symb
    { mkmod ~loc:$sloc $1 }
%inline mkmty(symb): symb
    { mkmty ~loc:$sloc $1 }
%inline mkcty(symb): symb
    { mkcty ~loc:$sloc $1 }
%inline mkctf(symb): symb
    { mkctf ~loc:$sloc $1 }
%inline mkcf(symb): symb
    { mkcf ~loc:$sloc $1 }
%inline mkclass(symb): symb
    { mkclass ~loc:$sloc $1 }

%inline wrap_mkstr_ext(symb): symb
    { wrap_mkstr_ext ~loc:$sloc $1 }
%inline wrap_mksig_ext(symb): symb
    { wrap_mksig_ext ~loc:$sloc $1 }

%inline mk_directive_arg(symb): symb
    { mk_directive_arg ~loc:$sloc $1 }

/* Generic definitions */

(* [iloption(X)] recognizes either nothing or [X]. Assuming [X] produces
   an OCaml list, it produces an OCaml list, too. *)

%inline iloption(X):
  /* nothing */
    { [] }
| x = X
    { x }

(* [llist(X)] recognizes a possibly empty list of [X]s. It is left-recursive. *)

reversed_llist(X):
  /* empty */
    { [] }
| xs = reversed_llist(X) x = X
    { x :: xs }

%inline llist(X):
  xs = rev(reversed_llist(X))
    { xs }

(* [reversed_nonempty_llist(X)] recognizes a nonempty list of [X]s, and produces
   an OCaml list in reverse order -- that is, the last element in the input text
   appears first in this list. Its definition is left-recursive. *)

reversed_nonempty_llist(X):
  x = X
    { [ x ] }
| xs = reversed_nonempty_llist(X) x = X
    { x :: xs }

(* [nonempty_llist(X)] recognizes a nonempty list of [X]s, and produces an OCaml
   list in direct order -- that is, the first element in the input text appears
   first in this list. *)

%inline nonempty_llist(X):
  xs = rev(reversed_nonempty_llist(X))
    { xs }

(* [reversed_separated_nonempty_llist(separator, X)] recognizes a nonempty list
   of [X]s, separated with [separator]s, and produces an OCaml list in reverse
   order -- that is, the last element in the input text appears first in this
   list. Its definition is left-recursive. *)

(* [inline_reversed_separated_nonempty_llist(separator, X)] is semantically
   equivalent to [reversed_separated_nonempty_llist(separator, X)], but is
   marked %inline, which means that the case of a list of length one and
   the case of a list of length more than one will be distinguished at the
   use site, and will give rise there to two productions. This can be used
   to avoid certain conflicts. *)

%inline inline_reversed_separated_nonempty_llist(separator, X):
  x = X
    { [ x ] }
| xs = reversed_separated_nonempty_llist(separator, X)
  separator
  x = X
    { x :: xs }

reversed_separated_nonempty_llist(separator, X):
  xs = inline_reversed_separated_nonempty_llist(separator, X)
    { xs }

(* [separated_nonempty_llist(separator, X)] recognizes a nonempty list of [X]s,
   separated with [separator]s, and produces an OCaml list in direct order --
   that is, the first element in the input text appears first in this list. *)

%inline separated_nonempty_llist(separator, X):
  xs = rev(reversed_separated_nonempty_llist(separator, X))
    { xs }

%inline inline_separated_nonempty_llist(separator, X):
  xs = rev(inline_reversed_separated_nonempty_llist(separator, X))
    { xs }

(* [reversed_separated_nontrivial_llist(separator, X)] recognizes a list of at
   least two [X]s, separated with [separator]s, and produces an OCaml list in
   reverse order -- that is, the last element in the input text appears first
   in this list. Its definition is left-recursive. *)

reversed_separated_nontrivial_llist(separator, X):
  xs = reversed_separated_nontrivial_llist(separator, X)
  separator
  x = X
    { x :: xs }
| x1 = X
  separator
  x2 = X
    { [ x2; x1 ] }

(* [separated_nontrivial_llist(separator, X)] recognizes a list of at least
   two [X]s, separated with [separator]s, and produces an OCaml list in direct
   order -- that is, the first element in the input text appears first in this
   list. *)

%inline separated_nontrivial_llist(separator, X):
  xs = rev(reversed_separated_nontrivial_llist(separator, X))
    { xs }

(* [separated_or_terminated_nonempty_list(delimiter, X)] recognizes a nonempty
   list of [X]s, separated with [delimiter]s, and optionally terminated with a
   final [delimiter]. Its definition is right-recursive. *)

separated_or_terminated_nonempty_list(delimiter, X):
  x = X ioption(delimiter)
    { [x] }
| x = X
  delimiter
  xs = separated_or_terminated_nonempty_list(delimiter, X)
    { x :: xs }

(* [reversed_preceded_or_separated_nonempty_llist(delimiter, X)] recognizes a
   nonempty list of [X]s, separated with [delimiter]s, and optionally preceded
   with a leading [delimiter]. It produces an OCaml list in reverse order. Its
   definition is left-recursive. *)

reversed_preceded_or_separated_nonempty_llist(delimiter, X):
  ioption(delimiter) x = X
    { [x] }
| xs = reversed_preceded_or_separated_nonempty_llist(delimiter, X)
  delimiter
  x = X
    { x :: xs }

(* [preceded_or_separated_nonempty_llist(delimiter, X)] recognizes a nonempty
   list of [X]s, separated with [delimiter]s, and optionally preceded with a
   leading [delimiter]. It produces an OCaml list in direct order. *)

%inline preceded_or_separated_nonempty_llist(delimiter, X):
  xs = rev(reversed_preceded_or_separated_nonempty_llist(delimiter, X))
    { xs }

(* [bar_llist(X)] recognizes a nonempty list of [X]'s, separated with BARs,
   with an optional leading BAR. We assume that [X] is itself parameterized
   with an opening symbol, which can be [epsilon] or [BAR]. *)

(* This construction may seem needlessly complicated: one might think that
   using [preceded_or_separated_nonempty_llist(BAR, X)], where [X] is *not*
   itself parameterized, would be sufficient. Indeed, this simpler approach
   would recognize the same language. However, the two approaches differ in
   the footprint of [X]. We want the start location of [X] to include [BAR]
   when present. In the future, we might consider switching to the simpler
   definition, at the cost of producing slightly different locations. TODO *)

reversed_bar_llist(X):
    (* An [X] without a leading BAR. *)
    x = X(epsilon)
      { [x] }
  | (* An [X] with a leading BAR. *)
    x = X(BAR)
      { [x] }
  | (* An initial list, followed with a BAR and an [X]. *)
    xs = reversed_bar_llist(X)
    x = X(BAR)
      { x :: xs }

%inline bar_llist(X):
  xs = reversed_bar_llist(X)
    { List.rev xs }

(* [xlist(A, B)] recognizes [AB*]. We assume that the semantic value for [A]
   is a pair [x, b], while the semantic value for [B*] is a list [bs].
   We return the pair [x, b :: bs]. *)

%inline xlist(A, B):
  a = A bs = B*
    { let (x, b) = a in x, b :: bs }

(* [listx(delimiter, X, Y)] recognizes a nonempty list of [X]s, optionally
   followed with a [Y], separated-or-terminated with [delimiter]s. The
   semantic value is a pair of a list of [X]s and an optional [Y]. *)

listx(delimiter, X, Y):
| x = X ioption(delimiter)
    { [x], None }
| x = X delimiter y = Y delimiter?
    { [x], Some y }
| x = X
  delimiter
  tail = listx(delimiter, X, Y)
    { let xs, y = tail in
      x :: xs, y }

(* -------------------------------------------------------------------------- *)

(* Entry points. *)

(* An .ml file. *)
implementation:
  structure EOF
    { $1 }
;

/* BEGIN AVOID */
(* An .mli file. *)
interface:
  signature EOF
    { $1 }
;
/* END AVOID */

(* A toplevel phrase. *)
toplevel_phrase:
  (* An expression with attributes, ended by a double semicolon. *)
  extra_str(text_str(str_exp))
  SEMISEMI
    { Ptop_def $1 }
| (* A list of structure items, ended by a double semicolon. *)
  extra_str(flatten(text_str(structure_item)*))
  SEMISEMI
    { Ptop_def $1 }
| (* A directive, ended by a double semicolon. *)
  toplevel_directive
  SEMISEMI
    { $1 }
| (* End of input. *)
  EOF
    { raise End_of_file }
;

(* An .ml file that is read by #use. *)
use_file:
  (* An optional standalone expression,
     followed with a series of elements,
     followed with EOF. *)
  extra_def(append(
    optional_use_file_standalone_expression,
    flatten(use_file_element*)
  ))
  EOF
    { $1 }
;

(* An optional standalone expression is just an expression with attributes
   (str_exp), with extra wrapping. *)
%inline optional_use_file_standalone_expression:
  iloption(text_def(top_def(str_exp)))
    { $1 }
;

(* An element in a #used file is one of the following:
   - a double semicolon followed with an optional standalone expression;
   - a structure item;
   - a toplevel directive.
 *)
%inline use_file_element:
  preceded(SEMISEMI, optional_use_file_standalone_expression)
| text_def(top_def(structure_item))
| text_def(mark_rhs_docs(toplevel_directive))
      { $1 }
;

/* BEGIN AVOID */
parse_module_type:
  module_type EOF
    { $1 }
;

parse_module_expr:
  module_expr EOF
    { $1 }
;

parse_core_type:
  core_type EOF
    { $1 }
;

parse_expression:
  seq_expr EOF
    { $1 }
;

parse_pattern:
  pattern EOF
    { $1 }
;

parse_mty_longident:
  mty_longident EOF
    { $1 }
;

parse_val_longident:
  val_longident EOF
    { $1 }
;

parse_constr_longident:
  constr_longident EOF
    { $1 }
;

parse_mod_ext_longident:
  mod_ext_longident EOF
    { $1 }
;

parse_mod_longident:
  mod_longident EOF
    { $1 }
;

parse_any_longident:
  any_longident EOF
    { $1 }
;
/* END AVOID */

(* -------------------------------------------------------------------------- *)

(* Functor arguments appear in module expressions and module types. *)

%inline functor_args:
  reversed_nonempty_llist(functor_arg)
    { $1 }
    (* Produce a reversed list on purpose;
       later processed using [fold_left]. *)
;

functor_arg:
    (* An anonymous and untyped argument. *)
    LPAREN RPAREN
      { $startpos, Unit }
  | (* An argument accompanied with an explicit type. *)
    LPAREN x = mkrhs(module_name) COLON mty = module_type RPAREN
      { $startpos, Named (x, mty) }
;

module_name:
    (* A named argument. *)
    x = UIDENT
      { Some x }
  | (* An anonymous argument. *)
    UNDERSCORE
      { None }
;

(* -------------------------------------------------------------------------- *)

(* Module expressions. *)

(* The syntax of module expressions is not properly stratified. The cases of
   functors, functor applications, and attributes interact and cause conflicts,
   which are resolved by precedence declarations. This is concise but fragile.
   Perhaps in the future an explicit stratification could be used. *)

module_expr:
  | STRUCT attrs = attributes s = structure END
      { mkmod ~loc:$sloc ~attrs (Pmod_structure s) }
  | STRUCT attributes structure error
      { unclosed ""struct"" $loc($1) ""end"" $loc($4) }
  | FUNCTOR attrs = attributes args = functor_args MINUSGREATER me = module_expr
      { wrap_mod_attrs ~loc:$sloc attrs (
          List.fold_left (fun acc (startpos, arg) ->
            mkmod ~loc:(startpos, $endpos) (Pmod_functor (arg, acc))
          ) me args
        ) }
  | me = paren_module_expr
      { me }
  | me = module_expr attr = attribute
      { Mod.attr me attr }
  | mkmod(
      (* A module identifier. *)
      x = mkrhs(mod_longident)
        { Pmod_ident x }
    | (* In a functor application, the actual argument must be parenthesized. *)
      me1 = module_expr me2 = paren_module_expr
        { Pmod_apply(me1, me2) }
    | (* Application to unit is sugar for application to an empty structure. *)
      me1 = module_expr LPAREN RPAREN
        { (* TODO review mkmod location *)
          Pmod_apply(me1, mkmod ~loc:$sloc (Pmod_structure [])) }
    | (* An extension. *)
      ex = extension
        { Pmod_extension ex }
    )
    { $1 }
;

(* A parenthesized module expression is a module expression that begins
   and ends with parentheses. *)

paren_module_expr:
    (* A module expression annotated with a module type. *)
    LPAREN me = module_expr COLON mty = module_type RPAREN
      { mkmod ~loc:$sloc (Pmod_constraint(me, mty)) }
  | LPAREN module_expr COLON module_type error
      { unclosed ""("" $loc($1) "")"" $loc($5) }
  | (* A module expression within parentheses. *)
    LPAREN me = module_expr RPAREN
      { me (* TODO consider reloc *) }
  | LPAREN module_expr error
      { unclosed ""("" $loc($1) "")"" $loc($3) }
  | (* A core language expression that produces a first-class module.
       This expression can be annotated in various ways. *)
    LPAREN VAL attrs = attributes e = expr_colon_package_type RPAREN
      { mkmod ~loc:$sloc ~attrs (Pmod_unpack e) }
  | LPAREN VAL attributes expr COLON error
      { unclosed ""("" $loc($1) "")"" $loc($6) }
  | LPAREN VAL attributes expr COLONGREATER error
      { unclosed ""("" $loc($1) "")"" $loc($6) }
  | LPAREN VAL attributes expr error
      { unclosed ""("" $loc($1) "")"" $loc($5) }
;

(* The various ways of annotating a core language expression that
   produces a first-class module that we wish to unpack. *)
%inline expr_colon_package_type:
    e = expr
      { e }
  | e = expr COLON ty = package_type
      { ghexp ~loc:$loc (Pexp_constraint (e, ty)) }
  | e = expr COLON ty1 = package_type COLONGREATER ty2 = package_type
      { ghexp ~loc:$loc (Pexp_coerce (e, Some ty1, ty2)) }
  | e = expr COLONGREATER ty2 = package_type
      { ghexp ~loc:$loc (Pexp_coerce (e, None, ty2)) }
;

(* A structure, which appears between STRUCT and END (among other places),
   begins with an optional standalone expression, and continues with a list
   of structure elements. *)
structure:
  extra_str(append(
    optional_structure_standalone_expression,
    flatten(structure_element*)
  ))
  { $1 }
;

(* An optional standalone expression is just an expression with attributes
   (str_exp), with extra wrapping. *)
%inline optional_structure_standalone_expression:
  items = iloption(mark_rhs_docs(text_str(str_exp)))
    { items }
;

(* An expression with attributes, wrapped as a structure item. *)
%inline str_exp:
  e = seq_expr
  attrs = post_item_attributes
    { mkstrexp e attrs }
;

(* A structure element is one of the following:
   - a double semicolon followed with an optional standalone expression;
   - a structure item. *)
%inline structure_element:
    append(text_str_SEMISEMI, optional_structure_standalone_expression)
  | text_str(structure_item)
      { $1 }
;

(* A structure item. *)
structure_item:
    let_bindings(ext)
      { val_of_let_bindings ~loc:$sloc $1 }
  | mkstr(
      item_extension post_item_attributes
        { let docs = symbol_docs $sloc in
          Pstr_extension ($1, add_docs_attrs docs $2) }
    | floating_attribute
        { Pstr_attribute $1 }
    )
  | wrap_mkstr_ext(
      primitive_declaration
        { pstr_primitive $1 }
    | value_description
        { pstr_primitive $1 }
    | type_declarations
        { pstr_type $1 }
    | str_type_extension
        { pstr_typext $1 }
    | str_exception_declaration
        { pstr_exception $1 }
    | module_binding
        { $1 }
    | rec_module_bindings
        { pstr_recmodule $1 }
    | module_type_declaration
        { let (body, ext) = $1 in (Pstr_modtype body, ext) }
    | open_declaration
        { let (body, ext) = $1 in (Pstr_open body, ext) }
    | class_declarations
        { let (ext, l) = $1 in (Pstr_class l, ext) }
    | class_type_declarations
        { let (ext, l) = $1 in (Pstr_class_type l, ext) }
    | include_statement(module_expr)
        { pstr_include $1 }
    )
    { $1 }
;

(* A single module binding. *)
%inline module_binding:
  MODULE
  ext = ext attrs1 = attributes
  name = mkrhs(module_name)
  body = module_binding_body
  attrs2 = post_item_attributes
    { let docs = symbol_docs $sloc in
      let loc = make_loc $sloc in
      let attrs = attrs1 @ attrs2 in
      let body = Mb.mk name body ~attrs ~loc ~docs in
      Pstr_module body, ext }
;

(* The body (right-hand side) of a module binding. *)
module_binding_body:
    EQUAL me = module_expr
      { me }
  | mkmod(
      COLON mty = module_type EQUAL me = module_expr
        { Pmod_constraint(me, mty) }
    | arg_and_pos = functor_arg body = module_binding_body
        { let (_, arg) = arg_and_pos in
          Pmod_functor(arg, body) }
  ) { $1 }
;

(* A group of recursive module bindings. *)
%inline rec_module_bindings:
  xlist(rec_module_binding, and_module_binding)
    { $1 }
;

(* The first binding in a group of recursive module bindings. *)
%inline rec_module_binding:
  MODULE
  ext = ext
  attrs1 = attributes
  REC
  name = mkrhs(module_name)
  body = module_binding_body
  attrs2 = post_item_attributes
  {
    let loc = make_loc $sloc in
    let attrs = attrs1 @ attrs2 in
    let docs = symbol_docs $sloc in
    ext,
    Mb.mk name body ~attrs ~loc ~docs
  }
;

(* The following bindings in a group of recursive module bindings. *)
%inline and_module_binding:
  AND
  attrs1 = attributes
  name = mkrhs(module_name)
  body = module_binding_body
  attrs2 = post_item_attributes
  {
    let loc = make_loc $sloc in
    let attrs = attrs1 @ attrs2 in
    let docs = symbol_docs $sloc in
    let text = symbol_text $symbolstartpos in
    Mb.mk name body ~attrs ~loc ~text ~docs
  }
;

(* -------------------------------------------------------------------------- *)

(* Shared material between structures and signatures. *)

(* An [include] statement can appear in a structure or in a signature,
   which is why this definition is parameterized. *)
%inline include_statement(thing):
  INCLUDE
  ext = ext
  attrs1 = attributes
  thing = thing
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Incl.mk thing ~attrs ~loc ~docs, ext
  }
;

(* A module type declaration. *)
module_type_declaration:
  MODULE TYPE
  ext = ext
  attrs1 = attributes
  id = mkrhs(ident)
  typ = preceded(EQUAL, module_type)?
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Mtd.mk id ?typ ~attrs ~loc ~docs, ext
  }
;

(* -------------------------------------------------------------------------- *)

(* Opens. *)

open_declaration:
  OPEN
  override = override_flag
  ext = ext
  attrs1 = attributes
  me = module_expr
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Opn.mk me ~override ~attrs ~loc ~docs, ext
  }
;

open_description:
  OPEN
  override = override_flag
  ext = ext
  attrs1 = attributes
  id = mkrhs(mod_ext_longident)
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Opn.mk id ~override ~attrs ~loc ~docs, ext
  }
;

%inline open_dot_declaration: mkrhs(mod_longident)
  { let loc = make_loc $loc($1) in
    let me = Mod.ident ~loc $1 in
    Opn.mk ~loc me }
;

(* -------------------------------------------------------------------------- *)

/* Module types */

module_type:
  | SIG attrs = attributes s = signature END
      { mkmty ~loc:$sloc ~attrs (Pmty_signature s) }
  | SIG attributes signature error
      { unclosed ""sig"" $loc($1) ""end"" $loc($4) }
  | FUNCTOR attrs = attributes args = functor_args
    MINUSGREATER mty = module_type
      %prec below_WITH
      { wrap_mty_attrs ~loc:$sloc attrs (
          List.fold_left (fun acc (startpos, arg) ->
            mkmty ~loc:(startpos, $endpos) (Pmty_functor (arg, acc))
          ) mty args
        ) }
  | MODULE TYPE OF attributes module_expr %prec below_LBRACKETAT
      { mkmty ~loc:$sloc ~attrs:$4 (Pmty_typeof $5) }
  | LPAREN module_type RPAREN
      { $2 }
  | LPAREN module_type error
      { unclosed ""("" $loc($1) "")"" $loc($3) }
  | module_type attribute
      { Mty.attr $1 $2 }
  | mkmty(
      mkrhs(mty_longident)
        { Pmty_ident $1 }
    | module_type MINUSGREATER module_type
        %prec below_WITH
        { Pmty_functor(Named (mknoloc None, $1), $3) }
    | module_type WITH separated_nonempty_llist(AND, with_constraint)
        { Pmty_with($1, $3) }
/*  | LPAREN MODULE mkrhs(mod_longident) RPAREN
        { Pmty_alias $3 } */
    | extension
        { Pmty_extension $1 }
    )
    { $1 }
;
(* A signature, which appears between SIG and END (among other places),
   is a list of signature elements. *)
signature:
  extra_sig(flatten(signature_element*))
    { $1 }
;

(* A signature element is one of the following:
   - a double semicolon;
   - a signature item. *)
%inline signature_element:
    text_sig_SEMISEMI
  | text_sig(signature_item)
      { $1 }
;

(* A signature item. *)
signature_item:
  | item_extension post_item_attributes
      { let docs = symbol_docs $sloc in
        mksig ~loc:$sloc (Psig_extension ($1, (add_docs_attrs docs $2))) }
  | mksig(
      floating_attribute
        { Psig_attribute $1 }
    )
    { $1 }
  | wrap_mksig_ext(
      value_description
        { psig_value $1 }
    | primitive_declaration
        { psig_value $1 }
    | type_declarations
        { psig_type $1 }
    | type_subst_declarations
        { psig_typesubst $1 }
    | sig_type_extension
        { psig_typext $1 }
    | sig_exception_declaration
        { psig_exception $1 }
    | module_declaration
        { let (body, ext) = $1 in (Psig_module body, ext) }
    | module_alias
        { let (body, ext) = $1 in (Psig_module body, ext) }
    | module_subst
        { let (body, ext) = $1 in (Psig_modsubst body, ext) }
    | rec_module_declarations
        { let (ext, l) = $1 in (Psig_recmodule l, ext) }
    | module_type_declaration
        { let (body, ext) = $1 in (Psig_modtype body, ext) }
    | module_type_subst
        { let (body, ext) = $1 in (Psig_modtypesubst body, ext) }
    | open_description
        { let (body, ext) = $1 in (Psig_open body, ext) }
    | include_statement(module_type)
        { psig_include $1 }
    | class_descriptions
        { let (ext, l) = $1 in (Psig_class l, ext) }
    | class_type_declarations
        { let (ext, l) = $1 in (Psig_class_type l, ext) }
    )
    { $1 }

(* A module declaration. *)
%inline module_declaration:
  MODULE
  ext = ext attrs1 = attributes
  name = mkrhs(module_name)
  body = module_declaration_body
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Md.mk name body ~attrs ~loc ~docs, ext
  }
;

(* The body (right-hand side) of a module declaration. *)
module_declaration_body:
    COLON mty = module_type
      { mty }
  | mkmty(
      arg_and_pos = functor_arg body = module_declaration_body
        { let (_, arg) = arg_and_pos in
          Pmty_functor(arg, body) }
    )
    { $1 }
;

(* A module alias declaration (in a signature). *)
%inline module_alias:
  MODULE
  ext = ext attrs1 = attributes
  name = mkrhs(module_name)
  EQUAL
  body = module_expr_alias
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Md.mk name body ~attrs ~loc ~docs, ext
  }
;
%inline module_expr_alias:
  id = mkrhs(mod_longident)
    { Mty.alias ~loc:(make_loc $sloc) id }
;
(* A module substitution (in a signature). *)
module_subst:
  MODULE
  ext = ext attrs1 = attributes
  uid = mkrhs(UIDENT)
  COLONEQUAL
  body = mkrhs(mod_ext_longident)
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Ms.mk uid body ~attrs ~loc ~docs, ext
  }
| MODULE ext attributes mkrhs(UIDENT) COLONEQUAL error
    { expecting $loc($6) ""module path"" }
;

(* A group of recursive module declarations. *)
%inline rec_module_declarations:
  xlist(rec_module_declaration, and_module_declaration)
    { $1 }
;
%inline rec_module_declaration:
  MODULE
  ext = ext
  attrs1 = attributes
  REC
  name = mkrhs(module_name)
  COLON
  mty = module_type
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    ext, Md.mk name mty ~attrs ~loc ~docs
  }
;
%inline and_module_declaration:
  AND
  attrs1 = attributes
  name = mkrhs(module_name)
  COLON
  mty = module_type
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let docs = symbol_docs $sloc in
    let loc = make_loc $sloc in
    let text = symbol_text $symbolstartpos in
    Md.mk name mty ~attrs ~loc ~text ~docs
  }
;

(* A module type substitution *)
module_type_subst:
  MODULE TYPE
  ext = ext
  attrs1 = attributes
  id = mkrhs(ident)
  COLONEQUAL
  typ=module_type
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Mtd.mk id ~typ ~attrs ~loc ~docs, ext
  }


(* -------------------------------------------------------------------------- *)

(* Class declarations. *)

%inline class_declarations:
  xlist(class_declaration, and_class_declaration)
    { $1 }
;
%inline class_declaration:
  CLASS
  ext = ext
  attrs1 = attributes
  virt = virtual_flag
  params = formal_class_parameters
  id = mkrhs(LIDENT)
  body = class_fun_binding
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    ext,
    Ci.mk id body ~virt ~params ~attrs ~loc ~docs
  }
;
%inline and_class_declaration:
  AND
  attrs1 = attributes
  virt = virtual_flag
  params = formal_class_parameters
  id = mkrhs(LIDENT)
  body = class_fun_binding
  attrs2 = post_item_attributes
  {
    let attrs = attrs1 @ attrs2 in
    let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    let text = symbol_text $symbolstartpos in
    Ci.mk id body ~virt ~params ~attrs ~loc ~text ~docs
  }
;

class_fun_binding:
    EQUAL class_expr
      { $2 }
  | mkclass(
      COLON class_type EQUAL class_expr
        { Pcl_constraint($4, $2) }
    | labeled_simple_pattern class_fun_binding
      { let (l,o,p) = $1 in Pcl_fun(l, o, p, $2) }
    ) { $1 }
;

formal_class_parameters:
  params = class_parameters(type_parameter)
    { params }
;

(* -------------------------------------------------------------------------- *)

(* Class expressions. *)

class_expr:
    class_simple_expr
      { $1 }
  | FUN attributes class_fun_def
      { wrap_class_attrs ~loc:$sloc $3 $2 }
  | let_bindings(no_ext) IN class_expr
      { class_of_let_bindings ~loc:$sloc $1 $3 }
  | LET OPEN override_flag attributes mkrhs(mod_longident) IN class_expr
      { let loc = ($startpos($2), $endpos($5)) in
        let od = Opn.mk ~override:$3 ~loc:(make_loc loc) $5 in
        mkclass ~loc:$sloc ~attrs:$4 (Pcl_open(od, $7)) }
  | class_expr attribute
      { Cl.attr $1 $2 }
  | mkclass(
      class_simple_expr nonempty_llist(labeled_simple_expr)
        { Pcl_apply($1, $2) }
    | extension
        { Pcl_extension $1 }
    ) { $1 }
;
class_simple_expr:
  | LPAREN class_expr RPAREN
      { $2 }
  | LPAREN class_expr error
      { unclosed ""("" $loc($1) "")"" $loc($3) }
  | mkclass(
      tys = actual_class_parameters cid = mkrhs(class_longident)
        { Pcl_constr(cid, tys) }
    | OBJECT attributes class_structure error
        { unclosed ""object"" $loc($1) ""end"" $loc($4) }
    | LPAREN class_expr COLON class_type RPAREN
        { Pcl_constraint($2, $4) }
    | LPAREN class_expr COLON class_type error
        { unclosed ""("" $loc($1) "")"" $loc($5) }
    ) { $1 }
  | OBJECT attributes class_structure END
    { mkclass ~loc:$sloc ~attrs:$2 (Pcl_structure $3) }
;

class_fun_def:
  mkclass(
    labeled_simple_pattern MINUSGREATER e = class_expr
  | labeled_simple_pattern e = class_fun_def
      { let (l,o,p) = $1 in Pcl_fun(l, o, p, e) }
  ) { $1 }
;
%inline class_structure:
  |  class_self_pattern extra_cstr(class_fields)
       { Cstr.mk $1 $2 }
;
class_self_pattern:
    LPAREN pattern RPAREN
      { reloc_pat ~loc:$sloc $2 }
  | mkpat(LPAREN pattern COLON core_type RPAREN
      { Ppat_constraint($2, $4) })
      { $1 }
  | /* empty */
      { ghpat ~loc:$sloc Ppat_any }
;
%inline class_fields:
  flatten(text_cstr(class_field)*)
    { $1 }
;
class_field:
  | INHERIT override_flag attributes class_expr
    self = preceded(AS, mkrhs(LIDENT))?
    post_item_attributes
      { let docs = symbol_docs $sloc in
        mkcf ~loc:$sloc (Pcf_inherit ($2, $4, self)) ~attrs:($3@$6) ~docs }
  | VAL value post_item_attributes
      { let v, attrs = $2 in
        let docs = symbol_docs $sloc in
        mkcf ~loc:$sloc (Pcf_val v) ~attrs:(attrs@$3) ~docs }
  | METHOD method_ post_item_attributes
      { let meth, attrs = $2 in
        let docs = symbol_docs $sloc in
        mkcf ~loc:$sloc (Pcf_method meth) ~attrs:(attrs@$3) ~docs }
  | CONSTRAINT attributes constrain_field post_item_attributes
      { let docs = symbol_docs $sloc in
        mkcf ~loc:$sloc (Pcf_constraint $3) ~attrs:($2@$4) ~docs }
  | INITIALIZER attributes seq_expr post_item_attributes
      { let docs = symbol_docs $sloc in
        mkcf ~loc:$sloc (Pcf_initializer $3) ~attrs:($2@$4) ~docs }
  | item_extension post_item_attributes
      { let docs = symbol_docs $sloc in
        mkcf ~loc:$sloc (Pcf_extension $1) ~attrs:$2 ~docs }
  | mkcf(floating_attribute
      { Pcf_attribute $1 })
      { $1 }
;
value:
    no_override_flag
    attrs = attributes
    mutable_ = virtual_with_mutable_flag
    label = mkrhs(label) COLON ty = core_type
      { (label, mutable_, Cfk_virtual ty), attrs }
  | override_flag attributes mutable_flag mkrhs(label) EQUAL seq_expr
      { ($4, $3, Cfk_concrete ($1, $6)), $2 }
  | override_flag attributes mutable_flag mkrhs(label) type_constraint
    EQUAL seq_expr
      { let e = mkexp_constraint ~loc:$sloc $7 $5 in
        ($4, $3, Cfk_concrete ($1, e)), $2
      }
;
method_:
    no_override_flag
    attrs = attributes
    private_ = virtual_with_private_flag
    label = mkrhs(label) COLON ty = poly_type
      { (label, private_, Cfk_virtual ty), attrs }
  | override_flag attributes private_flag mkrhs(label) strict_binding
      { let e = $5 in
        let loc = Location.(e.pexp_loc.loc_start, e.pexp_loc.loc_end) in
        ($4, $3,
        Cfk_concrete ($1, ghexp ~loc (Pexp_poly (e, None)))), $2 }
  | override_flag attributes private_flag mkrhs(label)
    COLON poly_type EQUAL seq_expr
      { let poly_exp =
          let loc = ($startpos($6), $endpos($8)) in
          ghexp ~loc (Pexp_poly($8, Some $6)) in
        ($4, $3, Cfk_concrete ($1, poly_exp)), $2 }
  | override_flag attributes private_flag mkrhs(label) COLON TYPE lident_list
    DOT core_type EQUAL seq_expr
      { let poly_exp_loc = ($startpos($7), $endpos($11)) in
        let poly_exp =
          let exp, poly =
            (* it seems odd to use the global ~loc here while poly_exp_loc
               is tighter, but this is what ocamlyacc does;
               TODO improve parser.mly *)
            wrap_type_annotation ~loc:$sloc $7 $9 $11 in
          ghexp ~loc:poly_exp_loc (Pexp_poly(exp, Some poly)) in
        ($4, $3,
        Cfk_concrete ($1, poly_exp)), $2 }
;

/* Class types */

class_type:
    class_signature
      { $1 }
  | mkcty(
      label = arg_label
      domain = tuple_type
      MINUSGREATER
      codomain = class_type
        { Pcty_arrow(label, domain, codomain) }
    ) { $1 }
 ;
class_signature:
    mkcty(
      tys = actual_class_parameters cid = mkrhs(clty_longident)
        { Pcty_constr (cid, tys) }
    | extension
        { Pcty_extension $1 }
    ) { $1 }
  | OBJECT attributes class_sig_body END
      { mkcty ~loc:$sloc ~attrs:$2 (Pcty_signature $3) }
  | OBJECT attributes class_sig_body error
      { unclosed ""object"" $loc($1) ""end"" $loc($4) }
  | class_signature attribute
      { Cty.attr $1 $2 }
  | LET OPEN override_flag attributes mkrhs(mod_longident) IN class_signature
      { let loc = ($startpos($2), $endpos($5)) in
        let od = Opn.mk ~override:$3 ~loc:(make_loc loc) $5 in
        mkcty ~loc:$sloc ~attrs:$4 (Pcty_open(od, $7)) }
;
%inline class_parameters(parameter):
  | /* empty */
      { [] }
  | LBRACKET params = separated_nonempty_llist(COMMA, parameter) RBRACKET
      { params }
;
%inline actual_class_parameters:
  tys = class_parameters(core_type)
    { tys }
;
%inline class_sig_body:
    class_self_type extra_csig(class_sig_fields)
      { Csig.mk $1 $2 }
;
class_self_type:
    LPAREN core_type RPAREN
      { $2 }
  | mktyp((* empty *) { Ptyp_any })
      { $1 }
;
%inline class_sig_fields:
  flatten(text_csig(class_sig_field)*)
    { $1 }
;
class_sig_field:
    INHERIT attributes class_signature post_item_attributes
      { let docs = symbol_docs $sloc in
        mkctf ~loc:$sloc (Pctf_inherit $3) ~attrs:($2@$4) ~docs }
  | VAL attributes value_type post_item_attributes
      { let docs = symbol_docs $sloc in
        mkctf ~loc:$sloc (Pctf_val $3) ~attrs:($2@$4) ~docs }
  | METHOD attributes private_virtual_flags mkrhs(label) COLON poly_type
    post_item_attributes
      { let (p, v) = $3 in
        let docs = symbol_docs $sloc in
        mkctf ~loc:$sloc (Pctf_method ($4, p, v, $6)) ~attrs:($2@$7) ~docs }
  | CONSTRAINT attributes constrain_field post_item_attributes
      { let docs = symbol_docs $sloc in
        mkctf ~loc:$sloc (Pctf_constraint $3) ~attrs:($2@$4) ~docs }
  | item_extension post_item_attributes
      { let docs = symbol_docs $sloc in
        mkctf ~loc:$sloc (Pctf_extension $1) ~attrs:$2 ~docs }
  | mkctf(floating_attribute
      { Pctf_attribute $1 })
      { $1 }
;
%inline value_type:
  flags = mutable_virtual_flags
  label = mkrhs(label)
  COLON
  ty = core_type
  {
    let mut, virt = flags in
    label, mut, virt, ty
  }
;
%inline constrain:
    core_type EQUAL core_type
    { $1, $3, make_loc $sloc }
;
constrain_field:
  core_type EQUAL core_type
    { $1, $3 }
;
(* A group of class descriptions. *)
%inline class_descriptions:
  xlist(class_description, and_class_description)
    { $1 }
;
%inline class_description:
  CLASS
  ext = ext
  attrs1 = attributes
  virt = virtual_flag
  params = formal_class_parameters
  id = mkrhs(LIDENT)
  COLON
  cty = class_type
  attrs2 = post_item_attributes
    {
      let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let docs = symbol_docs $sloc in
      ext,
      Ci.mk id cty ~virt ~params ~attrs ~loc ~docs
    }
;
%inline and_class_description:
  AND
  attrs1 = attributes
  virt = virtual_flag
  params = formal_class_parameters
  id = mkrhs(LIDENT)
  COLON
  cty = class_type
  attrs2 = post_item_attributes
    {
      let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let docs = symbol_docs $sloc in
      let text = symbol_text $symbolstartpos in
      Ci.mk id cty ~virt ~params ~attrs ~loc ~text ~docs
    }
;
class_type_declarations:
  xlist(class_type_declaration, and_class_type_declaration)
    { $1 }
;
%inline class_type_declaration:
  CLASS TYPE
  ext = ext
  attrs1 = attributes
  virt = virtual_flag
  params = formal_class_parameters
  id = mkrhs(LIDENT)
  EQUAL
  csig = class_signature
  attrs2 = post_item_attributes
    {
      let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let docs = symbol_docs $sloc in
      ext,
      Ci.mk id csig ~virt ~params ~attrs ~loc ~docs
    }
;
%inline and_class_type_declaration:
  AND
  attrs1 = attributes
  virt = virtual_flag
  params = formal_class_parameters
  id = mkrhs(LIDENT)
  EQUAL
  csig = class_signature
  attrs2 = post_item_attributes
    {
      let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let docs = symbol_docs $sloc in
      let text = symbol_text $symbolstartpos in
      Ci.mk id csig ~virt ~params ~attrs ~loc ~text ~docs
    }
;

/* Core expressions */

seq_expr:
  | expr        %prec below_SEMI  { $1 }
  | expr SEMI                     { $1 }
  | mkexp(expr SEMI seq_expr
    { Pexp_sequence($1, $3) })
    { $1 }
  | expr SEMI PERCENT attr_id seq_expr
    { let seq = mkexp ~loc:$sloc (Pexp_sequence ($1, $5)) in
      let payload = PStr [mkstrexp seq []] in
      mkexp ~loc:$sloc (Pexp_extension ($4, payload)) }
;
labeled_simple_pattern:
    QUESTION LPAREN label_let_pattern opt_default RPAREN
      { (Optional (fst $3), $4, snd $3) }
  | QUESTION label_var
      { (Optional (fst $2), None, snd $2) }
  | OPTLABEL LPAREN let_pattern opt_default RPAREN
      { (Optional $1, $4, $3) }
  | OPTLABEL pattern_var
      { (Optional $1, None, $2) }
  | TILDE LPAREN label_let_pattern RPAREN
      { (Labelled (fst $3), None, snd $3) }
  | TILDE label_var
      { (Labelled (fst $2), None, snd $2) }
  | LABEL simple_pattern
      { (Labelled $1, None, $2) }
  | simple_pattern
      { (Nolabel, None, $1) }
;

pattern_var:
  mkpat(
      mkrhs(LIDENT)     { Ppat_var $1 }
    | UNDERSCORE        { Ppat_any }
  ) { $1 }
;

%inline opt_default:
  preceded(EQUAL, seq_expr)?
    { $1 }
;
label_let_pattern:
    x = label_var
      { x }
  | x = label_var COLON cty = core_type
      { let lab, pat = x in
        lab,
        mkpat ~loc:$sloc (Ppat_constraint (pat, cty)) }
;
%inline label_var:
    mkrhs(LIDENT)
      { ($1.Location.txt, mkpat ~loc:$sloc (Ppat_var $1)) }
;
let_pattern:
    pattern
      { $1 }
  | mkpat(pattern COLON core_type
      { Ppat_constraint($1, $3) })
      { $1 }
;

%inline indexop_expr(dot, index, right):
  | array=simple_expr d=dot LPAREN i=index RPAREN r=right
    { array, d, Paren,   i, r }
  | array=simple_expr d=dot LBRACE i=index RBRACE r=right
    { array, d, Brace,   i, r }
  | array=simple_expr d=dot LBRACKET i=index RBRACKET r=right
    { array, d, Bracket, i, r }
;

%inline indexop_error(dot, index):
  | simple_expr dot _p=LPAREN index  _e=error
    { indexop_unclosed_error $loc(_p)  Paren $loc(_e) }
  | simple_expr dot _p=LBRACE index  _e=error
    { indexop_unclosed_error $loc(_p) Brace $loc(_e) }
  | simple_expr dot _p=LBRACKET index  _e=error
    { indexop_unclosed_error $loc(_p) Bracket $loc(_e) }
;

%inline qualified_dotop: ioption(DOT mod_longident {$2}) DOTOP { $1, $2 };

expr:
    simple_expr %prec below_HASH
      { $1 }
  | expr_attrs
      { let desc, attrs = $1 in
        mkexp_attrs ~loc:$sloc desc attrs }
  | mkexp(expr_)
      { $1 }
  | let_bindings(ext) IN seq_expr
      { expr_of_let_bindings ~loc:$sloc $1 $3 }
  | pbop_op = mkrhs(LETOP) bindings = letop_bindings IN body = seq_expr
      { let (pbop_pat, pbop_exp, rev_ands) = bindings in
        let ands = List.rev rev_ands in
        let pbop_loc = make_loc $sloc in
        let let_ = {pbop_op; pbop_pat; pbop_exp; pbop_loc} in
        mkexp ~loc:$sloc (Pexp_letop{ let_; ands; body}) }
  | expr COLONCOLON expr
      { mkexp_cons ~loc:$sloc $loc($2) (ghexp ~loc:$sloc (Pexp_tuple[$1;$3])) }
  | mkrhs(label) LESSMINUS expr
      { mkexp ~loc:$sloc (Pexp_setinstvar($1, $3)) }
  | simple_expr DOT mkrhs(label_longident) LESSMINUS expr
      { mkexp ~loc:$sloc (Pexp_setfield($1, $3, $5)) }
  | indexop_expr(DOT, seq_expr, LESSMINUS v=expr {Some v})
    { mk_indexop_expr builtin_indexing_operators ~loc:$sloc $1 }
  | indexop_expr(qualified_dotop, expr_semi_list, LESSMINUS v=expr {Some v})
    { mk_indexop_expr user_indexing_operators ~loc:$sloc $1 }
  | expr attribute
      { Exp.attr $1 $2 }
/* BEGIN AVOID */
  | UNDERSCORE
     { not_expecting $loc($1) ""wildcard \""_\"""" }
/* END AVOID */
;
%inline expr_attrs:
  | LET MODULE ext_attributes mkrhs(module_name) module_binding_body IN seq_expr
      { Pexp_letmodule($4, $5, $7), $3 }
  | LET EXCEPTION ext_attributes let_exception_declaration IN seq_expr
      { Pexp_letexception($4, $6), $3 }
  | LET OPEN override_flag ext_attributes module_expr IN seq_expr
      { let open_loc = make_loc ($startpos($2), $endpos($5)) in
        let od = Opn.mk $5 ~override:$3 ~loc:open_loc in
        Pexp_open(od, $7), $4 }
  | FUNCTION ext_attributes match_cases
      { Pexp_function $3, $2 }
  | FUN ext_attributes labeled_simple_pattern fun_def
      { let (l,o,p) = $3 in
        Pexp_fun(l, o, p, $4), $2 }
  | FUN ext_attributes LPAREN TYPE lident_list RPAREN fun_def
      { (mk_newtypes ~loc:$sloc $5 $7).pexp_desc, $2 }
  | MATCH ext_attributes seq_expr WITH match_cases
      { Pexp_match($3, $5), $2 }
  | TRY ext_attributes seq_expr WITH match_cases
      { Pexp_try($3, $5), $2 }
  | TRY ext_attributes seq_expr WITH error
      { syntax_error() }
  | IF ext_attributes seq_expr THEN expr ELSE expr
      { Pexp_ifthenelse($3, $5, Some $7), $2 }
  | IF ext_attributes seq_expr THEN expr
      { Pexp_ifthenelse($3, $5, None), $2 }
  | WHILE ext_attributes seq_expr DO seq_expr DONE
      { Pexp_while($3, $5), $2 }
  | FOR ext_attributes pattern EQUAL seq_expr direction_flag seq_expr DO
    seq_expr DONE
      { Pexp_for($3, $5, $7, $6, $9), $2 }
  | ASSERT ext_attributes simple_expr %prec below_HASH
      { Pexp_assert $3, $2 }
  | LAZY ext_attributes simple_expr %prec below_HASH
      { Pexp_lazy $3, $2 }
;
%inline expr_:
  | simple_expr nonempty_llist(labeled_simple_expr)
      { Pexp_apply($1, $2) }
  | expr_comma_list %prec below_COMMA
      { Pexp_tuple($1) }
  | mkrhs(constr_longident) simple_expr %prec below_HASH
      { Pexp_construct($1, Some $2) }
  | name_tag simple_expr %prec below_HASH
      { Pexp_variant($1, Some $2) }
  | e1 = expr op = op(infix_operator) e2 = expr
      { mkinfix e1 op e2 }
  | subtractive expr %prec prec_unary_minus
      { mkuminus ~oploc:$loc($1) $1 $2 }
  | additive expr %prec prec_unary_plus
      { mkuplus ~oploc:$loc($1) $1 $2 }
;

simple_expr:
  | LPAREN seq_expr RPAREN
      { reloc_exp ~loc:$sloc $2 }
  | LPAREN seq_expr error
      { unclosed ""("" $loc($1) "")"" $loc($3) }
  | LPAREN seq_expr type_constraint RPAREN
      { mkexp_constraint ~loc:$sloc $2 $3 }
  | indexop_expr(DOT, seq_expr, { None })
      { mk_indexop_expr builtin_indexing_operators ~loc:$sloc $1 }
  | indexop_expr(qualified_dotop, expr_semi_list, { None })
      { mk_indexop_expr user_indexing_operators ~loc:$sloc $1 }
  | indexop_error (DOT, seq_expr) { $1 }
  | indexop_error (qualified_dotop, expr_semi_list) { $1 }
  | simple_expr_attrs
    { let desc, attrs = $1 in
      mkexp_attrs ~loc:$sloc desc attrs }
  | mkexp(simple_expr_)
      { $1 }
;
%inline simple_expr_attrs:
  | BEGIN ext = ext attrs = attributes e = seq_expr END
      { e.pexp_desc, (ext, attrs @ e.pexp_attributes) }
  | BEGIN ext_attributes END
      { Pexp_construct (mkloc (Lident ""()"") (make_loc $sloc), None), $2 }
  | BEGIN ext_attributes seq_expr error
      { unclosed ""begin"" $loc($1) ""end"" $loc($4) }
  | NEW ext_attributes mkrhs(class_longident)
      { Pexp_new($3), $2 }
  | LPAREN MODULE ext_attributes module_expr RPAREN
      { Pexp_pack $4, $3 }
  | LPAREN MODULE ext_attributes module_expr COLON package_type RPAREN
      { Pexp_constraint (ghexp ~loc:$sloc (Pexp_pack $4), $6), $3 }
  | LPAREN MODULE ext_attributes module_expr COLON error
      { unclosed ""("" $loc($1) "")"" $loc($6) }
  | OBJECT ext_attributes class_structure END
      { Pexp_object $3, $2 }
  | OBJECT ext_attributes class_structure error
      { unclosed ""object"" $loc($1) ""end"" $loc($4) }
;
%inline simple_expr_:
  | mkrhs(val_longident)
      { Pexp_ident ($1) }
  | constant
      { Pexp_constant $1 }
  | mkrhs(constr_longident) %prec prec_constant_constructor
      { Pexp_construct($1, None) }
  | name_tag %prec prec_constant_constructor
      { Pexp_variant($1, None) }
  | op(PREFIXOP) simple_expr
      { Pexp_apply($1, [Nolabel,$2]) }
  | op(BANG {""!""}) simple_expr
      { Pexp_apply($1, [Nolabel,$2]) }
  | LBRACELESS object_expr_content GREATERRBRACE
      { Pexp_override $2 }
  | LBRACELESS object_expr_content error
      { unclosed ""{<"" $loc($1) "">}"" $loc($3) }
  | LBRACELESS GREATERRBRACE
      { Pexp_override [] }
  | simple_expr DOT mkrhs(label_longident)
      { Pexp_field($1, $3) }
  | od=open_dot_declaration DOT LPAREN seq_expr RPAREN
      { Pexp_open(od, $4) }
  | od=open_dot_declaration DOT LBRACELESS object_expr_content GREATERRBRACE
      { (* TODO: review the location of Pexp_override *)
        Pexp_open(od, mkexp ~loc:$sloc (Pexp_override $4)) }
  | mod_longident DOT LBRACELESS object_expr_content error
      { unclosed ""{<"" $loc($3) "">}"" $loc($5) }
  | simple_expr HASH mkrhs(label)
      { Pexp_send($1, $3) }
  | simple_expr op(HASHOP) simple_expr
      { mkinfix $1 $2 $3 }
  | extension
      { Pexp_extension $1 }
  | od=open_dot_declaration DOT mkrhs(LPAREN RPAREN {Lident ""()""})
      { Pexp_open(od, mkexp ~loc:($loc($3)) (Pexp_construct($3, None))) }
  | mod_longident DOT LPAREN seq_expr error
      { unclosed ""("" $loc($3) "")"" $loc($5) }
  | LBRACE record_expr_content RBRACE
      { let (exten, fields) = $2 in
        Pexp_record(fields, exten) }
  | LBRACE record_expr_content error
      { unclosed ""{"" $loc($1) ""}"" $loc($3) }
  | od=open_dot_declaration DOT LBRACE record_expr_content RBRACE
      { let (exten, fields) = $4 in
        Pexp_open(od, mkexp ~loc:($startpos($3), $endpos)
                        (Pexp_record(fields, exten))) }
  | mod_longident DOT LBRACE record_expr_content error
      { unclosed ""{"" $loc($3) ""}"" $loc($5) }
  | LBRACKETBAR expr_semi_list BARRBRACKET
      { Pexp_array($2) }
  | LBRACKETBAR expr_semi_list error
      { unclosed ""[|"" $loc($1) ""|]"" $loc($3) }
  | LBRACKETBAR BARRBRACKET
      { Pexp_array [] }
  | od=open_dot_declaration DOT LBRACKETBAR expr_semi_list BARRBRACKET
      { Pexp_open(od, mkexp ~loc:($startpos($3), $endpos) (Pexp_array($4))) }
  | od=open_dot_declaration DOT LBRACKETBAR BARRBRACKET
      { (* TODO: review the location of Pexp_array *)
        Pexp_open(od, mkexp ~loc:($startpos($3), $endpos) (Pexp_array [])) }
  | mod_longident DOT
    LBRACKETBAR expr_semi_list error
      { unclosed ""[|"" $loc($3) ""|]"" $loc($5) }
  | LBRACKET expr_semi_list RBRACKET
      { fst (mktailexp $loc($3) $2) }
  | LBRACKET expr_semi_list error
      { unclosed ""["" $loc($1) ""]"" $loc($3) }
  | od=open_dot_declaration DOT LBRACKET expr_semi_list RBRACKET
      { let list_exp =
          (* TODO: review the location of list_exp *)
          let tail_exp, _tail_loc = mktailexp $loc($5) $4 in
          mkexp ~loc:($startpos($3), $endpos) tail_exp in
        Pexp_open(od, list_exp) }
  | od=open_dot_declaration DOT mkrhs(LBRACKET RBRACKET {Lident ""[]""})
      { Pexp_open(od, mkexp ~loc:$loc($3) (Pexp_construct($3, None))) }
  | mod_longident DOT
    LBRACKET expr_semi_list error
      { unclosed ""["" $loc($3) ""]"" $loc($5) }
  | od=open_dot_declaration DOT LPAREN MODULE ext_attributes module_expr COLON
    package_type RPAREN
      { let modexp =
          mkexp_attrs ~loc:($startpos($3), $endpos)
            (Pexp_constraint (ghexp ~loc:$sloc (Pexp_pack $6), $8)) $5 in
        Pexp_open(od, modexp) }
  | mod_longident DOT
    LPAREN MODULE ext_attributes module_expr COLON error
      { unclosed ""("" $loc($3) "")"" $loc($8) }
;
labeled_simple_expr:
    simple_expr %prec below_HASH
      { (Nolabel, $1) }
  | LABEL simple_expr %prec below_HASH
      { (Labelled $1, $2) }
  | TILDE label = LIDENT
      { let loc = $loc(label) in
        (Labelled label, mkexpvar ~loc label) }
  | TILDE LPAREN label = LIDENT ty = type_constraint RPAREN
      { (Labelled label, mkexp_constraint ~loc:($startpos($2), $endpos)
                           (mkexpvar ~loc:$loc(label) label) ty) }
  | QUESTION label = LIDENT
      { let loc = $loc(label) in
        (Optional label, mkexpvar ~loc label) }
  | OPTLABEL simple_expr %prec below_HASH
      { (Optional $1, $2) }
;
%inline lident_list:
  xs = mkrhs(LIDENT)+
    { xs }
;
%inline let_ident:
    val_ident { mkpatvar ~loc:$sloc $1 }
;
let_binding_body_no_punning:
    let_ident strict_binding
      { ($1, $2) }
  | let_ident type_constraint EQUAL seq_expr
      { let v = $1 in (* PR#7344 *)
        let t =
          match $2 with
            Some t, None -> t
          | _, Some t -> t
          | _ -> assert false
        in
        let loc = Location.(t.ptyp_loc.loc_start, t.ptyp_loc.loc_end) in
        let typ = ghtyp ~loc (Ptyp_poly([],t)) in
        let patloc = ($startpos($1), $endpos($2)) in
        (ghpat ~loc:patloc (Ppat_constraint(v, typ)),
         mkexp_constraint ~loc:$sloc $4 $2) }
  | let_ident COLON poly(core_type) EQUAL seq_expr
      { let patloc = ($startpos($1), $endpos($3)) in
        (ghpat ~loc:patloc
           (Ppat_constraint($1, ghtyp ~loc:($loc($3)) $3)),
         $5) }
  | let_ident COLON TYPE lident_list DOT core_type EQUAL seq_expr
      { let exp, poly =
          wrap_type_annotation ~loc:$sloc $4 $6 $8 in
        let loc = ($startpos($1), $endpos($6)) in
        (ghpat ~loc (Ppat_constraint($1, poly)), exp) }
  | pattern_no_exn EQUAL seq_expr
      { ($1, $3) }
  | simple_pattern_not_ident COLON core_type EQUAL seq_expr
      { let loc = ($startpos($1), $endpos($3)) in
        (ghpat ~loc (Ppat_constraint($1, $3)), $5) }
;
let_binding_body:
  | let_binding_body_no_punning
      { let p,e = $1 in (p,e,false) }
/* BEGIN AVOID */
  | val_ident %prec below_HASH
      { (mkpatvar ~loc:$loc $1, mkexpvar ~loc:$loc $1, true) }
  (* The production that allows puns is marked so that [make list-parse-errors]
     does not attempt to exploit it. That would be problematic because it
     would then generate bindings such as [let x], which are rejected by the
     auxiliary function [addlb] via a call to [syntax_error]. *)
/* END AVOID */
;
(* The formal parameter EXT can be instantiated with ext or no_ext
   so as to indicate whether an extension is allowed or disallowed. *)
let_bindings(EXT):
    let_binding(EXT)                            { $1 }
  | let_bindings(EXT) and_let_binding           { addlb $1 $2 }
;
%inline let_binding(EXT):
  LET
  ext = EXT
  attrs1 = attributes
  rec_flag = rec_flag
  body = let_binding_body
  attrs2 = post_item_attributes
    {
      let attrs = attrs1 @ attrs2 in
      mklbs ext rec_flag (mklb ~loc:$sloc true body attrs)
    }
;
and_let_binding:
  AND
  attrs1 = attributes
  body = let_binding_body
  attrs2 = post_item_attributes
    {
      let attrs = attrs1 @ attrs2 in
      mklb ~loc:$sloc false body attrs
    }
;
letop_binding_body:
    pat = let_ident exp = strict_binding
      { (pat, exp) }
  | val_ident
      (* Let-punning *)
      { (mkpatvar ~loc:$loc $1, mkexpvar ~loc:$loc $1) }
  | pat = simple_pattern COLON typ = core_type EQUAL exp = seq_expr
      { let loc = ($startpos(pat), $endpos(typ)) in
        (ghpat ~loc (Ppat_constraint(pat, typ)), exp) }
  | pat = pattern_no_exn EQUAL exp = seq_expr
      { (pat, exp) }
;
letop_bindings:
    body = letop_binding_body
      { let let_pat, let_exp = body in
        let_pat, let_exp, [] }
  | bindings = letop_bindings pbop_op = mkrhs(ANDOP) body = letop_binding_body
      { let let_pat, let_exp, rev_ands = bindings in
        let pbop_pat, pbop_exp = body in
        let pbop_loc = make_loc $sloc in
        let and_ = {pbop_op; pbop_pat; pbop_exp; pbop_loc} in
        let_pat, let_exp, and_ :: rev_ands }
;
fun_binding:
    strict_binding
      { $1 }
  | type_constraint EQUAL seq_expr
      { mkexp_constraint ~loc:$sloc $3 $1 }
;
strict_binding:
    EQUAL seq_expr
      { $2 }
  | labeled_simple_pattern fun_binding
      { let (l, o, p) = $1 in ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2)) }
  | LPAREN TYPE lident_list RPAREN fun_binding
      { mk_newtypes ~loc:$sloc $3 $5 }
;
%inline match_cases:
  xs = preceded_or_separated_nonempty_llist(BAR, match_case)
    { xs }
;
match_case:
    pattern MINUSGREATER seq_expr
      { Exp.case $1 $3 }
  | pattern WHEN seq_expr MINUSGREATER seq_expr
      { Exp.case $1 ~guard:$3 $5 }
  | pattern MINUSGREATER DOT
      { Exp.case $1 (Exp.unreachable ~loc:(make_loc $loc($3)) ()) }
;
fun_def:
    MINUSGREATER seq_expr
      { $2 }
  | mkexp(COLON atomic_type MINUSGREATER seq_expr
      { Pexp_constraint ($4, $2) })
      { $1 }
/* Cf #5939: we used to accept (fun p when e0 -> e) */
  | labeled_simple_pattern fun_def
      {
       let (l,o,p) = $1 in
       ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2))
      }
  | LPAREN TYPE lident_list RPAREN fun_def
      { mk_newtypes ~loc:$sloc $3 $5 }
;
%inline expr_comma_list:
  es = separated_nontrivial_llist(COMMA, expr)
    { es }
;
record_expr_content:
  eo = ioption(terminated(simple_expr, WITH))
  fields = separated_or_terminated_nonempty_list(SEMI, record_expr_field)
    { eo, fields }
;
%inline record_expr_field:
  | label = mkrhs(label_longident)
    c = type_constraint?
    eo = preceded(EQUAL, expr)?
      { let constraint_loc, label, e =
          match eo with
          | None ->
              (* No pattern; this is a pun. Desugar it. *)
              $sloc, make_ghost label, exp_of_longident label
          | Some e ->
              ($startpos(c), $endpos), label, e
        in
        label, mkexp_opt_constraint ~loc:constraint_loc e c }
;
%inline object_expr_content:
  xs = separated_or_terminated_nonempty_list(SEMI, object_expr_field)
    { xs }
;
%inline object_expr_field:
    label = mkrhs(label)
    oe = preceded(EQUAL, expr)?
      { let label, e =
          match oe with
          | None ->
              (* No expression; this is a pun. Desugar it. *)
              make_ghost label, exp_of_label label
          | Some e ->
              label, e
        in
        label, e }
;
%inline expr_semi_list:
  es = separated_or_terminated_nonempty_list(SEMI, expr)
    { es }
;
type_constraint:
    COLON core_type                             { (Some $2, None) }
  | COLON core_type COLONGREATER core_type      { (Some $2, Some $4) }
  | COLONGREATER core_type                      { (None, Some $2) }
  | COLON error                                 { syntax_error() }
  | COLONGREATER error                          { syntax_error() }
;

/* Patterns */

(* Whereas [pattern] is an arbitrary pattern, [pattern_no_exn] is a pattern
   that does not begin with the [EXCEPTION] keyword. Thus, [pattern_no_exn]
   is the intersection of the context-free language [pattern] with the
   regular language [^EXCEPTION .*].

   Ideally, we would like to use [pattern] everywhere and check in a later
   phase that EXCEPTION patterns are used only where they are allowed (there
   is code in typing/typecore.ml to this end). Unfortunately, in the
   definition of [let_binding_body], we cannot allow [pattern]. That would
   create a shift/reduce conflict: upon seeing LET EXCEPTION ..., the parser
   wouldn't know whether this is the beginning of a LET EXCEPTION construct or
   the beginning of a LET construct whose pattern happens to begin with
   EXCEPTION. The conflict is avoided there by using [pattern_no_exn] in the
   definition of [let_binding_body].

   In order to avoid duplication between the definitions of [pattern] and
   [pattern_no_exn], we create a parameterized definition [pattern_(self)]
   and instantiate it twice. *)

pattern:
    pattern_(pattern)
      { $1 }
  | EXCEPTION ext_attributes pattern %prec prec_constr_appl
      { mkpat_attrs ~loc:$sloc (Ppat_exception $3) $2}
;

pattern_no_exn:
    pattern_(pattern_no_exn)
      { $1 }
;

%inline pattern_(self):
  | self COLONCOLON pattern
      { mkpat_cons ~loc:$sloc $loc($2) (ghpat ~loc:$sloc (Ppat_tuple[$1;$3])) }
  | self attribute
      { Pat.attr $1 $2 }
  | pattern_gen
      { $1 }
  | mkpat(
      self AS mkrhs(val_ident)
        { Ppat_alias($1, $3) }
    | self AS error
        { expecting $loc($3) ""identifier"" }
    | pattern_comma_list(self) %prec below_COMMA
        { Ppat_tuple(List.rev $1) }
    | self COLONCOLON error
        { expecting $loc($3) ""pattern"" }
    | self BAR pattern
        { Ppat_or($1, $3) }
    | self BAR error
        { expecting $loc($3) ""pattern"" }
  ) { $1 }
;

pattern_gen:
    simple_pattern
      { $1 }
  | mkpat(
      mkrhs(constr_longident) pattern %prec prec_constr_appl
        { Ppat_construct($1, Some ([], $2)) }
    | constr=mkrhs(constr_longident) LPAREN TYPE newtypes=lident_list RPAREN
        pat=simple_pattern
        { Ppat_construct(constr, Some (newtypes, pat)) }
    | name_tag pattern %prec prec_constr_appl
        { Ppat_variant($1, Some $2) }
    ) { $1 }
  | LAZY ext_attributes simple_pattern
      { mkpat_attrs ~loc:$sloc (Ppat_lazy $3) $2}
;
simple_pattern:
    mkpat(mkrhs(val_ident) %prec below_EQUAL
      { Ppat_var ($1) })
      { $1 }
  | simple_pattern_not_ident { $1 }
;

simple_pattern_not_ident:
  | LPAREN pattern RPAREN
      { reloc_pat ~loc:$sloc $2 }
  | simple_delimited_pattern
      { $1 }
  | LPAREN MODULE ext_attributes mkrhs(module_name) RPAREN
      { mkpat_attrs ~loc:$sloc (Ppat_unpack $4) $3 }
  | LPAREN MODULE ext_attributes mkrhs(module_name) COLON package_type RPAREN
      { mkpat_attrs ~loc:$sloc
          (Ppat_constraint(mkpat ~loc:$loc($4) (Ppat_unpack $4), $6))
          $3 }
  | mkpat(simple_pattern_not_ident_)
      { $1 }
;
%inline simple_pattern_not_ident_:
  | UNDERSCORE
      { Ppat_any }
  | signed_constant
      { Ppat_constant $1 }
  | signed_constant DOTDOT signed_constant
      { Ppat_interval ($1, $3) }
  | mkrhs(constr_longident)
      { Ppat_construct($1, None) }
  | name_tag
      { Ppat_variant($1, None) }
  | HASH mkrhs(type_longident)
      { Ppat_type ($2) }
  | mkrhs(mod_longident) DOT simple_delimited_pattern
      { Ppat_open($1, $3) }
  | mkrhs(mod_longident) DOT mkrhs(LBRACKET RBRACKET {Lident ""[]""})
    { Ppat_open($1, mkpat ~loc:$sloc (Ppat_construct($3, None))) }
  | mkrhs(mod_longident) DOT mkrhs(LPAREN RPAREN {Lident ""()""})
    { Ppat_open($1, mkpat ~loc:$sloc (Ppat_construct($3, None))) }
  | mkrhs(mod_longident) DOT LPAREN pattern RPAREN
      { Ppat_open ($1, $4) }
  | mod_longident DOT LPAREN pattern error
      { unclosed ""("" $loc($3) "")"" $loc($5)  }
  | mod_longident DOT LPAREN error
      { expecting $loc($4) ""pattern"" }
  | LPAREN pattern error
      { unclosed ""("" $loc($1) "")"" $loc($3) }
  | LPAREN pattern COLON core_type RPAREN
      { Ppat_constraint($2, $4) }
  | LPAREN pattern COLON core_type error
      { unclosed ""("" $loc($1) "")"" $loc($5) }
  | LPAREN pattern COLON error
      { expecting $loc($4) ""type"" }
  | LPAREN MODULE ext_attributes module_name COLON package_type
    error
      { unclosed ""("" $loc($1) "")"" $loc($7) }
  | extension
      { Ppat_extension $1 }
;

simple_delimited_pattern:
  mkpat(
      LBRACE record_pat_content RBRACE
      { let (fields, closed) = $2 in
        Ppat_record(fields, closed) }
    | LBRACE record_pat_content error
      { unclosed ""{"" $loc($1) ""}"" $loc($3) }
    | LBRACKET pattern_semi_list RBRACKET
      { fst (mktailpat $loc($3) $2) }
    | LBRACKET pattern_semi_list error
      { unclosed ""["" $loc($1) ""]"" $loc($3) }
    | LBRACKETBAR pattern_semi_list BARRBRACKET
      { Ppat_array $2 }
    | LBRACKETBAR BARRBRACKET
      { Ppat_array [] }
    | LBRACKETBAR pattern_semi_list error
      { unclosed ""[|"" $loc($1) ""|]"" $loc($3) }
  ) { $1 }

pattern_comma_list(self):
    pattern_comma_list(self) COMMA pattern      { $3 :: $1 }
  | self COMMA pattern                          { [$3; $1] }
  | self COMMA error                            { expecting $loc($3) ""pattern"" }
;
%inline pattern_semi_list:
  ps = separated_or_terminated_nonempty_list(SEMI, pattern)
    { ps }
;
(* A label-pattern list is a nonempty list of label-pattern pairs, optionally
   followed with an UNDERSCORE, separated-or-terminated with semicolons. *)
%inline record_pat_content:
  listx(SEMI, record_pat_field, UNDERSCORE)
    { let fields, closed = $1 in
      let closed = match closed with Some () -> Open | None -> Closed in
      fields, closed }
;
%inline record_pat_field:
  label = mkrhs(label_longident)
  octy = preceded(COLON, core_type)?
  opat = preceded(EQUAL, pattern)?
    { let constraint_loc, label, pat =
        match opat with
        | None ->
            (* No pattern; this is a pun. Desugar it.
               But that the pattern was there and the label reconstructed (which
               piece of AST is marked as ghost is important for warning
               emission). *)
            $sloc, make_ghost label, pat_of_label label
        | Some pat ->
            ($startpos(octy), $endpos), label, pat
      in
      label, mkpat_opt_constraint ~loc:constraint_loc pat octy
    }
;

/* Value descriptions */

value_description:
  VAL
  ext = ext
  attrs1 = attributes
  id = mkrhs(val_ident)
  COLON
  ty = possibly_poly(core_type)
  attrs2 = post_item_attributes
    { let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let docs = symbol_docs $sloc in
      Val.mk id ty ~attrs ~loc ~docs,
      ext }
;

/* Primitive declarations */

primitive_declaration:
  EXTERNAL
  ext = ext
  attrs1 = attributes
  id = mkrhs(val_ident)
  COLON
  ty = possibly_poly(core_type)
  EQUAL
  prim = raw_string+
  attrs2 = post_item_attributes
    { let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let docs = symbol_docs $sloc in
      Val.mk id ty ~prim ~attrs ~loc ~docs,
      ext }
;

(* Type declarations and type substitutions. *)

(* Type declarations [type t = u] and type substitutions [type t := u] are very
   similar, so we view them as instances of [generic_type_declarations]. In the
   case of a type declaration, the use of [nonrec_flag] means that [NONREC] may
   be absent or present, whereas in the case of a type substitution, the use of
   [no_nonrec_flag] means that [NONREC] must be absent. The use of [type_kind]
   versus [type_subst_kind] means that in the first case, we expect an [EQUAL]
   sign, whereas in the second case, we expect [COLONEQUAL]. *)

%inline type_declarations:
  generic_type_declarations(nonrec_flag, type_kind)
    { $1 }
;

%inline type_subst_declarations:
  generic_type_declarations(no_nonrec_flag, type_subst_kind)
    { $1 }
;

(* A set of type declarations or substitutions begins with a
   [generic_type_declaration] and continues with a possibly empty list of
   [generic_and_type_declaration]s. *)

%inline generic_type_declarations(flag, kind):
  xlist(
    generic_type_declaration(flag, kind),
    generic_and_type_declaration(kind)
  )
  { $1 }
;

(* [generic_type_declaration] and [generic_and_type_declaration] look similar,
   but are in reality different enough that it is difficult to share anything
   between them. *)

generic_type_declaration(flag, kind):
  TYPE
  ext = ext
  attrs1 = attributes
  flag = flag
  params = type_parameters
  id = mkrhs(LIDENT)
  kind_priv_manifest = kind
  cstrs = constraints
  attrs2 = post_item_attributes
    {
      let (kind, priv, manifest) = kind_priv_manifest in
      let docs = symbol_docs $sloc in
      let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      (flag, ext),
      Type.mk id ~params ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs
    }
;
%inline generic_and_type_declaration(kind):
  AND
  attrs1 = attributes
  params = type_parameters
  id = mkrhs(LIDENT)
  kind_priv_manifest = kind
  cstrs = constraints
  attrs2 = post_item_attributes
    {
      let (kind, priv, manifest) = kind_priv_manifest in
      let docs = symbol_docs $sloc in
      let attrs = attrs1 @ attrs2 in
      let loc = make_loc $sloc in
      let text = symbol_text $symbolstartpos in
      Type.mk id ~params ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs ~text
    }
;
%inline constraints:
  llist(preceded(CONSTRAINT, constrain))
    { $1 }
;
(* Lots of %inline expansion are required for [nonempty_type_kind] to be
   LR(1). At the cost of some manual expansion, it would be possible to give a
   definition that leads to a smaller grammar (after expansion) and therefore
   a smaller automaton. *)
nonempty_type_kind:
  | priv = inline_private_flag
    ty = core_type
      { (Ptype_abstract, priv, Some ty) }
  | oty = type_synonym
    priv = inline_private_flag
    cs = constructor_declarations
      { (Ptype_variant cs, priv, oty) }
  | oty = type_synonym
    priv = inline_private_flag
    DOTDOT
      { (Ptype_open, priv, oty) }
  | oty = type_synonym
    priv = inline_private_flag
    LBRACE ls = label_declarations RBRACE
      { (Ptype_record ls, priv, oty) }
;
%inline type_synonym:
  ioption(terminated(core_type, EQUAL))
    { $1 }
;
type_kind:
    /*empty*/
      { (Ptype_abstract, Public, None) }
  | EQUAL nonempty_type_kind
      { $2 }
;
%inline type_subst_kind:
    COLONEQUAL nonempty_type_kind
      { $2 }
;
type_parameters:
    /* empty */
      { [] }
  | p = type_parameter
      { [p] }
  | LPAREN ps = separated_nonempty_llist(COMMA, type_parameter) RPAREN
      { ps }
;
type_parameter:
    type_variance type_variable        { $2, $1 }
;
type_variable:
  mktyp(
    QUOTE tyvar = ident
      { Ptyp_var tyvar }
  | UNDERSCORE
      { Ptyp_any }
  ) { $1 }
;

type_variance:
    /* empty */                             { NoVariance, NoInjectivity }
  | PLUS                                    { Covariant, NoInjectivity }
  | MINUS                                   { Contravariant, NoInjectivity }
  | BANG                                    { NoVariance, Injective }
  | PLUS BANG | BANG PLUS                   { Covariant, Injective }
  | MINUS BANG | BANG MINUS                 { Contravariant, Injective }
  | INFIXOP2
      { if $1 = ""+!"" then Covariant, Injective else
        if $1 = ""-!"" then Contravariant, Injective else
        expecting $loc($1) ""type_variance"" }
  | PREFIXOP
      { if $1 = ""!+"" then Covariant, Injective else
        if $1 = ""!-"" then Contravariant, Injective else
        expecting $loc($1) ""type_variance"" }
;

(* A sequence of constructor declarations is either a single BAR, which
   means that the list is empty, or a nonempty BAR-separated list of
   declarations, with an optional leading BAR. *)
constructor_declarations:
  | BAR
      { [] }
  | cs = bar_llist(constructor_declaration)
      { cs }
;
(* A constructor declaration begins with an opening symbol, which can
   be either epsilon or BAR. Note that this opening symbol is included
   in the footprint $sloc. *)
(* Because [constructor_declaration] and [extension_constructor_declaration]
   are identical except for their semantic actions, we introduce the symbol
   [generic_constructor_declaration], whose semantic action is neutral -- it
   merely returns a tuple. *)
generic_constructor_declaration(opening):
  opening
  cid = mkrhs(constr_ident)
  vars_args_res = generalized_constructor_arguments
  attrs = attributes
    {
      let vars, args, res = vars_args_res in
      let info = symbol_info $endpos in
      let loc = make_loc $sloc in
      cid, vars, args, res, attrs, loc, info
    }
;
%inline constructor_declaration(opening):
  d = generic_constructor_declaration(opening)
    {
      let cid, vars, args, res, attrs, loc, info = d in
      Type.constructor cid ~vars ~args ?res ~attrs ~loc ~info
    }
;
str_exception_declaration:
  sig_exception_declaration
    { $1 }
| EXCEPTION
  ext = ext
  attrs1 = attributes
  id = mkrhs(constr_ident)
  EQUAL
  lid = mkrhs(constr_longident)
  attrs2 = attributes
  attrs = post_item_attributes
  { let loc = make_loc $sloc in
    let docs = symbol_docs $sloc in
    Te.mk_exception ~attrs
      (Te.rebind id lid ~attrs:(attrs1 @ attrs2) ~loc ~docs)
    , ext }
;
sig_exception_declaration:
  EXCEPTION
  ext = ext
  attrs1 = attributes
  id = mkrhs(constr_ident)
  vars_args_res = generalized_constructor_arguments
  attrs2 = attributes
  attrs = post_item_attributes
    { let vars, args, res = vars_args_res in
      let loc = make_loc ($startpos, $endpos(attrs2)) in
      let docs = symbol_docs $sloc in
      Te.mk_exception ~attrs
        (Te.decl id ~vars ~args ?res ~attrs:(attrs1 @ attrs2) ~loc ~docs)
      , ext }
;
%inline let_exception_declaration:
    mkrhs(constr_ident) generalized_constructor_arguments attributes
      { let vars, args, res = $2 in
        Te.decl $1 ~vars ~args ?res ~attrs:$3 ~loc:(make_loc $sloc) }
;
generalized_constructor_arguments:
    /*empty*/                     { ([],Pcstr_tuple [],None) }
  | OF constructor_arguments      { ([],$2,None) }
  | COLON constructor_arguments MINUSGREATER atomic_type %prec below_HASH
                                  { ([],$2,Some $4) }
  | COLON typevar_list DOT constructor_arguments MINUSGREATER atomic_type
     %prec below_HASH
                                  { ($2,$4,Some $6) }
  | COLON atomic_type %prec below_HASH
                                  { ([],Pcstr_tuple [],Some $2) }
  | COLON typevar_list DOT atomic_type %prec below_HASH
                                  { ($2,Pcstr_tuple [],Some $4) }
;

constructor_arguments:
  | tys = inline_separated_nonempty_llist(STAR, atomic_type)
    %prec below_HASH
      { Pcstr_tuple tys }
  | LBRACE label_declarations RBRACE
      { Pcstr_record $2 }
;
label_declarations:
    label_declaration                           { [$1] }
  | label_declaration_semi                      { [$1] }
  | label_declaration_semi label_declarations   { $1 :: $2 }
;
label_declaration:
    mutable_flag mkrhs(label) COLON poly_type_no_attr attributes
      { let info = symbol_info $endpos in
        Type.field $2 $4 ~mut:$1 ~attrs:$5 ~loc:(make_loc $sloc) ~info }
;
label_declaration_semi:
    mutable_flag mkrhs(label) COLON poly_type_no_attr attributes SEMI attributes
      { let info =
          match rhs_info $endpos($5) with
          | Some _ as info_before_semi -> info_before_semi
          | None -> symbol_info $endpos
       in
       Type.field $2 $4 ~mut:$1 ~attrs:($5 @ $7) ~loc:(make_loc $sloc) ~info }
;

/* Type Extensions */

%inline str_type_extension:
  type_extension(extension_constructor)
    { $1 }
;
%inline sig_type_extension:
  type_extension(extension_constructor_declaration)
    { $1 }
;
%inline type_extension(declaration):
  TYPE
  ext = ext
  attrs1 = attributes
  no_nonrec_flag
  params = type_parameters
  tid = mkrhs(type_longident)
  PLUSEQ
  priv = private_flag
  cs = bar_llist(declaration)
  attrs2 = post_item_attributes
    { let docs = symbol_docs $sloc in
      let attrs = attrs1 @ attrs2 in
      Te.mk tid cs ~params ~priv ~attrs ~docs,
      ext }
;
%inline extension_constructor(opening):
    extension_constructor_declaration(opening)
      { $1 }
  | extension_constructor_rebind(opening)
      { $1 }
;
%inline extension_constructor_declaration(opening):
  d = generic_constructor_declaration(opening)
    {
      let cid, vars, args, res, attrs, loc, info = d in
      Te.decl cid ~vars ~args ?res ~attrs ~loc ~info
    }
;
extension_constructor_rebind(opening):
  opening
  cid = mkrhs(constr_ident)
  EQUAL
  lid = mkrhs(constr_longident)
  attrs = attributes
      { let info = symbol_info $endpos in
        Te.rebind cid lid ~attrs ~loc:(make_loc $sloc) ~info }
;

/* ""with"" constraints (additional type equations over signature components) */

with_constraint:
    TYPE type_parameters mkrhs(label_longident) with_type_binder
    core_type_no_attr constraints
      { let lident = loc_last $3 in
        Pwith_type
          ($3,
           (Type.mk lident
              ~params:$2
              ~cstrs:$6
              ~manifest:$5
              ~priv:$4
              ~loc:(make_loc $sloc))) }
    /* used label_longident instead of type_longident to disallow
       functor applications in type path */
  | TYPE type_parameters mkrhs(label_longident)
    COLONEQUAL core_type_no_attr
      { let lident = loc_last $3 in
        Pwith_typesubst
         ($3,
           (Type.mk lident
              ~params:$2
              ~manifest:$5
              ~loc:(make_loc $sloc))) }
  | MODULE mkrhs(mod_longident) EQUAL mkrhs(mod_ext_longident)
      { Pwith_module ($2, $4) }
  | MODULE mkrhs(mod_longident) COLONEQUAL mkrhs(mod_ext_longident)
      { Pwith_modsubst ($2, $4) }
  | MODULE TYPE l=mkrhs(mty_longident) EQUAL rhs=module_type
      { Pwith_modtype (l, rhs) }
  | MODULE TYPE l=mkrhs(mty_longident) COLONEQUAL rhs=module_type
      { Pwith_modtypesubst (l, rhs) }
;
with_type_binder:
    EQUAL          { Public }
  | EQUAL PRIVATE  { Private }
;

/* Polymorphic types */

%inline typevar:
  QUOTE mkrhs(ident)
    { $2 }
;
%inline typevar_list:
  nonempty_llist(typevar)
    { $1 }
;
%inline poly(X):
  typevar_list DOT X
    { Ptyp_poly($1, $3) }
;
possibly_poly(X):
  X
    { $1 }
| mktyp(poly(X))
    { $1 }
;
%inline poly_type:
  possibly_poly(core_type)
    { $1 }
;
%inline poly_type_no_attr:
  possibly_poly(core_type_no_attr)
    { $1 }
;

(* -------------------------------------------------------------------------- *)

(* Core language types. *)

(* A core type (core_type) is a core type without attributes (core_type_no_attr)
   followed with a list of attributes. *)
core_type:
    core_type_no_attr
      { $1 }
  | core_type attribute
      { Typ.attr $1 $2 }
;

(* A core type without attributes is currently defined as an alias type, but
   this could change in the future if new forms of types are introduced. From
   the outside, one should use core_type_no_attr. *)
%inline core_type_no_attr:
  alias_type
    { $1 }
;

(* Alias types include:
   - function types (see below);
   - proper alias types:                  'a -> int as 'a
 *)
alias_type:
    function_type
      { $1 }
  | mktyp(
      ty = alias_type AS QUOTE tyvar = ident
        { Ptyp_alias(ty, tyvar) }
    )
    { $1 }
;

(* Function types include:
   - tuple types (see below);
   - proper function types:               int -> int
                                          foo: int -> int
                                          ?foo: int -> int
 *)
function_type:
  | ty = tuple_type
    %prec MINUSGREATER
      { ty }
  | mktyp(
      label = arg_label
      domain = extra_rhs(tuple_type)
      MINUSGREATER
      codomain = function_type
        { Ptyp_arrow(label, domain, codomain) }
    )
    { $1 }
;
%inline arg_label:
  | label = optlabel
      { Optional label }
  | label = LIDENT COLON
      { Labelled label }
  | /* empty */
      { Nolabel }
;
(* Tuple types include:
   - atomic types (see below);
   - proper tuple types:                  int * int * int list
   A proper tuple type is a star-separated list of at least two atomic types.
 *)
tuple_type:
  | ty = atomic_type
    %prec below_HASH
      { ty }
  | mktyp(
      tys = separated_nontrivial_llist(STAR, atomic_type)
        { Ptyp_tuple tys }
    )
    { $1 }
;

(* Atomic types are the most basic level in the syntax of types.
   Atomic types include:
   - types between parentheses:           (int -> int)
   - first-class module types:            (module S)
   - type variables:                      'a
   - applications of type constructors:   int, int list, int option list
   - variant types:                       [`A]
 *)
atomic_type:
  | LPAREN core_type RPAREN
      { $2 }
  | LPAREN MODULE ext_attributes package_type RPAREN
      { wrap_typ_attrs ~loc:$sloc (reloc_typ ~loc:$sloc $4) $3 }
  | mktyp( /* begin mktyp group */
      QUOTE ident
        { Ptyp_var $2 }
    | UNDERSCORE
        { Ptyp_any }
    | tys = actual_type_parameters
      tid = mkrhs(type_longident)
        { Ptyp_constr(tid, tys) }
    | LESS meth_list GREATER
        { let (f, c) = $2 in Ptyp_object (f, c) }
    | LESS GREATER
        { Ptyp_object ([], Closed) }
    | tys = actual_type_parameters
      HASH
      cid = mkrhs(clty_longident)
        { Ptyp_class(cid, tys) }
    | LBRACKET tag_field RBRACKET
        (* not row_field; see CONFLICTS *)
        { Ptyp_variant([$2], Closed, None) }
    | LBRACKET BAR row_field_list RBRACKET
        { Ptyp_variant($3, Closed, None) }
    | LBRACKET row_field BAR row_field_list RBRACKET
        { Ptyp_variant($2 :: $4, Closed, None) }
    | LBRACKETGREATER BAR? row_field_list RBRACKET
        { Ptyp_variant($3, Open, None) }
    | LBRACKETGREATER RBRACKET
        { Ptyp_variant([], Open, None) }
    | LBRACKETLESS BAR? row_field_list RBRACKET
        { Ptyp_variant($3, Closed, Some []) }
    | LBRACKETLESS BAR? row_field_list GREATER name_tag_list RBRACKET
        { Ptyp_variant($3, Closed, Some $5) }
    | extension
        { Ptyp_extension $1 }
  )
  { $1 } /* end mktyp group */
;

(* This is the syntax of the actual type parameters in an application of
   a type constructor, such as int, int list, or (int, bool) Hashtbl.t.
   We allow one of the following:
   - zero parameters;
   - one parameter:
     an atomic type;
     among other things, this can be an arbitrary type between parentheses;
   - two or more parameters:
     arbitrary types, between parentheses, separated with commas.
 *)
%inline actual_type_parameters:
  | /* empty */
      { [] }
  | ty = atomic_type
      { [ty] }
  | LPAREN tys = separated_nontrivial_llist(COMMA, core_type) RPAREN
      { tys }
;

%inline package_type: module_type
      { let (lid, cstrs, attrs) = package_type_of_module_type $1 in
        let descr = Ptyp_package (lid, cstrs) in
        mktyp ~loc:$sloc ~attrs descr }
;
%inline row_field_list:
  separated_nonempty_llist(BAR, row_field)
    { $1 }
;
row_field:
    tag_field
      { $1 }
  | core_type
      { Rf.inherit_ ~loc:(make_loc $sloc) $1 }
;
tag_field:
    mkrhs(name_tag) OF opt_ampersand amper_type_list attributes
      { let info = symbol_info $endpos in
        let attrs = add_info_attrs info $5 in
        Rf.tag ~loc:(make_loc $sloc) ~attrs $1 $3 $4 }
  | mkrhs(name_tag) attributes
      { let info = symbol_info $endpos in
        let attrs = add_info_attrs info $2 in
        Rf.tag ~loc:(make_loc $sloc) ~attrs $1 true [] }
;
opt_ampersand:
    AMPERSAND                                   { true }
  | /* empty */                                 { false }
;
%inline amper_type_list:
  separated_nonempty_llist(AMPERSAND, core_type_no_attr)
    { $1 }
;
%inline name_tag_list:
  nonempty_llist(name_tag)
    { $1 }
;
(* A method list (in an object type). *)
meth_list:
    head = field_semi         tail = meth_list
  | head = inherit_field SEMI tail = meth_list
      { let (f, c) = tail in (head :: f, c) }
  | head = field_semi
  | head = inherit_field SEMI
      { [head], Closed }
  | head = field
  | head = inherit_field
      { [head], Closed }
  | DOTDOT
      { [], Open }
;
%inline field:
  mkrhs(label) COLON poly_type_no_attr attributes
    { let info = symbol_info $endpos in
      let attrs = add_info_attrs info $4 in
      Of.tag ~loc:(make_loc $sloc) ~attrs $1 $3 }
;

%inline field_semi:
  mkrhs(label) COLON poly_type_no_attr attributes SEMI attributes
    { let info =
        match rhs_info $endpos($4) with
        | Some _ as info_before_semi -> info_before_semi
        | None -> symbol_info $endpos
      in
      let attrs = add_info_attrs info ($4 @ $6) in
      Of.tag ~loc:(make_loc $sloc) ~attrs $1 $3 }
;

%inline inherit_field:
  ty = atomic_type
    { Of.inherit_ ~loc:(make_loc $sloc) ty }
;

%inline label:
    LIDENT                                      { $1 }
;

/* Constants */

constant:
  | INT          { let (n, m) = $1 in Pconst_integer (n, m) }
  | CHAR         { Pconst_char $1 }
  | STRING       { let (s, strloc, d) = $1 in Pconst_string (s, strloc, d) }
  | FLOAT        { let (f, m) = $1 in Pconst_float (f, m) }
;
signed_constant:
    constant     { $1 }
  | MINUS INT    { let (n, m) = $2 in Pconst_integer(""-"" ^ n, m) }
  | MINUS FLOAT  { let (f, m) = $2 in Pconst_float(""-"" ^ f, m) }
  | PLUS INT     { let (n, m) = $2 in Pconst_integer (n, m) }
  | PLUS FLOAT   { let (f, m) = $2 in Pconst_float(f, m) }
;

/* Identifiers and long identifiers */

ident:
    UIDENT                    { $1 }
  | LIDENT                    { $1 }
;
val_extra_ident:
  | LPAREN operator RPAREN    { $2 }
  | LPAREN operator error     { unclosed ""("" $loc($1) "")"" $loc($3) }
  | LPAREN error              { expecting $loc($2) ""operator"" }
  | LPAREN MODULE error       { expecting $loc($3) ""module-expr"" }
;
val_ident:
    LIDENT                    { $1 }
  | val_extra_ident           { $1 }
;
operator:
    PREFIXOP                                    { $1 }
  | LETOP                                       { $1 }
  | ANDOP                                       { $1 }
  | DOTOP LPAREN index_mod RPAREN               { "".""^ $1 ^""("" ^ $3 ^ "")"" }
  | DOTOP LPAREN index_mod RPAREN LESSMINUS     { "".""^ $1 ^ ""("" ^ $3 ^ "")<-"" }
  | DOTOP LBRACKET index_mod RBRACKET           { "".""^ $1 ^""["" ^ $3 ^ ""]"" }
  | DOTOP LBRACKET index_mod RBRACKET LESSMINUS { "".""^ $1 ^ ""["" ^ $3 ^ ""]<-"" }
  | DOTOP LBRACE index_mod RBRACE               { "".""^ $1 ^""{"" ^ $3 ^ ""}"" }
  | DOTOP LBRACE index_mod RBRACE LESSMINUS     { "".""^ $1 ^ ""{"" ^ $3 ^ ""}<-"" }
  | HASHOP                                      { $1 }
  | BANG                                        { ""!"" }
  | infix_operator                              { $1 }
;
%inline infix_operator:
  | op = INFIXOP0 { op }
  | op = INFIXOP1 { op }
  | op = INFIXOP2 { op }
  | op = INFIXOP3 { op }
  | op = INFIXOP4 { op }
  | PLUS           {""+""}
  | PLUSDOT       {""+.""}
  | PLUSEQ        {""+=""}
  | MINUS          {""-""}
  | MINUSDOT      {""-.""}
  | STAR           {""*""}
  | PERCENT        {""%""}
  | EQUAL          {""=""}
  | LESS           {""<""}
  | GREATER        {"">""}
  | OR            {""or""}
  | BARBAR        {""||""}
  | AMPERSAND      {""&""}
  | AMPERAMPER    {""&&""}
  | COLONEQUAL    {"":=""}
;
index_mod:
| { """" }
| SEMI DOTDOT { "";.."" }
;

%inline constr_extra_ident:
  | LPAREN COLONCOLON RPAREN                    { ""::"" }
;
constr_extra_nonprefix_ident:
  | LBRACKET RBRACKET                           { ""[]"" }
  | LPAREN RPAREN                               { ""()"" }
  | FALSE                                       { ""false"" }
  | TRUE                                        { ""true"" }
;
constr_ident:
    UIDENT                                      { $1 }
  | constr_extra_ident                          { $1 }
  | constr_extra_nonprefix_ident                { $1 }
;
constr_longident:
    mod_longident       %prec below_DOT  { $1 } /* A.B.x vs (A).B.x */
  | mod_longident DOT constr_extra_ident { Ldot($1,$3) }
  | constr_extra_ident                   { Lident $1 }
  | constr_extra_nonprefix_ident         { Lident $1 }
;
mk_longident(prefix,final):
   | final            { Lident $1 }
   | prefix DOT final { Ldot($1,$3) }
;
val_longident:
    mk_longident(mod_longident, val_ident) { $1 }
;
label_longident:
    mk_longident(mod_longident, LIDENT) { $1 }
;
type_longident:
    mk_longident(mod_ext_longident, LIDENT)  { $1 }
;
mod_longident:
    mk_longident(mod_longident, UIDENT)  { $1 }
;
mod_ext_longident:
    mk_longident(mod_ext_longident, UIDENT) { $1 }
  | mod_ext_longident LPAREN mod_ext_longident RPAREN
      { lapply ~loc:$sloc $1 $3 }
  | mod_ext_longident LPAREN error
      { expecting $loc($3) ""module path"" }
;
mty_longident:
    mk_longident(mod_ext_longident,ident) { $1 }
;
clty_longident:
    mk_longident(mod_ext_longident,LIDENT) { $1 }
;
class_longident:
   mk_longident(mod_longident,LIDENT) { $1 }
;

/* BEGIN AVOID */
/* For compiler-libs: parse all valid longidents and a little more:
   final identifiers which are value specific are accepted even when
   the path prefix is only valid for types: (e.g. F(X).(::)) */
any_longident:
  | mk_longident (mod_ext_longident,
     ident | constr_extra_ident | val_extra_ident { $1 }
    ) { $1 }
  | constr_extra_nonprefix_ident { Lident $1 }
;
/* END AVOID */

/* Toplevel directives */

toplevel_directive:
  HASH dir = mkrhs(ident)
  arg = ioption(mk_directive_arg(toplevel_directive_argument))
    { mk_directive ~loc:$sloc dir arg }
;

%inline toplevel_directive_argument:
  | STRING        { let (s, _, _) = $1 in Pdir_string s }
  | INT           { let (n, m) = $1 in Pdir_int (n ,m) }
  | val_longident { Pdir_ident $1 }
  | mod_longident { Pdir_ident $1 }
  | FALSE         { Pdir_bool false }
  | TRUE          { Pdir_bool true }
;

/* Miscellaneous */

(* The symbol epsilon can be used instead of an /* empty */ comment. *)
%inline epsilon:
  /* empty */
    { () }
;

%inline raw_string:
  s = STRING
    { let body, _, _ = s in body }
;

name_tag:
    BACKQUOTE ident                             { $2 }
;
rec_flag:
    /* empty */                                 { Nonrecursive }
  | REC                                         { Recursive }
;
%inline nonrec_flag:
    /* empty */                                 { Recursive }
  | NONREC                                      { Nonrecursive }
;
%inline no_nonrec_flag:
    /* empty */ { Recursive }
/* BEGIN AVOID */
  | NONREC      { not_expecting $loc ""nonrec flag"" }
/* END AVOID */
;
direction_flag:
    TO                                          { Upto }
  | DOWNTO                                      { Downto }
;
private_flag:
  inline_private_flag
    { $1 }
;
%inline inline_private_flag:
    /* empty */                                 { Public }
  | PRIVATE                                     { Private }
;
mutable_flag:
    /* empty */                                 { Immutable }
  | MUTABLE                                     { Mutable }
;
virtual_flag:
    /* empty */                                 { Concrete }
  | VIRTUAL                                     { Virtual }
;
mutable_virtual_flags:
    /* empty */
      { Immutable, Concrete }
  | MUTABLE
      { Mutable, Concrete }
  | VIRTUAL
      { Immutable, Virtual }
  | MUTABLE VIRTUAL
  | VIRTUAL MUTABLE
      { Mutable, Virtual }
;
private_virtual_flags:
    /* empty */  { Public, Concrete }
  | PRIVATE { Private, Concrete }
  | VIRTUAL { Public, Virtual }
  | PRIVATE VIRTUAL { Private, Virtual }
  | VIRTUAL PRIVATE { Private, Virtual }
;
(* This nonterminal symbol indicates the definite presence of a VIRTUAL
   keyword and the possible presence of a MUTABLE keyword. *)
virtual_with_mutable_flag:
  | VIRTUAL { Immutable }
  | MUTABLE VIRTUAL { Mutable }
  | VIRTUAL MUTABLE { Mutable }
;
(* This nonterminal symbol indicates the definite presence of a VIRTUAL
   keyword and the possible presence of a PRIVATE keyword. *)
virtual_with_private_flag:
  | VIRTUAL { Public }
  | PRIVATE VIRTUAL { Private }
  | VIRTUAL PRIVATE { Private }
;
%inline no_override_flag:
    /* empty */                                 { Fresh }
;
%inline override_flag:
    /* empty */                                 { Fresh }
  | BANG                                        { Override }
;
subtractive:
  | MINUS                                       { ""-"" }
  | MINUSDOT                                    { ""-."" }
;
additive:
  | PLUS                                        { ""+"" }
  | PLUSDOT                                     { ""+."" }
;
optlabel:
   | OPTLABEL                                   { $1 }
   | QUESTION LIDENT COLON                      { $2 }
;

/* Attributes and extensions */

single_attr_id:
    LIDENT { $1 }
  | UIDENT { $1 }
  | AND { ""and"" }
  | AS { ""as"" }
  | ASSERT { ""assert"" }
  | BEGIN { ""begin"" }
  | CLASS { ""class"" }
  | CONSTRAINT { ""constraint"" }
  | DO { ""do"" }
  | DONE { ""done"" }
  | DOWNTO { ""downto"" }
  | ELSE { ""else"" }
  | END { ""end"" }
  | EXCEPTION { ""exception"" }
  | EXTERNAL { ""external"" }
  | FALSE { ""false"" }
  | FOR { ""for"" }
  | FUN { ""fun"" }
  | FUNCTION { ""function"" }
  | FUNCTOR { ""functor"" }
  | IF { ""if"" }
  | IN { ""in"" }
  | INCLUDE { ""include"" }
  | INHERIT { ""inherit"" }
  | INITIALIZER { ""initializer"" }
  | LAZY { ""lazy"" }
  | LET { ""let"" }
  | MATCH { ""match"" }
  | METHOD { ""method"" }
  | MODULE { ""module"" }
  | MUTABLE { ""mutable"" }
  | NEW { ""new"" }
  | NONREC { ""nonrec"" }
  | OBJECT { ""object"" }
  | OF { ""of"" }
  | OPEN { ""open"" }
  | OR { ""or"" }
  | PRIVATE { ""private"" }
  | REC { ""rec"" }
  | SIG { ""sig"" }
  | STRUCT { ""struct"" }
  | THEN { ""then"" }
  | TO { ""to"" }
  | TRUE { ""true"" }
  | TRY { ""try"" }
  | TYPE { ""type"" }
  | VAL { ""val"" }
  | VIRTUAL { ""virtual"" }
  | WHEN { ""when"" }
  | WHILE { ""while"" }
  | WITH { ""with"" }
/* mod/land/lor/lxor/lsl/lsr/asr are not supported for now */
;

attr_id:
  mkloc(
      single_attr_id { $1 }
    | single_attr_id DOT attr_id { $1 ^ ""."" ^ $3.txt }
  ) { $1 }
;
attribute:
  LBRACKETAT attr_id payload RBRACKET
    { Attr.mk ~loc:(make_loc $sloc) $2 $3 }
;
post_item_attribute:
  LBRACKETATAT attr_id payload RBRACKET
    { Attr.mk ~loc:(make_loc $sloc) $2 $3 }
;
floating_attribute:
  LBRACKETATATAT attr_id payload RBRACKET
    { mark_symbol_docs $sloc;
      Attr.mk ~loc:(make_loc $sloc) $2 $3 }
;
%inline post_item_attributes:
  post_item_attribute*
    { $1 }
;
%inline attributes:
  attribute*
    { $1 }
;
ext:
  | /* empty */     { None }
  | PERCENT attr_id { Some $2 }
;
%inline no_ext:
  | /* empty */     { None }
/* BEGIN AVOID */
  | PERCENT attr_id { not_expecting $loc ""extension"" }
/* END AVOID */
;
%inline ext_attributes:
  ext attributes    { $1, $2 }
;
extension:
  | LBRACKETPERCENT attr_id payload RBRACKET { ($2, $3) }
  | QUOTED_STRING_EXPR
    { mk_quotedext ~loc:$sloc $1 }
;
item_extension:
  | LBRACKETPERCENTPERCENT attr_id payload RBRACKET { ($2, $3) }
  | QUOTED_STRING_ITEM
    { mk_quotedext ~loc:$sloc $1 }
;
payload:
    structure { PStr $1 }
  | COLON signature { PSig $2 }
  | COLON core_type { PTyp $2 }
  | QUESTION pattern { PPat ($2, None) }
  | QUESTION pattern WHEN seq_expr { PPat ($2, Some $4) }
;
%%
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* This module is the entry point of the typechecker. It sets up subtyping
   constraints for every expression, statement, and declaration form in a
   JavaScript AST; the subtyping constraints are themselves solved in module
   Flow_js. It also manages environments, including not only the maintenance of
   scope information for every function (pushing/popping scopes, looking up
   variables) but also flow-sensitive information about local variables at every
   point inside a function (and when to narrow or widen their types). *)

open Utils_js

let choose_provider_and_warn_about_duplicates =
  let warn_duplicate_providers m (provider, _) duplicates acc =
    match duplicates with
    | [] -> acc
    | (f, _) :: fs -> SMap.add m (provider, (f, List.map fst fs)) acc
  in
  fun m errmap providers fallback ->
    let (definitions, implementations) =
      let f (key, _) = Files.has_flow_ext key in
      List.partition f providers
    in
    match (implementations, definitions) with
    (* If there are no definitions or implementations, use the fallback *)
    | ([], []) -> (fallback (), errmap)
    (* Else if there are no definitions, use the first implementation *)
    | (impl :: dup_impls, []) -> (Some (snd impl), warn_duplicate_providers m impl dup_impls errmap)
    (* Else use the first definition *)
    | ([], defn :: dup_defns) -> (Some (snd defn), warn_duplicate_providers m defn dup_defns errmap)
    (* Don't complain about the first implementation being a duplicate *)
    | (_impl :: dup_impls, defn :: dup_defns) ->
      let errmap =
        errmap
        |> warn_duplicate_providers m defn dup_impls
        |> warn_duplicate_providers m defn dup_defns
      in
      (Some (snd defn), errmap)

(**
 * A set of module.name_mapper config entry allows users to specify regexp
 * matcher strings each with a template string in order to map the names of a
 * dependency in a JS file to another name before trying to resolve it.
 *
 * The user can specify any number of these mappers, but the one that gets
 * applied to any given module name is the first one whose name matches the
 * regexp string. For the node module system, we go a step further and only
 * choose candidates that match the string *and* are a valid, resolvable path.
 *)
let module_name_candidates_cache = Hashtbl.create 50

let module_name_candidates ~options name =
  match Hashtbl.find_opt module_name_candidates_cache name with
  | Some candidates -> candidates
  | None ->
    let mappers = Options.module_name_mappers options in
    let root = Options.root options in
    let expand_project_root_token = Files.expand_project_root_token ~root in
    let map_name mapped_names (regexp, template) =
      let new_name =
        name
        (* First we apply the mapper *)
        |> Str.global_replace regexp template
        (* Then we replace the PROJECT_ROOT placeholder. *)
        |> expand_project_root_token
      in
      if new_name = name then
        mapped_names
      else
        new_name :: mapped_names
    in
    let candidates = List.rev (name :: List.fold_left map_name [] mappers) in
    Hashtbl.add module_name_candidates_cache name candidates;
    candidates

let add_package filename = function
  | Ok package -> Package_heaps.Package_heap_mutator.add_package_json filename package
  | Error _ -> Package_heaps.Package_heap_mutator.add_error filename

type package_incompatible_reason =
  (* Didn't exist before, now it exists *)
  | New
  (* Was valid, now is invalid *)
  | Became_invalid
  (* Was invalid, now is valid *)
  | Became_valid
  (* The `name` property changed from the former to the latter *)
  | Name_changed of string option * string option
  (* The `main` property changed from the former to the latter *)
  | Main_changed of string option * string option
  | Unknown

let string_of_package_incompatible_reason =
  let string_of_option = function
    | None -> ""<None>""
    | Some x -> x
  in
  function
  | New -> ""new""
  | Became_invalid -> ""became invalid""
  | Became_valid -> ""became valid""
  | Name_changed (old, new_) ->
    Printf.sprintf ""name changed from `%s` to `%s`"" (string_of_option old) (string_of_option new_)
  | Main_changed (old, new_) ->
    Printf.sprintf ""main changed from `%s` to `%s`"" (string_of_option old) (string_of_option new_)
  | Unknown -> ""Unknown""

type package_incompatible_return =
  | Compatible
  | Incompatible of package_incompatible_reason

let package_incompatible ~reader filename new_package =
  let old_package = Package_heaps.Reader.get_package ~reader filename in
  match (old_package, new_package) with
  | (None, Ok _) -> Incompatible New (* didn't exist before, found a new one *)
  | (None, Error _) -> Compatible (* didn't exist before, new one is invalid *)
  | (Some (Error ()), Error _) -> Compatible (* was invalid before, still invalid *)
  | (Some (Error ()), Ok _) -> Incompatible Became_valid (* was invalid before, new one is valid *)
  | (Some (Ok _), Error _) -> Incompatible Became_invalid (* existed before, new one is invalid *)
  | (Some (Ok old_package), Ok new_package) ->
    if old_package = new_package then
      Compatible
    else
      let old_main = Package_json.main old_package in
      let new_main = Package_json.main new_package in
      let old_name = Package_json.name old_package in
      let new_name = Package_json.name new_package in
      if old_name <> new_name then
        Incompatible (Name_changed (old_name, new_name))
      else if old_main <> new_main then
        Incompatible (Main_changed (old_main, new_main))
      else
        (* This shouldn't happen -- if it does, it probably means we need to add cases above *)
        Incompatible Unknown

type resolution_acc = { mutable paths: SSet.t }

(* Specification of a module system. Currently this signature is sufficient to
   model both Haste and Node, but should be further generalized. *)
module type MODULE_SYSTEM = sig
  (* Given a file and docblock info, make the name of the module it exports. *)
  val exported_module : Options.t -> File_key.t -> Docblock.t -> string option

  (* Given a file and a reference in it to an imported module, make the name of
     the module it refers to. If given an optional reference to an accumulator,
     record paths that were looked up but not found during resolution. *)
  val imported_module :
    options:Options.t ->
    reader:Abstract_state_reader.t ->
    SSet.t SMap.t ->
    File_key.t ->
    ?resolution_acc:resolution_acc ->
    string ->
    Modulename.t

  (* for a given module name, choose a provider from among a set of
     files with that exported name. also check for duplicates and
     generate warnings, as dictated by module system rules. *)
  val choose_provider :
    (* module name *)
    string ->
    (* set of candidate provider files *)
    (File_key.t * Parsing_heaps.file_addr) list ->
    (* map from files to error sets (accumulator) *)
    (File_key.t * File_key.t Nel.t) SMap.t ->
    (* file, error map (accumulator) *)
    Parsing_heaps.file_addr option * (File_key.t * File_key.t Nel.t) SMap.t
end

(****************** Node module system *********************)

(* TODO this exists only until we start resolving files using
   NameHeap. unfortunately that will require more refactoring
   than it should, since imported_module is currently called
   during local inference, and simply storing raw module names
   in cx.required et al and looking them up at merge time appears
   to violate some well-hidden private agreements. TODO *)

(* only purpose here is to guarantee a case-sensitive file exists
   and try to keep it from being too horrendously expensive *)

let case_sensitive = not (Sys.file_exists (String.uppercase_ascii (Sys.getcwd ())))

(* map of dirs to file lists *)

(** TODO [perf]: investigate whether this takes too much memory **)
let files_in_dir = ref SMap.empty

(* called from Types_js.typecheck, so we rebuild every time *)
let clear_filename_cache () = files_in_dir := SMap.empty

(* when system is case-insensitive, do our own file exists check *)
let rec file_exists path =
  (* case doesn't matter for ""/"", ""."", ""..."" and these serve as a base-case for
   * case-insensitive filesystems *)
  let dir = Filename.dirname path in
  if
    case_sensitive
    || path = Filename.current_dir_name
    || path = Filename.parent_dir_name
    || path = dir
  then
    Sys.file_exists path
  else
    let files =
      match SMap.find_opt dir !files_in_dir with
      | Some files -> files
      | None ->
        let files =
          if Disk.is_directory dir && file_exists dir then
            SSet.of_list (Array.to_list (Sys.readdir dir))
          else
            SSet.empty
        in
        files_in_dir := SMap.add dir files !files_in_dir;
        files
    in
    SSet.mem (Filename.basename path) files

(*******************************)

module Node = struct
  let exported_module _ _ _ = None

  let record_path path = function
    | None -> ()
    | Some resolution_acc -> resolution_acc.paths <- SSet.add path resolution_acc.paths

  (** [path_if_exists acc path] determines whether [path] (a) has an extension
    Flow cares about, (b) exists, and (c) is not ignored. If [path] does not
    exist, it checks whether [path ^ "".flow""] exists, is not ignored, etc.
    Returns [Some path] if so; if not, adds [path] to [acc] and returns [None].

    Note: if [path ^ "".flow""] exists and [path] does not, returns [Some path],
    not [Some (path ^ "".flow"")]! *)
  let path_if_exists =
    let path_exists ~file_options path =
      file_exists path && (not (Files.is_ignored file_options path)) && not (Sys.is_directory path)
    in
    let is_flow_file ~file_options path = Files.is_flow_file ~options:file_options path in
    fun ~file_options resolution_acc raw_path ->
      let (path, path_to_check) =
        match Sys_utils.realpath raw_path with
        | Some path ->
          let is_flow = is_flow_file ~file_options path in
          (path, Base.Option.some_if is_flow path)
        | None ->
          let decl_path = raw_path ^ Files.flow_ext in
          let is_flow = is_flow_file ~file_options raw_path && Sys.file_exists decl_path in
          (raw_path, Base.Option.some_if is_flow decl_path)
      in
      if Base.Option.exists ~f:(path_exists ~file_options) path_to_check then
        Some (Files.eponymous_module (Files.filename_from_string ~options:file_options path))
      else (
        record_path path resolution_acc;
        None
      )

  let path_if_exists_with_file_exts ~file_options resolution_acc path file_exts =
    lazy_seq
      (file_exts
      |> Base.List.map ~f:(fun ext ->
             lazy (path_if_exists ~file_options resolution_acc (path ^ ext))
         )
      )

  let parse_main ~reader ~file_options resolution_acc package_filename file_exts =
    let%bind.Base.Option package_filename = Sys_utils.realpath package_filename in
    let package =
      match Package_heaps.Reader_dispatcher.get_package ~reader package_filename with
      | Some (Ok package) -> package
      | Some (Error ()) ->
        (* invalid, but we already raised an error when building PackageHeap *)
        Package_json.empty
      | None -> Package_json.empty
    in
    match Package_json.main package with
    | None -> None
    | Some file ->
      let dir = Filename.dirname package_filename in
      let path = Files.normalize_path dir file in
      let path_w_index = Filename.concat path ""index"" in
      lazy_seq
        [
          lazy (path_if_exists ~file_options resolution_acc path);
          lazy (path_if_exists_with_file_exts ~file_options resolution_acc path file_exts);
          lazy (path_if_exists_with_file_exts ~file_options resolution_acc path_w_index file_exts);
        ]

  let resolve_relative ~options ~reader ?resolution_acc root_path rel_path =
    let file_options = Options.file_options options in
    let path = Files.normalize_path root_path rel_path in
    (* We do not try resource file extensions here. So while you can write
     * require('foo') to require foo.js, it should never resolve to foo.css
     *)
    let file_exts = Files.module_file_exts file_options in
    lazy_seq
      [
        lazy (path_if_exists ~file_options resolution_acc path);
        lazy (path_if_exists_with_file_exts ~file_options resolution_acc path file_exts);
        lazy
          (parse_main
             ~reader
             ~file_options
             resolution_acc
             (Filename.concat path ""package.json"")
             file_exts
          );
        lazy
          (path_if_exists_with_file_exts
             ~file_options
             resolution_acc
             (Filename.concat path ""index"")
             file_exts
          );
      ]

  let rec node_module ~options ~reader node_modules_containers file resolution_acc dir r =
    let file_options = Options.file_options options in
    lazy_seq
      [
        lazy
          (match SMap.find_opt dir node_modules_containers with
          | Some existing_node_modules_dirs ->
            lazy_seq
              (Files.node_resolver_dirnames file_options
              |> Base.List.map ~f:(fun dirname ->
                     lazy
                       ( if SSet.mem dirname existing_node_modules_dirs then
                         resolve_relative
                           ~options
                           ~reader
                           ?resolution_acc
                           dir
                           (spf ""%s%s%s"" dirname Filename.dir_sep r)
                       else
                         None
                       )
                 )
              )
          | None -> None);
        lazy
          (let parent_dir = Filename.dirname dir in
           if dir = parent_dir then
             None
           else
             node_module
               ~options
               ~reader
               node_modules_containers
               file
               resolution_acc
               (Filename.dirname dir)
               r
          );
      ]

  let absolute r = Str.string_match Files.absolute_path_regexp r 0

  let explicitly_relative r =
    Str.string_match Files.current_dir_name r 0 || Str.string_match Files.parent_dir_name r 0

  let resolve_import ~options ~reader node_modules_containers f ?resolution_acc import_str =
    let file = File_key.to_string f in
    let dir = Filename.dirname file in
    let root_str = Options.root options |> Path.to_string in
    if explicitly_relative import_str || absolute import_str then
      resolve_relative ~options ~reader ?resolution_acc dir import_str
    else
      lazy_seq
        [
          lazy
            ( if Options.node_resolver_allow_root_relative options then
              lazy_seq
                (Options.node_resolver_root_relative_dirnames options
                |> Base.List.map ~f:(fun root_relative_dirname ->
                       lazy
                         (let root_str =
                            if root_relative_dirname = """" then
                              root_str
                            else
                              Filename.concat root_str root_relative_dirname
                          in
                          resolve_relative ~options ~reader ?resolution_acc root_str import_str
                         )
                   )
                )
            else
              None
            );
          lazy (node_module ~options ~reader node_modules_containers f resolution_acc dir import_str);
        ]

  let imported_module ~options ~reader node_modules_containers file ?resolution_acc r =
    match
      List.find_map
        (resolve_import ~options ~reader node_modules_containers file ?resolution_acc)
        (module_name_candidates ~options r)
    with
    | Some m -> m
    | None -> Modulename.String r

  (* in node, file names are module names, as guaranteed by
     our implementation of exported_name, so anything but a
     singleton provider set is craziness. *)
  let choose_provider m files errmap =
    let fallback () = None in
    choose_provider_and_warn_about_duplicates m errmap files fallback
end

(****************** Haste module system *********************)

module Haste : MODULE_SYSTEM = struct
  let short_module_name_of = function
    | File_key.Builtins -> assert false
    | File_key.LibFile file
    | File_key.SourceFile file
    | File_key.JsonFile file
    | File_key.ResourceFile file ->
      Filename.basename file |> Filename.chop_extension

  let is_mock =
    let mock_path = Str.regexp "".*/__mocks__/.*"" in
    function
    | File_key.Builtins -> false
    | File_key.LibFile file
    | File_key.SourceFile file
    | File_key.JsonFile file
    | File_key.ResourceFile file ->
      (* Standardize \ to / in path for Windows *)
      let file = Sys_utils.normalize_filename_dir_sep file in
      Str.string_match mock_path file 0

  let is_haste_file options =
    let includes = lazy (Base.List.map ~f:Str.regexp (Options.haste_paths_includes options)) in
    let excludes = lazy (Base.List.map ~f:Str.regexp (Options.haste_paths_excludes options)) in
    let matches_includes name =
      List.exists (fun r -> Str.string_match r name 0) (Lazy.force includes)
    in
    let matches_excludes name =
      List.exists (fun r -> Str.string_match r name 0) (Lazy.force excludes)
    in
    (fun name -> matches_includes name && not (matches_excludes name))

  let haste_name =
    let reduce_name name (regexp, template) = Str.global_replace regexp template name in
    (fun options name -> List.fold_left reduce_name name (Options.haste_name_reducers options))

  let exported_module options =
    let is_haste_file = is_haste_file options in
    fun file info ->
      match file with
      | File_key.SourceFile _ ->
        if is_mock file then
          Some (short_module_name_of file)
        else if Options.haste_use_name_reducers options then
          (* Standardize \ to / in path for Windows *)
          let normalized_file_name =
            Sys_utils.normalize_filename_dir_sep (File_key.to_string file)
          in
          if is_haste_file normalized_file_name then
            Some (haste_name options normalized_file_name)
          else
            None
        else
          Docblock.providesModule info
      | _ ->
        (* Lib files, resource files, etc don't have any fancy haste name *)
        None

  let resolve_haste_module r =
    match Parsing_heaps.get_haste_module r with
    | Some _ -> Some (Modulename.String r)
    | None -> None

  let resolve_haste_package ~options ~reader file ?resolution_acc r =
    let (dir_opt, rest) =
      match Str.split_delim (Str.regexp_string ""/"") r with
      | [] -> (None, [])
      | package :: rest ->
        (Package_heaps.Reader_dispatcher.get_package_directory ~reader package, rest)
    in
    match dir_opt with
    | None -> None
    | Some package_dir ->
      let file_dirname = Filename.dirname (File_key.to_string file) in
      Files.construct_path package_dir rest
      |> Node.resolve_relative ~options ~reader ?resolution_acc file_dirname

  let resolve_import ~options ~reader node_modules_containers file ?resolution_acc r =
    lazy_seq
      [
        lazy (resolve_haste_module r);
        lazy (resolve_haste_package ~options ~reader file ?resolution_acc r);
        lazy (Node.resolve_import ~options ~reader node_modules_containers file ?resolution_acc r);
      ]

  let imported_module ~options ~reader node_modules_containers file ?resolution_acc r =
    (* For historical reasons, the Haste module system always picks the first
     * matching candidate, unlike the Node module system which picks the first
     * ""valid"" matching candidate. *)
    let r = List.hd (module_name_candidates ~options r) in
    match resolve_import ~options ~reader node_modules_containers file ?resolution_acc r with
    | Some m -> m
    | None -> Modulename.String r

  (* in haste, many files may provide the same module. here we're also
     supporting the notion of mock modules - allowed duplicates used as
     fallbacks. we prefer the non-mock if it exists, otherwise choose an
     arbitrary mock, if any exist. if multiple non-mock providers exist,
     we pick one arbitrarily and issue duplicate module warnings for the
     rest. *)
  let choose_provider m files errmap =
    match files with
    | [] -> (None, errmap)
    | [(_, p)] -> (Some p, errmap)
    | files ->
      let (mocks, non_mocks) =
        let f (key, _) = is_mock key in
        List.partition f files
      in
      let fallback () = Some (snd (List.hd mocks)) in
      choose_provider_and_warn_about_duplicates m errmap non_mocks fallback
end

(****************** module system switch *********************)

(* Switch between module systems, based on environment. We could eventually use
   functors, but that seems like overkill at this point. *)

let module_system = ref None

(* TODO: is it premature optimization to memoize this? how bad is doing the
   Hashtbl.find each time? *)
let get_module_system opts =
  match !module_system with
  | Some system -> system
  | None ->
    let module M =
    ( val match Options.module_system opts with
          | Options.Node -> (module Node : MODULE_SYSTEM)
          | Options.Haste -> (module Haste : MODULE_SYSTEM)
      )
    in
    let system = (module M : MODULE_SYSTEM) in
    module_system := Some system;
    system

let exported_module ~options =
  let module M = (val get_module_system options) in
  M.exported_module options

let imported_module ~options ~reader ~node_modules_containers file ?resolution_acc r =
  let module M = (val get_module_system options) in
  M.imported_module ~options ~reader node_modules_containers file ?resolution_acc r

let choose_provider ~options m files errmap =
  let module M = (val get_module_system options) in
  M.choose_provider m files errmap

(******************)
(***** public *****)
(******************)

(** Resolve references to required modules in a file, and record the results.

    TODO [perf]: measure size and possibly optimize *)
let resolved_requires_of ~options ~reader node_modules_containers file require_loc =
  let resolution_acc = { paths = SSet.empty } in
  let resolved_modules =
    SMap.fold
      (fun mref _locs acc ->
        let m =
          imported_module file mref ~options ~reader ~node_modules_containers ~resolution_acc
        in
        SMap.add mref m acc)
      require_loc
      SMap.empty
  in
  let { paths = phantom_dependencies } = resolution_acc in
  Parsing_heaps.mk_resolved_requires ~resolved_modules ~phantom_dependencies

let add_parsed_resolved_requires ~mutator ~reader ~options ~node_modules_containers file =
  let file_addr = Parsing_heaps.get_file_addr_unsafe file in
  let parse = Parsing_heaps.Mutator_reader.get_typed_parse_unsafe ~reader file file_addr in
  let file_sig = Parsing_heaps.read_file_sig_unsafe file parse |> File_sig.abstractify_locs in
  let require_loc = File_sig.With_ALoc.(require_loc_map file_sig.module_sig) in
  let resolved_requires =
    let reader = Abstract_state_reader.Mutator_state_reader reader in
    resolved_requires_of ~options ~reader node_modules_containers file require_loc
  in
  Parsing_heaps.Resolved_requires_mutator.add_resolved_requires
    mutator
    file_addr
    parse
    resolved_requires

(* Repick providers for modules that are exported by new and changed files, or
   were provided by changed and deleted files.

   For deleted files, their exported modules, if in old modules, will pick a
   new provider, or be left with no provider.

   For changed files, their exported modules, if in old modules, may pick
   the same provider (i.e., the changed file) or a new provider (a different
   file). If not in old modules, they may pick a new provider (i.e., the
   changed file) or the same provider (a different file).

   For new files, their exported modules may pick a new provider (i.e., the new
   file) or the same provider (a different file).

   Suppose that:
   new_or_changed is a list of parsed / unparsed file names.
   old_modules is a set of removed module names.

   Modules provided by parsed / unparsed files may or may not have a
   provider. Modules named in old_modules definitely do not have a
   provider. Together, they are considered ""dirty"" modules. Providers for dirty
   modules must be repicked.

   Files that depend on the subset of dirty modules that either have changed
   providers or are provided by changed files will be rechecked.

   Preconditions:
   1. all files in new_or_changed have entries in InfoHeap (true if
   we're properly calling add_parsed_info and add_unparsed_info for every
   parsed / unparsed file before calling commit_modules)
   2. all modules not mentioned in old_modules, but provided by one or more
   files in InfoHeap, have some provider registered in NameHeap.
   (However, the current provider may not be the one we now want,
   given newly parsed / unparsed files.)
   3. conversely all modules in old_modules lack a provider in NameHeap.

   Postconditions:
   1. all modules provided by at least 1 file in InfoHeap have a provider
   registered in NameHeap, and it's the provider we want according to our
   precedence and scoping rules.

   We make use of a shadow map in the master process which maintains
   a view of what's going on in NameHeap and InfoHeap, mapping module
   names to sets of filenames of providers.
   TODO: this shadow map is probably a perf bottleneck, get rid of it.

   Algorithm here:

   1. Calculate repick set:
   (a) add all removed modules to the set of modules to repick a provider for.
   (b) add the modules provided by all parsed / unparsed files to the repick set.

   2. Commit providers for dirty modules:
   (a) For each module in the repick set, pick a winner from its available
   providers. if it's different than the current provider, or if there is no
   current provider, add the new provider to the list to be registered.
   (b) remove the unregistered modules from NameHeap
   (c) register the new providers in NameHeap
*)
let commit_modules ~transaction ~workers ~options dirty_modules =
  let module Heap = SharedMem.NewAPI in
  let debug = Options.is_debug_mode options in
  let mutator = Parsing_heaps.Commit_modules_mutator.create transaction in
  let f (unchanged, no_providers, errmap) mname =
    let mname_str = Modulename.to_string mname in
    let (provider_ent, all_providers) =
      match mname with
      | Modulename.String name ->
        let m = Parsing_heaps.get_haste_module_unsafe name in
        (Heap.get_haste_provider m, Heap.get_haste_all_providers_exclusive m)
      | Modulename.Filename key ->
        let m = Parsing_heaps.get_file_module_unsafe key in
        (Heap.get_file_provider m, Heap.get_file_all_providers_exclusive m)
    in
    let all_providers =
      let f acc f =
        let key = Parsing_heaps.read_file_key f in
        FilenameMap.add key f acc
      in
      List.fold_left f FilenameMap.empty all_providers |> FilenameMap.bindings
    in
    let old_provider = Heap.entity_read_latest provider_ent in
    let (new_provider, errmap) = choose_provider ~options mname_str all_providers errmap in
    match (old_provider, new_provider) with
    | (_, None) ->
      if debug then prerr_endlinef ""no remaining providers: %s"" mname_str;
      Heap.entity_advance provider_ent None;
      let no_providers = Modulename.Set.add mname no_providers in
      (unchanged, no_providers, errmap)
    | (None, Some p) ->
      (* When can this happen? Either m pointed to a file that used to
         provide m and changed or got deleted (causing m to be in
         old_modules), or m didn't have a provider before. *)
      if debug then
        prerr_endlinef ""initial provider %s -> %s"" mname_str (Parsing_heaps.read_file_name p);
      Heap.entity_advance provider_ent (Some p);
      (unchanged, no_providers, errmap)
    | (Some old_p, Some new_p) ->
      if Heap.files_equal old_p new_p then (
        (* When can this happen? Say m pointed to f before, a different file
           f' that provides m changed (so m is not in old_modules), but f
           continues to be the chosen provider = p (winning over f'). *)
        if debug then
          prerr_endlinef
            ""unchanged provider: %s -> %s""
            mname_str
            (Parsing_heaps.read_file_name new_p);
        let unchanged =
          if Heap.file_changed old_p then
            unchanged
          else
            Modulename.Set.add mname unchanged
        in
        (unchanged, no_providers, errmap)
      ) else (
        (* When can this happen? Say m pointed to f before, a different file
           f' that provides m changed (so m is not in old_modules), and
           now f' becomes the chosen provider = p (winning over f). *)
        if debug then
          prerr_endlinef
            ""new provider: %s -> %s replaces %s""
            mname_str
            (Parsing_heaps.read_file_name new_p)
            (Parsing_heaps.read_file_name old_p);
        Heap.entity_advance provider_ent (Some new_p);
        (unchanged, no_providers, errmap)
      )
  in
  let%lwt (unchanged, no_providers, duplicate_providers) =
    MultiWorkerLwt.call
      workers
      ~job:(List.fold_left f)
      ~neutral:(Modulename.Set.empty, Modulename.Set.empty, SMap.empty)
      ~merge:(fun (a1, a2, a3) (b1, b2, b3) ->
        (Modulename.Set.union a1 b1, Modulename.Set.union a2 b2, SMap.union a3 b3))
      ~next:(MultiWorkerLwt.next workers (Modulename.Set.elements dirty_modules))
  in
  Parsing_heaps.Commit_modules_mutator.record_no_providers mutator no_providers;
  let changed_modules = Modulename.Set.diff dirty_modules unchanged in
  if debug then prerr_endlinef ""*** done committing modules ***"";
  Lwt.return (changed_modules, duplicate_providers)
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

module ImplicitInstantiationKit : Implicit_instantiation.KIT = Implicit_instantiation.Make (struct
  type output = unit

  let on_constant_tparam _ _ = ()

  let on_pinned_tparam _ _ _ = ()

  let on_missing_bounds cx name ~tparam_binder_reason ~instantiation_reason =
    Flow_js.add_output
      cx
      (Error_message.EImplicitInstantiationUnderconstrainedError
         {
           bound = Subst_name.string_of_subst_name name;
           reason_call = instantiation_reason;
           reason_l = tparam_binder_reason;
         }
      )

  let on_upper_non_t cx name u ~tparam_binder_reason ~instantiation_reason:_ =
    let msg =
      Subst_name.string_of_subst_name name
      ^ "" contains a non-Type.t upper bound ""
      ^ Type.string_of_use_ctor u
    in
    Flow_js.add_output
      cx
      (Error_message.EImplicitInstantiationTemporaryError
         (Reason.aloc_of_reason tparam_binder_reason, msg)
      )
end)

let create_cx_with_context_optimizer init_cx master_cx ~reducer ~f =
  let file = Context.file init_cx in
  let metadata = Context.metadata init_cx in
  let aloc_table = Utils_js.FilenameMap.find file (Context.aloc_tables init_cx) in
  let module_ref = Files.module_ref file in
  let ccx = Context.make_ccx master_cx in
  let res = f () in
  Context.merge_into
    ccx
    {
      Type.TypeContext.graph = reducer#get_reduced_graph;
      trust_graph = reducer#get_reduced_trust_graph;
      property_maps = reducer#get_reduced_property_maps;
      call_props = reducer#get_reduced_call_props;
      export_maps = reducer#get_reduced_export_maps;
      evaluated = reducer#get_reduced_evaluated;
    };
  let cx =
    Context.make ccx metadata file aloc_table (Reason.OrdinaryName module_ref) Context.PostInference
  in
  (cx, res)

let detect_sketchy_null_checks cx master_cx =
  let add_error ~loc ~null_loc kind falsy_loc =
    Error_message.ESketchyNullLint { kind; loc; null_loc; falsy_loc } |> Flow_js.add_output cx
  in
  let detect_function exists_excuses loc exists_check =
    ExistsCheck.(
      let exists_excuse =
        Loc_collections.ALocMap.find_opt loc exists_excuses |> Base.Option.value ~default:empty
      in
      match exists_check.null_loc with
      | None -> ()
      | Some null_loc ->
        let add_error = add_error ~loc ~null_loc in
        if Base.Option.is_none exists_excuse.bool_loc then
          Base.Option.iter exists_check.bool_loc ~f:(add_error Lints.SketchyNullBool);
        if Base.Option.is_none exists_excuse.number_loc then
          Base.Option.iter exists_check.number_loc ~f:(add_error Lints.SketchyNullNumber);
        if Base.Option.is_none exists_excuse.string_loc then
          Base.Option.iter exists_check.string_loc ~f:(add_error Lints.SketchyNullString);
        if Base.Option.is_none exists_excuse.mixed_loc then
          Base.Option.iter exists_check.mixed_loc ~f:(add_error Lints.SketchyNullMixed);
        if Base.Option.is_none exists_excuse.enum_bool_loc then
          Base.Option.iter exists_check.enum_bool_loc ~f:(add_error Lints.SketchyNullEnumBool);
        if Base.Option.is_none exists_excuse.enum_number_loc then
          Base.Option.iter exists_check.enum_number_loc ~f:(add_error Lints.SketchyNullEnumNumber);
        if Base.Option.is_none exists_excuse.enum_string_loc then
          Base.Option.iter exists_check.enum_string_loc ~f:(add_error Lints.SketchyNullEnumString);
        ()
    )
  in
  let exists_checks =
    let open Loc_collections in
    let open ExistsCheck in
    let checks = Context.exists_checks cx in
    if not @@ ALocMap.is_empty checks then
      let reducer =
        object
          inherit
            Context_optimizer.context_optimizer
              ~no_lowers:(fun _ r -> Type.EmptyT.make r (Type.bogus_trust ())) as super

          method! type_ cx pole t =
            let open Type in
            match t with
            | ModuleT _
            | EvalT _
            | ThisClassT _
            | TypeDestructorTriggerT _
            | OpenPredT _
            | DefT
                ( _,
                  _,
                  ( InstanceT _ | ClassT _ | FunT _ | ArrT _ | ObjT _ | PolyT _
                  | ReactAbstractComponentT _ )
                ) ->
              t
            | _ -> super#type_ cx pole t
        end
      in

      let (cx, checks) =
        create_cx_with_context_optimizer cx master_cx ~reducer ~f:(fun () ->
            ALocMap.map (Type.TypeSet.map (reducer#type_ cx Polarity.Neutral)) checks
        )
      in

      let rec make_checks seen cur_checks loc t =
        let open Type in
        let open TypeUtil in
        let open Reason in
        match t with
        | AnnotT (_, t, _) -> make_checks seen cur_checks loc t
        | OpenT (_, id) when ISet.mem id seen -> cur_checks
        | OpenT (_, id) ->
          Context.find_resolved cx t
          |> Base.Option.value_map
               ~f:(make_checks (ISet.add id seen) cur_checks loc)
               ~default:cur_checks
        (* Ignore AnyTs for sketchy null checks; otherwise they'd always trigger the lint. *)
        | AnyT _ -> cur_checks
        | GenericT { bound = t; _ }
        | OpaqueT (_, { underlying_t = Some t; _ })
        | OpaqueT (_, { underlying_t = None; super_t = Some t; _ }) ->
          make_checks seen cur_checks loc t
        | MaybeT (r, t) ->
          let acc = make_checks seen cur_checks loc t in
          let acc = make_checks seen acc loc (NullT.why r (Trust.bogus_trust ())) in
          make_checks seen acc loc (VoidT.why r (Trust.bogus_trust ()))
        | OptionalT { reason = r; type_ = t; _ } ->
          let acc = make_checks seen cur_checks loc t in
          make_checks seen acc loc (VoidT.why r (Trust.bogus_trust ()))
        | UnionT (_, rep) ->
          UnionRep.members rep
          |> Base.List.fold ~f:(fun acc t -> make_checks seen acc loc t) ~init:cur_checks
        | _ ->
          let t_loc =
            let reason = reason_of_t t in
            match annot_aloc_of_reason reason with
            | Some loc -> Some loc
            | None -> Some (def_aloc_of_reason reason)
          in
          let exists_check =
            ALocMap.find_opt loc cur_checks |> Base.Option.value ~default:ExistsCheck.empty
          in
          let exists_check =
            match Type_filter.maybe t with
            | DefT (_, _, EmptyT) -> exists_check
            | _ -> { exists_check with null_loc = t_loc }
          in
          let exists_check =
            match t |> Type_filter.not_exists |> Type_filter.not_maybe with
            | DefT (_, _, BoolT _) -> { exists_check with bool_loc = t_loc }
            | DefT (_, _, StrT _) -> { exists_check with string_loc = t_loc }
            | DefT (_, _, NumT _) -> { exists_check with number_loc = t_loc }
            | DefT (_, _, MixedT _) -> { exists_check with mixed_loc = t_loc }
            | DefT (_, _, EnumT { representation_t = DefT (_, _, BoolT _); _ }) ->
              { exists_check with enum_bool_loc = t_loc }
            | DefT (_, _, EnumT { representation_t = DefT (_, _, StrT _); _ }) ->
              { exists_check with enum_string_loc = t_loc }
            | DefT (_, _, EnumT { representation_t = DefT (_, _, NumT _); _ }) ->
              { exists_check with enum_number_loc = t_loc }
            | _ -> exists_check
          in
          if exists_check = ExistsCheck.empty then
            cur_checks
          else
            ALocMap.add loc exists_check cur_checks
      in

      ALocMap.fold
        (fun loc tset acc ->
          Type.TypeSet.fold (fun t acc -> make_checks ISet.empty acc loc t) tset acc)
        checks
        ALocMap.empty
    else
      ALocMap.empty
  in

  Loc_collections.ALocMap.iter (detect_function (Context.exists_excuses cx)) exists_checks

let detect_test_prop_misses cx =
  let misses = Context.test_prop_get_never_hit cx in
  Base.List.iter
    ~f:(fun (prop_name, (reason_prop, reason_obj), use_op, suggestion) ->
      Flow_js.add_output
        cx
        (Error_message.EPropNotFound { prop_name; reason_prop; reason_obj; use_op; suggestion }))
    misses

let detect_unnecessary_optional_chains cx =
  Base.List.iter
    ~f:(fun (loc, lhs_reason) ->
      Flow_js.add_output cx (Error_message.EUnnecessaryOptionalChain (loc, lhs_reason)))
    (Context.unnecessary_optional_chains cx)

let detect_unnecessary_invariants cx =
  Base.List.iter
    ~f:(fun (loc, reason) ->
      Flow_js.add_output cx (Error_message.EUnnecessaryInvariant (loc, reason)))
    (Context.unnecessary_invariants cx)

let detect_invalid_type_assert_calls cx typed_ast file_sig =
  if Context.type_asserts cx then Type_asserts.detect_invalid_calls ~full_cx:cx typed_ast file_sig

let detect_es6_import_export_errors = Strict_es6_import_export.detect_errors

let detect_escaped_generics results =
  Base.List.iter
    ~f:(fun (cx, _, (_, { Flow_ast.Program.statements; _ })) ->
      Generic_escape.scan_for_escapes cx ~add_output:Flow_js.add_output statements)
    results

let detect_non_voidable_properties cx =
  (* This function approximately checks whether VoidT can flow to the provided
   * type without actually creating the flow so as not to disturb type inference.
   * Even though this is happening post-merge, it is possible to encounter an
   * unresolved tvar, in which case it conservatively returns false.
   *)
  let rec is_voidable seen_ids =
    Type.(
      function
      | OpenT (_, id) ->
        (* tvar is recursive: conservatively assume it is non-voidable *)
        if ISet.mem id seen_ids then
          false
        else (
          match Flow_js_utils.possible_types cx id with
          (* tvar has no lower bounds: we conservatively assume it's non-voidable
           * except in the special case when it also has no upper bounds
           *)
          | [] -> Flow_js_utils.possible_uses cx id = []
          (* tvar is resolved: look at voidability of the resolved type *)
          | [t] -> is_voidable (ISet.add id seen_ids) t
          (* tvar is unresolved: conservatively assume it is non-voidable *)
          | _ -> false
        )
      (* a union is voidable if any of its members are voidable *)
      | UnionT (_, rep) -> UnionRep.members rep |> List.exists (is_voidable seen_ids)
      (* an intersection is voidable if all of its members are voidable *)
      | IntersectionT (_, rep) -> InterRep.members rep |> List.for_all (is_voidable seen_ids)
      (* trivially voidable *)
      | MaybeT _
      | DefT (_, _, (VoidT | MixedT (Mixed_everything | Mixed_non_null)))
      | OptionalT _
      | AnyT _ ->
        true
      (* conservatively assume all other types are non-voidable *)
      | _ -> false
    )
  in
  let check_properties (property_map : Type.Properties.id) :
      ALoc.t Property_assignment.error list SMap.t -> unit =
    let pmap = Context.find_props cx property_map in
    SMap.iter (fun name errors ->
        let should_error =
          match NameUtils.Map.find_opt (Reason.OrdinaryName name) pmap with
          | Some (Type.Field (_, t, _)) -> not @@ is_voidable ISet.empty t
          | _ -> true
        in
        if should_error then
          List.iter
            (fun { Property_assignment.loc; desc } ->
              Flow_js.add_output cx (Error_message.EUninitializedInstanceProperty (loc, desc)))
            errors
    )
  in
  List.iter
    (fun {
           Context.public_property_map;
           private_property_map;
           errors = { Property_assignment.public_property_errors; private_property_errors };
         } ->
      check_properties public_property_map public_property_errors;
      check_properties private_property_map private_property_errors)
    (Context.voidable_checks cx)

let check_implicit_instantiations cx master_cx =
  if Context.run_post_inference_implicit_instantiation cx then
    let implicit_instantiation_checks = Context.implicit_instantiation_checks cx in
    ImplicitInstantiationKit.fold
      cx
      master_cx
      ~init:()
      ~f:(fun _ _ _ _ -> ())
      ~post:(fun ~init_cx ~cx ->
        let new_errors = Context.errors cx in
        Flow_error.ErrorSet.iter (fun error -> Context.add_error init_cx error) new_errors)
      implicit_instantiation_checks

class resolver_visitor =
  (* TODO: replace this with the context_optimizer *)
  let no_lowers _cx r = Type.Unsoundness.merged_any r in
  object (self)
    inherit [unit] Type_mapper.t_with_uses as super

    method! type_ cx map_cx t =
      let open Type in
      match t with
      | OpenT (r, id) -> Flow_js_utils.merge_tvar ~filter_empty:true ~no_lowers cx r id
      | EvalT (t', dt, _id) ->
        let t'' = self#type_ cx map_cx t' in
        let dt' = self#defer_use_type cx map_cx dt in
        if t' == t'' && dt == dt' then
          t
        else
          Flow_cache.Eval.id cx t'' dt'
      | _ -> super#type_ cx map_cx t

    (* Only called from type_ and the CreateObjWithComputedPropT use case *)
    method tvar _cx _seen _r id = id

    (* overridden in type_ *)
    method eval_id _cx _map_cx _id = assert false

    method props cx map_cx id =
      let props_map = Context.find_props cx id in
      let props_map' =
        NameUtils.Map.ident_map (Type.Property.ident_map_t (self#type_ cx map_cx)) props_map
      in
      let id' =
        if props_map == props_map' then
          id
        (* When mapping results in a new property map, we have to use a
           generated id, rather than a location from source. *)
        else
          Context.generate_property_map cx props_map'
      in
      id'

    (* These should already be fully-resolved. *)
    method exports _cx _map_cx id = id

    method call_prop cx map_cx id =
      let t = Context.find_call cx id in
      let t' = self#type_ cx map_cx t in
      if t == t' then
        id
      else
        Context.make_call_prop cx t'
  end

let detect_matching_props_violations cx =
  let open Type in
  let resolver = new resolver_visitor in
  let step (reason, key, sentinel, obj) =
    let sentinel = resolver#type_ cx () sentinel in
    match drop_generic sentinel with
    (* TODO: it should not be possible to create a MatchingPropT with a non-tvar tout *)
    | DefT (_, _, (BoolT (Some _) | StrT (Literal _) | NumT (Literal _))) ->
      let obj = resolver#type_ cx () obj in
      (* Limit the check to promitive literal sentinels *)
      let use_op =
        Op
          (MatchingProp
             {
               op = reason;
               obj = TypeUtil.reason_of_t obj;
               key;
               sentinel_reason = TypeUtil.reason_of_t sentinel;
             }
          )
      in
      (* If `obj` is a GenericT, we replace it with it's upper bound, since ultimately it will flow into
         `sentinel` rather than the other way around. *)
      Flow_js.flow cx (MatchingPropT (reason, key, sentinel), UseT (use_op, drop_generic obj))
    | _ -> ()
  in
  match Context.env_mode cx with
  | Options.SSAEnv _ ->
    let matching_props = Context.new_env_matching_props cx in
    List.iter
      (fun (prop_name, other_loc, obj_loc) ->
        let env = Context.environment cx in
        let other_t = Base.Option.value_exn (Loc_env.find_write env other_loc) in
        let obj_t = New_env.New_env.provider_type_for_def_loc env obj_loc in
        step (TypeUtil.reason_of_t other_t, prop_name, other_t, obj_t))
      matching_props
  | _ ->
    let matching_props = Context.matching_props cx in
    List.iter step matching_props

let detect_literal_subtypes =
  let lb_visitor = new resolver_visitor in
  let ub_visitor =
    let open Type in
    let rec unwrap = function
      | GenericT { bound; _ } -> unwrap bound
      | t -> t
    in
    object (_self)
      inherit resolver_visitor as super

      method! type_ cx map_cx t = t |> super#type_ cx map_cx |> unwrap
    end
  in
  fun cx ->
    match Context.env_mode cx with
    | Options.SSAEnv _ ->
      let new_env_checks = Context.new_env_literal_subtypes cx in
      List.iter
        (fun (loc, check) ->
          let open Type in
          let env = Context.environment cx in
          let u =
            UseT (Op (Internal Refinement), New_env.New_env.provider_type_for_def_loc env loc)
          in
          let l =
            match check with
            | Env_api.SingletonNum (lit_loc, sense, num, raw) ->
              let reason = lit_loc |> Reason.(mk_reason (RNumberLit raw)) in
              DefT (reason, bogus_trust (), NumT (Literal (Some sense, (num, raw))))
            | Env_api.SingletonBool (lit_loc, b) ->
              let reason = lit_loc |> Reason.(mk_reason (RBooleanLit b)) in
              DefT (reason, bogus_trust (), BoolT (Some b))
            | Env_api.SingletonStr (lit_loc, sense, str) ->
              let reason = lit_loc |> Reason.(mk_reason (RStringLit (OrdinaryName str))) in
              DefT (reason, bogus_trust (), StrT (Literal (Some sense, Reason.OrdinaryName str)))
          in
          let l = lb_visitor#type_ cx () l in
          let u = ub_visitor#use_type cx () u in
          Flow_js.flow cx (l, u))
        new_env_checks
    | _ ->
      let checks = Context.literal_subtypes cx in
      List.iter
        (fun (t, u) ->
          let t = lb_visitor#type_ cx () t in
          let u = ub_visitor#use_type cx () u in
          Flow_js.flow cx (t, u))
        checks

let check_constrained_writes init_cx master_cx =
  let checks = Context.constrained_writes init_cx in
  if not @@ Base.List.is_empty checks then (
    let reducer =
      let mk_reason =
        let open Reason in
        let open Utils_js in
        update_desc_reason (function
            | RIdentifier (OrdinaryName name) -> RCustom (spf ""variable `%s` of unknown type"" name)
            | RParameter (Some name)
            | RRestParameter (Some name) ->
              RUnknownParameter name
            | RTypeParam (name, _, _) ->
              RCustom
                (spf ""unknown implicit instantiation of `%s`"" (Subst_name.string_of_subst_name name))
            | desc -> desc
            )
      in
      new Context_optimizer.context_optimizer ~no_lowers:(fun _ r ->
          Type.EmptyT.make (mk_reason r) (Type.bogus_trust ())
      )
    in
    let (cx, checks) =
      create_cx_with_context_optimizer init_cx master_cx ~reducer ~f:(fun () ->
          Base.List.map
            ~f:(fun (t, u) ->
              let t = reducer#type_ init_cx Polarity.Neutral t in
              let u = reducer#use_type init_cx Polarity.Neutral u in
              (t, u))
            checks
      )
    in
    Base.List.iter ~f:(Flow_js.flow cx) checks;

    let new_errors = Context.errors cx in
    Flow_error.ErrorSet.iter (Context.add_error init_cx) new_errors
  )

let get_lint_severities metadata strict_mode lint_severities =
  if metadata.Context.strict || metadata.Context.strict_local then
    StrictModeSettings.fold
      (fun lint_kind lint_severities ->
        LintSettings.set_value lint_kind (Severity.Err, None) lint_severities)
      strict_mode
      lint_severities
  else
    lint_severities

(* Post-merge errors.
 *
 * At this point, all dependencies have been merged and the component has been
 * linked together. Any constraints should have already been evaluated, which
 * means we can complain about things that either haven't happened yet, or
 * which require complete knowledge of tvar bounds.
 *)
let post_merge_checks cx master_cx ast tast metadata file_sig =
  let results = [(cx, ast, tast)] in
  detect_sketchy_null_checks cx master_cx;
  detect_non_voidable_properties cx;
  check_implicit_instantiations cx master_cx;
  detect_test_prop_misses cx;
  detect_unnecessary_optional_chains cx;
  detect_unnecessary_invariants cx;
  detect_invalid_type_assert_calls cx tast file_sig;
  detect_es6_import_export_errors cx metadata results;
  detect_escaped_generics results;
  detect_matching_props_violations cx;
  detect_literal_subtypes cx;
  check_constrained_writes cx master_cx

let optimize_builtins cx =
  let reducer =
    let no_lowers _ r = Type.AnyT (r, Type.AnyError (Some Type.UnresolvedName)) in
    new Context_optimizer.context_optimizer ~no_lowers
  in
  let builtins = Context.builtins cx in
  let on_missing name t =
    let reason = TypeUtil.reason_of_t t in
    Flow_js.flow_t cx (Type.AnyT (reason, Type.AnyError (Some Type.UnresolvedName)), t);
    Flow_js.add_output
      cx
      (Error_message.EBuiltinLookupFailed { reason; name = Some name; potential_generator = None })
  in
  Builtins.optimize_entries builtins ~on_missing ~optimize:(reducer#type_ cx Polarity.Neutral);
  Context.set_graph cx reducer#get_reduced_graph;
  Context.set_trust_graph cx reducer#get_reduced_trust_graph;
  Context.set_property_maps cx reducer#get_reduced_property_maps;
  Context.set_call_props cx reducer#get_reduced_call_props;
  Context.set_export_maps cx reducer#get_reduced_export_maps;
  Context.set_evaluated cx reducer#get_reduced_evaluated
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* This module sets up the definitions for JavaScript globals. Eventually, this
   module should become redundant: we should be able to automatically interpret
   TypeScript type definition files for these and many other primitives. That
   said, in some cases handcoding may turn out to be necessary because the type
   system is not powerful enough to encode the invariants of a library
   function. In any case, this part of the design must be revisited in the
   future. *)

open Utils_js
module Files = Files
module Parsing = Parsing_service_js
module Infer = Type_inference_js

let is_ok { Parsing.parsed; _ } = not (FilenameSet.is_empty parsed)

let is_fail { Parsing.failed; _ } = fst failed <> []

type lib_result =
  | Lib_ok of {
      ast: (Loc.t, Loc.t) Flow_ast.Program.t;
      file_sig: File_sig.With_Loc.t;
      tolerable_errors: File_sig.With_Loc.tolerable_error list;
    }
  | Lib_fail of Parsing.parse_failure
  | Lib_skip

let parse_lib_file ~reader options file =
  (* types are always allowed in lib files *)
  let types_mode = Parsing.TypesAllowed in
  (* lib files are always ""use strict"" *)
  let use_strict = true in
  try%lwt
    let lib_file = File_key.LibFile file in
    let filename_set = FilenameSet.singleton lib_file in
    let next = Parsing.next_of_filename_set (* workers *) None filename_set in
    let%lwt results =
      Parsing.parse_with_defaults ~types_mode ~use_strict ~reader options (* workers *) None next
    in
    Lwt.return
      ( if is_ok results then
        let ast = Parsing_heaps.Mutator_reader.get_ast_unsafe ~reader lib_file in
        let (file_sig, tolerable_errors) =
          Parsing_heaps.Mutator_reader.get_tolerable_file_sig_unsafe ~reader lib_file
        in
        Lib_ok { ast; file_sig; tolerable_errors }
      else if is_fail results then
        let error = List.hd (snd results.Parsing.failed) in
        Lib_fail error
      else
        Lib_skip
      )
  with
  | _ -> failwith (spf ""Can't read library definitions file %s, exiting."" file)

let infer_lib_file ~ccx ~options ~exclude_syms lib_file ast file_sig =
  let verbose = Options.verbose options in
  let lint_severities = Options.lint_severities options in
  let metadata =
    Context.(
      let metadata = metadata_of_options options in
      { metadata with checked = false }
    )
  in
  (* Lib files use only concrete locations, so this is not used. *)
  let aloc_table = lazy (ALoc.empty_table lib_file) in
  let cx =
    Context.make
      ccx
      metadata
      lib_file
      aloc_table
      (Reason.OrdinaryName Files.lib_module_ref)
      Context.InitLib
  in
  let syms = Infer.infer_lib_file cx ast ~exclude_syms ~lint_severities ~file_sig in

  if verbose != None then
    prerr_endlinef
      ""load_lib %s: added symbols { %s }""
      (File_key.to_string lib_file)
      (String.concat "", "" (Base.List.map ~f:Reason.display_string_of_name syms));

  (* symbols loaded from this file are suppressed if found in later ones *)
  NameUtils.Set.union exclude_syms (NameUtils.Set.of_list syms)

(* process all lib files: parse, infer, and add the symbols they define
   to the builtins object.

   Note: we support overrides of definitions found earlier in the list of
   files by those of the same name found in later ones, so caller must
   preserve lib path declaration order in the (flattened) list of files
   passed.

   returns (success, parse and signature errors, exports)
*)
let load_lib_files ~ccx ~options ~reader files =
  (* iterate in reverse override order *)
  let%lwt (_, ok, errors, ordered_asts) =
    List.rev files
    |> Lwt_list.fold_left_s
         (fun (exclude_syms, ok_acc, errors_acc, asts_acc) file ->
           let lib_file = File_key.LibFile file in
           match%lwt parse_lib_file ~reader options file with
           | Lib_ok { ast; file_sig; tolerable_errors } ->
             let file_sig = File_sig.abstractify_locs file_sig in
             let tolerable_errors = File_sig.abstractify_tolerable_errors tolerable_errors in
             let exclude_syms = infer_lib_file ~ccx ~options ~exclude_syms lib_file ast file_sig in
             let errors =
               tolerable_errors
               |> Inference_utils.set_of_file_sig_tolerable_errors ~source_file:lib_file
             in
             let errors_acc = Flow_error.ErrorSet.union errors errors_acc in
             let asts_acc = ast :: asts_acc in
             Lwt.return (exclude_syms, ok_acc, errors_acc, asts_acc)
           | Lib_fail fail ->
             let errors =
               match fail with
               | Parsing.Uncaught_exception exn ->
                 Inference_utils.set_of_parse_exception ~source_file:lib_file exn
               | Parsing.Parse_error error ->
                 Inference_utils.set_of_parse_error ~source_file:lib_file error
               | Parsing.Docblock_errors errs ->
                 Inference_utils.set_of_docblock_errors ~source_file:lib_file errs
             in
             let errors_acc = Flow_error.ErrorSet.union errors errors_acc in
             Lwt.return (exclude_syms, false, errors_acc, asts_acc)
           | Lib_skip -> Lwt.return (exclude_syms, ok_acc, errors_acc, asts_acc))
         (NameUtils.Set.empty, true, Flow_error.ErrorSet.empty, [])
  in
  let builtin_exports =
    if ok then
      let sig_opts =
        {
          Type_sig_parse.type_asserts = Options.type_asserts options;
          suppress_types = Options.suppress_types options;
          munge = (* libs shouldn't have private fields *) false;
          ignore_static_propTypes = true;
          facebook_keyMirror = (* irrelevant for libs *) false;
          facebook_fbt = Options.facebook_fbt options;
          max_literal_len = Options.max_literal_length options;
          exact_by_default = Options.exact_by_default options;
          module_ref_prefix = Options.haste_module_ref_prefix options;
          enable_enums = Options.enums options;
          enable_relay_integration = Options.enable_relay_integration options;
          relay_integration_module_prefix = Options.relay_integration_module_prefix options;
        }
      in
      let (_builtin_errors, _builtin_locs, builtins) =
        Type_sig_utils.parse_and_pack_builtins sig_opts ordered_asts
      in
      let builtins =
        (* hide #flow-internal-react-server-module module *)
        let { Packed_type_sig.Builtins.modules; _ } = builtins in
        let modules = SMap.remove Type.react_server_module_ref modules in
        { builtins with Packed_type_sig.Builtins.modules }
      in
      Exports.of_builtins builtins
    else
      Exports.empty
  in
  Lwt.return (ok, errors, builtin_exports)

type init_result = {
  ok: bool;
  errors: Flow_error.ErrorSet.t FilenameMap.t;
  warnings: Flow_error.ErrorSet.t FilenameMap.t;
  suppressions: Error_suppressions.t;
  exports: Exports.t;
}

let error_set_to_filemap err_set =
  Flow_error.ErrorSet.fold
    (fun error map ->
      let file = Flow_error.source_file error in
      FilenameMap.update
        file
        (function
          | None -> Some (Flow_error.ErrorSet.singleton error)
          | Some set -> Some (Flow_error.ErrorSet.add error set))
        map)
    err_set
    FilenameMap.empty

(* initialize builtins:
   parse and do local inference on library files, and set up master context.
   returns list of (lib file, success) pairs.
*)
let init ~options ~reader lib_files =
  let ccx = Context.(make_ccx (empty_master_cx ())) in
  let master_cx =
    let metadata =
      Context.(
        let metadata = metadata_of_options options in
        { metadata with checked = false }
      )
    in
    (* Lib files use only concrete locations, so this is not used. *)
    let aloc_table = lazy (ALoc.empty_table File_key.Builtins) in
    Context.make
      ccx
      metadata
      File_key.Builtins
      aloc_table
      (Reason.OrdinaryName Files.lib_module_ref)
      Context.InitLib
  in

  let%lwt (ok, parse_and_sig_errors, exports) = load_lib_files ~ccx ~options ~reader lib_files in
  Merge_js.optimize_builtins master_cx;

  let (errors, warnings, suppressions) =
    let errors = Context.errors master_cx |> Flow_error.ErrorSet.union parse_and_sig_errors in
    let suppressions = Context.error_suppressions master_cx in
    let severity_cover = Context.severity_cover master_cx in
    let include_suppressions = Context.include_suppressions master_cx in
    let (errors, warnings, suppressions) =
      Error_suppressions.filter_lints
        ~include_suppressions
        suppressions
        errors
        (Context.aloc_tables master_cx)
        severity_cover
    in
    (error_set_to_filemap errors, error_set_to_filemap warnings, suppressions)
  in
  (* store master signature context to heap *)
  Context_heaps.Init_master_context_mutator.add_master ~audit:Expensive.ok master_cx;

  Lwt.return { ok; errors; warnings; suppressions; exports }
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Base
open Worker

(*****************************************************************************
 * Module building workers
 *
 * A worker is a subprocess executing an arbitrary function
 *
 * You should first create a fixed amount of workers and then use those
 * because the amount of workers is limited and to make the load-balancing
 * of tasks better (cf multiWorker.ml)
 *
 * On Unix, we ""spawn"" workers when initializing Hack. Then, this
 * worker, ""fork"" a clone process for each incoming request.
 * The forked ""clone"" will die after processing a single request.
 *
 * On Windows, we do not ""prespawn"" when initializing Hack, but we just
 * allocate all the required information into a record. Then, we
 * spawn a worker for each incoming request. It will also die after
 * one request.
 *
 * A worker never handle more than one request at a time.
 *
 *****************************************************************************)

type process_id = int

type worker_id = int

type worker_failure =
  | Worker_oomed  (** Worker killed by Out Of Memory. *)
  | Worker_quit of Unix.process_status option

exception Worker_failed of (process_id * worker_failure)

exception Worker_busy

type send_job_failure =
  | Worker_already_exited of Unix.process_status option
  | Other_send_job_failure of Exception.t

exception Worker_failed_to_send_job of send_job_failure

let status_string = function
  | Some (Unix.WEXITED i) -> Printf.sprintf ""WEXITED %d"" i
  | Some (Unix.WSIGNALED i) -> Printf.sprintf ""WSIGNALED %d"" i
  | Some (Unix.WSTOPPED i) -> Printf.sprintf ""WSTOPPED %d"" i
  | None -> ""GONE""

let failure_to_string f =
  match f with
  | Worker_oomed -> ""Worker_oomed""
  | Worker_quit s -> Printf.sprintf ""(Worker_quit %s)"" (status_string s)

let () =
  Caml.Printexc.register_printer @@ function
  | Worker_failed_to_send_job (Other_send_job_failure exn) ->
    Some (Printf.sprintf ""Other_send_job_failure: %s"" (Exception.to_string exn))
  | Worker_failed_to_send_job (Worker_already_exited status) ->
    Some (Printf.sprintf ""Worker_already_exited: %s"" (status_string status))
  | Worker_failed (id, failure) ->
    Some (Printf.sprintf ""Worker_failed (process_id = %d): %s"" id (failure_to_string failure))
  | _ -> None

(* Should we 'prespawn' the worker ? *)
let use_prespawned = not Sys.win32

(* The maximum amount of workers *)
let max_workers = 1000

type void (* an empty type *)

type call_wrapper = { wrap: 'x 'b. ('x -> 'b) -> 'x -> 'b }

(*****************************************************************************
 * Everything we need to know about a worker.
 *
 *****************************************************************************)

type worker = {
  (* Simple id for the worker. This is not the worker pid: on Windows, we spawn
   * a new worker for each job.
   *
   * This is also an offset into the shared heap segment, used to access
   * worker-local data. As such, the numbering is important. The IDs must be
   * dense and start at 1. (0 is the controller process offset.) *)
  id: int;
  (* The call wrapper will wrap any workload sent to the worker (via ""call""
   * below) before invoking the workload.
   *
   * That is, when calling the worker with workload `f x`, it will be wrapped
   * as `wrap (f x)`.
   *
   * This allows universal handling of workload at the time we create the actual
   * workers. For example, this can be useful to handle exceptions uniformly
   * across workers regardless what workload is called on them. *)
  call_wrapper: call_wrapper option;
  (* On Unix, Worker sends status messages over this fd to this Controller. On
   * Windows, it doesn't send anything, so don't try to read from it (it should
   * be set to None). *)
  controller_fd: Unix.file_descr option;
  (* Sanity check: is the worker still available ? *)
  mutable killed: bool;
  (* Sanity check: is the worker currently busy ? *)
  mutable busy: bool;
  (* On Unix, a reference to the 'prespawned' worker. *)
  prespawned: (void, request) Daemon.handle option;
  (* On Windows, a function to spawn a worker. *)
  spawn: unit -> (void, request) Daemon.handle;
}
[@@warning ""-69""]

let worker_id w = w.id

(* Has the worker been killed *)
let is_killed w = w.killed

(* Mark the worker as busy. Throw if it is already busy *)
let mark_busy w =
  if w.busy then raise Worker_busy;
  w.busy <- true

(* Mark the worker as free *)
let mark_free w = w.busy <- false

(* If the worker isn't prespawned, spawn the worker *)
let spawn w =
  match w.prespawned with
  | None -> w.spawn ()
  | Some handle -> handle

(* If the worker isn't prespawned, close the worker *)
let close w h = if Option.is_none w.prespawned then Daemon.close h

(* If there is a call_wrapper, apply it and create the Request *)
let wrap_request w f x =
  match w.call_wrapper with
  | Some { wrap } -> Request (fun { send } -> send (wrap f x))
  | None -> Request (fun { send } -> send (f x))

type 'a entry_state = 'a * Caml.Gc.control * SharedMem.handle * int

type 'a entry = ('a entry_state * Unix.file_descr option, request, void) Daemon.entry

let entry_counter = ref 0

let register_entry_point ~restore =
  Int.incr entry_counter;
  let restore (st, gc_control, heap_handle, worker_id) =
    restore st ~worker_id;
    SharedMem.connect heap_handle ~worker_id;
    Caml.Gc.set gc_control
  in
  let name = Printf.sprintf ""worker_%d"" !entry_counter in
  Daemon.register_entry_point
    name
    ( if Sys.win32 then
      win32_worker_main restore
    else
      unix_worker_main restore
    )

(**************************************************************************
 * Creates a pool of workers.
 *
 **************************************************************************)

let workers = ref []

(* Build one worker. *)
let make_one ?call_wrapper controller_fd spawn id =
  if id >= max_workers then failwith ""Too many workers"";

  let prespawned =
    if not use_prespawned then
      None
    else
      Some (spawn ())
  in
  let worker =
    { call_wrapper; controller_fd; id; busy = false; killed = false; prespawned; spawn }
  in
  workers := worker :: !workers;
  worker

(* Make a few workers. When workload is given to a worker (via ""call"" below),
 * the workload is wrapped in the calL_wrapper. *)
let make ~call_wrapper ~saved_state ~entry ~nbr_procs ~gc_control ~heap_handle =
  let setup_controller_fd () =
    if use_prespawned then
      let (parent_fd, child_fd) = Unix.pipe () in
      (* parent_fd is only used in this process. Don't leak it to children.
       * This will auto-close parent_fd in children created with Daemon.spawn
       * since Daemon.spawn uses exec. *)
      let () = Unix.set_close_on_exec parent_fd in
      (Some parent_fd, Some child_fd)
    else
      (* We don't use the side channel on Windows. *)
      (None, None)
  in
  let spawn worker_id name child_fd () =
    Unix.clear_close_on_exec heap_handle;

    (* Daemon.spawn runs exec after forking. We explicitly *do* want to ""leak""
     * child_fd to this one spawned process because it will be using that FD to
     * send messages back up to us. Close_on_exec is probably already false, but
     * we force it again to be false here just in case. *)
    Base.Option.iter child_fd ~f:Unix.clear_close_on_exec;
    let state = (saved_state, gc_control, heap_handle, worker_id) in
    let handle =
      Daemon.spawn ~name (Daemon.null_fd (), Unix.stdout, Unix.stderr) entry (state, child_fd)
    in
    Unix.set_close_on_exec heap_handle;

    (* This process no longer needs child_fd after its spawned the child.
     * Messages are read using controller_fd. *)
    Base.Option.iter child_fd ~f:Unix.close;
    handle
  in
  let made_workers = ref [] in
  let pid = Unix.getpid () in
  for n = 1 to nbr_procs do
    let (controller_fd, child_fd) = setup_controller_fd () in
    let name = Printf.sprintf ""worker process %d/%d for server %d"" n nbr_procs pid in
    made_workers := make_one ?call_wrapper controller_fd (spawn n name child_fd) n :: !made_workers
  done;
  !made_workers

(** Sends a request to call `f x` on `worker` *)
let send worker worker_pid outfd (f : 'a -> 'b) (x : 'a) : unit Lwt.t =
  let outfd_lwt = Lwt_unix.of_unix_file_descr ~blocking:false ~set_flags:true outfd in
  let request = wrap_request worker f x in
  try%lwt
    (* Wait in an lwt-friendly manner for the worker to be writable (should be instant) *)
    let%lwt () = Lwt_unix.wait_write outfd_lwt in

    (* Write in a lwt-unfriendly, blocking manner to the worker.

       I, glevi, found a perf regression when I used Marshal_tools_lwt to send the job
       to the worker. Here's my hypothesis:

       1. On a machine with many CPUs (like 56) we create 56 threads to send a job to each worker.
       2. Lwt attempts to write the jobs to the workers in parallel.
       3. Each worker spends more time between getting the first byte and last byte
       4. Something something this leads to more context switches for the worker
       5. The worker spends more time on a job

       This is reinforced by the observation that the regression only happens as the number of
       workers grows.

       By switching from Marshal_tools_lwt.to_fd_with_preamble to Marshal_tools.to_fd_with_preamble,
       the issue seems to have disappeared. *)
    let _ = Marshal_tools.to_fd_with_preamble ~flags:[Caml.Marshal.Closures] outfd request in
    Lwt.return_unit
  with
  | exn ->
    let exn = Exception.wrap exn in
    Hh_logger.error ~exn ""Failed to read response from work #%d"" (worker_id worker);

    (* Failed to send the job to the worker. Is it because the worker is dead or is it
     * something else? *)
    (match%lwt Lwt_unix.waitpid [Unix.WNOHANG] worker_pid with
    | (0, _) -> raise (Worker_failed_to_send_job (Other_send_job_failure exn))
    | (_, status) -> raise (Worker_failed_to_send_job (Worker_already_exited (Some status)))
    | exception Unix.Unix_error (Unix.ECHILD, _, _) ->
      raise (Worker_failed_to_send_job (Worker_already_exited None)))

let read (type result) worker_pid infd : (result * Measure.record_data) Lwt.t =
  let infd_lwt = Lwt_unix.of_unix_file_descr ~blocking:false ~set_flags:true infd in
  try%lwt
    (* Wait in an lwt-friendly manner for the worker to finish the job *)
    let%lwt () = Lwt_unix.wait_read infd_lwt in

    (* Read in a lwt-unfriendly, blocking manner from the worker.

       Unlike writing (see `send`), reading from the worker didn't seem to trigger a perf issue
       in our testing, but there's really nothing more urgent than reading a response from a
       finished worker, so reading in a blocking manner is fine. *)
    (* Due to https://github.com/ocsigen/lwt/issues/564, annotation cannot go on let%let node *)
    let data : result = Marshal_tools.from_fd_with_preamble infd in
    let stats : Measure.record_data = Marshal_tools.from_fd_with_preamble infd in
    Lwt.return (data, stats)
  with
  | Lwt.Canceled as exn ->
    (* Worker is handling a job but we're cancelling *)
    let exn = Exception.wrap exn in

    (* Each worker might call this but that's ok *)
    WorkerCancel.stop_workers ();

    (* Wait for the worker to finish cancelling *)
    let%lwt () = Lwt_unix.wait_read infd_lwt in
    (* Read the junk from the pipe *)
    let _ = Marshal_tools.from_fd_with_preamble infd in
    let _ = Marshal_tools.from_fd_with_preamble infd in
    Exception.reraise exn
  | exn ->
    let exn = Exception.wrap exn in
    (match%lwt Lwt_unix.waitpid [Unix.WNOHANG] worker_pid with
    | (0, _)
    | (_, Unix.WEXITED 0) ->
      (* The worker is still running or exited normally. It's odd that we failed to read
       * the response, so just raise that exception *)
      Exception.reraise exn
    | (_, Unix.WEXITED i) ->
      (match Exit.error_type_opt i with
      | Some Exit.Out_of_shared_memory -> raise SharedMem.Out_of_shared_memory
      | Some Exit.Hash_table_full -> raise SharedMem.Hash_table_full
      | Some Exit.Heap_full -> raise SharedMem.Heap_full
      | _ ->
        let () = Caml.Printf.eprintf ""Subprocess(%d): fail %d"" worker_pid i in
        raise (Worker_failed (worker_pid, Worker_quit (Some (Unix.WEXITED i)))))
    | (_, Unix.WSTOPPED i) ->
      let () = Caml.Printf.eprintf ""Subprocess(%d): stopped %d"" worker_pid i in
      raise (Worker_failed (worker_pid, Worker_quit (Some (Unix.WSTOPPED i))))
    | (_, Unix.WSIGNALED i) ->
      let () = Caml.Printf.eprintf ""Subprocess(%d): signaled %d"" worker_pid i in
      raise (Worker_failed (worker_pid, Worker_quit (Some (Unix.WSIGNALED i))))
    | exception Unix.Unix_error (Unix.ECHILD, _, _) ->
      let () = Caml.Printf.eprintf ""Subprocess(%d): gone"" worker_pid in
      raise (Worker_failed (worker_pid, Worker_quit None)))

(** Send a job to a worker

    This is basically an lwt thread that writes a job to the worker, waits for the response, and
    then returns the result. *)
let call w (f : 'a -> 'b) (x : 'a) : 'b Lwt.t =
  if is_killed w then Printf.ksprintf failwith ""killed worker (%d)"" (worker_id w);
  mark_busy w;

  (* Spawn the worker, if not prespawned. *)
  let ({ Daemon.pid = worker_pid; channels = (inc, outc) } as h) = spawn w in
  let infd = Daemon.descr_of_in_channel inc in
  let outfd = Daemon.descr_of_out_channel outc in
  try%lwt
    let%lwt () = send w worker_pid outfd f x in
    let%lwt (res, measure_data) = read worker_pid infd in
    close w h;
    Measure.merge (Measure.deserialize measure_data);
    mark_free w;
    Lwt.return res
  with
  | exn ->
    let exn = Exception.wrap exn in
    (* No matter what, always mark worker as free when we're done *)
    mark_free w;
    Exception.reraise exn

(**************************************************************************
 * Worker termination
 **************************************************************************)

let kill w =
  if not (is_killed w) then (
    w.killed <- true;
    Base.Option.iter ~f:Daemon.kill w.prespawned
  )

let killall () = List.iter ~f:kill !workers
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Name_def
open Type
open Reason
open Loc_collections
module Ast = Flow_ast

module type S = sig
  val resolve_component :
    Context.t -> (Name_def.def * reason) ALocMap.t -> Name_def_ordering.result -> unit
end

module Make (Env : Env_sig.S) (Statement : Statement_sig.S with module Env := Env) : S = struct
  module Type_annotation = Statement.Anno

  let expression cx ~hint ?cond exp =
    let cache = Context.node_cache cx in
    let (((_, t), _) as exp) = Statement.expression ~hint ?cond cx exp in
    Node_cache.set_expression cache exp;
    t

  let rec resolve_binding cx loc b =
    match b with
    | Root (Annotation anno) ->
      let cache = Context.node_cache cx in
      let (t, anno) = Type_annotation.mk_type_available_annotation cx Subst_name.Map.empty anno in
      Node_cache.set_annotation cache anno;
      t
    | Root (Value exp) ->
      (* TODO: look up the annotation for the variable at loc and pass in *)
      expression cx ~hint:None exp
    | Root (Contextual _) -> Tvar.mk cx (mk_reason (RCustom ""contextual variable"") loc)
    | Root Catch -> AnyT.annot (mk_reason (RCustom ""catch parameter"") loc)
    | Root (For (kind, exp)) ->
      let reason = mk_reason (RCustom ""for-in"") loc (*TODO: loc should be loc of loop *) in
      let right_t = expression cx ~hint:None ~cond:OtherTest exp in
      begin
        match kind with
        | In ->
          Flow_js.flow cx (right_t, AssertForInRHST reason);
          StrT.at loc |> with_trust bogus_trust
        | Of { await } -> Statement.for_of_elemt cx right_t reason await
      end
    | Select (sel, b) ->
      let t = resolve_binding cx loc b in
      let selector =
        match sel with
        | Name_def.Elem n ->
          let key =
            DefT
              ( mk_reason RNumber loc,
                bogus_trust (),
                NumT (Literal (None, (float n, string_of_int n)))
              )
          in
          Type.Elem key
        | Name_def.Prop { prop; has_default } -> Type.Prop (prop, has_default)
        | Name_def.ArrRest n -> Type.ArrRest n
        | Name_def.ObjRest { used_props; after_computed = _ } ->
          (* TODO: eveyrthing after a computed prop should be optional *)
          Type.ObjRest used_props
        | Name_def.Computed exp ->
          let t = expression cx ~hint:None exp in
          Type.Elem t
        | Name_def.Default _exp ->
          (* TODO: change the way default works to see exp as a source *)
          Type.Default
      in
      let reason = mk_reason (RCustom ""destructured var"") loc in
      Tvar.mk_no_wrap_where cx reason (fun tout ->
          Flow_js.flow
            cx
            (t, DestructuringT (reason, DestructInfer, selector, tout, Reason.mk_id ()))
      )

  let resolve_inferred_function cx id_loc reason function_ =
    let cache = Context.node_cache cx in
    let ((fun_type, _) as fn) =
      (* TODO: This is intended to be the general type for the variable in the old environment, needed
         for generic escape detection. We can do generic escape differently in the future and remove
         this when we kill the old env. *)
      let general = Tvar.mk cx reason in
      Statement.mk_function cx ~hint:None ~needs_this_param:true ~general reason function_
    in
    Node_cache.set_function cache id_loc fn;
    fun_type

  let resolve_annotated_function cx reason ({ Ast.Function.body; params; _ } as function_) =
    let (({ Statement.Func_stmt_sig.fparams; _ } as func_sig), _) =
      Statement.mk_func_sig
        cx
        ~hint:None
        ~needs_this_param:true
        Subst_name.Map.empty
        reason
        function_
    in
    let this_t =
      let default =
        if Signature_utils.This_finder.found_this_in_body_or_params body params then
          let loc = aloc_of_reason reason in
          Tvar.mk cx (mk_reason RThis loc)
        else
          Type.implicit_mixed_this reason
      in
      Base.Option.value (Statement.Func_stmt_params.this fparams) ~default
    in
    Statement.Func_stmt_sig.functiontype cx this_t func_sig

  let resolve_op_assign cx ~id_loc ~exp_loc id_reason op rhs =
    let open Ast.Expression in
    match op with
    | Assignment.PlusAssign ->
      (* lhs += rhs *)
      let reason = mk_reason (RCustom ""+="") exp_loc in
      let lhs_t =
        New_env.New_env.read_entry_exn ~lookup_mode:Env_sig.LookupMode.ForValue cx id_loc id_reason
      in
      let rhs_t = expression cx ~hint:None rhs in
      Statement.plus_assign
        cx
        ~reason
        ~lhs_reason:id_reason
        ~rhs_reason:(mk_expression_reason rhs)
        lhs_t
        rhs_t
    | Assignment.MinusAssign
    | Assignment.MultAssign
    | Assignment.ExpAssign
    | Assignment.DivAssign
    | Assignment.ModAssign
    | Assignment.LShiftAssign
    | Assignment.RShiftAssign
    | Assignment.RShift3Assign
    | Assignment.BitOrAssign
    | Assignment.BitXorAssign
    | Assignment.BitAndAssign ->
      (* lhs (numop)= rhs *)
      let lhs_t =
        New_env.New_env.read_entry_exn ~lookup_mode:Env_sig.LookupMode.ForValue cx id_loc id_reason
      in
      let rhs_t = expression cx ~hint:None rhs in
      Statement.arith_assign cx exp_loc lhs_t rhs_t
    | Assignment.NullishAssign
    | Assignment.AndAssign
    | Assignment.OrAssign ->
      Tvar.mk cx (mk_reason (RCustom ""unhandled def"") id_loc)

  let resolve_update cx ~id_loc ~exp_loc id_reason =
    let reason = mk_reason (RCustom ""update"") exp_loc in
    let id_t =
      New_env.New_env.read_entry_exn ~lookup_mode:Env_sig.LookupMode.ForValue cx id_loc id_reason
    in
    Flow_js.flow cx (id_t, AssertArithmeticOperandT reason);
    NumT.at exp_loc |> with_trust literal_trust

  let resolve_type_alias cx loc alias =
    let cache = Context.node_cache cx in
    let (t, ast) = Statement.type_alias cx loc alias in
    Node_cache.set_alias cache loc (t, ast);
    t

  let resolve_opaque_type cx loc opaque =
    let cache = Context.node_cache cx in
    let (t, ast) = Statement.opaque_type cx loc opaque in
    Node_cache.set_opaque cache loc (t, ast);
    t

  let resolve_import cx id_loc import_reason import_kind module_name source_loc import =
    match import with
    | Name_def.Named { kind; remote; remote_loc; local } ->
      let import_kind = Base.Option.value ~default:import_kind kind in
      Statement.import_named_specifier_type
        cx
        import_reason
        import_kind
        ~source_loc
        ~module_name
        ~remote_name_loc:remote_loc
        ~remote_name:remote
        ~local_name:local
    | Namespace ->
      Statement.import_namespace_specifier_type
        cx
        import_reason
        import_kind
        ~source_loc
        ~module_name
        ~local_loc:id_loc
    | Default local_name ->
      Statement.import_default_specifier_type
        cx
        import_reason
        import_kind
        ~source_loc
        ~module_name
        ~local_loc:id_loc
        ~local_name

  let resolve_interface cx loc inter =
    let cache = Context.node_cache cx in
    let (t, ast) = Statement.interface cx loc inter in
    Node_cache.set_interface cache loc (t, ast);
    t

  let resolve_declare_class cx loc class_ =
    let cache = Context.node_cache cx in
    let (t, ast) = Statement.declare_class cx loc class_ in
    Node_cache.set_declared_class cache loc (t, ast);
    t

  let resolve_enum cx id_loc enum_reason enum =
    if Context.enable_enums cx then
      let enum_t = Statement.mk_enum cx ~enum_reason id_loc enum in
      DefT (enum_reason, literal_trust (), EnumObjectT enum_t)
    else (
      Flow_js.add_output cx (Error_message.EEnumsNotEnabled id_loc);
      AnyT.error enum_reason
    )

  let resolve cx id_loc (def, def_reason) =
    let t =
      match def with
      | Binding b -> resolve_binding cx id_loc b
      | Function { function_; fully_annotated = false } ->
        resolve_inferred_function cx id_loc def_reason function_
      | Function { function_; fully_annotated = true } ->
        resolve_annotated_function cx def_reason function_
      | OpAssign { exp_loc; op; rhs } -> resolve_op_assign cx ~id_loc ~exp_loc def_reason op rhs
      | Update { exp_loc; op = _ } -> resolve_update cx ~id_loc ~exp_loc def_reason
      | TypeAlias (loc, alias) -> resolve_type_alias cx loc alias
      | OpaqueType (loc, opaque) -> resolve_opaque_type cx loc opaque
      | Import { import_kind; source; source_loc; import } ->
        resolve_import cx id_loc def_reason import_kind source source_loc import
      | Interface (loc, inter) -> resolve_interface cx loc inter
      | DeclaredClass (loc, class_) -> resolve_declare_class cx loc class_
      | Enum enum -> resolve_enum cx id_loc def_reason enum
      | _ -> Tvar.mk cx (mk_reason (RCustom ""unhandled def"") id_loc)
    in
    Debug_js.Verbose.print_if_verbose_lazy
      cx
      ( lazy
        [
          Printf.sprintf
            ""Setting variable at %s to %s""
            (ALoc.debug_to_string id_loc)
            (Debug_js.dump_t cx t);
        ]
        );
    New_env.New_env.resolve_env_entry cx t id_loc

  let resolve_component cx graph component =
    let open Name_def_ordering in
    let resolve_element = function
      | Name_def_ordering.Normal loc
      | Resolvable loc
      | Illegal { loc; _ } ->
        resolve cx loc (ALocMap.find loc graph)
    in
    match component with
    | Singleton elt -> resolve_element elt
    | ResolvableSCC elts -> Nel.iter (fun elt -> resolve_element elt) elts
    | IllegalSCC elts -> Nel.iter (fun (elt, _, _) -> resolve_element elt) elts
end
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

type 'a in_channel = Timeout.in_channel

type 'a out_channel = Stdlib.out_channel

type ('in_, 'out) channel_pair = 'in_ in_channel * 'out out_channel

type ('in_, 'out) handle = {
  channels: ('in_, 'out) channel_pair;
  pid: int;
}

(* Windows: ensure that the serialize/deserialize functions
   for the custom block of ""Unix.file_descr"" are registred. *)
let () = Lazy.force Handle.init

let to_channel : 'a out_channel -> ?flags:Marshal.extern_flags list -> ?flush:bool -> 'a -> unit =
 fun oc ?(flags = []) ?flush:(should_flush = true) v ->
  Marshal.to_channel oc v flags;
  if should_flush then flush oc

let from_channel : ?timeout:Timeout.t -> 'a in_channel -> 'a =
 (fun ?timeout ic -> Timeout.input_value ?timeout ic)

let flush : 'a out_channel -> unit = Stdlib.flush

let descr_of_in_channel : 'a in_channel -> Unix.file_descr = Timeout.descr_of_in_channel

let descr_of_out_channel : 'a out_channel -> Unix.file_descr = Unix.descr_of_out_channel

let cast_in ic = ic

let cast_out oc = oc

(* We cannot fork() on Windows, so in order to emulate this in a
 * cross-platform way, we use create_process() and set the HH_SERVER_DAEMON
 * environment variable to indicate which function the child should
 * execute. On Unix, create_process() does fork + exec, so global state is
 * not copied; in particular, if you have set a mutable reference the
 * daemon will not see it. All state must be explicitly passed via
 * environment variables; see set/get_context() below.
 *
 * With some factoring we could make the daemons into separate binaries
 * altogether and dispense with this emulation. *)

module Entry : sig
  (* All the 'untyped' operations---that are required for the
     entry-points hashtable and the parameters stored in env
     variable---are hidden in this sub-module, behind a 'type-safe'
     interface. *)

  type ('param, 'input, 'output) t

  val name_of_entry : ('param, 'input, 'output) t -> string

  val register :
    string -> ('param -> ('input, 'output) channel_pair -> unit) -> ('param, 'input, 'output) t

  val find : ('param, 'input, 'output) t -> 'param -> ('input, 'output) channel_pair -> unit

  val set_context :
    ('param, 'input, 'output) t -> 'param -> Unix.file_descr * Unix.file_descr -> unit

  val get_context : unit -> ('param, 'input, 'output) t * 'param * ('input, 'output) channel_pair

  val clear_context : unit -> unit
end = struct
  type ('param, 'input, 'output) t = string

  let name_of_entry name = name

  (* Store functions as 'Obj.t' *)
  let entry_points : (string, Obj.t) Hashtbl.t = Hashtbl.create 23

  let register name f =
    if Hashtbl.mem entry_points name then
      Printf.ksprintf failwith ""Daemon.register_entry_point: duplicate entry point %S."" name;
    Hashtbl.add entry_points name (Obj.repr f);
    name

  let find name =
    try Obj.obj (Hashtbl.find entry_points name) with
    | Not_found -> Printf.ksprintf failwith ""Unknown entry point %S"" name

  let set_context entry param (ic, oc) =
    let data = (ic, oc, param) in
    Unix.putenv ""HH_SERVER_DAEMON"" entry;
    let (file, oc) =
      Filename.open_temp_file
        ~mode:[Open_binary]
        ~temp_dir:Sys_utils.temp_dir_name
        ""daemon_param""
        "".bin""
    in
    Marshal.to_channel oc data [Marshal.Closures];
    close_out oc;
    Unix.putenv ""HH_SERVER_DAEMON_PARAM"" file

  (* How this works on Unix: It may appear like we are passing file descriptors
   * from one process to another here, but in_handle / out_handle are actually
   * file descriptors that are already open in the current process -- they were
   * created by the parent process before it did fork + exec. However, since
   * exec causes the child to ""forget"" everything, we have to pass the numbers
   * of these file descriptors as arguments.
   *
   * I'm not entirely sure what this does on Windows. *)
  let get_context () =
    let entry = Unix.getenv ""HH_SERVER_DAEMON"" in
    if entry = """" then raise Not_found;
    let file = Sys.getenv ""HH_SERVER_DAEMON_PARAM"" in
    if file = """" then raise Not_found;
    let (in_handle, out_handle, param) =
      try
        let ic = Stdlib.open_in_bin file in
        let res = Marshal.from_channel ic in
        Stdlib.close_in ic;
        Sys.remove file;
        res
      with
      | exn -> failwith (""Can't find daemon parameters: "" ^ Printexc.to_string exn)
    in
    (entry, param, (Timeout.in_channel_of_descr in_handle, Unix.out_channel_of_descr out_handle))

  let clear_context () =
    Unix.putenv ""HH_SERVER_DAEMON"" """";
    Unix.putenv ""HH_SERVER_DAEMON_PARAM"" """"
end

type ('param, 'input, 'output) entry = ('param, 'input, 'output) Entry.t

let exec entry param ic oc =
  (*
   * The name ""exec"" is a bit of a misnomer. By the time we
   * get here, the ""exec"" syscall has already finished and the
   * process image has been replaced. We're using ""exec"" here to mean
   * running the proper entry.
   *
   * Since Linux's ""exec"" has already completed, we can actaully set
   * FD_CLOEXEC on the opened channels.
   *)
  let () = Unix.set_close_on_exec (descr_of_in_channel ic) in
  let () = Unix.set_close_on_exec (descr_of_out_channel oc) in
  let f = Entry.find entry in
  try
    f param (ic, oc);
    exit 0
  with
  | e ->
    let e = Exception.wrap e in
    prerr_endline (Exception.to_string e);
    exit 2

let register_entry_point = Entry.register

let name_of_entry = Entry.name_of_entry

let fd_of_path path =
  Sys_utils.with_umask 0o111 (fun () ->
      Sys_utils.mkdir_no_fail (Filename.dirname path);
      Unix.openfile path [Unix.O_RDWR; Unix.O_CREAT; Unix.O_TRUNC] 0o666
  )

let null_fd () = fd_of_path Sys_utils.null_path

let setup_channels channel_mode =
  let mk =
    match channel_mode with
    | `pipe -> (fun () -> Unix.pipe ())
    | `socket -> (fun () -> Unix.socketpair Unix.PF_UNIX Unix.SOCK_STREAM 0)
  in
  let (parent_in, child_out) = mk () in
  let (child_in, parent_out) = mk () in
  Unix.set_close_on_exec parent_in;
  Unix.set_close_on_exec parent_out;
  ((parent_in, child_out), (child_in, parent_out))

let descr_as_channels (descr_in, descr_out) =
  let ic = Timeout.in_channel_of_descr descr_in in
  let oc = Unix.out_channel_of_descr descr_out in
  (ic, oc)

(* This only works on Unix, and should be avoided as far as possible. Use
 * Daemon.spawn instead. *)
let fork
    ?(channel_mode = `pipe)
    (type param)
    (log_stdout, log_stderr)
    (f : param -> ('a, 'b) channel_pair -> unit)
    (param : param) : ('b, 'a) handle =
  let ((parent_in, child_out), (child_in, parent_out)) = setup_channels channel_mode in
  (* Since don't use exec, we can actually set CLOEXEC before the fork. *)
  Unix.set_close_on_exec child_in;
  Unix.set_close_on_exec child_out;
  let (parent_in, child_out) = descr_as_channels (parent_in, child_out) in
  let (child_in, parent_out) = descr_as_channels (child_in, parent_out) in
  match Fork.fork () with
  | -1 -> failwith ""Go get yourself a real computer""
  | 0 ->
    (* child *)
    (try
       ignore (Unix.setsid ());
       Timeout.close_in parent_in;
       close_out parent_out;
       Sys_utils.with_umask 0o111 (fun () ->
           let fd = null_fd () in
           Unix.dup2 fd Unix.stdin;
           Unix.close fd
       );
       Unix.dup2 log_stdout Unix.stdout;
       Unix.dup2 log_stderr Unix.stderr;
       if log_stdout <> Unix.stdout then Unix.close log_stdout;
       if log_stderr <> Unix.stderr && log_stderr <> log_stdout then Unix.close log_stderr;
       f param (child_in, child_out);
       exit 0
     with
    | e ->
      let e = Exception.wrap e in
      prerr_endline (Exception.to_string e);
      exit 1)
  | pid ->
    (* parent *)
    Timeout.close_in child_in;
    close_out child_out;
    { channels = (parent_in, parent_out); pid }

let spawn
    (type param input output)
    ?(channel_mode = `pipe)
    ?name
    (stdin, stdout, stderr)
    (entry : (param, input, output) entry)
    (param : param) : (output, input) handle =
  let ((parent_in, child_out), (child_in, parent_out)) = setup_channels channel_mode in
  Entry.set_context entry param (child_in, child_out);
  let exe = Sys_utils.executable_path () in
  let name = Base.Option.value ~default:(Entry.name_of_entry entry) name in
  let pid = Unix.create_process exe [| exe; name |] stdin stdout stderr in
  Entry.clear_context ();
  Unix.close child_in;
  Unix.close child_out;
  let close_if_open fd =
    try Unix.close fd with
    | Unix.Unix_error (Unix.EBADF, _, _) -> ()
  in
  if stdin <> Unix.stdin then close_if_open stdin;
  if stdout <> Unix.stdout then close_if_open stdout;
  if stderr <> Unix.stderr && stderr <> stdout then close_if_open stderr;

  PidLog.log ~reason:(Entry.name_of_entry entry) ~no_fail:true pid;
  { channels = (Timeout.in_channel_of_descr parent_in, Unix.out_channel_of_descr parent_out); pid }

(* for testing code *)
let devnull () =
  let ic = Timeout.open_in ""/dev/null"" in
  let oc = open_out ""/dev/null"" in
  { channels = (ic, oc); pid = 0 }

(**
 * In order for the Daemon infrastructure to work, the beginning of your
 * program (or very close to the beginning) must start with a call to
 * check_entry_point.
 *
 * Details: Daemon.spawn essentially does a fork then exec of the currently
 * running program. Thus, the child process will just end up running the exact
 * same program as the parent if you forgot to start with a check_entry_point.
 * The parent process sees this as a NOOP when its program starts, but a
 * child process (from Daemon.spawn) will use this as a GOTO to its entry
 * point.
 *)
let check_entry_point () =
  try
    let (entry, param, (ic, oc)) = Entry.get_context () in
    Entry.clear_context ();
    exec entry param ic oc
  with
  | Not_found -> ()

let close { channels = (ic, oc); _ } =
  Timeout.close_in ic;
  close_out oc

let kill h =
  close h;
  Sys_utils.terminate_process h.pid

let close_out = close_out

let output_string = output_string

let flush = flush

let close_in = Timeout.close_in

let input_char ic = Timeout.input_char ic

let input_value ic = Timeout.input_value ic
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*                         Alain Frisch, LexiFi                           *)
(*                                                                        *)
(*   Copyright 2012 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(** The interface of a -ppx rewriter

  A -ppx rewriter is a program that accepts a serialized abstract syntax
  tree and outputs another, possibly modified, abstract syntax tree.
  This module encapsulates the interface between the compiler and
  the -ppx rewriters, handling such details as the serialization format,
  forwarding of command-line flags, and storing state.

  {!mapper} enables AST rewriting using open recursion.
  A typical mapper would be based on {!default_mapper}, a deep
  identity mapper, and will fall back on it for handling the syntax it
  does not modify. For example:

  {[
open Asttypes
open Parsetree
open Ast_mapper

let test_mapper argv =
  { default_mapper with
    expr = fun mapper expr ->
      match expr with
      | { pexp_desc = Pexp_extension ({ txt = ""test"" }, PStr [])} ->
        Ast_helper.Exp.constant (Const_int 42)
      | other -> default_mapper.expr mapper other; }

let () =
  register ""ppx_test"" test_mapper]}

  This -ppx rewriter, which replaces [[%test]] in expressions with
  the constant [42], can be compiled using
  [ocamlc -o ppx_test -I +compiler-libs ocamlcommon.cma ppx_test.ml].

  {b Warning:} this module is unstable and part of
  {{!Compiler_libs}compiler-libs}.

  *)

open Parsetree

(** {1 A generic Parsetree mapper} *)

type mapper = {
  attribute: mapper -> attribute -> attribute;
  attributes: mapper -> attribute list -> attribute list;
  binding_op: mapper -> binding_op -> binding_op;
  case: mapper -> case -> case;
  cases: mapper -> case list -> case list;
  class_declaration: mapper -> class_declaration -> class_declaration;
  class_description: mapper -> class_description -> class_description;
  class_expr: mapper -> class_expr -> class_expr;
  class_field: mapper -> class_field -> class_field;
  class_signature: mapper -> class_signature -> class_signature;
  class_structure: mapper -> class_structure -> class_structure;
  class_type: mapper -> class_type -> class_type;
  class_type_declaration: mapper -> class_type_declaration
                          -> class_type_declaration;
  class_type_field: mapper -> class_type_field -> class_type_field;
  constant: mapper -> constant -> constant;
  constructor_declaration: mapper -> constructor_declaration
                           -> constructor_declaration;
  expr: mapper -> expression -> expression;
  extension: mapper -> extension -> extension;
  extension_constructor: mapper -> extension_constructor
                         -> extension_constructor;
  include_declaration: mapper -> include_declaration -> include_declaration;
  include_description: mapper -> include_description -> include_description;
  label_declaration: mapper -> label_declaration -> label_declaration;
  location: mapper -> Location.t -> Location.t;
  module_binding: mapper -> module_binding -> module_binding;
  module_declaration: mapper -> module_declaration -> module_declaration;
  module_substitution: mapper -> module_substitution -> module_substitution;
  module_expr: mapper -> module_expr -> module_expr;
  module_type: mapper -> module_type -> module_type;
  module_type_declaration: mapper -> module_type_declaration
                           -> module_type_declaration;
  open_declaration: mapper -> open_declaration -> open_declaration;
  open_description: mapper -> open_description -> open_description;
  pat: mapper -> pattern -> pattern;
  payload: mapper -> payload -> payload;
  signature: mapper -> signature -> signature;
  signature_item: mapper -> signature_item -> signature_item;
  structure: mapper -> structure -> structure;
  structure_item: mapper -> structure_item -> structure_item;
  typ: mapper -> core_type -> core_type;
  type_declaration: mapper -> type_declaration -> type_declaration;
  type_extension: mapper -> type_extension -> type_extension;
  type_exception: mapper -> type_exception -> type_exception;
  type_kind: mapper -> type_kind -> type_kind;
  value_binding: mapper -> value_binding -> value_binding;
  value_description: mapper -> value_description -> value_description;
  with_constraint: mapper -> with_constraint -> with_constraint;
  directive_argument: mapper -> directive_argument -> directive_argument;
  toplevel_directive: mapper -> toplevel_directive -> toplevel_directive;
  toplevel_phrase: mapper -> toplevel_phrase -> toplevel_phrase;
}
(** A mapper record implements one ""method"" per syntactic category,
    using an open recursion style: each method takes as its first
    argument the mapper to be applied to children in the syntax
    tree. *)

val default_mapper: mapper
(** A default mapper, which implements a ""deep identity"" mapping. *)

(** {1 Apply mappers to compilation units} *)

val tool_name: unit -> string
(** Can be used within a ppx preprocessor to know which tool is
    calling it [""ocamlc""], [""ocamlopt""], [""ocamldoc""], [""ocamldep""],
    [""ocaml""], ...  Some global variables that reflect command-line
    options are automatically synchronized between the calling tool
    and the ppx preprocessor: {!Clflags.include_dirs},
    {!Load_path}, {!Clflags.open_modules}, {!Clflags.for_package},
    {!Clflags.debug}. *)


val apply: source:string -> target:string -> mapper -> unit
(** Apply a mapper (parametrized by the unit name) to a dumped
    parsetree found in the [source] file and put the result in the
    [target] file. The [structure] or [signature] field of the mapper
    is applied to the implementation or interface.  *)

val run_main: (string list -> mapper) -> unit
(** Entry point to call to implement a standalone -ppx rewriter from a
    mapper, parametrized by the command line arguments.  The current
    unit name can be obtained from {!Location.input_name}.  This
    function implements proper error reporting for uncaught
    exceptions. *)

(** {1 Registration API} *)

val register_function: (string -> (string list -> mapper) -> unit) ref

val register: string -> (string list -> mapper) -> unit
(** Apply the [register_function].  The default behavior is to run the
    mapper immediately, taking arguments from the process command
    line.  This is to support a scenario where a mapper is linked as a
    stand-alone executable.

    It is possible to overwrite the [register_function] to define
    ""-ppx drivers"", which combine several mappers in a single process.
    Typically, a driver starts by defining [register_function] to a
    custom implementation, then lets ppx rewriters (linked statically
    or dynamically) register themselves, and then run all or some of
    them.  It is also possible to have -ppx drivers apply rewriters to
    only specific parts of an AST.

    The first argument to [register] is a symbolic name to be used by
    the ppx driver.  *)


(** {1 Convenience functions to write mappers} *)

val map_opt: ('a -> 'b) -> 'a option -> 'b option

val extension_of_error: Location.error -> extension
(** Encode an error into an 'ocaml.error' extension node which can be
    inserted in a generated Parsetree.  The compiler will be
    responsible for reporting the error. *)

val attribute_of_warning: Location.t -> string -> attribute
(** Encode a warning message into an 'ocaml.ppwarning' attribute which can be
    inserted in a generated Parsetree.  The compiler will be
    responsible for reporting the warning. *)

(** {1 Helper functions to call external mappers} *)

val add_ppx_context_str:
    tool_name:string -> Parsetree.structure -> Parsetree.structure
(** Extract information from the current environment and encode it
    into an attribute which is prepended to the list of structure
    items in order to pass the information to an external
    processor. *)

val add_ppx_context_sig:
    tool_name:string -> Parsetree.signature -> Parsetree.signature
(** Same as [add_ppx_context_str], but for signatures. *)

val drop_ppx_context_str:
    restore:bool -> Parsetree.structure -> Parsetree.structure
(** Drop the ocaml.ppx.context attribute from a structure.  If
    [restore] is true, also restore the associated data in the current
    process. *)

val drop_ppx_context_sig:
    restore:bool -> Parsetree.signature -> Parsetree.signature
(** Same as [drop_ppx_context_str], but for signatures. *)

(** {1 Cookies} *)

(** Cookies are used to pass information from a ppx processor to
    a further invocation of itself, when called from the OCaml
    toplevel (or other tools that support cookies). *)

val set_cookie: string -> Parsetree.expression -> unit
val get_cookie: string -> Parsetree.expression option
",ocaml
"(******************************************************************************)
(*      Copyright (c) 2008, 2009, Sebastien MONDET                            *)
(*                                                                            *)
(*      Permission is hereby granted, free of charge, to any person           *)
(*      obtaining a copy of this software and associated documentation        *)
(*      files (the ""Software""), to deal in the Software without               *)
(*      restriction, including without limitation the rights to use,          *)
(*      copy, modify, merge, publish, distribute, sublicense, and/or sell     *)
(*      copies of the Software, and to permit persons to whom the             *)
(*      Software is furnished to do so, subject to the following              *)
(*      conditions:                                                           *)
(*                                                                            *)
(*      The above copyright notice and this permission notice shall be        *)
(*      included in all copies or substantial portions of the Software.       *)
(*                                                                            *)
(*      THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,       *)
(*      EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES       *)
(*      OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND              *)
(*      NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT           *)
(*      HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,          *)
(*      WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING          *)
(*      FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR         *)
(*      OTHER DEALINGS IN THE SOFTWARE.                                       *)
(******************************************************************************)

(** The (X)HTML output format, implements {!type:Signatures.printer}
    functions. *)

(**/**)

type t = {
  stack: Commands.Stack.t;
  mutable write: string -> unit;
  write_mem: (string -> unit) Stack.t;
  mutable current_line: int;
  mutable started_text: bool;
  mutable inside_header:bool;
  mutable current_table: Commands.Table.table option;
  mutable current_section: (int * string * Buffer.t) option;
  error: Error.error -> unit;
  mutable loc: Error.location;
  class_hook: string option;
  url_hook: string -> string;
  img_hook: string -> string;
  separate_header: (string * string * string) ref option;
  make_section_links: [ `never | `when_labeled | `always ];
}

module CS = Commands.Stack

let (~%) = Printf.sprintf

module AddClass = struct
  let name add style =
    match add with
    | None -> """"
    | Some s -> ~% "" %s%s"" s style
  
  let attribute add style =
    match add with
    | None -> """"
    | Some s -> ~% "" class=\""%s%s\"""" s style

end

let create
    ~writer ?class_hook ?separate_header
    ?(make_section_links=`when_labeled)
    ?(img_hook=fun s -> s) ?(url_hook=fun s -> s) () =
  let module S = Signatures in
  let write = writer.S.w_write in
  {
    stack = CS.empty ();
    write = write;
    write_mem = Stack.create ();
    current_line = 1;
    started_text = false;
    inside_header = false;
    current_table = None;
    current_section = None;
    error = writer.S.w_error;
    loc = {Error.l_line = -1; l_char = -1; l_file = ""NO FILE"";};
    class_hook = class_hook;
    url_hook = url_hook;
    img_hook = img_hook;
    separate_header = separate_header;
    make_section_links = make_section_links;
  }
    

let strstat s = (~% ""[%d:%d]"" s.Error.l_line s.Error.l_char)
let debugstr t s msg = 
  if false then
    (~% ""<!--DEBUG:[%s] Loc:[%d;%d] CurLine:%d-->""
       msg s.Error.l_line s.Error.l_char t.current_line)
  else
    """"

let sanitize_comments line =
  let patterns = [('<', ""LT""); ('>', ""GT""); ('&', ""AMP""); ('-', ""DASH"")] in
  Escape.replace_chars ~src:line ~patterns
    (* let src = Escape.replace_string ~src:line ~find:""-->"" ~replace_with:""XXX"" in *)
    (* Escape.replace_string ~src ~find:""<!--"" ~replace_with:""XXXX"" *)

let sanitize_pcdata line =
  let patterns = [('<', ""&lt;""); ('>', ""&gt;""); ('&', ""&amp;"")] in
  Escape.replace_chars ~src:line ~patterns

let sanitize_xml_attribute src =
  let patterns =
    [('<', ""&lt;""); ('>', ""&gt;""); ('&', ""&amp;""); ('""', ""&quot;"")] in
  Escape.replace_chars ~src ~patterns


let quotation_open_close t a =
  let default = (""&ldquo;"", ""&rdquo;"") in
  try
    match List.hd a with
    | ""'""  -> (""&lsquo;"", ""&rsquo;"")
    | ""en"" -> (""&ldquo;"", ""&rdquo;"")
    | ""fr"" -> (""&laquo;&nbsp;"", ""&nbsp;&raquo;"")
    | ""de"" -> (""&bdquo;"", ""&rdquo;"")
    | ""es"" -> (""&laquo;"", ""&raquo;"")
    | s    -> 
        t.error (Error.mk t.loc `warning (`unknown_quotation_style s));
        default
  with
  | e -> default

let list_start t =
  function `itemize -> ~% ""\n<ul%s>\n"" (AddClass.attribute t.class_hook ""ul"")
  | `numbered -> ~%  ""\n<ol%s>\n"" (AddClass.attribute t.class_hook ""ol"")
let list_item t = function
  | `itemize -> ~% ""</li>\n<li%s>"" (AddClass.attribute t.class_hook ""li"")
  | `numbered -> ~% ""</li>\n<li%s>""  (AddClass.attribute t.class_hook ""li"")
let list_firstitem t = 
  function `itemize -> ~% ""<li%s>"" (AddClass.attribute t.class_hook ""li"")
  | `numbered -> ~% ""<li%s>"" (AddClass.attribute t.class_hook ""li"")
let list_stop t = 
  function `itemize -> ""</li>\n</ul>\n"" | `numbered -> ""</li>\n</ol>\n""

let section_start t n l =
  let buf = Buffer.create 42 in
  match t.current_section with
  | Some _ ->
    failwith ""Nested Sections not allowed""
  | None ->
    t.current_section <- Some (n, l, buf);
    Stack.push t.write t.write_mem;
    t.write ""</div>\n"";
    t.write <- Buffer.add_string buf;
    ()

let section_stop t n l =
  begin match t.current_section with
  | None -> failwith ""fatal error: section_stop with no section_start""
  | Some (n, l, buf) ->
    let lsan =
      match t.make_section_links, sanitize_xml_attribute l with
      | `never, _ -> """"
      | `when_labeled, """" -> """" 
      | `when_labeled, s -> ~% "" id=\""%s\"""" s
      | `always, """" -> ~% "" id=\""%s\"""" (Escape.clean_string (Buffer.contents buf))
      | `always, s  -> ~% "" id=\""%s\"""" s
    in
    t.write <- Stack.pop t.write_mem;
    t.current_section <- None;
    let tag = ~% ""h%d"" (n + 1) in
    ~% ""<%s%s%s>%s</%s>\n<div class=\""p%s\"">""
      tag lsan (AddClass.attribute t.class_hook tag)
      (Buffer.contents buf)
      tag (AddClass.name t.class_hook ""p"")
  end

let link_start t args =
  let link, new_write = Commands.Link.start ~url_hook:t.url_hook args in
  Stack.push t.write t.write_mem;
  t.write <- new_write;
  link

let link_stop t l =
  t.write <- Stack.pop t.write_mem;
  let kind, target, text = Commands.Link.stop l in
  let target_str = 
    (match target with Some s -> s | None -> ""#"") in
  t.write
    (~% ""<a href=\""%s%s\""%s>%s</a>"" 
       (match kind with `local -> ""#"" | `generic -> """")
       (sanitize_xml_attribute target_str)
       (AddClass.attribute t.class_hook ""a"")
       (match text with Some s -> s | None -> sanitize_pcdata target_str));
  ()

let image_start t args =
  (* http://www.w3.org/Style/Examples/007/figures *)
  let error_msg m = t.error (Error.mk t.loc `error m) in
  let src, opts, lbl =
    Commands.Names.image_params ~img_hook:t.img_hook error_msg args in
  let opts_str =
    match opts with
    | `wpx px -> (~% ""width=\""%dpx\""""  px)
    | `wpercent w -> (~% ""width=\""%d%%\"""" w)
    | `none -> """" 
  in
  let sansrc =
    match sanitize_xml_attribute src with
      """" -> ""http://IMAGEWITHNOSOURCE"" | s -> s in
  let sanlbl =
    match sanitize_xml_attribute lbl with 
    | """" -> """" | s -> ~% ""id=\""%s\"" "" s in
  t.write
    (~% ""\n<div class=\""figure%s\"" %s>\n  <a href=\""%s\"">\
        \n    <img src=\""%s\"" %s %s alt=\""%s\""%s/>\n  </a><br/>\n""
       (AddClass.name t.class_hook ""figure"")
        sanlbl sansrc sansrc opts_str sanlbl sansrc
        (AddClass.attribute t.class_hook ""img""));
  `image (src, opts, lbl)

let image_stop = ""</div>""

let header_start t =
  t.inside_header <- true; 
  begin match t.separate_header with
  | None ->
      t.write (~% ""%s\n<div class=\""header%s\"">\n""
                 (if t.started_text then ""</div>"" else """")
                 (AddClass.name t.class_hook ""header""))
  | Some r ->
      Stack.push t.write t.write_mem;
      t.write <- (fun str -> 
                    match CS.head t.stack with
                    | Some `title    -> let t,a,s = !r in r := (t ^ str, a, s);
                    | Some `authors  -> let t,a,s = !r in r := (t, a ^ str, s);
                    | Some `subtitle -> let t,a,s = !r in r := (t, a, s ^ str);
                    | _ -> ());
  end

let header_stop t =
  t.inside_header <- false;
  begin match t.separate_header with
  | None ->
      t.started_text <- true; (* we put the <p> *)
      t.write (~% ""</div> <!-- END HEADER -->\n<div class=\""p%s\"">\n""
                 (AddClass.name t.class_hook ""p""))
  | Some r ->
      t.write <- Stack.pop t.write_mem;
  end

let title_start t =
  t.write (~% ""\n  <h1%s>"" (AddClass.attribute t.class_hook ""h1""))
let title_stop t = t.write ""</h1>\n""
let authors_start t =
  t.write (~% ""  <div class=\""authors%s\"">""
             (AddClass.name t.class_hook ""authors""))
let authors_stop t = t.write ""</div>\n""
let subtitle_start t =
  t.write (~% ""  <div class=\""subtitle%s\"">""
             (AddClass.name t.class_hook ""subtitle""))
let subtitle_stop t = t.write ""</div>\n""

let table_start t args =
  (* http://www.topxml.com/xhtml/articles/xhtml_tables/ *)
  let table, to_stack, new_write = Commands.Table.start args in
  t.current_table <- Some table;
  Stack.push t.write t.write_mem;
  t.write <- new_write;
  to_stack

let print_table t table =
  let module CT = Commands.Table in
  let write = t.write in
  let lbl_str =
    match table.CT.label with
    | None -> """"
    | Some s -> (~% ""id=\""%s\"""" (sanitize_xml_attribute s))
  in
  write
    (~% ""<div class=\""tablefigure%s\"">\n\
         <table class=\""tablefigure%s\""  border=\""1\"" %s >\n""
       (AddClass.name t.class_hook ""tablefigure"")
         (AddClass.name t.class_hook ""table"")
         lbl_str);
  let caption_str = (Buffer.contents table.CT.caption) in
  if not (Escape.is_white_space caption_str) then (
    write (~% ""<caption  class=\""tablefigure%s\"" %s>%s</caption>\n<tr>""
             (AddClass.name t.class_hook ""p"")
             lbl_str caption_str);
  );

  let riddle = CT.Util.make_riddle table in

  let rec write_cells cells cur_row cur_col =
    match cells with
    | [] -> (* fill the gap + warning *)
        ()
    | c :: tl ->
        let typ_of_cell = if c.CT.is_head then ""h"" else ""d"" in
        let alignement =
          match c.CT.align with
          | `right ->
              ~% ""class=\""rightalign%s\"" style=\""text-align:right;\""""
                (AddClass.name t.class_hook ""cellrightalign"")
          | `center ->
              ~% ""class=\""centeralign%s\"" style=\""text-align:center;\""""
                (AddClass.name t.class_hook ""cellcenteralign"")
          | `left ->
              ~% ""class=\""leftalign%s\"" style=\""text-align:left;\""""
                (AddClass.name t.class_hook ""cellleftalign"")
        in
        write (~% ""<t%s  rowspan=\""%d\"" colspan=\""%d\"" %s >%s</t%s>""
                 typ_of_cell c.CT.rows_used c.CT.cols_used alignement
                 (Buffer.contents c.CT.cell_text)
                 typ_of_cell);
        CT.Util.fill_riddle riddle
          cur_row cur_col c.CT.rows_used c.CT.cols_used;
        let next_row, next_col = 
          CT.Util.next_coordinates riddle table cur_row cur_col in
        if cur_row <> next_row then (
          write ""</tr>\n"";
          if tl <> [] then
            write (~% ""<tr%s>"" (AddClass.attribute t.class_hook ""tr""));
        );
        write_cells tl next_row next_col
  in
  write_cells (List.rev table.CT.cells) 0 0;
  write ""</table></div>\n""


let table_stop t =
  begin match t.current_table with
  | None -> failwith ""Why am I here ??? no table to end.""
  | Some tab ->
      (* p (~% ""End of table: %s\n"" (Buffer.contents tab.caption)); *)
      t.write <- Stack.pop t.write_mem;
      t.current_table <- None;
      print_table t tab;
  end

let cell_start t args =
  begin match t.current_table with
  | None ->
      t.error (Error.mk t.loc `error `cell_out_of_table);
      `cell (false, 1, `center)
  | Some tab ->
      Commands.Table.cell_start ~loc:t.loc ~error:t.error tab args
  end

let cell_stop t env =
  match t.current_table with
  | None -> (* Already warned *) ()
  | Some tab -> Commands.Table.cell_stop ~loc:t.loc ~error:t.error tab

let note_start t =
  t.write
    (~% ""<small class=\""notebegin%s\"">(</small><small class=\""note%s\"">""
       (AddClass.name t.class_hook ""notebegin"")
       (AddClass.name t.class_hook ""note""));
  `note

let note_stop t =
  ~% ""</small><small class=\""noteend%s\"">)</small>""
    (AddClass.name t.class_hook ""noteend"")

let may_start_text t =
  if not t.started_text && not t.inside_header then (
    t.started_text <- true;
    t.write (~% ""<div class=\""p%s\"">"" (AddClass.name t.class_hook ""p""));
  )

let start_environment ?(is_begin=false) t location name args =
  t.loc <- location;
  let module C = Commands.Names in
  let cmd name args =
    match name with
    | s when C.is_header s -> (header_start t); `header
    | s when C.is_title s ->  (title_start t); `title
    | s when C.is_subtitle s -> (subtitle_start t); `subtitle
    | s when C.is_authors s -> (authors_start t); `authors
    | _ ->
        may_start_text t;
        begin match name with
        | s when C.is_quotation s        ->
            let op, clo = quotation_open_close t args in
            t.write op;
            `quotation (op, clo)
        | s when C.is_italic s ->
            t.write (~% ""<i%s>"" (AddClass.attribute t.class_hook ""i""));
            `italic
        | s when C.is_bold s ->
            t.write (~% ""<b%s>"" (AddClass.attribute t.class_hook ""b""));
            `bold
        | s when C.is_mono_space s ->
            t.write (~% ""<tt%s>"" (AddClass.attribute t.class_hook ""tt""));
            `mono_space
        | s when C.is_superscript s ->
            t.write (~% ""<sup%s>"" (AddClass.attribute t.class_hook ""sup""));
            `superscript
        | s when C.is_subscript s ->
            t.write (~% ""<sub%s>"" (AddClass.attribute t.class_hook ""sub""));
            `subscript
        | s when (C.is_end s)           -> `cmd_end
        | s when C.is_list s             ->
            let style, other_args, waiting =
              let error_msg m = t.error (Error.mk t.loc `error m) in
              match args with
              | [] -> (`itemize, [], ref true)
              | h :: t -> (C.list_style error_msg h, t, ref true) in
            t.write (list_start t style);
            `list (style, other_args, waiting)
        | s when C.is_item s -> `item
        | s when C.is_section s -> 
            let level, label = C.section_params args in
            section_start t level label;
            `section (level, label)
        | s when C.is_link s -> (link_start t args)
        | s when C.is_image s -> image_start t args
        | s when C.is_table s -> table_start t args
        | s when C.is_cell s -> cell_start t args
        | s when C.is_note s -> note_start t
        | s when C.is_quote s ->
            t.write (~% ""<blockquote%s>"" (AddClass.attribute t.class_hook ""quote""));
            t.write (~% ""<div class=\""p%s\"">"" (AddClass.name t.class_hook ""p""));
            `quote
        | s ->
            t.error (Error.mk t.loc `error (`unknown_command  s));
            `unknown (s, args)
        end
  in
  let the_cmd =
    if C.is_begin name then (
      match args with
      | [] ->
          t.error (Error.mk t.loc `error `begin_without_arg);
          (`cmd_begin ("""", []))
      | h :: t -> (`cmd_begin (h, t))
    ) else (
      cmd name args
    )
  in
  if is_begin then (
    CS.push t.stack (`cmd_inside the_cmd);
  ) else (
    CS.push t.stack the_cmd;
  )

let start_command t location name args =
  t.loc <- location;
  (* p (~% ""Command: \""%s\""(%s)\n"" name (String.concat "", "" args)); *)
  match Commands.non_env_cmd_of_name name args with
  | `unknown (name, args) -> start_environment t location name args
  | cmd -> CS.push t.stack cmd

let stop_command t location =
  t.loc <- location;
  let rec out_of_env env =
    match env with
    | `cmd_end ->
        begin match CS.pop t.stack with
        | Some (`cmd_inside benv) ->
            (* p (~% ""{end} %s\n"" (Commands.env_to_string benv)); *)
            out_of_env benv
        | Some c ->
            t.error (Error.mk t.loc `error `non_matching_end);
            CS.push t.stack c;
        | None ->
            t.error (Error.mk t.loc `error `non_matching_end);
        end
    | `cmd_begin (nam, args) ->
        (* p (~% ""cmd begin %s(%s)\n"" nam (String.concat "", "" args)); *)
        start_environment ~is_begin:true t location nam args;
    | `paragraph ->
        t.write (~% ""</div>\n<div class=\""p%s\"">""
                   (AddClass.name t.class_hook ""p""))
    | `new_line -> 
        t.write (~% ""<br%s/>\n"" (AddClass.attribute t.class_hook ""br""))
    | `non_break_space -> t.write ""&nbsp;""
    | `horizontal_ellipsis -> t.write ""&hellip;""
    | `en_dash -> t.write ""&ndash;""
    | `em_dash -> t.write ""&mdash;""
    | `open_brace -> t.write ""{""
    | `close_brace -> t.write ""}""
    | `sharp -> t.write ""#""
    | (`utf8_char i) -> t.write (~% ""&#%d;"" i)
    | (`quotation (op, clo)) -> t.write clo
    | `italic       ->  t.write ""</i>""  
    | `bold         ->  t.write ""</b>""  
    | `mono_space   ->  t.write ""</tt>"" 
    | `superscript  ->  t.write ""</sup>""
    | `subscript    ->  t.write ""</sub>""
    | `list (style, _, r) -> t.write (list_stop t style)
    | `item ->
        begin match CS.head t.stack with
        | Some (`list (style, _, r))
        | Some (`cmd_inside (`list (style, _, r))) ->
            if !r then (
              t.write (list_firstitem t style);
              r := false;
            ) else (
              t.write (list_item t style);
            );
        | Some c ->
            t.error (Error.mk t.loc `error `item_out_of_list);
            CS.push t.stack c;
        | None ->
            t.error (Error.mk t.loc `error `item_out_of_list);
        end
    | `section (level, label) ->
      let section = (section_stop t level label) in
      t.write section;
    | `link l -> link_stop t l;
    | `image _ -> t.write image_stop;
    | `header ->  (header_stop t);
    | `title -> title_stop t;
    | `subtitle -> subtitle_stop t;
    | `authors -> authors_stop t;
    | `table _ -> table_stop t
    | `cell _ as c -> cell_stop t c
    | `note -> t.write (note_stop t)
    | `quote ->  t.write ""</div></blockquote>""
    | `cmd_inside c ->
        t.error (Error.mk t.loc `error `closing_brace_matching_begin);
    | `unknown c -> () (* Already ""t.error-ed"" in start_environment *)
    | c -> (* shouldn't be there !! *)
        t.error (Error.mk t.loc `fatal_error 
                   (`transformer_lost (Commands.env_to_string c)));
  in
  match CS.pop t.stack with
  | Some env -> out_of_env env
  | None ->
      t.error (Error.mk t.loc `error `nothing_to_end_with_brace)


let handle_comment_line t location line =
  t.loc <- location;
  t.write (~% ""%s<!--%s-->\n"" (debugstr t location ""Comment"")
             (sanitize_comments line));
  t.current_line <- t.current_line + 1;
  ()

let handle_text t location line =
  t.loc <- location;
  if not (Escape.is_white_space line) then (
    may_start_text t;
  );
  
  if (t.started_text && (not t.inside_header)) ||
    (t.inside_header && (CS.head t.stack <> Some `header)) then (

      let debug = debugstr t location ""Text"" in
      let pcdata = sanitize_pcdata line in
      if location.Error.l_line > t.current_line then (
        t.write (~% ""%s%s"" debug pcdata);
        t.current_line <- location.Error.l_line;
      ) else (
        t.write (~% ""%s%s"" debug pcdata);
      )
    ) else (
      if
        CS.head t.stack = Some `header
        && (not (Escape.is_white_space line))
      then (
        t.write (~% ""<!-- IGNORED TEXT: %s -->"" (sanitize_comments line));
      );

    )


let terminate t location =
  t.loc <- location;
  if (CS.to_list t.stack) <> [] then (
    let l = List.map Commands.env_to_string (CS.to_list t.stack) in
    t.error (Error.mk t.loc `error (`terminating_with_open_environments l));
  );  
  t.write (if t.started_text then ""</div>\n"" else """");
  () 


let start_raw_mode t location kind_str args =
  t.current_line <- location.Error.l_line;
  let kind = Commands.Raw.raw_cmd_of_str kind_str in
  begin match kind with
  | `code ->
      CS.push t.stack (`code args);
      begin match args with
      | _ :: q :: _ ->
        t.write (~% ""\n<!--verbatimbegin:%s -->\n"" (sanitize_comments q))
      | _ -> ()
      end;
      t.write (~% ""<pre%s>""  (AddClass.attribute t.class_hook ""pre""));
  | `bypass | `text | `ignore as env_kind ->
      CS.push t.stack env_kind;
  end

let handle_raw_text t location text =
  t.current_line <- location.Error.l_line;
  begin match CS.head t.stack with
  | Some (`code _) | Some `text ->
      let pcdata = sanitize_pcdata text in
      t.write (~% ""%s"" pcdata);
  | Some `bypass ->
      t.write text;
  | Some `ignore -> ()
  | _ ->
      failwith ""handle_raw_text: Shouldn't be there, Parser's fault ?"";
  end
  
let stop_raw_mode t location =
  t.current_line <- location.Error.l_line;
  begin match CS.pop t.stack with
  | Some (`code args) ->
      t.write ""</pre>"";
      begin match args with
      | _ :: q :: _ ->
        t.write (~% ""\n<!--verbatimend:%s -->\n"" (sanitize_comments q))
      | _ -> ()
      end;
  | Some `bypass | Some `text | Some `ignore -> ()
  | _ ->
      (* warning ? error ? anyway, *)
      failwith ""Shouldn't be there, Parser's fault ?"";
  end

(**/**)

(** Build a [printer] to feed {!val:Parser.do_transformation}, the
optional arguments have the same meaning than for
{!val:Transform.brtx_to_html}. *)
let build ?(print_comments=false)
    ?make_section_links
    ?separate_header ?img_hook ?url_hook ?class_hook ~writer () =
  let t =
    create ~writer ?make_section_links
      ?class_hook ?separate_header ?img_hook ?url_hook () in
  { Signatures.
      print_comment =
      if print_comments then 
        (handle_comment_line t)
      else 
        (fun a b -> ());
    print_text =    handle_text t;
    enter_cmd =     start_command t;
    leave_cmd =     stop_command t;
    terminate =     terminate t;
    is_raw = Commands.Raw.is_raw_cmd;
    default_raw_end = Commands.Raw.default_raw_end;
    enter_raw =     start_raw_mode t;
    print_raw =     handle_raw_text t;
    leave_raw =     stop_raw_mode t;
    error = writer.Signatures.w_error; }

(** Build an HTML header. *)
let header ?(title="""") ?(comment="""") ?stylesheet_link () =
  let css_str =
    match stylesheet_link with
    | None -> """"
    | Some f ->
        ~% ""<link rel=\""stylesheet\""  type=\""text/css\"" href=\""%s\"" />\n""
          (sanitize_xml_attribute f)
  in
  ~% ""<!DOCTYPE html
    PUBLIC \""-//W3C//DTD XHTML 1.0 Strict//EN\""
    \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"">
    <html xmlns=\""http://www.w3.org/1999/xhtml\"" xml:lang=\""en\"" lang=\""en\"">
    <!-- %s -->
    <head>
    <meta http-equiv=\""Content-Type\"" content=\""text/html; charset=utf-8\"" />
    %s<title>%s</title>
    </head>
    <body>"" (sanitize_comments comment) css_str (sanitize_pcdata title)

(** Close an HTML document. *)
let footer () = ""</body>\n</html>\n""

",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Test_utils
module ALocMap = Loc_collections.ALocMap
module ALocSet = Loc_collections.ALocSet

let jsx_mode = ref Options.Jsx_react

let react_runtime = ref Options.ReactRuntimeClassic

module TestCx = struct
  type t = unit

  let enable_enums _ = true

  let jsx _cx = !jsx_mode

  let react_runtime _cx = !react_runtime

  let env_mode _cx = Options.SSAEnv { resolved = true }

  let enable_const_params _cx = true

  let add_new_env_literal_subtypes _ _ = ()

  let add_new_env_matching_props _ _ = ()
end

module Name_resolver = Name_resolver.Make_Test_With_Cx (TestCx)

let print_values refinement_of_id =
  let open Name_resolver.Env_api in
  let rec print_value write_loc =
    match write_loc with
    | Uninitialized _ -> ""(uninitialized)""
    | Undeclared _ -> ""(undeclared)""
    | UndeclaredClass { def; _ } ->
      let loc = Reason.poly_loc_of_reason def in
      Utils_js.spf
        ""(undeclared class) %s: (%s)""
        (L.debug_to_string loc)
        Reason.(desc_of_reason def |> string_of_desc)
    | Projection l -> Utils_js.spf ""projection at %s"" (L.debug_to_string l)
    | Write reason ->
      let loc = Reason.poly_loc_of_reason reason in
      Utils_js.spf
        ""%s: (%s)""
        (L.debug_to_string loc)
        Reason.(desc_of_reason reason |> string_of_desc)
    | Refinement { refinement_id; writes; write_id = _ } ->
      let refinement = refinement_of_id refinement_id in
      let refinement_str = show_refinement_kind_without_locs (snd refinement) in
      let writes_str = String.concat "","" (List.map print_value writes) in
      Printf.sprintf ""{refinement = %s; writes = %s}"" refinement_str writes_str
    | This -> ""This""
    | Super -> ""Super""
    | Arguments -> ""Arguments""
    | Global name -> ""Global "" ^ name
    | Unreachable _ -> ""unreachable""
    | Undefined _ -> ""undefined""
    | Number _ -> ""number""
    | DeclaredFunction l -> Printf.sprintf ""declared function %s"" (L.debug_to_string l)
  in
  fun values ->
    let kvlist = L.LMap.bindings values in
    let strlist =
      Base.List.map
        ~f:(fun (read_loc, { def_loc = _; val_kind = _; write_locs; name = _; id = _ }) ->
          Printf.sprintf
            ""%s => {\n    %s\n  }""
            (L.debug_to_string read_loc)
            (String.concat "",\n    "" @@ Base.List.map ~f:print_value write_locs))
        kvlist
    in
    Printf.printf ""[\n  %s]"" (String.concat "";\n  "" strlist)

(* TODO: ocamlformat mangles the ppx syntax. *)
[@@@ocamlformat ""disable=true""]

let print_ssa_test ?(custom_jsx = None) ?(react_runtime_automatic=false) contents =
  if react_runtime_automatic then (
    react_runtime := Options.ReactRuntimeAutomatic
  );
  (match custom_jsx with
  | None -> ()
  | Some str ->
      let (ast, _errors) = Parser_flow.jsx_pragma_expression str None in
      let aloc_ast = Ast_loc_utils.loc_to_aloc_mapper#expression ast in
      jsx_mode := Options.Jsx_pragma (str, aloc_ast)

  );
  let aloc_ast = parse_with_alocs contents in
  let refined_reads, refinement_of_id = Name_resolver.program () aloc_ast in
  print_values refinement_of_id refined_reads;
  react_runtime := Options.ReactRuntimeClassic;
  jsx_mode := Options.Jsx_react

let%expect_test ""logical_expr"" =
  print_ssa_test {|let x = null;
let y = null;
(x && (y = x)) + x|};
  [%expect {|
    [
      (3, 1) to (3, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (3, 11) to (3, 12) => {
        {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
      };
      (3, 17) to (3, 18) => {
        (1, 4) to (1, 5): (`x`)
      }] |}]

let%expect_test ""logical_expr_successive"" =
  print_ssa_test {|let x = null;
x && (x && x)|};
  [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
      };
      (2, 11) to (2, 12) => {
        {refinement = Truthy; writes = {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}}
      }] |}]

let%expect_test ""logical_or"" =
  print_ssa_test {|let x = null;
x || x|};
  [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 5) to (2, 6) => {
        {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_nc_and"" =
  print_ssa_test {|let x = null;
(x ?? x) && x|};
  [%expect{|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
      };
      (2, 12) to (2, 13) => {
        {refinement = Or (And (Not (Maybe), Truthy), Truthy); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_nc_no_key"" =
  print_ssa_test {|let x = null;
((x != null) ?? x) && x|};
  [%expect {|
    [
      (2, 2) to (2, 3) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 16) to (2, 17) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 22) to (2, 23) => {
        {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_nested_right"" =
  print_ssa_test {|let x = null;
x || (x || x)|};
  [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
      };
      (2, 11) to (2, 12) => {
        {refinement = Not (Truthy); writes = {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}}
      }] |}]

let%expect_test ""logical_nested"" =
  print_ssa_test {|let x = null;
(x || (x != null)) && x|};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 7) to (2, 8) => {
        {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
      };
      (2, 22) to (2, 23) => {
        {refinement = Or (Truthy, Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_nested2"" =
  print_ssa_test {|let x = null;
(x && x) || (x && x)|};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
      };
      (2, 13) to (2, 14) => {
        {refinement = Or (Not (Truthy), Not (Truthy)); writes = (1, 4) to (1, 5): (`x`)}
      };
      (2, 18) to (2, 19) => {
        {refinement = Truthy; writes = {refinement = Or (Not (Truthy), Not (Truthy)); writes = (1, 4) to (1, 5): (`x`)}}
      }] |}]

let%expect_test ""logical_assignment_and"" =
  print_ssa_test {|let x = null;
x &&= x;|}; [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_assignment_or"" =
  print_ssa_test {|let x = null;
x ||= x;|}; [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_assignment_nullish"" =
  print_ssa_test {|let x = null;
x ??= x;|}; [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 7) => {
        {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""logical_assignment_and_throws"" =
  print_ssa_test {|let x = null;
x &&= invariant(false);|}; [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 15) => {
        Global invariant
      }] |}]

let%expect_test ""logical_assignment_or_throws"" =
  print_ssa_test {|let x = null;
x ||= invariant(false);|}; [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 15) => {
        Global invariant
      }] |}]

let%expect_test ""logical_assignment_nullish_throws"" =
  print_ssa_test {|let x = null;
x ??= invariant(false);|}; [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 15) => {
        Global invariant
      }] |}]

let%expect_test ""assignment_truthy"" =
  print_ssa_test {|let x = null;
(x = null) && x|};
  [%expect {|
    [
      (2, 14) to (2, 15) => {
        {refinement = Truthy; writes = (2, 1) to (2, 2): (`x`)}
      }] |}]

let%expect_test ""eq_null"" =
  print_ssa_test {|let x = null;
(x == null) && x|};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 15) to (2, 16) => {
        {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""neq_null"" =
  print_ssa_test {|let x = null;
(x != null) && x|};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 15) to (2, 16) => {
        {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_eq_null"" =
  print_ssa_test {|let x = null;
(x === null) && x|};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 16) to (2, 17) => {
        {refinement = Null; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_neq_null"" =
  print_ssa_test {|let x = null;
(x !== null) && x|};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 16) to (2, 17) => {
        {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_eq_null_sentinel"" =
  print_ssa_test {|
if (o.err === null) {
  o
} else {
  o;
}
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global o
        };
        (3, 2) to (3, 3) => {
          {refinement = SentinelR err; writes = Global o}
        };
        (5, 2) to (5, 3) => {
          {refinement = Not (SentinelR err); writes = Global o}
        }]
      |}]

let%expect_test ""strict_neq_null_sentinel"" =
  print_ssa_test {|
if (o.err !== null) {
  o
} else {
  o;
}
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global o
        };
        (3, 2) to (3, 3) => {
          {refinement = Not (SentinelR err); writes = Global o}
        };
        (5, 2) to (5, 3) => {
          {refinement = SentinelR err; writes = Global o}
        }]
      |}]

let%expect_test ""eq_undefined"" =
  print_ssa_test {|let x = undefined;
(x == undefined) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 15) => {
        Global undefined
      };
      (2, 20) to (2, 21) => {
        {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""neq_undefined"" =
  print_ssa_test {|let x = undefined;
(x != undefined) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 6) to (2, 15) => {
        Global undefined
      };
      (2, 20) to (2, 21) => {
        {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_eq_undefined"" =
  print_ssa_test {|let x = undefined;
(x === undefined) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 7) to (2, 16) => {
        Global undefined
      };
      (2, 21) to (2, 22) => {
        {refinement = Not (Not (Undefined)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_neq_undefined"" =
  print_ssa_test {|let x = undefined;
(x !== undefined) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 7) to (2, 16) => {
        Global undefined
      };
      (2, 21) to (2, 22) => {
        {refinement = Not (Undefined); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_eq_undefined_sentinel"" =
  print_ssa_test {|
if (o.err === undefined) {
  o
} else {
  o;
}
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global o
        };
        (2, 14) to (2, 23) => {
          Global undefined
        };
        (3, 2) to (3, 3) => {
          {refinement = Not (Not (SentinelR err)); writes = Global o}
        };
        (5, 2) to (5, 3) => {
          {refinement = Not (SentinelR err); writes = Global o}
        }]
      |}]

let%expect_test ""strict_neq_undefined_sentinel"" =
  print_ssa_test {|
if (o.err !== undefined) {
  o
} else {
  o;
}
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global o
        };
        (2, 14) to (2, 23) => {
          Global undefined
        };
        (3, 2) to (3, 3) => {
          {refinement = Not (SentinelR err); writes = Global o}
        };
        (5, 2) to (5, 3) => {
          {refinement = Not (Not (SentinelR err)); writes = Global o}
        }]
      |}]

let%expect_test ""undefined_already_bound"" =
  print_ssa_test {|let undefined = 3;
let x = null;
(x !== undefined) && x|};
  [%expect {|
    [
      (3, 1) to (3, 2) => {
        (2, 4) to (2, 5): (`x`)
      };
      (3, 7) to (3, 16) => {
        (1, 4) to (1, 13): (`undefined`)
      };
      (3, 21) to (3, 22) => {
        (2, 4) to (2, 5): (`x`)
      }] |}]

let%expect_test ""eq_void"" =
  print_ssa_test {|let x = undefined;
(x == void 0) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 17) to (2, 18) => {
        {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""neq_void"" =
  print_ssa_test {|let x = undefined;
(x != void 0) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 17) to (2, 18) => {
        {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_eq_void"" =
  print_ssa_test {|let x = undefined;
(x === void 0) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 18) to (2, 19) => {
        {refinement = Not (Not (Undefined)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""strict_neq_void"" =
  print_ssa_test {|let x = undefined;
(x !== void 0) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 18) to (2, 19) => {
        {refinement = Not (Undefined); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""instanceof"" =
  print_ssa_test {|let x = undefined;
(x instanceof Object) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 14) to (2, 20) => {
        Global Object
      };
      (2, 25) to (2, 26) => {
        {refinement = instanceof; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""Array.isArray"" =
  print_ssa_test {|let x = undefined;
(Array.isArray(x)) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 6) => {
        Global Array
      };
      (2, 15) to (2, 16) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 22) to (2, 23) => {
        {refinement = isArray; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""unary_negation"" =
  print_ssa_test {|let x = undefined;
(!Array.isArray(x)) && x;
!x && x;
!(x || x) && x;|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 2) to (2, 7) => {
        Global Array
      };
      (2, 16) to (2, 17) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 23) to (2, 24) => {
        {refinement = Not (isArray); writes = (1, 4) to (1, 5): (`x`)}
      };
      (3, 1) to (3, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (3, 6) to (3, 7) => {
        {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
      };
      (4, 2) to (4, 3) => {
        (1, 4) to (1, 5): (`x`)
      };
      (4, 7) to (4, 8) => {
        {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
      };
      (4, 13) to (4, 14) => {
        {refinement = And (Not (Truthy), Not (Truthy)); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_bool"" =
  print_ssa_test {|let x = undefined;
(typeof x == ""boolean"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 27) to (2, 28) => {
        {refinement = bool; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_bool"" =
  print_ssa_test {|let x = undefined;
(typeof x != ""boolean"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 27) to (2, 28) => {
        {refinement = Not (bool); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_number"" =
  print_ssa_test {|let x = undefined;
(typeof x == ""number"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = number; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_number"" =
  print_ssa_test {|let x = undefined;
(typeof x != ""number"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (number); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_function"" =
  print_ssa_test {|let x = undefined;
(typeof x == ""function"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 28) to (2, 29) => {
        {refinement = function; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_function"" =
  print_ssa_test {|let x = undefined;
(typeof x != ""function"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 28) to (2, 29) => {
        {refinement = Not (function); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_object"" =
  print_ssa_test {|let x = undefined;
(typeof x == ""object"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = object; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_object"" =
  print_ssa_test {|let x = undefined;
(typeof x != ""object"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (object); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_string"" =
  print_ssa_test {|let x = undefined;
(typeof x == ""string"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = string; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_string"" =
  print_ssa_test {|let x = undefined;
(typeof x != ""string"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (string); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_symbol"" =
  print_ssa_test {|let x = undefined;
(typeof x == ""symbol"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = symbol; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_symbol"" =
  print_ssa_test {|let x = undefined;
(typeof x != ""symbol"") && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (symbol); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_bool_template"" =
  print_ssa_test {|let x = undefined;
(typeof x == `boolean`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 27) to (2, 28) => {
        {refinement = bool; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_bool_template"" =
  print_ssa_test {|let x = undefined;
(typeof x != `boolean`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 27) to (2, 28) => {
        {refinement = Not (bool); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_number_template"" =
  print_ssa_test {|let x = undefined;
(typeof x == `number`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = number; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_number_template"" =
  print_ssa_test {|let x = undefined;
(typeof x != `number`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (number); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_function_template"" =
  print_ssa_test {|let x = undefined;
(typeof x == `function`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 28) to (2, 29) => {
        {refinement = function; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_function_template"" =
  print_ssa_test {|let x = undefined;
(typeof x != `function`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 28) to (2, 29) => {
        {refinement = Not (function); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_object_template"" =
  print_ssa_test {|let x = undefined;
(typeof x == `object`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = object; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_object_template"" =
  print_ssa_test {|let x = undefined;
(typeof x != `object`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (object); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_string_template"" =
  print_ssa_test {|let x = undefined;
(typeof x == `string`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = string; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_string_template"" =
  print_ssa_test {|let x = undefined;
(typeof x != `string`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (string); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""typeof_symbol_template"" =
  print_ssa_test {|let x = undefined;
(typeof x == `symbol`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = symbol; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""not_typeof_symbol_template"" =
  print_ssa_test {|let x = undefined;
(typeof x != `symbol`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 8) to (2, 9) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 26) to (2, 27) => {
        {refinement = Not (symbol); writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""singleton_bool"" =
  print_ssa_test {|let x = undefined;
(x === true) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 16) to (2, 17) => {
        {refinement = true; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""singleton_str"" =
  print_ssa_test {|let x = undefined;
(x === ""str"") && x|};
  [%expect{|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 17) to (2, 18) => {
        {refinement = str; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""singleton_str_template"" =
  print_ssa_test {|let x = undefined;
(x === `str`) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 17) to (2, 18) => {
        {refinement = str; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""singleton_num"" =
  print_ssa_test {|let x = undefined;
(x === 3) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 13) to (2, 14) => {
        {refinement = 3; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""singleton_num_neg"" =
  print_ssa_test {|let x = undefined;
(x === -3) && x|};
  [%expect {|
    [
      (1, 8) to (1, 17) => {
        Global undefined
      };
      (2, 1) to (2, 2) => {
        (1, 4) to (1, 5): (`x`)
      };
      (2, 14) to (2, 15) => {
        {refinement = -3; writes = (1, 4) to (1, 5): (`x`)}
      }] |}]

let%expect_test ""sentinel_lit"" =
  print_ssa_test {|let x = undefined;
(x.foo === 3) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 17) to (2, 18) => {
          {refinement = SentinelR foo; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""sentinel_lit_indexed "" =
  print_ssa_test {|let x = undefined;
(x[""foo""] === 3) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 20) to (2, 21) => {
          {refinement = SentinelR foo; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""sentinel_nonlit"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
(x.foo === y) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 1) to (3, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 11) to (3, 12) => {
          (2, 4) to (2, 5): (`y`)
        };
        (3, 17) to (3, 18) => {
          {refinement = SentinelR foo; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""sentinel_nonlit_indexed"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
(x[""foo""] === y) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 1) to (3, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 14) to (3, 15) => {
          (2, 4) to (2, 5): (`y`)
        };
        (3, 20) to (3, 21) => {
          {refinement = SentinelR foo; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""refined_call_in_member_expressions"" =
  print_ssa_test {|let x = undefined;
if (x.foo != null && x.foo.bar()) {}|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 21) to (2, 22) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 21) to (2, 26) => {
          {refinement = Not (Maybe); writes = projection at (2, 4) to (2, 9)}
        }]
       |}]

let%expect_test ""refined_call_in_unrefinable_member_expressions"" =
  print_ssa_test {|let x = undefined;
if (x.foo != null && x.foo.bar()[0] === BAZ) {}|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 21) to (2, 22) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 21) to (2, 26) => {
          {refinement = Not (Maybe); writes = projection at (2, 4) to (2, 9)}
        };
        (2, 40) to (2, 43) => {
          Global BAZ
        }]
       |}]

let%expect_test ""optional_chain_lit"" =
  print_ssa_test {|let x = undefined;
(x?.foo === 3) ? x : x|};
    [%expect{|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 17) to (2, 18) => {
          {refinement = And (And (Not (Maybe), PropExistsR (foo)), SentinelR foo); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 21) to (2, 22) => {
          {refinement = Or (Or (Not (Not (Maybe)), Not (PropExistsR (foo))), Not (SentinelR foo)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""optional_chain_not_lit"" =
  print_ssa_test {|let x = undefined;
(x?.foo !== 3) ? x : x|};
    [%expect{|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 17) to (2, 18) => {
          {refinement = Or (Or (Not (Not (Maybe)), Not (PropExistsR (foo))), Not (SentinelR foo)); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 21) to (2, 22) => {
          {refinement = And (And (Not (Maybe), PropExistsR (foo)), SentinelR foo); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""optional_chain_member_base"" =
  print_ssa_test {|let x = undefined;
(x.foo?.bar === 3) ? x : x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 21) to (2, 22) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 25) to (2, 26) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""optional_chain_with_call"" =
  print_ssa_test {|let x = undefined;
(x?.foo().bar === 3) ? x : x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 23) to (2, 24) => {
          {refinement = And (Not (Maybe), PropExistsR (foo)); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 27) to (2, 28) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""optional_multiple_chains"" =
  print_ssa_test {|let x = undefined;
(x?.foo?.bar.baz?.qux === 3) ? x : x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 31) to (2, 32) => {
          {refinement = And (Not (Maybe), PropExistsR (foo)); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 35) to (2, 36) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""optional_base_call"" =
  print_ssa_test {|let x = undefined;
(x?.().foo?.bar.baz?.qux === 3) ? x : x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 34) to (2, 35) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 38) to (2, 39) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""sentinel_standalone"" =
  print_ssa_test {|let x = undefined;
x.foo && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 1) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 9) to (2, 10) => {
          {refinement = PropExistsR (foo); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""optional_chain_standalone"" =
  print_ssa_test {|let x = undefined;
x?.foo && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 1) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 10) to (2, 11) => {
          {refinement = And (Not (Maybe), PropExistsR (foo)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""no_sentinel_in_non_strict"" =
  print_ssa_test {|
var x : {p:?string} = {p:""xxx""};
if (x.p != null) {
  alert("""");
  x.p;
}
|};
    [%expect {|
      [
        (3, 4) to (3, 5) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 2) to (4, 7) => {
          Global alert
        };
        (5, 2) to (5, 3) => {
          (2, 4) to (2, 5): (`x`)
        }] |}]

let%expect_test ""conditional_expression"" =
  print_ssa_test {|let x = undefined;
(x ? x: x) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 5) to (2, 6) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 8) to (2, 9) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 14) to (2, 15) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""conditional_throw"" =
  print_ssa_test {|let x = undefined;
(x ? invariant() : x) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 5) to (2, 14) => {
          Global invariant
        };
        (2, 19) to (2, 20) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 25) to (2, 26) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""conditional_throw2"" =
  print_ssa_test {|let x = undefined;
(x ? x : invariant()) && x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 5) to (2, 6) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (2, 9) to (2, 18) => {
          Global invariant
        };
        (2, 25) to (2, 26) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""logical_throw_and"" =
  print_ssa_test {|let x = undefined;
x && invariant();
x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 1) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 5) to (2, 14) => {
          Global invariant
        };
        (3, 0) to (3, 1) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""logical_throw_or"" =
  print_ssa_test {|let x = undefined;
x || invariant();
x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 1) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 5) to (2, 14) => {
          Global invariant
        };
        (3, 0) to (3, 1) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""logical_throw_nc"" =
  print_ssa_test {|let x = undefined;
x ?? invariant();
x|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 1) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 5) to (2, 14) => {
          Global invariant
        };
        (3, 0) to (3, 1) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""logical_throw_reassignment"" =
  print_ssa_test {|let x = undefined;
try {
  x ?? invariant(false, x = 3);
} finally {
  x;
}|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 2) to (3, 3) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 7) to (3, 16) => {
          Global invariant
        };
        (5, 2) to (5, 3) => {
          (1, 4) to (1, 5): (`x`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""nested_logical_throw_and"" =
  print_ssa_test {|let x = undefined;
(x && invariant()) && x;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 6) to (2, 15) => {
          Global invariant
        };
        (2, 22) to (2, 23) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (3, 0) to (3, 1) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""nested_logical_throw_or"" =
  print_ssa_test {|let x = undefined;
(x || invariant()) && x;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 6) to (2, 15) => {
          Global invariant
        };
        (2, 22) to (2, 23) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (3, 0) to (3, 1) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""nested_logical_throw_nc"" =
  print_ssa_test {|let x = undefined;
(x ?? invariant()) && x;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 1) to (2, 2) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 6) to (2, 15) => {
          Global invariant
        };
        (2, 22) to (2, 23) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        };
        (3, 0) to (3, 1) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""if_else_statement"" =
  print_ssa_test {|let x = undefined;
if (x) {
  x;
} else {
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 3) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (5, 2) to (5, 3) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        };
        (7, 0) to (7, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""if_no_else_statement"" =
  print_ssa_test {|let x = undefined;
if (x) {
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 3) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (5, 0) to (5, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""if_no_else_statement_with_assignment"" =
  print_ssa_test {|let x = undefined;
if (x !== null) {
  x = null;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          (3, 2) to (3, 3): (`x`),
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""if_throw_else_statement"" =
  print_ssa_test {|let x = undefined;
if (x) {
  throw 'error';
} else {
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 2) to (5, 3) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        };
        (7, 0) to (7, 1) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""if_else_throw_statement"" =
  print_ssa_test {|let x = undefined;
if (x) {
  x;
} else {
  throw 'error';
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 3) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (7, 0) to (7, 1) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""if_return_else_statement"" =
  print_ssa_test {|function f() {
  let x = undefined;
  if (x) {
    return;
  } else {
    x;
  }
  x;
}
|};
    [%expect{|
      [
        (2, 10) to (2, 19) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (2, 6) to (2, 7): (`x`)
        };
        (6, 4) to (6, 5) => {
          {refinement = Not (Truthy); writes = (2, 6) to (2, 7): (`x`)}
        };
        (8, 2) to (8, 3) => {
          {refinement = Not (Truthy); writes = (2, 6) to (2, 7): (`x`)}
        }] |}]

let%expect_test ""if_else_return_statement"" =
  print_ssa_test {|function f() {
  let x = undefined;
  if (x) {
    x;
  } else {
    return;
  }
  x;
}
|};
    [%expect{|
      [
        (2, 10) to (2, 19) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (2, 6) to (2, 7): (`x`)
        };
        (4, 4) to (4, 5) => {
          {refinement = Truthy; writes = (2, 6) to (2, 7): (`x`)}
        };
        (8, 2) to (8, 3) => {
          {refinement = Truthy; writes = (2, 6) to (2, 7): (`x`)}
        }] |}]

let%expect_test ""nested_if_else_statement"" =
  print_ssa_test {|let x = undefined;
if (x) {
  if (x === null) {
    throw 'error';
  }
  x;
} else {
  if (x === null) {
    x;
  } else {
    throw 'error';
  }
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 6) to (3, 7) => {
          {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Null); writes = {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}}
        };
        (8, 6) to (8, 7) => {
          {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}
        };
        (9, 4) to (9, 5) => {
          {refinement = Null; writes = {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (13, 2) to (13, 3) => {
          {refinement = Null; writes = {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (15, 0) to (15, 1) => {
          {refinement = Not (Null); writes = {refinement = Truthy; writes = (1, 4) to (1, 5): (`x`)}},
          {refinement = Null; writes = {refinement = Not (Truthy); writes = (1, 4) to (1, 5): (`x`)}}
        }] |}]

let%expect_test ""while"" =
  print_ssa_test {|let x = undefined;
while (x != null) {
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 7) to (2, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""while_throw"" =
  print_ssa_test {|let x = undefined;
while (x != null) {
  throw 'error';
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 7) to (2, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""while_break_with_control_flow_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
while (x != null) {
  if (y == null) {
    break;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 7) to (3, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)}
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`),
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (2, 4) to (2, 5): (`y`)}
        };
        (10, 0) to (10, 1) => {
          (1, 4) to (1, 5): (`x`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""while_with_runtime_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
while (x != null) {
  if (y == null) {
    x = 2;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 7) to (3, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          (2, 4) to (2, 5): (`y`)
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`)
        };
        (10, 0) to (10, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`),(5, 4) to (5, 5): (`x`)}
        }] |}]

let%expect_test ""while_with_var_write"" =
  print_ssa_test {|
while (true) {
  var a = function() {}
}
a()|};
  [%expect {|
    [
      (5, 0) to (5, 1) => {
        (uninitialized),
        (3, 6) to (3, 7): (`a`)
      }]
      |}]

let%expect_test ""while_continue"" =
  print_ssa_test {|let x = undefined;
while (x != null) {
  continue;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 7) to (2, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""while_continue_with_control_flow_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
while (x != null) {
  if (y == null) {
    continue;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 7) to (3, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)}
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`),
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (2, 4) to (2, 5): (`y`)}
        };
        (10, 0) to (10, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""while_phi_node_refinement"" =
  print_ssa_test {|let x = undefined;
while (x != null) {
  if (x === 3) {
    continue;
  }
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 7) to (2, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 6) to (3, 7) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (3); writes = {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (8, 0) to (8, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`),{refinement = 3; writes = (1, 4) to (1, 5): (`x`)},{refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}}
        }] |}]

let%expect_test ""do_while"" =
  print_ssa_test {|let x = undefined;
do {
  x;
} while (x != null);
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 2) to (3, 3) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 9) to (4, 10) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""do_while_break_with_control_flow_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
do {
  if (y == null) {
    break;
  }
  y;
} while (x != null);
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)}
        };
        (8, 9) to (8, 10) => {
          (1, 4) to (1, 5): (`x`)
        };
        (9, 0) to (9, 1) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (2, 4) to (2, 5): (`y`)}
        };
        (10, 0) to (10, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""do_while_with_runtime_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
do {
  if (y == null) {
    x = 2;
  }
  y;
} while (x != null);
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          (2, 4) to (2, 5): (`y`)
        };
        (8, 9) to (8, 10) => {
          (1, 4) to (1, 5): (`x`),
          (5, 4) to (5, 5): (`x`)
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`)
        };
        (10, 0) to (10, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`),(5, 4) to (5, 5): (`x`)}
        }] |}]

let%expect_test ""do_while_continue"" =
  print_ssa_test {|let x = undefined;
do {
  continue;
} while (x != null);
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (4, 9) to (4, 10) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""do_while_continue_with_control_flow_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
do {
  if (y == null) {
    continue;
  }
  y;
} while (x != null);
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)}
        };
        (8, 9) to (8, 10) => {
          (1, 4) to (1, 5): (`x`)
        };
        (9, 0) to (9, 1) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (2, 4) to (2, 5): (`y`)}
        };
        (10, 0) to (10, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""do_while_phi_node_refinement"" =
  print_ssa_test {|let x = undefined;
do {
  if (x === 3) {
    continue;
  }
  x;
} while (x != null);
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`x`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}
        };
        (7, 9) to (7, 10) => {
          {refinement = 3; writes = (1, 4) to (1, 5): (`x`)},
          {refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}
        };
        (8, 0) to (8, 1) => {
          {refinement = Not (Not (Maybe)); writes = {refinement = 3; writes = (1, 4) to (1, 5): (`x`)},{refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}}
        }] |}]

let%expect_test ""for_no_init_no_update"" =
  print_ssa_test {|let x = undefined;
for (;x != null;) {
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 6) to (2, 7) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""for_no_init_no_update_throw"" =
  print_ssa_test {|let x = undefined;
for (;x != null;) {
  throw 'error';
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 6) to (2, 7) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""for_no_init_no_update_break_with_control_flow_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
for (; x != null; ) {
  if (y == null) {
    break;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 7) to (3, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)}
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`),
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (2, 4) to (2, 5): (`y`)}
        };
        (10, 0) to (10, 1) => {
          (1, 4) to (1, 5): (`x`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""for_no_init_no_update_with_runtime_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
for (;x != null;) {
  if (y == null) {
    x = 2;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          (2, 4) to (2, 5): (`y`)
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`)
        };
        (10, 0) to (10, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`),(5, 4) to (5, 5): (`x`)}
        }] |}]

let%expect_test ""for_no_init_no_update_continue"" =
  print_ssa_test {|let x = undefined;
for (; x != null; ) {
  continue;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 7) to (2, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""for_no_init_no_update_continue_with_control_flow_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
for (;x != null;) {
  if (y == null) {
    continue;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)}
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`),
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (2, 4) to (2, 5): (`y`)}
        };
        (10, 0) to (10, 1) => {
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""for_no_init_no_update_phi_refinement"" =
  print_ssa_test {|let x = undefined;
for (; x != null; ) {
  if (x === 3) {
    break;
  }
  x;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 7) to (2, 8) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 6) to (3, 7) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (3); writes = {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`x`),
          {refinement = 3; writes = {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}},
          {refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""for_shadow"" =
  print_ssa_test {|let x = undefined;
for (let x = null; x != null; x++) {
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 19) to (2, 20) => {
          (2, 9) to (2, 10): (`x`)
        };
        (2, 30) to (2, 31) => {
          {refinement = Not (Maybe); writes = (2, 9) to (2, 10): (`x`)}
        };
        (4, 0) to (4, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""for"" =
  print_ssa_test {|for (let x = 3; x != null; x++) {
  x;
}|};
    [%expect {|
      [
        (1, 16) to (1, 17) => {
          (1, 9) to (1, 10): (`x`)
        };
        (1, 27) to (1, 28) => {
          {refinement = Not (Maybe); writes = (1, 9) to (1, 10): (`x`)}
        };
        (2, 2) to (2, 3) => {
          {refinement = Not (Maybe); writes = (1, 9) to (1, 10): (`x`)}
        }] |}]

let%expect_test ""for_throw"" =
  print_ssa_test {|for (let x = 3; x != null; x++) {
  throw 'error';
}|};
    [%expect {|
      [
        (1, 16) to (1, 17) => {
          (1, 9) to (1, 10): (`x`)
        };
        (1, 27) to (1, 28) => {
          unreachable
        }] |}]

let%expect_test ""for_break_with_control_flow_writes"" =
  print_ssa_test {|let y = undefined;
for (let x = 3; x != null; x++) {
  if (y == null) {
    break;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 16) to (2, 17) => {
          (2, 9) to (2, 10): (`x`)
        };
        (2, 27) to (2, 28) => {
          {refinement = Not (Maybe); writes = (2, 9) to (2, 10): (`x`)}
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`y`)}
        }] |}]

let%expect_test ""for_with_runtime_writes"" =
  print_ssa_test {|let y = undefined;
for (let x = 3; x != null; x++) {
  if (y == null) {
    x = 2;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 16) to (2, 17) => {
          (2, 9) to (2, 10): (`x`)
        };
        (2, 27) to (2, 28) => {
          (4, 4) to (4, 5): (`x`),
          {refinement = Not (Maybe); writes = (2, 9) to (2, 10): (`x`)}
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          (1, 4) to (1, 5): (`y`)
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`)
        }] |}]

let%expect_test ""for_continue"" =
  print_ssa_test {|for (let x = 3; x != null; x++) {
  continue;
}
x;|};
    [%expect {|
      [
        (1, 16) to (1, 17) => {
          (1, 9) to (1, 10): (`x`)
        };
        (1, 27) to (1, 28) => {
          {refinement = Not (Maybe); writes = (1, 9) to (1, 10): (`x`)}
        };
        (4, 0) to (4, 1) => {
          Global x
        }] |}]

let%expect_test ""for_continue_with_control_flow_writes"" =
  print_ssa_test {|let y = undefined;
for (let x = 3; x != null; x++) {
  if (y == null) {
    continue;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 16) to (2, 17) => {
          (2, 9) to (2, 10): (`x`)
        };
        (2, 27) to (2, 28) => {
          {refinement = Not (Maybe); writes = (2, 9) to (2, 10): (`x`)}
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`y`)}
        }] |}]

let%expect_test ""no_havoc_before_write_seen"" =
  print_ssa_test {|function f() { return 42 }
var x: number;
x;
x = 42;|};
  [%expect {|
    [
      (3, 0) to (3, 1) => {
        (uninitialized)
      }] |}]

let%expect_test ""havoc_before_write_seen"" =
  print_ssa_test {|function f() { return 42 }
f();
var x: number;
x;
x = 42;|};
  [%expect {|
    [
      (2, 0) to (2, 1) => {
        (1, 9) to (1, 10): (`f`)
      };
      (4, 0) to (4, 1) => {
        (uninitialized)
      }] |}]

let%expect_test ""dont_havoc_to_uninit_in_function"" =
  print_ssa_test {|function f() { return 42 }
function g() { return f() }|};
  [%expect {|
    [
      (2, 22) to (2, 23) => {
        (1, 9) to (1, 10): (`f`)
      }] |}]

let%expect_test ""declare_predicate_fn"" =
  print_ssa_test {|declare function f(x: number): boolean %checks(x) |};
  [%expect {|
    [
      (1, 47) to (1, 48) => {
        (1, 19) to (1, 20): (`x`)
      }] |}]

let%expect_test ""switch_decl"" =
  print_ssa_test {|switch ('') { case '': const foo = ''; foo; };|};
  [%expect {|
    [
      (1, 39) to (1, 42) => {
        (1, 29) to (1, 32): (`foo`)
      }] |}]

let%expect_test ""switch_weird_decl"" =
  print_ssa_test {|switch ('') { case l: 0; break; case '': let l };|};
  [%expect {|
    [
      (1, 19) to (1, 20) => {
        (undeclared)
      }] |}]

let%expect_test ""switch_shadow"" =
  print_ssa_test {|function switch_scope(x) {
  switch (x) {
    default:
      let x;
      x = """"; // doesn't refine outer x
      x
  }
  x
}|};
  [%expect {|
    [
      (2, 10) to (2, 11) => {
        (1, 22) to (1, 23): (`x`)
      };
      (6, 6) to (6, 7) => {
        (5, 6) to (5, 7): (`x`)
      };
      (8, 2) to (8, 3) => {
        (1, 22) to (1, 23): (`x`)
      }] |}]

let%expect_test ""switch_nested_block_shadow"" =
  print_ssa_test {|function switch_scope() {
  switch ('foo') {
    case 'foo': {
      const bar = 3;
      break;
    }
  }
  bar;
  const {bar} = {};
  bar;
}|};
  [%expect {|
    [
      (8, 2) to (8, 5) => {
        (undeclared)
      };
      (10, 2) to (10, 5) => {
        (9, 9) to (9, 12): (`bar`)
      }] |}]

let%expect_test ""for_nested_block_shadow"" =
  print_ssa_test {|function for_scope() {
  for (;;) {
    const bar = 3;
    break;
  }
  bar;
  const {bar} = {};
  bar;
}|};
  [%expect {|
    [
      (6, 2) to (6, 5) => {
        (undeclared)
      };
      (8, 2) to (8, 5) => {
        (7, 9) to (7, 12): (`bar`)
      }] |}]

let%expect_test ""for_in"" =
  print_ssa_test {|let stuff = {}
for (let thing in stuff) {
  thing
}|};
    [%expect {|
      [
        (2, 18) to (2, 23) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 9) to (2, 14): (`thing`)
        }] |}]

let%expect_test ""for_in_reassign"" =
  print_ssa_test {|let stuff = {}
for (let thing in stuff) {
  thing;
  thing = 3;
}|};
    [%expect {|
      [
        (2, 18) to (2, 23) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 9) to (2, 14): (`thing`)
        }] |}]

let%expect_test ""for_in_destructure"" =
  print_ssa_test {|let stuff = {}
for (let {thing} in stuff) {
  thing;
}|};
    [%expect {|
      [
        (2, 20) to (2, 25) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 10) to (2, 15): (`thing`)
        }] |}]

let%expect_test ""for_in_destructure_reassign"" =
  print_ssa_test {|let stuff = {}
for (let {thing} in stuff) {
  thing;
  thing = 3;
}|};
    [%expect {|
      [
        (2, 20) to (2, 25) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 10) to (2, 15): (`thing`)
        }] |}]

let%expect_test ""for_in_shadow"" =
  print_ssa_test {|let thing = undefined;
let stuff = {}
for (let thing in stuff) {
  thing;
}
thing;|};
    [%expect {|
      [
        (1, 12) to (1, 21) => {
          Global undefined
        };
        (3, 18) to (3, 23) => {
          (2, 4) to (2, 9): (`stuff`)
        };
        (4, 2) to (4, 7) => {
          (3, 9) to (3, 14): (`thing`)
        };
        (6, 0) to (6, 5) => {
          (1, 4) to (1, 9): (`thing`)
        }] |}]

let%expect_test ""for_in_throw"" =
  print_ssa_test {|let x = undefined;
for (let thing in {}) {
  throw 'error';
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (5, 0) to (5, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""for_in_break_with_control_flow_writes"" =
  print_ssa_test {|let y = undefined;
for (let thing in {}) {
  if (y == null) {
    break;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`y`)}
        }] |}]

let%expect_test ""for_in_with_runtime_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
for (let thing in {}) {
  if (y == null) {
    x = 2;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          (2, 4) to (2, 5): (`y`)
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`)
        };
        (10, 0) to (10, 1) => {
          (1, 4) to (1, 5): (`x`),
          (5, 4) to (5, 5): (`x`)
        }] |}]

let%expect_test ""for_in_continue"" =
  print_ssa_test {|let x = undefined;
for (let thing in {}) {
  continue;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (5, 0) to (5, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""for_in_continue_with_control_flow_writes"" =
  print_ssa_test {|let y = undefined;
for (let thing in {}) {
  if (y == null) {
    continue;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`y`)}
        }] |}]

let%expect_test ""for_in_reassign_right"" =
  print_ssa_test {|let stuff = {};
for (let thing in stuff) {
  stuff = [];
}
stuff;|};
    [%expect {|
      [
        (2, 18) to (2, 23) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (5, 0) to (5, 5) => {
          (1, 4) to (1, 9): (`stuff`),
          (3, 2) to (3, 7): (`stuff`)
        }] |}]

let%expect_test ""for_of"" =
  print_ssa_test {|let stuff = {}
for (let thing of stuff) {
  thing
}|};
    [%expect {|
      [
        (2, 18) to (2, 23) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 9) to (2, 14): (`thing`)
        }] |}]

let%expect_test ""for_of_reassign"" =
  print_ssa_test {|let stuff = {}
for (let thing of stuff) {
  thing;
  thing = 3;
}|};
    [%expect {|
      [
        (2, 18) to (2, 23) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 9) to (2, 14): (`thing`)
        }] |}]

let%expect_test ""for_of_destructure"" =
  print_ssa_test {|let stuff = {}
for (let {thing} of stuff) {
  thing;
}|};
    [%expect {|
      [
        (2, 20) to (2, 25) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 10) to (2, 15): (`thing`)
        }] |}]

let%expect_test ""for_of_destructure_reassign"" =
  print_ssa_test {|let stuff = {}
for (let {thing} of stuff) {
  thing;
  thing = 3;
}|};
    [%expect {|
      [
        (2, 20) to (2, 25) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (3, 2) to (3, 7) => {
          (2, 10) to (2, 15): (`thing`)
        }] |}]

let%expect_test ""for_of_shadow"" =
  print_ssa_test {|let thing = undefined;
let stuff = {}
for (let thing of stuff) {
  thing;
}
thing;|};
    [%expect {|
      [
        (1, 12) to (1, 21) => {
          Global undefined
        };
        (3, 18) to (3, 23) => {
          (2, 4) to (2, 9): (`stuff`)
        };
        (4, 2) to (4, 7) => {
          (3, 9) to (3, 14): (`thing`)
        };
        (6, 0) to (6, 5) => {
          (1, 4) to (1, 9): (`thing`)
        }] |}]

let%expect_test ""for_of_throw"" =
  print_ssa_test {|let x = undefined;
for (let thing of {}) {
  throw 'error';
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (5, 0) to (5, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""for_of_break_with_control_flow_writes"" =
  print_ssa_test {|let y = undefined;
for (let thing of {}) {
  if (y == null) {
    break;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`y`)}
        }] |}]

let%expect_test ""for_of_with_runtime_writes"" =
  print_ssa_test {|let x = undefined;
let y = undefined;
for (let thing of {}) {
  if (y == null) {
    x = 2;
  }
  y;
}
y;
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (4, 6) to (4, 7) => {
          (2, 4) to (2, 5): (`y`)
        };
        (7, 2) to (7, 3) => {
          (2, 4) to (2, 5): (`y`)
        };
        (9, 0) to (9, 1) => {
          (2, 4) to (2, 5): (`y`)
        };
        (10, 0) to (10, 1) => {
          (1, 4) to (1, 5): (`x`),
          (5, 4) to (5, 5): (`x`)
        }] |}]

let%expect_test ""for_of_continue"" =
  print_ssa_test {|let x = undefined;
for (let thing of {}) {
  continue;
}
x;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (5, 0) to (5, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""for_of_continue_with_control_flow_writes"" =
  print_ssa_test {|let y = undefined;
for (let thing of {}) {
  if (y == null) {
    continue;
  }
  y;
}
y;|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 6) to (3, 7) => {
          (1, 4) to (1, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)}
        };
        (8, 0) to (8, 1) => {
          (1, 4) to (1, 5): (`y`),
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`y`)},
          {refinement = Not (Not (Maybe)); writes = (1, 4) to (1, 5): (`y`)}
        }] |}]

let%expect_test ""for_of_reassign_right"" =
  print_ssa_test {|let stuff = {};
for (let thing of stuff) {
  stuff = [];
}
stuff;|};
    [%expect {|
      [
        (2, 18) to (2, 23) => {
          (1, 4) to (1, 9): (`stuff`)
        };
        (5, 0) to (5, 5) => {
          (1, 4) to (1, 9): (`stuff`),
          (3, 2) to (3, 7): (`stuff`)
        }] |}]

let%expect_test ""invariant"" =
  print_ssa_test {|let x = undefined;
invariant(x != null, ""other arg"");
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 9) => {
          Global invariant
        };
        (2, 10) to (2, 11) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 0) to (3, 1) => {
          {refinement = Not (Maybe); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""invariant_false"" =
  print_ssa_test {|let x = undefined;
if (x === 3) {
  invariant(false);
}
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 11) => {
          Global invariant
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""invariant_no_args"" =
  print_ssa_test {|let x = undefined;
if (x === 3) {
  invariant();
}
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 4) to (2, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 2) to (3, 11) => {
          Global invariant
        };
        (5, 0) to (5, 1) => {
          {refinement = Not (3); writes = (1, 4) to (1, 5): (`x`)}
        }] |}]

let%expect_test ""invariant_reassign"" =
  print_ssa_test {|let x = undefined;
if (true) {
  invariant(false, x = 3);
}
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (3, 2) to (3, 11) => {
          Global invariant
        };
        (5, 0) to (5, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""try_catch_invariant_reassign"" =
  print_ssa_test {|let x = undefined;

try {
  if (true) {
    invariant(false, x = 3);
  }
} finally {
  x;
}|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (5, 4) to (5, 13) => {
          Global invariant
        };
        (8, 2) to (8, 3) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""switch_empty"" =
  print_ssa_test {|let x = undefined;
switch (x) {};
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 0) to (2, 13) => {
          (1, 4) to (1, 5): (`x`)
        };
        (2, 8) to (2, 9) => {
          (1, 4) to (1, 5): (`x`)
        };
        (3, 0) to (3, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""switch_only_default"" =
  print_ssa_test {|let x = undefined;
switch (x) {
  default: {
    x;
  }
};
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 9) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 4) to (4, 5) => {
          (1, 4) to (1, 5): (`x`)
        };
        (7, 0) to (7, 1) => {
          (1, 4) to (1, 5): (`x`)
        }] |}]

let%expect_test ""switch_break_every_case"" =
  print_ssa_test {|let x = undefined;
switch (x) {
  case null:
    x;
    break;
  case 3:
    x;
    break;
  case false:
    x;
    break;
  default: {
    x;
  }
};
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 9) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 4) to (4, 5) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)}
        };
        (7, 4) to (7, 5) => {
          {refinement = 3; writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (10, 4) to (10, 5) => {
          {refinement = false; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}
        };
        (13, 4) to (13, 5) => {
          {refinement = Not (false); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}
        };
        (16, 0) to (16, 1) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)},
          {refinement = 3; writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}},
          {refinement = false; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}},
          {refinement = Not (false); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}
        }]|}]

let%expect_test ""switch_prop_return_every_case"" =
  print_ssa_test {|function foo() {
let x = undefined;
switch (x) {
  case 1:
    return;
  case 2:
    return;
  default:
    return;
};
}
|};
    [%expect {|
      [
        (2, 8) to (2, 17) => {
          Global undefined
        };
        (3, 8) to (3, 9) => {
          (2, 4) to (2, 5): (`x`)
        }]
      |}]

let%expect_test ""switch_with_fallthroughs"" =
  print_ssa_test {|let x = undefined;
switch (x) {
  case null:
    x;
  case 3:
    x;
    break;
  case true:
  case false:
    x;
  default: {
    x;
  }
}
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 9) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 4) to (4, 5) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)}
        };
        (6, 4) to (6, 5) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)},
          {refinement = 3; writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (10, 4) to (10, 5) => {
          {refinement = true; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}},
          {refinement = false; writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}}
        };
        (12, 4) to (12, 5) => {
          {refinement = true; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}},
          {refinement = false; writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}},
          {refinement = Not (false); writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}}
        };
        (15, 0) to (15, 1) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)},
          {refinement = 3; writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}},
          {refinement = true; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}},
          {refinement = false; writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}},
          {refinement = Not (false); writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}}
        }] |}]

let%expect_test ""switch_merge_all_breaks"" =
  print_ssa_test {|let x;
switch (1) {
  case 1:
    x = 1;
    break;
  default:
    x = 2;
    break;
};
x;
|};
    [%expect {|
      [
        (10, 0) to (10, 1) => {
          (4, 4) to (4, 5): (`x`),
          (7, 4) to (7, 5): (`x`)
        }] |}]

let%expect_test ""switch_throw_in_default"" =
  print_ssa_test {|let x = undefined;
switch (x) {
  case null:
    x;
  case 3:
    x;
    break;
  case true:
  case false:
    x;
    break;
  default: {
    throw 'error'
  }
};
x;
|};
    [%expect {|
      [
        (1, 8) to (1, 17) => {
          Global undefined
        };
        (2, 8) to (2, 9) => {
          (1, 4) to (1, 5): (`x`)
        };
        (4, 4) to (4, 5) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)}
        };
        (6, 4) to (6, 5) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)},
          {refinement = 3; writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}
        };
        (10, 4) to (10, 5) => {
          {refinement = true; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}},
          {refinement = false; writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}}
        };
        (16, 0) to (16, 1) => {
          {refinement = Null; writes = (1, 4) to (1, 5): (`x`)},
          {refinement = 3; writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}},
          {refinement = true; writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}},
          {refinement = false; writes = {refinement = Not (true); writes = {refinement = Not (3); writes = {refinement = Not (Null); writes = (1, 4) to (1, 5): (`x`)}}}}
        }] |}]

let%expect_test ""arguments_read"" =
  print_ssa_test {|
arguments;
|};
    [%expect {|
      [
        (2, 0) to (2, 9) => {
          Arguments
        }] |}]

let%expect_test ""arguments_shadowed"" =
  print_ssa_test {|
function foo(arguments) {
  arguments;
}
|};
    [%expect {|
      [
        (3, 2) to (3, 11) => {
          (2, 13) to (2, 22): (`arguments`)
        }] |}]

let%expect_test ""global_refinement"" =
  print_ssa_test {|
Map != null && Map
|};
    [%expect {|
      [
        (2, 0) to (2, 3) => {
          Global Map
        };
        (2, 15) to (2, 18) => {
          {refinement = Not (Maybe); writes = Global Map}
        }] |}]

let%expect_test ""global_refinement_control_flow"" =
  print_ssa_test {|
if (Map != null) {
  throw 'error';
}
Map;
|};
    [%expect {|
      [
        (2, 4) to (2, 7) => {
          Global Map
        };
        (5, 0) to (5, 3) => {
          {refinement = Not (Not (Maybe)); writes = Global Map}
        }] |}]

let%expect_test ""global_overwrite"" =
  print_ssa_test {|
if (true) {
  undefined = null;
}
undefined;
|};
    [%expect {|
      [
        (5, 0) to (5, 9) => {
          Global undefined,
          (3, 2) to (3, 11): (`undefined`)
        }] |}]

let%expect_test ""havoc_from_uninitialized"" =
  print_ssa_test {|
var x: number;
function havoc() {
    x = 42;
}
havoc();
(x: void)
// todo: this should probably also include undefined
|};
  [%expect {|
    [
      (6, 0) to (6, 5) => {
        (3, 9) to (3, 14): (`havoc`)
      };
      (7, 1) to (7, 2) => {
        (uninitialized),
        (2, 4) to (2, 5): (`x`)
      }] |}]

let%expect_test ""captured_havoc"" =
  print_ssa_test {|function g() {
  var xx : { p : number } | null = { p : 4 };
  if (xx) {
    return function () {
       xx.p = 3;
    }
  }
}
|};
  [%expect {|
    [
      (3, 6) to (3, 8) => {
        (2, 6) to (2, 8): (`xx`)
      };
      (5, 7) to (5, 9) => {
        {refinement = Truthy; writes = (2, 6) to (2, 8): (`xx`)}
      }] |}]

let%expect_test ""no_providers"" =
  print_ssa_test {|
var x;
function fn() {
    x;
}
|};
  [%expect {|
    [
      (4, 4) to (4, 5) => {
        (uninitialized)
      }] |}]

let%expect_test ""class_expr"" =
  print_ssa_test {|
let y = 42;
let x = class y { m() { x; y } };
y;
|};
    [%expect {|
      [
        (3, 24) to (3, 25) => {
          (3, 4) to (3, 5): (`x`)
        };
        (3, 27) to (3, 28) => {
          (3, 14) to (3, 15): (`y`)
        };
        (4, 0) to (4, 1) => {
          (2, 4) to (2, 5): (`y`)
        }]|}]

let%expect_test ""havoc"" =
  print_ssa_test {|
let x = 3;
function f() { x = 'string'}
let y = 3;
if (x != null && y != null) {
  f();
  x;
  y;
}
|};
    [%expect {|
      [
        (5, 4) to (5, 5) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 17) to (5, 18) => {
          (4, 4) to (4, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          (3, 9) to (3, 10): (`f`)
        };
        (7, 2) to (7, 3) => {
          (2, 4) to (2, 5): (`x`)
        };
        (8, 2) to (8, 3) => {
          {refinement = Not (Maybe); writes = (4, 4) to (4, 5): (`y`)}
        }] |}]

let%expect_test ""predicate_function_outside_predicate_position"" =
  print_ssa_test {|
let x = null;
let y = 3;
function f(x): %checks { return x != null }
f(x, y);
x;
y;

x = 'string';
|};
    [%expect {|
      [
        (4, 32) to (4, 33) => {
          (4, 11) to (4, 12): (`x`)
        };
        (5, 0) to (5, 1) => {
          (4, 9) to (4, 10): (`f`)
        };
        (5, 2) to (5, 3) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 5) to (5, 6) => {
          (3, 4) to (3, 5): (`y`)
        };
        (6, 0) to (6, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (7, 0) to (7, 1) => {
          (3, 4) to (3, 5): (`y`)
        }] |}]

let%expect_test ""latent_refinements"" =
  print_ssa_test {|
let x = 3;
function f() { x = 'string'}
let y = 3;
if (f(x, y)) {
  x;
  y;
}
if (y.f(x, y)) {
  // No refinements on either
  x;
  y;
}
|};
    [%expect {|
      [
        (5, 4) to (5, 5) => {
          (3, 9) to (3, 10): (`f`)
        };
        (5, 6) to (5, 7) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 9) to (5, 10) => {
          (4, 4) to (4, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          {refinement = LatentR (index = 1); writes = (2, 4) to (2, 5): (`x`)}
        };
        (7, 2) to (7, 3) => {
          {refinement = LatentR (index = 2); writes = (4, 4) to (4, 5): (`y`)}
        };
        (9, 4) to (9, 5) => {
          (4, 4) to (4, 5): (`y`)
        };
        (9, 8) to (9, 9) => {
          (2, 4) to (2, 5): (`x`)
        };
        (9, 11) to (9, 12) => {
          (4, 4) to (4, 5): (`y`)
        };
        (11, 2) to (11, 3) => {
          (2, 4) to (2, 5): (`x`)
        };
        (12, 2) to (12, 3) => {
          (4, 4) to (4, 5): (`y`)
        }] |}]

let%expect_test ""heap_refinement_basic"" =
  print_ssa_test {|
let x = {};
if (x.foo === 3) {
  x.foo;
  if (x.foo === 4) {
    x.foo;
  }
}
|};
    [%expect {|
      [
        (3, 4) to (3, 5) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 2) to (4, 3) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 2) to (4, 7) => {
          {refinement = 3; writes = projection at (3, 4) to (3, 9)}
        };
        (5, 6) to (5, 7) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (5, 6) to (5, 11) => {
          {refinement = 3; writes = projection at (3, 4) to (3, 9)}
        };
        (6, 4) to (6, 5) => {
          {refinement = SentinelR foo; writes = {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}}
        };
        (6, 4) to (6, 9) => {
          {refinement = 4; writes = {refinement = 3; writes = projection at (3, 4) to (3, 9)}}
        }] |}]

let%expect_test ""heap_refinement_this_basic"" =
  print_ssa_test {|
if (this.foo === 3) {
  this.foo;
}
|};
    [%expect {|
      [
        (2, 4) to (2, 8) => {
          This
        };
        (3, 2) to (3, 6) => {
          {refinement = SentinelR foo; writes = This}
        };
        (3, 2) to (3, 10) => {
          {refinement = 3; writes = projection at (2, 4) to (2, 12)}
        }]
     |}]

let%expect_test ""heap_refinement_basic"" =
  print_ssa_test {|
let x = {};
if (x.foo === 3) {
  x.foo;
  if (x.foo === 4) {
    x.foo;
  }
}
|};
    [%expect {|
      [
        (3, 4) to (3, 5) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 2) to (4, 3) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 2) to (4, 7) => {
          {refinement = 3; writes = projection at (3, 4) to (3, 9)}
        };
        (5, 6) to (5, 7) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (5, 6) to (5, 11) => {
          {refinement = 3; writes = projection at (3, 4) to (3, 9)}
        };
        (6, 4) to (6, 5) => {
          {refinement = SentinelR foo; writes = {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}}
        };
        (6, 4) to (6, 9) => {
          {refinement = 4; writes = {refinement = 3; writes = projection at (3, 4) to (3, 9)}}
        }] |}]

let%expect_test ""heap_refinement_destrucure"" =
  print_ssa_test {|
let x = {};
if (x.foo === 3) {
  const { foo } = x;
  foo;
}
|};
    [%expect {|
      [
        (3, 4) to (3, 5) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 10) to (4, 13) => {
          {refinement = 3; writes = projection at (3, 4) to (3, 9)}
        };
        (4, 18) to (4, 19) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (5, 2) to (5, 5) => {
          {refinement = 3; writes = (4, 10) to (4, 13): (`foo`)}
        }] |}]

let%expect_test ""heap_refinement_from_assign_destrucure"" =
  print_ssa_test {|
let x = {};
x.foo = 3;
const { foo } = x;
foo;
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 8) to (4, 11) => {
          (3, 0) to (3, 5): (some property)
        };
        (4, 16) to (4, 17) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 0) to (5, 3) => {
          (4, 8) to (4, 11): (`foo`)
        }]
      |}]

let%expect_test ""heap_refinement_deep_destrucure"" =
  print_ssa_test {|
let x = {};
if (x.bar.baz.hello.world === 4) {
  const { bar: { baz: { hello: {world: hi} } } } = x;
  hi;
}
|};
    [%expect {|
      [
        (3, 4) to (3, 5) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 24) to (4, 29) => {
          {refinement = SentinelR world; writes = projection at (3, 4) to (3, 19)}
        };
        (4, 32) to (4, 37) => {
          {refinement = 4; writes = projection at (3, 4) to (3, 25)}
        };
        (4, 51) to (4, 52) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 2) to (5, 4) => {
          {refinement = 4; writes = (4, 39) to (4, 41): (`hi`)}
        }] |}]

let%expect_test ""heap_refinement_from_assign_deep_destrucure"" =
  print_ssa_test {|
let x = {};
x.bar.baz.hello.world = 4;
const { bar: { baz: { hello: {world: hi} } } } = x;
hi;
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 30) to (4, 35) => {
          (3, 0) to (3, 21): (some property)
        };
        (4, 49) to (4, 50) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 0) to (5, 2) => {
          (4, 37) to (4, 39): (`hi`)
        }] |}]

let%expect_test ""heap_refinement_merge_branches"" =
  print_ssa_test {|
declare var invariant: any;
let x = {};
if (true) {
  invariant(x.foo === 3);
} else {
  invariant(x.foo === 4);
}
x.foo; // 3 | 4
|};
    [%expect {|
      [
        (5, 2) to (5, 11) => {
          (2, 12) to (2, 21): (`invariant`)
        };
        (5, 12) to (5, 13) => {
          (3, 4) to (3, 5): (`x`)
        };
        (7, 2) to (7, 11) => {
          (2, 12) to (2, 21): (`invariant`)
        };
        (7, 12) to (7, 13) => {
          (3, 4) to (3, 5): (`x`)
        };
        (9, 0) to (9, 1) => {
          {refinement = SentinelR foo; writes = (3, 4) to (3, 5): (`x`)},
          {refinement = SentinelR foo; writes = (3, 4) to (3, 5): (`x`)}
        };
        (9, 0) to (9, 5) => {
          {refinement = 3; writes = projection at (5, 12) to (5, 17)},
          {refinement = 4; writes = projection at (7, 12) to (7, 17)}
        }] |}]

let%expect_test ""heap_refinement_one_branch"" =
  print_ssa_test {|
declare var invariant: any;
let x = {};
if (true) {
  invariant(x.foo === 3);
} else {
}
x.foo; // No refinement
|};
    [%expect {|
      [
        (5, 2) to (5, 11) => {
          (2, 12) to (2, 21): (`invariant`)
        };
        (5, 12) to (5, 13) => {
          (3, 4) to (3, 5): (`x`)
        };
        (8, 0) to (8, 1) => {
          (3, 4) to (3, 5): (`x`),
          {refinement = SentinelR foo; writes = (3, 4) to (3, 5): (`x`)}
        }] |}]

let%expect_test ""heap_refinement_while_loop_subject_changed"" =
  print_ssa_test {|
let x = {};
while (x.foo === 3) {
  x.foo;
  x = {};
  break;
}
x.foo; // No heap refinement here
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 2) to (4, 3) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 2) to (4, 7) => {
          {refinement = 3; writes = projection at (3, 7) to (3, 12)}
        };
        (8, 0) to (8, 1) => {
          (2, 4) to (2, 5): (`x`),
          (5, 2) to (5, 3): (`x`)
        }] |}]

let%expect_test ""heap_refinement_while_loop_projection_changed"" =
  print_ssa_test {|
declare var invariant: any;
let x = {};
while (x.foo === 3) {
  invariant(x.foo === 4);
  x.foo;
  break;
}
x.foo; // No heap refinement here from guard, but union of === 4 and projection
|};
    [%expect {|
      [
        (4, 7) to (4, 8) => {
          (3, 4) to (3, 5): (`x`)
        };
        (5, 2) to (5, 11) => {
          (2, 12) to (2, 21): (`invariant`)
        };
        (5, 12) to (5, 13) => {
          {refinement = SentinelR foo; writes = (3, 4) to (3, 5): (`x`)}
        };
        (5, 12) to (5, 17) => {
          {refinement = 3; writes = projection at (4, 7) to (4, 12)}
        };
        (6, 2) to (6, 3) => {
          {refinement = SentinelR foo; writes = {refinement = SentinelR foo; writes = (3, 4) to (3, 5): (`x`)}}
        };
        (6, 2) to (6, 7) => {
          {refinement = 4; writes = {refinement = 3; writes = projection at (4, 7) to (4, 12)}}
        };
        (9, 0) to (9, 1) => {
          (3, 4) to (3, 5): (`x`),
          {refinement = SentinelR foo; writes = {refinement = SentinelR foo; writes = (3, 4) to (3, 5): (`x`)}}
        };
        (9, 0) to (9, 5) => {
          projection at (4, 7) to (4, 12),
          {refinement = 4; writes = {refinement = 3; writes = projection at (4, 7) to (4, 12)}}
        }] |}]

let%expect_test ""heap_refinement_while_loop_negated"" =
  print_ssa_test {|
let x = {};
while (x.foo === 3) {
  x.foo;
}
x.foo;
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 2) to (4, 3) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 2) to (4, 7) => {
          {refinement = 3; writes = projection at (3, 7) to (3, 12)}
        };
        (6, 0) to (6, 1) => {
          {refinement = Not (SentinelR foo); writes = (2, 4) to (2, 5): (`x`)}
        };
        (6, 0) to (6, 5) => {
          {refinement = Not (3); writes = projection at (3, 7) to (3, 12)}
        }] |}]

let%expect_test ""heap_refinement_loop_control_flow_write"" =
  print_ssa_test {|
let x = {};
while (x.foo === 3) {
  if (x.foo === 4) {
    x.foo;
  } else { throw 'error'}
  x.foo;
}
x.foo;
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 6) to (4, 7) => {
          {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 6) to (4, 11) => {
          {refinement = 3; writes = projection at (3, 7) to (3, 12)}
        };
        (5, 4) to (5, 5) => {
          {refinement = SentinelR foo; writes = {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}}
        };
        (5, 4) to (5, 9) => {
          {refinement = 4; writes = {refinement = 3; writes = projection at (3, 7) to (3, 12)}}
        };
        (7, 2) to (7, 3) => {
          {refinement = SentinelR foo; writes = {refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}}
        };
        (7, 2) to (7, 7) => {
          {refinement = 4; writes = {refinement = 3; writes = projection at (3, 7) to (3, 12)}}
        };
        (9, 0) to (9, 1) => {
          {refinement = Not (SentinelR foo); writes = (2, 4) to (2, 5): (`x`),{refinement = SentinelR foo; writes = (2, 4) to (2, 5): (`x`)}}
        };
        (9, 0) to (9, 5) => {
          {refinement = Not (3); writes = projection at (3, 7) to (3, 12),{refinement = 4; writes = projection at (3, 7) to (3, 12)}}
        }] |}]

let%expect_test ""heap_refinement_write"" =
  print_ssa_test {|
let x = {};
x.foo = 3;
x.foo;
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 0) to (4, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 0) to (4, 5) => {
          (3, 0) to (3, 5): (some property)
        }] |}]

let%expect_test ""heap_refinement_write_havoc_member"" =
  print_ssa_test {|
let x = {};
x.foo = 3;
let y = x;
y.foo = 3;
x.foo; // should no longer be refined
y.foo; // still refined
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 8) to (4, 9) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          (4, 4) to (4, 5): (`y`)
        };
        (6, 0) to (6, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (7, 0) to (7, 1) => {
          (4, 4) to (4, 5): (`y`)
        };
        (7, 0) to (7, 5) => {
          (5, 0) to (5, 5): (some property)
        }] |}]

let%expect_test ""heap_refinement_write_havoc_elem"" =
  print_ssa_test {|
let x = {};
x.foo = 3;
let y = x;
y.foo = 3;
y[x] = 4;
x.foo; // should no longer be refined
y.foo; // should no longer be refined
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 8) to (4, 9) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 0) to (5, 1) => {
          (4, 4) to (4, 5): (`y`)
        };
        (6, 0) to (6, 1) => {
          (4, 4) to (4, 5): (`y`)
        };
        (6, 2) to (6, 3) => {
          (2, 4) to (2, 5): (`x`)
        };
        (7, 0) to (7, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (8, 0) to (8, 1) => {
          (4, 4) to (4, 5): (`y`)
        }] |}]

let%expect_test ""heap_refinement_havoc_on_write"" =
  print_ssa_test {|
let x = {};
x.foo = 3;
x.foo;
x = {};
x.foo; // No more refinement
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 0) to (4, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 0) to (4, 5) => {
          (3, 0) to (3, 5): (some property)
        };
        (6, 0) to (6, 1) => {
          (5, 0) to (5, 1): (`x`)
        }] |}]

let%expect_test ""unreachable_code"" =
  print_ssa_test {|
x = 4;
x;
throw new Error();
var x = 3;
x;
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 0) to (2, 1): (`x`)
        };
        (4, 10) to (4, 15) => {
          Global Error
        };
        (6, 0) to (6, 1) => {
          unreachable
        }] |}]

let%expect_test ""function_hoisted_typeof"" =
  print_ssa_test {|
let x = null;
if (Math.random()) {
  x = 'string';
} else {
  x = 4;
}

x = 5;
// Note that the typeofs here report all the providers and not x = 5
function f<T: typeof x = typeof x>(y: typeof x): typeof x { return null; }
declare function f<T: typeof x = typeof x>(y: typeof x): typeof x;
// The return here should not be hoisted, but the param is because
// we havoc before we visit the params.
let y = (z: typeof x): typeof x => 3;
|};
    [%expect {|
      [
        (3, 4) to (3, 8) => {
          Global Math
        };
        (11, 21) to (11, 22) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (11, 32) to (11, 33) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (11, 45) to (11, 46) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (11, 56) to (11, 57) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (12, 29) to (12, 30) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (12, 40) to (12, 41) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (12, 43) to (12, 44) => {
          (15, 4) to (15, 5): (`y`)
        };
        (12, 53) to (12, 54) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (12, 64) to (12, 65) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (15, 19) to (15, 20) => {
          (2, 4) to (2, 5): (`x`),
          (4, 2) to (4, 3): (`x`),
          (6, 2) to (6, 3): (`x`)
        };
        (15, 30) to (15, 31) => {
          (9, 0) to (9, 1): (`x`)
        }] |}]

let%expect_test ""hoisted_global_refinement"" =
  print_ssa_test {|
if (global != null) {
  global;
  function f(x: typeof global) { }
}
|};
    [%expect {|
      [
        (2, 4) to (2, 10) => {
          Global global
        };
        (3, 2) to (3, 8) => {
          {refinement = Not (Maybe); writes = Global global}
        };
        (4, 23) to (4, 29) => {
          Global global
        }] |}]

let%expect_test ""type_alias"" =
  print_ssa_test {|
type t = number;
let x: t = 42;
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 5) to (2, 6): (`t`)
        }] |}]

let%expect_test ""type_alias_global"" =
  print_ssa_test {|
let x: t = 42;
|};
    [%expect {|
      [
        (2, 7) to (2, 8) => {
          Global t
        }] |}]

let%expect_test ""type_alias_refine"" =
  print_ssa_test {|
if (t) {
  let x: t = 42;
}
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global t
        };
        (3, 9) to (3, 10) => {
          {refinement = Truthy; writes = Global t}
        }] |}]

let%expect_test ""type_alias_no_init"" =
  print_ssa_test {|
type t = number;
let x: t;
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 5) to (2, 6): (`t`)
        }] |}]

let%expect_test ""type_alias_lookup"" =
  print_ssa_test {|
import * as React from 'react';
type T = React.ComponentType;
var C: React.ComponentType;
|};
    [%expect {|
      [
        (3, 9) to (3, 14) => {
          (2, 12) to (2, 17): (`React`)
        };
        (4, 7) to (4, 12) => {
          (2, 12) to (2, 17): (`React`)
        }] |}]

let%expect_test ""new_type_arg"" =
  print_ssa_test {|
type A = number;
new Set<A>();
|};
    [%expect {|
      [
        (3, 4) to (3, 7) => {
          Global Set
        };
        (3, 8) to (3, 9) => {
          (2, 5) to (2, 6): (`A`)
        }] |}]

let%expect_test ""class_as_type"" =
  print_ssa_test {|
class C { }
var x: C = new C();
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 6) to (2, 7): (`C`)
        };
        (3, 15) to (3, 16) => {
          (2, 6) to (2, 7): (`C`)
        }] |}]

let%expect_test ""interface_as_type"" =
  print_ssa_test {|
interface C { }
var x: C;
|};
    [%expect {|
      [
        (3, 7) to (3, 8) => {
          (2, 10) to (2, 11): (`C`)
        }] |}]

let%expect_test ""hoist_type"" =
  print_ssa_test {|
var x: T;
type T = number;
|};
    [%expect {|
      [
        (2, 7) to (2, 8) => {
          (3, 5) to (3, 6): (`T`)
        }] |}]

let%expect_test ""hoist_interface"" =
  print_ssa_test {|
var x: C;
interface C { }
|};
    [%expect {|
      [
        (2, 7) to (2, 8) => {
          (3, 10) to (3, 11): (`C`)
        }] |}]

let%expect_test ""opaque"" =
  print_ssa_test {|
var x: T;
opaque type T: C = C;
interface C { }
|};
    [%expect {|
      [
        (2, 7) to (2, 8) => {
          (3, 12) to (3, 13): (`T`)
        };
        (3, 15) to (3, 16) => {
          (4, 10) to (4, 11): (`C`)
        };
        (3, 19) to (3, 20) => {
          (4, 10) to (4, 11): (`C`)
        }] |}]

let%expect_test ""mutual"" =
  print_ssa_test {|
type A = Array<B>;
type B = { a: A };
|};
    [%expect {|
      [
        (2, 9) to (2, 14) => {
          Global Array
        };
        (2, 15) to (2, 16) => {
          (3, 5) to (3, 6): (`B`)
        };
        (3, 14) to (3, 15) => {
          (2, 5) to (2, 6): (`A`)
        }] |}]

let%expect_test ""fun_tparam"" =
  print_ssa_test {|
function f<X, Y: X = number>(x: X, y: Y) {
  (x: Y);
}
|};
    [%expect {|
      [
        (2, 17) to (2, 18) => {
          (2, 11) to (2, 12): (`X`)
        };
        (2, 32) to (2, 33) => {
          (2, 11) to (2, 12): (`X`)
        };
        (2, 38) to (2, 39) => {
          (2, 14) to (2, 15): (`Y`)
        };
        (3, 3) to (3, 4) => {
          (2, 29) to (2, 30): (`x`)
        };
        (3, 6) to (3, 7) => {
          (2, 14) to (2, 15): (`Y`)
        }] |}]

let%expect_test ""fun_tparam_return"" =
  print_ssa_test {|
function f<X, Y: X = number>(x: X, y: Y): Y {
  (x: Y);
}
|};
    [%expect {|
      [
        (2, 17) to (2, 18) => {
          (2, 11) to (2, 12): (`X`)
        };
        (2, 32) to (2, 33) => {
          (2, 11) to (2, 12): (`X`)
        };
        (2, 38) to (2, 39) => {
          (2, 14) to (2, 15): (`Y`)
        };
        (2, 42) to (2, 43) => {
          (2, 14) to (2, 15): (`Y`)
        };
        (3, 3) to (3, 4) => {
          (2, 29) to (2, 30): (`x`)
        };
        (3, 6) to (3, 7) => {
          (2, 14) to (2, 15): (`Y`)
        }] |}]

let%expect_test ""fun_tparam_global_bound"" =
  print_ssa_test {|
function f<Z: Z>() { }
|};
    [%expect {|
      [
        (2, 14) to (2, 15) => {
          Global Z
        }] |}]

let%expect_test ""fun_inline_tparam"" =
  print_ssa_test {|
let x = function f<X, Y: X = number>(x: X, y: Y) {
  (x: Y);
}
|};
    [%expect {|
      [
        (2, 25) to (2, 26) => {
          (2, 19) to (2, 20): (`X`)
        };
        (2, 40) to (2, 41) => {
          (2, 19) to (2, 20): (`X`)
        };
        (2, 46) to (2, 47) => {
          (2, 22) to (2, 23): (`Y`)
        };
        (3, 3) to (3, 4) => {
          (2, 37) to (2, 38): (`x`)
        };
        (3, 6) to (3, 7) => {
          (2, 22) to (2, 23): (`Y`)
        }] |}]

let%expect_test ""arrow_fun_tparam"" =
  print_ssa_test {|
let x = <X, Y: X = number>(x: X, y: Y) => {
  (x: Y);
}
|};
    [%expect {|
      [
        (2, 15) to (2, 16) => {
          (2, 9) to (2, 10): (`X`)
        };
        (2, 30) to (2, 31) => {
          (2, 9) to (2, 10): (`X`)
        };
        (2, 36) to (2, 37) => {
          (2, 12) to (2, 13): (`Y`)
        };
        (3, 3) to (3, 4) => {
          (2, 27) to (2, 28): (`x`)
        };
        (3, 6) to (3, 7) => {
          (2, 12) to (2, 13): (`Y`)
        }] |}]

let%expect_test ""type_tparam"" =
  print_ssa_test {|
type T<X, Y: X = number> = Array<[X, Y]>
|};
    [%expect {|
      [
        (2, 13) to (2, 14) => {
          (2, 7) to (2, 8): (`X`)
        };
        (2, 27) to (2, 32) => {
          Global Array
        };
        (2, 34) to (2, 35) => {
          (2, 7) to (2, 8): (`X`)
        };
        (2, 37) to (2, 38) => {
          (2, 10) to (2, 11): (`Y`)
        }] |}]

let%expect_test ""opaque_tparam"" =
  print_ssa_test {|
opaque type T<X>: X = X
|};
    [%expect {|
      [
        (2, 18) to (2, 19) => {
          (2, 14) to (2, 15): (`X`)
        };
        (2, 22) to (2, 23) => {
          (2, 14) to (2, 15): (`X`)
        }] |}]

let%expect_test ""opaque_tparam"" =
  print_ssa_test {|
declare opaque type T<X>: X;
|};
    [%expect {|
      [
        (2, 26) to (2, 27) => {
          (2, 22) to (2, 23): (`X`)
        }] |}]

let%expect_test ""interface_tparam"" =
  print_ssa_test {|
interface T<X, Y:X> {
  x: X;
  y: Y;
};
|};
    [%expect {|
      [
        (2, 17) to (2, 18) => {
          (2, 12) to (2, 13): (`X`)
        };
        (3, 5) to (3, 6) => {
          (2, 12) to (2, 13): (`X`)
        };
        (4, 5) to (4, 6) => {
          (2, 15) to (2, 16): (`Y`)
        }] |}]

let%expect_test ""interface_miss"" =
  print_ssa_test {|
interface T<X> extends X { };
|};
    [%expect {|
      [
        (2, 23) to (2, 24) => {
          Global X
        }] |}]

let%expect_test ""interface_extends_tparam"" =
  print_ssa_test {|
type X<S> = S;

interface T<X> extends X<X> {
  x: X
};
|};
    [%expect {|
      [
        (2, 12) to (2, 13) => {
          (2, 7) to (2, 8): (`S`)
        };
        (4, 23) to (4, 24) => {
          (2, 5) to (2, 6): (`X`)
        };
        (4, 25) to (4, 26) => {
          (4, 12) to (4, 13): (`X`)
        };
        (5, 5) to (5, 6) => {
          (4, 12) to (4, 13): (`X`)
        }] |}]

let%expect_test ""fun_type_tparam"" =
  print_ssa_test {|
type T<W> = <X: W, Y: X>(X) => Y
|};
    [%expect {|
      [
        (2, 16) to (2, 17) => {
          (2, 7) to (2, 8): (`W`)
        };
        (2, 22) to (2, 23) => {
          (2, 13) to (2, 14): (`X`)
        };
        (2, 25) to (2, 26) => {
          (2, 13) to (2, 14): (`X`)
        };
        (2, 31) to (2, 32) => {
          (2, 19) to (2, 20): (`Y`)
        }] |}]

let%expect_test ""class_tparam"" =
  print_ssa_test {|
class C<X, Y:X> extends X<X> implements Y<Y> {
  f<Z:Y>(x:X, y:Y) {
    let z: Z;
  }
}
|};
    [%expect {|
      [
        (2, 13) to (2, 14) => {
          (2, 8) to (2, 9): (`X`)
        };
        (2, 24) to (2, 25) => {
          Global X
        };
        (2, 26) to (2, 27) => {
          (2, 8) to (2, 9): (`X`)
        };
        (2, 40) to (2, 41) => {
          Global Y
        };
        (2, 42) to (2, 43) => {
          (2, 11) to (2, 12): (`Y`)
        };
        (3, 6) to (3, 7) => {
          (2, 11) to (2, 12): (`Y`)
        };
        (3, 11) to (3, 12) => {
          (2, 8) to (2, 9): (`X`)
        };
        (3, 16) to (3, 17) => {
          (2, 11) to (2, 12): (`Y`)
        };
        (4, 11) to (4, 12) => {
          (3, 4) to (3, 5): (`Z`)
        }] |}]

let%expect_test ""declare_class_tparam"" =
  print_ssa_test {|
declare class C<X, Y:X, Z = X> extends X<X> mixins Z<Z> implements Y<Y> {
  f<Z:Y>(X, Y): Z;
}
|};
    [%expect {|
      [
        (2, 21) to (2, 22) => {
          (2, 16) to (2, 17): (`X`)
        };
        (2, 28) to (2, 29) => {
          (2, 16) to (2, 17): (`X`)
        };
        (2, 39) to (2, 40) => {
          Global X
        };
        (2, 41) to (2, 42) => {
          (2, 16) to (2, 17): (`X`)
        };
        (2, 51) to (2, 52) => {
          Global Z
        };
        (2, 53) to (2, 54) => {
          (2, 24) to (2, 25): (`Z`)
        };
        (2, 67) to (2, 68) => {
          Global Y
        };
        (2, 69) to (2, 70) => {
          (2, 19) to (2, 20): (`Y`)
        };
        (3, 6) to (3, 7) => {
          (2, 19) to (2, 20): (`Y`)
        };
        (3, 9) to (3, 10) => {
          (2, 16) to (2, 17): (`X`)
        };
        (3, 12) to (3, 13) => {
          (2, 19) to (2, 20): (`Y`)
        };
        (3, 16) to (3, 17) => {
          (3, 4) to (3, 5): (`Z`)
        }] |}]

let%expect_test ""class_expr_tparam"" =
  print_ssa_test {|
var w = class <X, Y:X> extends X<X> implements Y<Y> {
  f<Z:Y>(x:X, y:Y) {
    let z: Z;
  }
}
|};
    [%expect {|
      [
        (2, 20) to (2, 21) => {
          (2, 15) to (2, 16): (`X`)
        };
        (2, 31) to (2, 32) => {
          Global X
        };
        (2, 33) to (2, 34) => {
          (2, 15) to (2, 16): (`X`)
        };
        (2, 47) to (2, 48) => {
          Global Y
        };
        (2, 49) to (2, 50) => {
          (2, 18) to (2, 19): (`Y`)
        };
        (3, 6) to (3, 7) => {
          (2, 18) to (2, 19): (`Y`)
        };
        (3, 11) to (3, 12) => {
          (2, 15) to (2, 16): (`X`)
        };
        (3, 16) to (3, 17) => {
          (2, 18) to (2, 19): (`Y`)
        };
        (4, 11) to (4, 12) => {
          (3, 4) to (3, 5): (`Z`)
        }] |}]

let%expect_test ""import_type"" =
  print_ssa_test {|
var x: S;
import { type S } from '';
|};
    [%expect {|
      [
        (2, 7) to (2, 8) => {
          (3, 14) to (3, 15): (`S`)
        }] |}]

let%expect_test ""import_mix"" =
  print_ssa_test {|
var x: S = t;
var a: W;
import { type S, t, w as y, typeof w as W } from '';
t;
y;
w;
|};
    [%expect {|
      [
        (2, 7) to (2, 8) => {
          (4, 14) to (4, 15): (`S`)
        };
        (2, 11) to (2, 12) => {
          (4, 17) to (4, 18): (`t`)
        };
        (3, 7) to (3, 8) => {
          (4, 40) to (4, 41): (`W`)
        };
        (5, 0) to (5, 1) => {
          (4, 17) to (4, 18): (`t`)
        };
        (6, 0) to (6, 1) => {
          (4, 25) to (4, 26): (`y`)
        };
        (7, 0) to (7, 1) => {
          Global w
        }] |}]

let%expect_test ""import_def"" =
  print_ssa_test {|
(NS: NST);
(ps: ns);
(ps: ms);
(1: a);
(2: b);
import type {a, b} from ''
import typeof ns from '';
import type ms from '';
import ps from ''
import * as NS from ''
import typeof * as NST from ''
(NS: NST);
(ps: ns);
(ps: ms);
(1: a);
(2: b);
|};
    [%expect {|
      [
        (2, 1) to (2, 3) => {
          (11, 12) to (11, 14): (`NS`)
        };
        (2, 5) to (2, 8) => {
          (12, 19) to (12, 22): (`NST`)
        };
        (3, 1) to (3, 3) => {
          (10, 7) to (10, 9): (`ps`)
        };
        (3, 5) to (3, 7) => {
          (8, 14) to (8, 16): (`ns`)
        };
        (4, 1) to (4, 3) => {
          (10, 7) to (10, 9): (`ps`)
        };
        (4, 5) to (4, 7) => {
          (9, 12) to (9, 14): (`ms`)
        };
        (5, 4) to (5, 5) => {
          (7, 13) to (7, 14): (`a`)
        };
        (6, 4) to (6, 5) => {
          (7, 16) to (7, 17): (`b`)
        };
        (13, 1) to (13, 3) => {
          (11, 12) to (11, 14): (`NS`)
        };
        (13, 5) to (13, 8) => {
          (12, 19) to (12, 22): (`NST`)
        };
        (14, 1) to (14, 3) => {
          (10, 7) to (10, 9): (`ps`)
        };
        (14, 5) to (14, 7) => {
          (8, 14) to (8, 16): (`ns`)
        };
        (15, 1) to (15, 3) => {
          (10, 7) to (10, 9): (`ps`)
        };
        (15, 5) to (15, 7) => {
          (9, 12) to (9, 14): (`ms`)
        };
        (16, 4) to (16, 5) => {
          (7, 13) to (7, 14): (`a`)
        };
        (17, 4) to (17, 5) => {
          (7, 16) to (7, 17): (`b`)
        }] |}]

let%expect_test ""inc"" =
  print_ssa_test {|
let x = 0;
++x;
x++;
x;
  |};
  [%expect {|
    [
      (3, 2) to (3, 3) => {
        (2, 4) to (2, 5): (`x`)
      };
      (4, 0) to (4, 1) => {
        (3, 2) to (3, 3): (`x`)
      };
      (5, 0) to (5, 1) => {
        (4, 0) to (4, 1): (`x`)
      }] |}]

let%expect_test ""inc_heap"" =
  print_ssa_test {|
let x = { a: 0 };
++x.a;
x.a++;
x.a;
  |};
  [%expect {|
    [
      (3, 2) to (3, 3) => {
        (2, 4) to (2, 5): (`x`)
      };
      (4, 0) to (4, 1) => {
        (2, 4) to (2, 5): (`x`)
      };
      (4, 0) to (4, 3) => {
        number
      };
      (5, 0) to (5, 1) => {
        (2, 4) to (2, 5): (`x`)
      };
      (5, 0) to (5, 3) => {
        number
      }] |}]

let%expect_test ""op_assign_heap"" =
  print_ssa_test {|
let x = { a: 0 };
x.a += 42;
x.a;
  |};
  [%expect {|
    [
      (3, 0) to (3, 1) => {
        (2, 4) to (2, 5): (`x`)
      };
      (4, 0) to (4, 1) => {
        (2, 4) to (2, 5): (`x`)
      };
      (4, 0) to (4, 3) => {
        (3, 0) to (3, 3): (some property)
      }] |}]

let%expect_test ""class1"" =
  print_ssa_test {|
(C: void); // as a value, C is undefined and in the TDZ

declare var c: C; // as a type, C refers to the class below
c.foo;

class C {
    foo: number;
}
  |};
  [%expect {|
    [
      (2, 1) to (2, 2) => {
        (undeclared class) (7, 6) to (7, 7): (`C`)
      };
      (4, 15) to (4, 16) => {
        (undeclared class) (7, 6) to (7, 7): (`C`)
      };
      (5, 0) to (5, 1) => {
        (4, 12) to (4, 13): (`c`)
      }] |}]

let%expect_test ""class2"" =
  print_ssa_test {|
class C {
  foo: D;
}
class D extends C {
  bar;
}
  |};
  [%expect {|
    [
      (3, 7) to (3, 8) => {
        (5, 6) to (5, 7): (`D`)
      };
      (5, 16) to (5, 17) => {
        (2, 6) to (2, 7): (`C`)
      }] |}]

let%expect_test ""class3"" =
  print_ssa_test {|
C;
class C {
  x: C;
}
C;
  |};
  [%expect {|
    [
      (2, 0) to (2, 1) => {
        (undeclared class) (3, 6) to (3, 7): (`C`)
      };
      (4, 5) to (4, 6) => {
        (3, 6) to (3, 7): (`C`)
      };
      (6, 0) to (6, 1) => {
        (3, 6) to (3, 7): (`C`)
      }] |}]

let%expect_test ""class4"" =
  print_ssa_test {|

function havoced() {
  C;
}

class C {
}
  |};
  [%expect {|
    [
      (4, 2) to (4, 3) => {
        (7, 6) to (7, 7): (`C`)
      }] |}]

let%expect_test ""class5"" =
  print_ssa_test {|

function havoc() {
  C = 42;
}

havoc();
C;

class C {
}
  |};
  [%expect {|
    [
      (7, 0) to (7, 5) => {
        (3, 9) to (3, 14): (`havoc`)
      };
      (8, 0) to (8, 1) => {
        (undeclared class) (10, 6) to (10, 7): (`C`)
      }] |}]

let%expect_test ""deps_recur_broken_init"" =
  print_ssa_test {|
type T = number;
let x: T;
function f() {
  x = x;
}
  |};
  [%expect {|
    [
      (3, 7) to (3, 8) => {
        (2, 5) to (2, 6): (`T`)
      };
      (5, 6) to (5, 7) => {
        (3, 4) to (3, 5): (`x`)
      }] |}]

let%expect_test ""class3"" =
  print_ssa_test {|
class C {
  foo: D;
}
class D extends C {
  bar;
}
  |};
  [%expect {|
    [
      (3, 7) to (3, 8) => {
        (5, 6) to (5, 7): (`D`)
      };
      (5, 16) to (5, 17) => {
        (2, 6) to (2, 7): (`C`)
      }] |}]

let%expect_test ""enum"" =
  print_ssa_test {|
function havoced() {
  var x: E = E.Foo
}
enum E {
  Foo
}
  |};
  [%expect {|
    [
      (3, 9) to (3, 10) => {
        (5, 5) to (5, 6): (`E`)
      };
      (3, 13) to (3, 14) => {
        (5, 5) to (5, 6): (`E`)
      }] |}]

let%expect_test ""react_jsx"" =
  print_ssa_test {|
const React = require('react');

<div />;
  |};
    [%expect {|
      [
        (2, 14) to (2, 21) => {
          Global require
        };
        (4, 0) to (4, 7) => {
          (2, 6) to (2, 11): (`React`)
        };
        (4, 1) to (4, 4) => {
          Global div
        }] |}]

let%expect_test ""unreachable_jsx"" =
  print_ssa_test {|
const React = require('react');
throw new Error();
<Component />;
|};
    [%expect {|
      [
        (2, 14) to (2, 21) => {
          Global require
        };
        (3, 10) to (3, 15) => {
          Global Error
        };
        (4, 0) to (4, 13) => {
          unreachable
        }] |}]

let%expect_test ""custom_jsx_pragma"" =
  print_ssa_test ~custom_jsx:(Some ""createMikesCoolElement"") {|
  let createMikesCoolElement = (null: any);
<FirstElement />
function time_to_create_some_elements_bro() {
  <SecondElement />
}
|};
    [%expect {|
      [
        (3, 0) to (3, 16) => {
          (2, 6) to (2, 28): (`createMikesCoolElement`)
        };
        (3, 1) to (3, 13) => {
          Global FirstElement
        };
        (5, 2) to (5, 19) => {
          (2, 6) to (2, 28): (`createMikesCoolElement`)
        };
        (5, 3) to (5, 16) => {
          Global SecondElement
        }] |}]

let%expect_test ""automatic_react_runtime"" =
  print_ssa_test ~react_runtime_automatic:true {|
  let createMikesCoolElement = (null: any);
<FirstElement />
function time_to_create_some_elements_bro() {
  <SecondElement />
}
|};
    [%expect {|
      [
        (3, 1) to (3, 13) => {
          Global FirstElement
        };
        (5, 3) to (5, 16) => {
          Global SecondElement
        }] |}]

let%expect_test ""react_jsx"" =
  print_ssa_test {|
const React = require('react');

<div />;
|};
    [%expect {|
      [
        (2, 14) to (2, 21) => {
          Global require
        };
        (4, 0) to (4, 7) => {
          (2, 6) to (2, 11): (`React`)
        };
        (4, 1) to (4, 4) => {
          Global div
        }] |}]

let%expect_test ""unreachable_jsx"" =
  print_ssa_test {|
const React = require('react');
throw new Error();
<Component />;
|};
    [%expect {|
      [
        (2, 14) to (2, 21) => {
          Global require
        };
        (3, 10) to (3, 15) => {
          Global Error
        };
        (4, 0) to (4, 13) => {
          unreachable
        }] |}]

let%expect_test ""switch_reread_discriminant"" =
  print_ssa_test {|
let y = {};
switch (y.x) { // Does not report a Projection
    case 'ONE': break;
    case 'TWO': break;
    default:
      (y.x: empty);
}
|};
    [%expect {|
      [
        (3, 8) to (3, 9) => {
          (2, 4) to (2, 5): (`y`)
        };
        (4, 4) to (4, 22) => {
          (2, 4) to (2, 5): (`y`)
        };
        (5, 4) to (5, 22) => {
          {refinement = Not (SentinelR x); writes = (2, 4) to (2, 5): (`y`)}
        };
        (7, 7) to (7, 8) => {
          {refinement = Not (SentinelR x); writes = {refinement = Not (SentinelR x); writes = (2, 4) to (2, 5): (`y`)}}
        };
        (7, 7) to (7, 10) => {
          {refinement = Not (TWO); writes = {refinement = Not (ONE); writes = projection at (3, 8) to (3, 11)}}
        }] |}]

let%expect_test ""no_refinement_write_on_indexed"" =
  print_ssa_test {|
let x = {};
let y = 'str';
x[y] = 3;
x[y]; // Should not report an entry
|};
    [%expect {|
      [
        (4, 0) to (4, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 2) to (4, 3) => {
          (3, 4) to (3, 5): (`y`)
        };
        (5, 0) to (5, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (5, 2) to (5, 3) => {
          (3, 4) to (3, 5): (`y`)
        }] |}]

let%expect_test ""switch_no_default"" =
  print_ssa_test {|
let y = 'ONE';
switch (y) {
    case 'ONE': break;
    case 'TWO': break;
}
|};
    [%expect {|
      [
        (3, 0) to (6, 1) => {
          {refinement = Not (TWO); writes = {refinement = Not (ONE); writes = (2, 4) to (2, 5): (`y`)}}
        };
        (3, 8) to (3, 9) => {
          (2, 4) to (2, 5): (`y`)
        }] |}]

let%expect_test ""switch_exhaustive_return"" =
  print_ssa_test {|
let obj = {};
  switch (obj.k) {
    case 'a':
      throw 0;
    case 'b':
      throw 1;
  }
|};
    [%expect {|
      [
        (3, 2) to (8, 3) => {
          {refinement = Not (b); writes = {refinement = Not (a); writes = projection at (3, 10) to (3, 15)}}
        };
        (3, 10) to (3, 13) => {
          (2, 4) to (2, 7): (`obj`)
        };
        (4, 4) to (5, 14) => {
          (2, 4) to (2, 7): (`obj`)
        };
        (6, 4) to (7, 14) => {
          {refinement = Not (SentinelR k); writes = (2, 4) to (2, 7): (`obj`)}
        }] |}]

let%expect_test ""switch_exhaustive_fallthrough_return"" =
  print_ssa_test {|
let obj = {};
  switch (obj.k) {
    case 'a':
    case 'b':
      throw 1;
  }
|};
    [%expect {|
      [
        (3, 2) to (7, 3) => {
          {refinement = Not (b); writes = {refinement = Not (a); writes = projection at (3, 10) to (3, 15)}}
        };
        (3, 10) to (3, 13) => {
          (2, 4) to (2, 7): (`obj`)
        };
        (4, 4) to (4, 13) => {
          (2, 4) to (2, 7): (`obj`)
        };
        (5, 4) to (6, 14) => {
          {refinement = Not (SentinelR k); writes = (2, 4) to (2, 7): (`obj`)}
        }] |}]

let%expect_test ""reference_before_declaration"" =
  print_ssa_test {|
  _const;
  _let;
  _var;
  _func1;
  _func2;
  _func3;
  _func4;
  _class;
  E;

  const _const = 3;
  let _let = 3;
  var _var = 3;
  function _func1() {}
  export function _func2() {}
  export default function _func3() {}
  declare export function _func4(): void
class _class {}
  enum E { A }
|};
    [%expect {|
      [
        (2, 2) to (2, 8) => {
          (undeclared)
        };
        (3, 2) to (3, 6) => {
          (undeclared)
        };
        (4, 2) to (4, 6) => {
          (uninitialized)
        };
        (5, 2) to (5, 8) => {
          (15, 11) to (15, 17): (`_func1`)
        };
        (6, 2) to (6, 8) => {
          (16, 18) to (16, 24): (`_func2`)
        };
        (7, 2) to (7, 8) => {
          (17, 26) to (17, 32): (`_func3`)
        };
        (8, 2) to (8, 8) => {
          declared function (18, 26) to (18, 32)
        };
        (9, 2) to (9, 8) => {
          (undeclared class) (19, 6) to (19, 12): (`_class`)
        };
        (10, 2) to (10, 3) => {
          (undeclared)
        }] |}]

let%expect_test ""declaration_declares_undeclared"" =
  print_ssa_test {|
x;
x = 3; // Does not count as a write until LHS is declared
x;
let x;
x;
x = 3;
x;
|};
    [%expect {|
      [
        (2, 0) to (2, 1) => {
          (undeclared)
        };
        (4, 0) to (4, 1) => {
          (undeclared)
        };
        (6, 0) to (6, 1) => {
          (uninitialized)
        };
        (8, 0) to (8, 1) => {
          (7, 0) to (7, 1): (`x`)
        }] |}]

let%expect_test ""undeclared_havoc_no_writes"" =
  print_ssa_test {|
console.log('foo');
x;
let x;
|};
    [%expect {|
      [
        (2, 0) to (2, 7) => {
          Global console
        };
        (3, 0) to (3, 1) => {
          (undeclared)
        }] |}]

let%expect_test ""undeclared_havoc_function_writes"" =
  print_ssa_test {|
function f() { x = 3 }
console.log('foo');
x;
let x;
|};
    [%expect {|
      [
        (3, 0) to (3, 7) => {
          Global console
        };
        (4, 0) to (4, 1) => {
          (undeclared)
        }] |}]

let%expect_test ""undeclared_enter_function_scope"" =
  print_ssa_test {|
function f() { x; }
let x;
x = 3;
|};
    [%expect {|
      [
        (2, 15) to (2, 16) => {
          (4, 0) to (4, 1): (`x`)
        }] |}]

let%expect_test ""default_switch_refinement"" =
  print_ssa_test {|
type Enum = 'ONE' | 'TWO';
type Selection = { x: 'ONE' } | { x: 'TWO' } | { x: 'NONE' }

type Rule = {
  x: Enum,
  y: Selection,
}

function foo(r: Rule) {
  const x = r.x;
  const y = r.y;
  if (y.x === x) {
    switch (y.x) {
      case 'ONE': break;
      case 'TWO': break;
      default: (y.x: empty);
    }
  }
}
|};
    [%expect {|
      [
        (6, 5) to (6, 9) => {
          (2, 5) to (2, 9): (`Enum`)
        };
        (7, 5) to (7, 14) => {
          (3, 5) to (3, 14): (`Selection`)
        };
        (10, 16) to (10, 20) => {
          (5, 5) to (5, 9): (`Rule`)
        };
        (11, 12) to (11, 13) => {
          (10, 13) to (10, 14): (`r`)
        };
        (12, 12) to (12, 13) => {
          (10, 13) to (10, 14): (`r`)
        };
        (13, 6) to (13, 7) => {
          (12, 8) to (12, 9): (`y`)
        };
        (13, 14) to (13, 15) => {
          (11, 8) to (11, 9): (`x`)
        };
        (14, 12) to (14, 13) => {
          {refinement = SentinelR x; writes = (12, 8) to (12, 9): (`y`)}
        };
        (15, 6) to (15, 24) => {
          {refinement = SentinelR x; writes = (12, 8) to (12, 9): (`y`)}
        };
        (16, 6) to (16, 24) => {
          {refinement = Not (SentinelR x); writes = {refinement = SentinelR x; writes = (12, 8) to (12, 9): (`y`)}}
        };
        (17, 16) to (17, 17) => {
          {refinement = Not (SentinelR x); writes = {refinement = Not (SentinelR x); writes = {refinement = SentinelR x; writes = (12, 8) to (12, 9): (`y`)}}}
        };
        (17, 16) to (17, 19) => {
          {refinement = Not (TWO); writes = {refinement = Not (ONE); writes = projection at (14, 12) to (14, 15)}}
        }] |}]

let%expect_test ""prop_exists"" =
  print_ssa_test {|
const x = {foo: 3};

if (x.foo) {
  x;
  x.foo;
}
|};
    [%expect {|
[
  (4, 4) to (4, 5) => {
    (2, 6) to (2, 7): (`x`)
  };
  (5, 2) to (5, 3) => {
    {refinement = PropExistsR (foo); writes = (2, 6) to (2, 7): (`x`)}
  };
  (6, 2) to (6, 3) => {
    {refinement = PropExistsR (foo); writes = (2, 6) to (2, 7): (`x`)}
  };
  (6, 2) to (6, 7) => {
    {refinement = Truthy; writes = projection at (4, 4) to (4, 9)}
  }] |}]

let%expect_test ""try_catch_env_merging"" =
  print_ssa_test {|
function maz2() {
  let x: number[] = [];
  try {
    throw new Error(`just capturing a stack trace`);
  } catch (e) {
    var a: string = x[0];
  }
  var c: string = x[0]; // reachable
}
|};
    [%expect {|
      [
        (5, 14) to (5, 19) => {
          Global Error
        };
        (7, 20) to (7, 21) => {
          (3, 6) to (3, 7): (`x`)
        };
        (9, 18) to (9, 19) => {
          (3, 6) to (3, 7): (`x`)
        }] |}]

let%expect_test ""try_catch_catch_throws"" =
  print_ssa_test {|
function bar(response) {
    var payload;
    try {
        payload = JSON.parse(response);
    } catch (e) {
        throw new Error('...');
    }
    // here via [try] only.
    if (payload.error) {    // ok
        // ...
    }
}
|};
    [%expect {|
      [
        (5, 18) to (5, 22) => {
          Global JSON
        };
        (5, 29) to (5, 37) => {
          (2, 13) to (2, 21): (`response`)
        };
        (7, 18) to (7, 23) => {
          Global Error
        };
        (10, 8) to (10, 15) => {
          (5, 8) to (5, 15): (`payload`)
        }] |}]

let%expect_test ""try_catch_throw_in_both_then_finally"" =
  print_ssa_test {|
function bar(response) {
    var payload;
    try {
      throw new Error();
    } catch (e) {
      throw new Error();
    } finally {
      payload = 3;
    }
    // This line is dead
    payload;
}
|};
    [%expect {|
      [
        (5, 16) to (5, 21) => {
          Global Error
        };
        (7, 16) to (7, 21) => {
          Global Error
        };
        (12, 4) to (12, 11) => {
          unreachable
        }] |}]

let%expect_test ""try_catch_throw_in_both_then_finally"" =
  print_ssa_test {|
function bar(response) {
    var payload;
    try {
      throw new Error();
    } catch (e) {
      payload = 4;
    } finally {
      payload;
    }
    payload;
}
|};
    [%expect {|
      [
        (5, 16) to (5, 21) => {
          Global Error
        };
        (9, 6) to (9, 13) => {
          (uninitialized),
          (7, 6) to (7, 13): (`payload`)
        };
        (11, 4) to (11, 11) => {
          (uninitialized),
          (7, 6) to (7, 13): (`payload`)
        }] |}]

let%expect_test ""exports_global"" =
  print_ssa_test {|
exports.foo = 1;
|};
    [%expect {|
      [
        (2, 0) to (2, 7) => {
          Global exports
        }] |}]

let%expect_test ""import_havoc"" =
  print_ssa_test {|
import {func} from './a';

function f() {
  func();
}
|};
    [%expect {|
      [
        (5, 2) to (5, 6) => {
          (2, 8) to (2, 12): (`func`)
        }] |}]

let%expect_test ""test27"" =
  print_ssa_test {|
if (!x.a) { x.c; } else { x.b; }
|};
    [%expect {|
      [
        (2, 5) to (2, 6) => {
          Global x
        };
        (2, 12) to (2, 13) => {
          {refinement = Not (PropExistsR (a)); writes = Global x}
        };
        (2, 26) to (2, 27) => {
          {refinement = PropExistsR (a); writes = Global x}
        }] |}]

let%expect_test ""conjunct"" =
  print_ssa_test {|
if (x.a && x.b)
  { x.a; x.b }
else
  { x.a; x.b }
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global x
        };
        (2, 11) to (2, 12) => {
          {refinement = PropExistsR (a); writes = Global x}
        };
        (3, 4) to (3, 5) => {
          {refinement = And (PropExistsR (a), PropExistsR (b)); writes = Global x}
        };
        (3, 4) to (3, 7) => {
          {refinement = Truthy; writes = projection at (2, 4) to (2, 7)}
        };
        (3, 9) to (3, 10) => {
          {refinement = And (PropExistsR (a), PropExistsR (b)); writes = Global x}
        };
        (3, 9) to (3, 12) => {
          {refinement = Truthy; writes = projection at (2, 11) to (2, 14)}
        };
        (5, 4) to (5, 5) => {
          {refinement = Or (Not (PropExistsR (a)), Not (PropExistsR (b))); writes = Global x}
        };
        (5, 9) to (5, 10) => {
          {refinement = Or (Not (PropExistsR (a)), Not (PropExistsR (b))); writes = Global x}
        }] |}]

let%expect_test ""disjunct"" =
  print_ssa_test {|
if (x.a || x.b)
  { x.a; x.b }
else
  { x.a; x.b }
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global x
        };
        (2, 11) to (2, 12) => {
          {refinement = Not (PropExistsR (a)); writes = Global x}
        };
        (3, 4) to (3, 5) => {
          {refinement = Or (PropExistsR (a), PropExistsR (b)); writes = Global x}
        };
        (3, 9) to (3, 10) => {
          {refinement = Or (PropExistsR (a), PropExistsR (b)); writes = Global x}
        };
        (5, 4) to (5, 5) => {
          {refinement = And (Not (PropExistsR (a)), Not (PropExistsR (b))); writes = Global x}
        };
        (5, 4) to (5, 7) => {
          {refinement = Not (Truthy); writes = projection at (2, 4) to (2, 7)}
        };
        (5, 9) to (5, 10) => {
          {refinement = And (Not (PropExistsR (a)), Not (PropExistsR (b))); writes = Global x}
        };
        (5, 9) to (5, 12) => {
          {refinement = Not (Truthy); writes = projection at (2, 11) to (2, 14)}
        }] |}]

let%expect_test ""complex"" =
  print_ssa_test {|
if ((x.a || x.b) && x.c)
  { x.a; x.b; x.c }
else
  { x.a; x.b; x.c }
|};
    [%expect {|
      [
        (2, 5) to (2, 6) => {
          Global x
        };
        (2, 12) to (2, 13) => {
          {refinement = Not (PropExistsR (a)); writes = Global x}
        };
        (2, 20) to (2, 21) => {
          {refinement = Or (PropExistsR (a), PropExistsR (b)); writes = Global x}
        };
        (3, 4) to (3, 5) => {
          {refinement = And (Or (PropExistsR (a), PropExistsR (b)), PropExistsR (c)); writes = Global x}
        };
        (3, 9) to (3, 10) => {
          {refinement = And (Or (PropExistsR (a), PropExistsR (b)), PropExistsR (c)); writes = Global x}
        };
        (3, 14) to (3, 15) => {
          {refinement = And (Or (PropExistsR (a), PropExistsR (b)), PropExistsR (c)); writes = Global x}
        };
        (3, 14) to (3, 17) => {
          {refinement = Truthy; writes = projection at (2, 20) to (2, 23)}
        };
        (5, 4) to (5, 5) => {
          {refinement = Or (And (Not (PropExistsR (a)), Not (PropExistsR (b))), Not (PropExistsR (c))); writes = Global x}
        };
        (5, 9) to (5, 10) => {
          {refinement = Or (And (Not (PropExistsR (a)), Not (PropExistsR (b))), Not (PropExistsR (c))); writes = Global x}
        };
        (5, 14) to (5, 15) => {
          {refinement = Or (And (Not (PropExistsR (a)), Not (PropExistsR (b))), Not (PropExistsR (c))); writes = Global x}
        }] |}]

let%expect_test ""changeset"" =
  print_ssa_test {|
if (x && x.a)
  { x.a; }
else
  { x.a; }
x.a;
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global x
        };
        (2, 9) to (2, 10) => {
          {refinement = Truthy; writes = Global x}
        };
        (3, 4) to (3, 5) => {
          {refinement = And (Truthy, PropExistsR (a)); writes = Global x}
        };
        (3, 4) to (3, 7) => {
          {refinement = Truthy; writes = projection at (2, 9) to (2, 12)}
        };
        (5, 4) to (5, 5) => {
          {refinement = Or (Not (Truthy), Not (PropExistsR (a))); writes = Global x}
        };
        (6, 0) to (6, 1) => {
          Global x
        }] |}]

let%expect_test ""no_changeset"" =
  print_ssa_test {|
if (x.a)
  { x.a; }
else
  { x.a; }
x.a;
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global x
        };
        (3, 4) to (3, 5) => {
          {refinement = PropExistsR (a); writes = Global x}
        };
        (3, 4) to (3, 7) => {
          {refinement = Truthy; writes = projection at (2, 4) to (2, 7)}
        };
        (5, 4) to (5, 5) => {
          {refinement = Not (PropExistsR (a)); writes = Global x}
        };
        (5, 4) to (5, 7) => {
          {refinement = Not (Truthy); writes = projection at (2, 4) to (2, 7)}
        };
        (6, 0) to (6, 1) => {
          Global x
        };
        (6, 0) to (6, 3) => {
          {refinement = Truthy; writes = projection at (2, 4) to (2, 7)},
          {refinement = Not (Truthy); writes = projection at (2, 4) to (2, 7)}
        }] |}]

let%expect_test ""changeset_update"" =
  print_ssa_test {|
if (x.a)
  { x.a = 42 }
x.a;
|};
    [%expect {|
      [
        (2, 4) to (2, 5) => {
          Global x
        };
        (3, 4) to (3, 5) => {
          {refinement = PropExistsR (a); writes = Global x}
        };
        (3, 4) to (3, 7) => {
          {refinement = Truthy; writes = projection at (2, 4) to (2, 7)}
        };
        (4, 0) to (4, 1) => {
          Global x
        };
        (4, 0) to (4, 3) => {
          (3, 4) to (3, 7): (some property),
          {refinement = Not (Truthy); writes = projection at (2, 4) to (2, 7)}
        }] |}]

let%expect_test ""changeset_pre_exist"" =
  print_ssa_test {|
if(x && x.a) {
  if(x && x.a) {}
  else {
    x.a;
  }
  x.a;
}
|};
    [%expect {|
      [
        (2, 3) to (2, 4) => {
          Global x
        };
        (2, 8) to (2, 9) => {
          {refinement = Truthy; writes = Global x}
        };
        (3, 5) to (3, 6) => {
          {refinement = And (Truthy, PropExistsR (a)); writes = Global x}
        };
        (3, 10) to (3, 11) => {
          {refinement = Truthy; writes = {refinement = And (Truthy, PropExistsR (a)); writes = Global x}}
        };
        (3, 10) to (3, 13) => {
          {refinement = Truthy; writes = projection at (2, 8) to (2, 11)}
        };
        (5, 4) to (5, 5) => {
          {refinement = Or (Not (Truthy), Not (PropExistsR (a))); writes = {refinement = And (Truthy, PropExistsR (a)); writes = Global x}}
        };
        (5, 4) to (5, 7) => {
          {refinement = Truthy; writes = projection at (2, 8) to (2, 11)}
        };
        (7, 2) to (7, 3) => {
          {refinement = And (Truthy, PropExistsR (a)); writes = Global x}
        };
        (7, 2) to (7, 5) => {
          {refinement = Truthy; writes = projection at (2, 8) to (2, 11)},
          {refinement = Truthy; writes = {refinement = Truthy; writes = projection at (2, 8) to (2, 11)}}
        }] |}]

let%expect_test ""optional_refi"" =
  print_ssa_test {|
var x: ?Array<number> = null;
x?.[x[0]];
if(x?.[x[0]]) { x; }
|};
    [%expect {|
      [
        (2, 8) to (2, 13) => {
          Global Array
        };
        (3, 0) to (3, 1) => {
          (2, 4) to (2, 5): (`x`)
        };
        (3, 4) to (3, 5) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 3) to (4, 4) => {
          (2, 4) to (2, 5): (`x`)
        };
        (4, 7) to (4, 8) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`x`)}
        };
        (4, 16) to (4, 17) => {
          {refinement = Not (Maybe); writes = (2, 4) to (2, 5): (`x`)}
        }] |}]

let%expect_test ""optional_refi2"" =
  print_ssa_test {|
declare var x: ?{y: {f: (mixed) => void, z?: {w: mixed => void}}};
x?.y.f(x);
x?.y.z?.w(x.y.z);
(x?.y).f(x);
|};
    [%expect {|
      [
        (3, 0) to (3, 1) => {
          (2, 12) to (2, 13): (`x`)
        };
        (3, 7) to (3, 8) => {
          {refinement = And (Not (Maybe), PropExistsR (y)); writes = (2, 12) to (2, 13): (`x`)}
        };
        (4, 0) to (4, 1) => {
          (2, 12) to (2, 13): (`x`)
        };
        (4, 10) to (4, 11) => {
          {refinement = And (Not (Maybe), PropExistsR (y)); writes = (2, 12) to (2, 13): (`x`)}
        };
        (4, 10) to (4, 13) => {
          {refinement = PropExistsR (z); writes = projection at (4, 0) to (4, 4)}
        };
        (4, 10) to (4, 15) => {
          {refinement = And (Not (Maybe), PropExistsR (w)); writes = projection at (4, 0) to (4, 6)}
        };
        (5, 1) to (5, 2) => {
          (2, 12) to (2, 13): (`x`)
        };
        (5, 9) to (5, 10) => {
          (2, 12) to (2, 13): (`x`)
        }] |}]

let%expect_test ""optional_refi3"" =
  print_ssa_test {|
declare var x: mixed;
if (x?.a === 42) {
  x;
  x.a;
} else {
  x;
  x.a;
}
x;
x.a;
|};
    [%expect {|
      [
        (3, 4) to (3, 5) => {
          (2, 12) to (2, 13): (`x`)
        };
        (4, 2) to (4, 3) => {
          {refinement = And (And (Not (Maybe), PropExistsR (a)), SentinelR a); writes = (2, 12) to (2, 13): (`x`)}
        };
        (5, 2) to (5, 3) => {
          {refinement = And (And (Not (Maybe), PropExistsR (a)), SentinelR a); writes = (2, 12) to (2, 13): (`x`)}
        };
        (5, 2) to (5, 5) => {
          {refinement = 42; writes = projection at (3, 4) to (3, 8)}
        };
        (7, 2) to (7, 3) => {
          {refinement = Or (Or (Not (Not (Maybe)), Not (PropExistsR (a))), Not (SentinelR a)); writes = (2, 12) to (2, 13): (`x`)}
        };
        (8, 2) to (8, 3) => {
          {refinement = Or (Or (Not (Not (Maybe)), Not (PropExistsR (a))), Not (SentinelR a)); writes = (2, 12) to (2, 13): (`x`)}
        };
        (10, 0) to (10, 1) => {
          (2, 12) to (2, 13): (`x`)
        };
        (11, 0) to (11, 1) => {
          (2, 12) to (2, 13): (`x`)
        }] |}]
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                              OCamlFormat                               *)
(*                                                                        *)
(*            Copyright (c) Facebook, Inc. and its affiliates.            *)
(*                                                                        *)
(*      This source code is licensed under the MIT license found in       *)
(*      the LICENSE file in the root directory of this source tree.       *)
(*                                                                        *)
(**************************************************************************)

(** Interface over the AST defined in vendor/ocaml-4.13 *)

open Parser_standard

include module type of Parsetree

type use_file = toplevel_phrase list

type 'a t =
  | Structure : structure t
  | Signature : signature t
  | Use_file : use_file t
  | Core_type : core_type t
  | Module_type : module_type t
  | Expression : expression t
  (* not implemented *)
  | Repl_file : unit t

module Parse : sig
  val ast : 'a t -> Lexing.lexbuf -> 'a
end

val equal : 'a t -> 'a -> 'a -> bool

val map : 'a t -> Ast_mapper.mapper -> 'a -> 'a

module Printast : sig
  include module type of Printast

  val ast : 'a t -> Format.formatter -> 'a -> unit
end
",ocaml
"module StringMap = Map.Make (String)

type kind = Structure | Signature | Use_file

type setup = {
  mutable has_ref : bool;
  mutable base_file : string option;
  kind : kind;
  dir : string;
}

let register_file dir kind tests fname =
  match String.split_on_char '.' fname with
  | test_name :: ((""ml"" | ""mli"" | ""mlt"") as ext) :: rest -> (
      let fname = dir ^ ""/"" ^ fname in
      let src_test_name = test_name ^ ""."" ^ ext in
      let setup =
        match StringMap.find src_test_name !tests with
        | setup -> setup
        | exception Not_found ->
            let s = { has_ref = false; base_file = None; kind; dir } in
            tests := StringMap.add src_test_name s !tests;
            s
      in
      match rest with
      | [] -> ()
      | [ ""ref"" ] -> setup.has_ref <- true
      | _ -> invalid_arg fname)
  (* ignore dune file, .foo.whatever.swp, etc *)
  | _ -> ()

let emit_test test_name setup =
  let out_name = test_name ^ "".stdout"" in
  let ref_name =
    setup.dir ^ ""/"" ^ if setup.has_ref then test_name ^ "".ref"" else test_name
  in
  let kind =
    match setup.kind with
    | Structure -> ""-structure""
    | Signature -> ""-signature""
    | Use_file -> ""-use-file""
  in
  Printf.printf
    {|
(rule (action (with-stdout-to %s (run ./gen/driver.exe %s %%{dep:%s}))))
(rule (alias runtest) (action (diff %s %s)))
|}
    out_name kind
    (setup.dir ^ ""/"" ^ test_name)
    ref_name out_name

let read_dir map kind =
  let dir =
    match kind with
    | Structure -> ""structure""
    | Signature -> ""signature""
    | Use_file -> ""use_file""
  in
  Sys.readdir (""./"" ^ dir) |> Array.iter (register_file dir kind map)

let () =
  let map = ref StringMap.empty in
  read_dir map Structure;
  read_dir map Signature;
  read_dir map Use_file;
  StringMap.iter emit_test !map
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                      TypeRex                                           *)
(*                                                                        *)
(*   Copyright OCamlPro 2011-2017. All rights reserved.                   *)
(*   This file is distributed under the terms of the LGPL v2.1 with       *)
(*   the special exception on linking described in the file LICENSE.      *)
(*      (GNU Lesser General Public Licence version 2.1)                   *)
(*                                                                        *)
(*     Contact: <typerex@ocamlpro.com> (http://www.ocamlpro.com/)         *)
(*                                                                        *)
(*  THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,       *)
(*  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES       *)
(*  OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND              *)
(*  NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS   *)
(*  BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN    *)
(*  ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN     *)
(*  CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE      *)
(*  SOFTWARE.                                                             *)
(**************************************************************************)

type color =
  | Red
  | Pink
  | Purple
  | DeepPurple
  | Indigo
  | Blue
  | LightBlue
  | Cyan
  | Teal
  | Green
  | LightGreen
  | Lime
  | Yellow
  | Amber
  | Orange
  | DeepOrange
  | Brown
  | Grey
  | BlueGrey
  | Black
  | White
  | Transparent

type shade =
  | Lighten of int
  | Darken of int
  | Accent of int
  | None

type t = { color : color ; shade : shade }

let color_to_string = function
  | Red -> ""red""
  | Pink -> ""pink""
  | Purple -> ""purple""
  | DeepPurple -> ""deep-purple""
  | Indigo -> ""indigo""
  | Blue -> ""blue""
  | LightBlue -> ""light-blue""
  | Cyan -> ""cyan""
  | Teal -> ""teal""
  | Green -> ""green""
  | LightGreen -> ""light-green""
  | Lime -> ""lime""
  | Yellow -> ""yellow""
  | Amber -> ""amber""
  | Orange -> ""orange""
  | DeepOrange -> ""deep-orange""
  | Brown -> ""brown""
  | Grey -> ""grey""
  | BlueGrey -> ""blue-grey""
  | Black -> ""black""
  | White -> ""white""
  | Transparent -> ""transparent""

let shade_to_string = function
  | Lighten i -> Printf.sprintf ""lighten-%d"" i
  | Darken i -> Printf.sprintf ""darken-%d"" i
  | Accent i -> Printf.sprintf ""accent-%d"" i
  | None ->  """"

let background_color div color =
  let col = color_to_string color.color in
  Js_utils.Manip.addClass div col ;
  match color.shade with
  | None -> ()
  | shade ->
      Js_utils.Manip.addClass div (shade_to_string shade)

let text_color div color =
  let col = color_to_string color.color ^ ""-text""in
  Js_utils.Manip.addClass div col ;
  match color.shade with
  | None -> ()
  | shade ->
      let shade = ""text-"" ^ shade_to_string shade in
      Js_utils.Manip.addClass div shade
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Type.TypeContext
module ALocMap = Loc_collections.ALocMap

exception Props_not_found of Type.Properties.id

exception Call_not_found of int

exception Exports_not_found of Type.Exports.id

exception Require_not_found of string

exception Module_not_found of string

type metadata = {
  (* local *)
  checked: bool;
  include_suppressions: bool;
  jsx: Options.jsx_mode;
  munge_underscores: bool;
  strict: bool;
  strict_local: bool;
  verbose: Verbose.t option;
  (* global *)
  any_propagation: bool;
  automatic_require_default: bool;
  babel_loose_array_spread: bool;
  cycle_errors: bool;
  enable_const_params: bool;
  enable_enums: bool;
  enable_relay_integration: bool;
  enforce_local_inference_annotations: bool;
  enforce_strict_call_arity: bool;
  enforce_this_annotations: bool;
  env_mode: Options.env_mode;
  env_mode_constrain_write_dirs: string list;
  exact_by_default: bool;
  exact_empty_objects: bool;
  experimental_infer_indexers: bool;
  facebook_fbs: string option;
  facebook_fbt: string option;
  facebook_module_interop: bool;
  haste_module_ref_prefix: string option;
  ignore_non_literal_requires: bool;
  local_inference_annotation_dirs: string list;
  max_literal_length: int;
  max_trace_depth: int;
  max_workers: int;
  missing_module_generators: (Str.regexp * string) list;
  react_runtime: Options.react_runtime;
  react_server_component_exts: SSet.t;
  recursion_limit: int;
  relay_integration_excludes: Str.regexp list;
  relay_integration_module_prefix: string option;
  relay_integration_module_prefix_includes: Str.regexp list;
  root: Path.t;
  run_post_inference_implicit_instantiation: bool;
  statement_reorder_checking: Options.statement_order_mode;
  strict_es6_import_export: bool;
  strict_es6_import_export_excludes: string list;
  strip_root: bool;
  suppress_types: SSet.t;
  trust_mode: Options.trust_mode;
  type_asserts: bool;
}

type test_prop_hit_or_miss =
  | Hit
  | Miss of Reason.name option * (Reason.t * Reason.t) * Type.use_op * string option

type type_assert_kind =
  | Is
  | Throws
  | Wraps

type voidable_check = {
  public_property_map: Type.Properties.id;
  private_property_map: Type.Properties.id;
  errors: ALoc.t Property_assignment.errors;
}

module Implicit_instantiation_check = struct
  type poly_t = ALoc.t * Type.typeparam Nel.t * Type.t

  type operation =
    | Call of Type.funcalltype
    | Constructor of Type.call_arg list

  type t = {
    lhs: Type.t;
    poly_t: poly_t;
    operation: Type.use_op * Reason.t * operation;
  }
end

(* Equivalently, we could use a Reason.t option, but this is more self-documenting. *)
type computed_property_state =
  | ResolvedOnce of Reason.t
  | ResolvedMultipleTimes

type subst_cache_err =
  | ETooFewTypeArgs of ALoc.t Reason.virtual_reason * int
  | ETooManyTypeArgs of ALoc.t Reason.virtual_reason * int

type sig_t = Type.TypeContext.t

type master_context = {
  master_sig_cx: sig_t;
  builtins: Builtins.t;
}

type component_t = {
  mutable sig_cx: sig_t;
  mutable builtins: Builtins.t;
  (* mapping from keyed alocs to concrete locations *)
  mutable aloc_tables: ALoc.table Lazy.t Utils_js.FilenameMap.t;
  (* map from goal ids to types *)
  mutable goal_map: Type.t IMap.t;
  (* graph tracking full resolution of types *)
  mutable type_graph: Graph_explorer.graph;
  (* map of speculation ids to sets of unresolved tvars *)
  mutable all_unresolved: ISet.t IMap.t;
  (* map from TypeAssert assertion locations to the type being asserted *)
  mutable type_asserts_map: (type_assert_kind * ALoc.t) ALocMap.t;
  mutable errors: Flow_error.ErrorSet.t;
  mutable error_suppressions: Error_suppressions.t;
  mutable severity_cover: ExactCover.lint_severity_cover Utils_js.FilenameMap.t;
  (* map from exists proposition locations to the types of values running through them *)
  mutable exists_checks: Type.TypeSet.t ALocMap.t;
  (* map from exists proposition locations to the types of excuses for them *)
  (* If a variable appears in something like `x || ''`, the existence check
   * is excused and not considered sketchy. (The program behaves identically to how it would
   * if the null check was made explicit (`x == null ? '' : x`), and this is a fairly
   * common pattern. Excusing it eliminates a lot of noise from the lint rule. *)
  (* The above example assumes that x is a string. If it were a different type
   * it wouldn't be excused. *)
  mutable exists_excuses: ExistsCheck.t ALocMap.t;
  (* For the definite instance property assignment analysis, we should only
   * emit errors for a given property if VoidT flows to the type of that
   * property. Ideally, we would create a VoidT ~> property type flow when we
   * perform the analysis. The problem is that doing that causes the type
   * inference behavior to depend on lint settings which can lead to some weird
   * behavior, such as extra errors even when the lint is off. The solution is
   * to collect all of potential errors that we would have created a flow for
   * in the context and deal with them post-merge. At this point, the tvars of
   * nearly all properties will have a concrete type that we can safely pattern
   * match on without affecting other constraints. For the unresolved tvars, we
   * conservatively emit errors.
   *)
  mutable voidable_checks: voidable_check list;
  mutable test_prop_hits_and_misses: test_prop_hit_or_miss IMap.t;
  (* A map from syntactic computed properties to the reasons of the first lower bound they receive.
   * If multiple lower bounds are received, we instead store ResolvedMultipleTimes so that we don't
   * emit multiple errors for a single syntactic computed property.
   *)
  mutable computed_property_states: computed_property_state IMap.t;
  mutable spread_widened_types: Type.Object.slice IMap.t;
  mutable optional_chains_useful: (Reason.t * bool) ALocMap.t;
  mutable invariants_useful: (Reason.t * bool) ALocMap.t;
  constraint_cache: Type.FlowSet.t ref;
  subst_cache: (Type.Poly.id * Type.t list, subst_cache_err list * Type.t) Hashtbl.t;
  instantiation_cache: (Reason.t * Reason.t * Reason.t Nel.t, Type.t) Hashtbl.t;
  repos_cache: Repos_cache.t ref;
  eval_id_cache:
    (Type.Eval.id, Type.t) Hashtbl.t * (Type.t * Type.defer_use_t, Type.Eval.id) Hashtbl.t;
  eval_repos_cache: (Type.t * Type.defer_use_t * Type.Eval.id, Type.t) Hashtbl.t;
  fix_cache: (bool * Type.t, Type.t) Hashtbl.t;
  spread_cache: Spread_cache.t;
  speculation_state: Speculation_state.t;
  (* Post-inference checks *)
  mutable literal_subtypes: (Type.t * Type.use_t) list;
  mutable new_env_literal_subtypes: (ALoc.t * Env_api.new_env_literal_check) list;
  mutable matching_props: (Reason.reason * string * Type.t * Type.t) list;
  mutable new_env_matching_props: (string * ALoc.t * ALoc.t) list;
  mutable implicit_instantiation_checks: Implicit_instantiation_check.t list;
  mutable inferred_indexers: Type.dicttype list ALocMap.t;
  mutable constrained_writes: (Type.t * Type.use_t) list;
  mutable env_value_cache: Type.t IMap.t;
  mutable env_type_cache: Type.t IMap.t;
  (* map from annot tvar ids to nodes used during annotation processing *)
  mutable annot_graph: Type.AConstraint.node IMap.t;
}
[@@warning ""-69""]

type phase =
  | InitLib
  | Checking
  | Merging
  | PostInference

let string_of_phase = function
  | InitLib -> ""InitLib""
  | Checking -> ""Checking""
  | Merging -> ""Merging""
  | PostInference -> ""PostInference""

type t = {
  ccx: component_t;
  file: File_key.t;
  phase: phase;
  aloc_table: ALoc.table Lazy.t;
  metadata: metadata;
  module_info: Module_info.t;
  mutable require_map: Type.tvar ALocMap.t;
  trust_constructor: unit -> Trust.trust_rep;
  mutable declare_module_ref: Module_info.t option;
  mutable environment: Loc_env.t;
  node_cache: Node_cache.t;
}

let metadata_of_options options =
  {
    (* local *)
    checked = Options.all options;
    include_suppressions = Options.include_suppressions options;
    jsx = Options.Jsx_react;
    munge_underscores = Options.should_munge_underscores options;
    strict = false;
    strict_local = false;
    verbose = Options.verbose options;
    (* global *)
    any_propagation = Options.any_propagation options;
    automatic_require_default = Options.automatic_require_default options;
    babel_loose_array_spread = Options.babel_loose_array_spread options;
    cycle_errors = Options.cycle_errors options;
    enable_const_params = Options.enable_const_params options;
    enable_enums = Options.enums options;
    enable_relay_integration = Options.enable_relay_integration options;
    enforce_local_inference_annotations = Options.enforce_local_inference_annotations options;
    enforce_strict_call_arity = Options.enforce_strict_call_arity options;
    enforce_this_annotations = Options.enforce_this_annotations options;
    env_mode = Options.env_mode options;
    env_mode_constrain_write_dirs = Options.env_mode_constrain_write_dirs options;
    exact_by_default = Options.exact_by_default options;
    exact_empty_objects = Options.exact_empty_objects options;
    experimental_infer_indexers = Options.experimental_infer_indexers options;
    facebook_fbs = Options.facebook_fbs options;
    facebook_fbt = Options.facebook_fbt options;
    facebook_module_interop = Options.facebook_module_interop options;
    haste_module_ref_prefix = Options.haste_module_ref_prefix options;
    ignore_non_literal_requires = Options.should_ignore_non_literal_requires options;
    local_inference_annotation_dirs = Options.local_inference_annotation_dirs options;
    max_literal_length = Options.max_literal_length options;
    max_trace_depth = Options.max_trace_depth options;
    max_workers = Options.max_workers options;
    missing_module_generators = Options.missing_module_generators options;
    react_runtime = Options.react_runtime options;
    react_server_component_exts = Options.react_server_component_exts options;
    recursion_limit = Options.recursion_limit options;
    relay_integration_excludes = Options.relay_integration_excludes options;
    relay_integration_module_prefix = Options.relay_integration_module_prefix options;
    relay_integration_module_prefix_includes =
      Options.relay_integration_module_prefix_includes options;
    root = Options.root options;
    run_post_inference_implicit_instantiation =
      Options.run_post_inference_implicit_instantiation options;
    statement_reorder_checking = Options.statement_reorder_checking options;
    strict_es6_import_export = Options.strict_es6_import_export options;
    strict_es6_import_export_excludes = Options.strict_es6_import_export_excludes options;
    strip_root = Options.should_strip_root options;
    suppress_types = Options.suppress_types options;
    trust_mode = Options.trust_mode options;
    type_asserts = Options.type_asserts options;
  }

let docblock_overrides docblock_info metadata =
  let metadata =
    let jsx =
      match Docblock.jsx docblock_info with
      | Some (expr, jsx_expr) ->
        let jsx_expr = Ast_loc_utils.loc_to_aloc_mapper#expression jsx_expr in
        Options.Jsx_pragma (expr, jsx_expr)
      | None -> Options.Jsx_react
    in
    { metadata with jsx }
  in
  let metadata =
    match Docblock.flow docblock_info with
    | None -> metadata
    | Some Docblock.OptIn -> { metadata with checked = true }
    | Some Docblock.OptInStrict -> { metadata with checked = true; strict = true }
    | Some Docblock.OptInStrictLocal -> { metadata with checked = true; strict_local = true }
    (* --all (which sets metadata.checked = true) overrides @noflow, so there are
       currently no scenarios where we'd change checked = true to false. in the
       future, there may be a case where checked defaults to true (but is not
       forced to be true ala --all), but for now we do *not* want to force
       checked = false here. *)
    | Some Docblock.OptOut -> metadata
  in
  let metadata =
    if Docblock.preventMunge docblock_info then
      { metadata with munge_underscores = false }
    else
      metadata
  in
  metadata

let empty_sig_cx =
  {
    graph = IMap.empty;
    trust_graph = IMap.empty;
    property_maps = Type.Properties.Map.empty;
    call_props = IMap.empty;
    export_maps = Type.Exports.Map.empty;
    evaluated = Type.Eval.Map.empty;
  }

let empty_master_cx () = { master_sig_cx = empty_sig_cx; builtins = Builtins.empty () }

let make_ccx master_cx =
  {
    sig_cx = master_cx.master_sig_cx;
    builtins = master_cx.builtins;
    aloc_tables = Utils_js.FilenameMap.empty;
    goal_map = IMap.empty;
    type_graph = Graph_explorer.new_graph ();
    all_unresolved = IMap.empty;
    type_asserts_map = ALocMap.empty;
    matching_props = [];
    new_env_matching_props = [];
    literal_subtypes = [];
    new_env_literal_subtypes = [];
    constrained_writes = [];
    env_value_cache = IMap.empty;
    env_type_cache = IMap.empty;
    errors = Flow_error.ErrorSet.empty;
    error_suppressions = Error_suppressions.empty;
    severity_cover = Utils_js.FilenameMap.empty;
    exists_checks = ALocMap.empty;
    exists_excuses = ALocMap.empty;
    voidable_checks = [];
    implicit_instantiation_checks = [];
    inferred_indexers = ALocMap.empty;
    test_prop_hits_and_misses = IMap.empty;
    computed_property_states = IMap.empty;
    spread_widened_types = IMap.empty;
    optional_chains_useful = ALocMap.empty;
    invariants_useful = ALocMap.empty;
    constraint_cache = ref Type.FlowSet.empty;
    subst_cache = Hashtbl.create 0;
    instantiation_cache = Hashtbl.create 0;
    repos_cache = ref Repos_cache.empty;
    eval_id_cache = (Hashtbl.create 0, Hashtbl.create 0);
    eval_repos_cache = Hashtbl.create 0;
    fix_cache = Hashtbl.create 0;
    spread_cache = Hashtbl.create 0;
    speculation_state = ref [];
    annot_graph = IMap.empty;
  }

let make ccx metadata file aloc_table module_ref phase =
  ccx.aloc_tables <- Utils_js.FilenameMap.add file aloc_table ccx.aloc_tables;
  {
    ccx;
    file;
    phase;
    aloc_table;
    metadata;
    module_info = Module_info.empty_cjs_module module_ref;
    require_map = ALocMap.empty;
    trust_constructor = Trust.literal_trust;
    declare_module_ref = None;
    environment = Loc_env.empty;
    node_cache = Node_cache.empty;
  }

let sig_cx cx = cx.ccx.sig_cx

let trust_graph_sig sig_cx = sig_cx.trust_graph

(* modules *)

let push_declare_module cx info =
  match cx.declare_module_ref with
  | Some _ -> failwith ""declare module must be one level deep""
  | None -> cx.declare_module_ref <- Some info

let pop_declare_module cx =
  match cx.declare_module_ref with
  | None -> failwith ""pop empty declare module""
  | Some _ -> cx.declare_module_ref <- None

let module_info cx =
  match cx.declare_module_ref with
  | Some info -> info
  | None -> cx.module_info

let module_kind cx =
  let info = module_info cx in
  info.Module_info.kind

let module_ref cx =
  let info = module_info cx in
  info.Module_info.ref

(* accessors *)
let current_phase cx = cx.phase

let all_unresolved cx = cx.ccx.all_unresolved

let trust_constructor cx = cx.trust_constructor

let cx_with_trust cx trust = { cx with trust_constructor = trust }

let metadata cx = cx.metadata

let max_literal_length cx = cx.metadata.max_literal_length

let babel_loose_array_spread cx = cx.metadata.babel_loose_array_spread

let builtins cx = cx.ccx.builtins

let enable_const_params cx =
  cx.metadata.enable_const_params || cx.metadata.strict || cx.metadata.strict_local

let enable_enums cx = cx.metadata.enable_enums

let enable_relay_integration cx =
  cx.metadata.enable_relay_integration
  && Relay_options.enabled_for_file cx.metadata.relay_integration_excludes cx.file

let relay_integration_module_prefix cx =
  Relay_options.module_prefix_for_file
    cx.metadata.relay_integration_module_prefix_includes
    cx.file
    cx.metadata.relay_integration_module_prefix

let env_mode cx = cx.metadata.env_mode

let enforce_strict_call_arity cx = cx.metadata.enforce_strict_call_arity

let errors cx = cx.ccx.errors

let error_suppressions cx = cx.ccx.error_suppressions

let evaluated cx = cx.ccx.sig_cx.evaluated

let goals cx = cx.ccx.goal_map

let exact_by_default cx = cx.metadata.exact_by_default

let exact_empty_objects cx = cx.metadata.exact_empty_objects

let enforce_local_inference_annotations cx = cx.metadata.enforce_local_inference_annotations

let local_inference_annotation_dirs cx = cx.metadata.local_inference_annotation_dirs

let enforce_this_annotations cx = cx.metadata.enforce_this_annotations

let experimental_infer_indexers cx = cx.metadata.experimental_infer_indexers

let statement_reorder_checking cx = cx.metadata.statement_reorder_checking

let cycle_errors cx = cx.metadata.cycle_errors

let run_post_inference_implicit_instantiation cx =
  cx.metadata.run_post_inference_implicit_instantiation

let file cx = cx.file

let aloc_tables cx = cx.ccx.aloc_tables

let find_props cx id =
  try Type.Properties.Map.find id cx.ccx.sig_cx.property_maps with
  | Not_found -> raise (Props_not_found id)

let find_call cx id =
  try IMap.find id cx.ccx.sig_cx.call_props with
  | Not_found -> raise (Call_not_found id)

let find_exports cx id =
  try Type.Exports.Map.find id cx.ccx.sig_cx.export_maps with
  | Not_found -> raise (Exports_not_found id)

let find_require cx loc =
  try ALocMap.find loc cx.require_map with
  | Not_found -> raise (Require_not_found (ALoc.debug_to_string ~include_source:true loc))

let find_tvar cx id =
  try IMap.find id cx.ccx.sig_cx.graph with
  | Not_found -> raise (Union_find.Tvar_not_found id)

let graph cx = cx.ccx.sig_cx.graph

let trust_graph cx = trust_graph_sig cx.ccx.sig_cx

let is_checked cx = cx.metadata.checked

let is_verbose cx =
  match cx.metadata.verbose with
  | None -> false
  | Some { Verbose.focused_files = None; _ } -> true
  | Some { Verbose.focused_files = Some files; _ } ->
    let file = file cx in
    Base.List.mem files (File_key.to_string file) ~equal:String.equal

let is_strict cx = Base.Option.is_some cx.declare_module_ref || cx.metadata.strict

let is_strict_local cx = cx.metadata.strict_local

let include_suppressions cx = cx.metadata.include_suppressions

let severity_cover cx = cx.ccx.severity_cover

let max_trace_depth cx = cx.metadata.max_trace_depth

let require_map cx = cx.require_map

let property_maps cx = cx.ccx.sig_cx.property_maps

let call_props cx = cx.ccx.sig_cx.call_props

let export_maps cx = cx.ccx.sig_cx.export_maps

let react_runtime cx = cx.metadata.react_runtime

let in_react_server_component_file cx =
  let file = file cx in
  let exts = cx.metadata.react_server_component_exts in
  SSet.exists (File_key.check_suffix file) exts

let recursion_limit cx = cx.metadata.recursion_limit

let root cx = cx.metadata.root

let facebook_fbs cx = cx.metadata.facebook_fbs

let facebook_fbt cx = cx.metadata.facebook_fbt

let facebook_module_interop cx = cx.metadata.facebook_module_interop

let haste_module_ref_prefix cx = cx.metadata.haste_module_ref_prefix

let should_ignore_non_literal_requires cx = cx.metadata.ignore_non_literal_requires

let should_munge_underscores cx = cx.metadata.munge_underscores

let should_strip_root cx = cx.metadata.strip_root

let suppress_types cx = cx.metadata.suppress_types

let type_asserts_map cx = cx.ccx.type_asserts_map

let literal_subtypes cx = cx.ccx.literal_subtypes

let new_env_literal_subtypes cx = cx.ccx.new_env_literal_subtypes

let constrained_writes cx = cx.ccx.constrained_writes

let env_cache_find_opt cx ~for_value id =
  let cache =
    if for_value then
      cx.ccx.env_value_cache
    else
      cx.ccx.env_type_cache
  in
  IMap.find_opt id cache

let type_graph cx = cx.ccx.type_graph

let matching_props cx = cx.ccx.matching_props

let new_env_matching_props cx = cx.ccx.new_env_matching_props

let trust_mode cx = cx.metadata.trust_mode

let type_asserts cx = cx.metadata.type_asserts

let verbose cx = cx.metadata.verbose

let max_workers cx = cx.metadata.max_workers

let missing_module_generators cx = cx.metadata.missing_module_generators

let jsx cx = cx.metadata.jsx

let exists_checks cx = cx.ccx.exists_checks

let exists_excuses cx = cx.ccx.exists_excuses

let voidable_checks cx = cx.ccx.voidable_checks

let implicit_instantiation_checks cx = cx.ccx.implicit_instantiation_checks

let inferred_indexers cx = cx.ccx.inferred_indexers

let environment cx = cx.environment

let any_propagation cx = cx.metadata.any_propagation

let node_cache cx = cx.node_cache

let automatic_require_default cx = cx.metadata.automatic_require_default

let trust_tracking cx =
  match cx.metadata.trust_mode with
  | Options.CheckTrust
  | Options.SilentTrust ->
    true
  | Options.NoTrust -> false

let trust_errors cx =
  match cx.metadata.trust_mode with
  | Options.CheckTrust -> true
  | Options.SilentTrust
  | Options.NoTrust ->
    false

let env_option_enabled cx option =
  let open Options in
  match (cx.metadata.env_mode, cx.metadata.env_mode_constrain_write_dirs, option) with
  | (SSAEnv _, _, _) -> false
  | (ClassicEnv opts, _, _) when List.mem option opts -> true
  | (_, (_ :: _ as dirs), ConstrainWrites) ->
    let filename = File_key.to_string @@ file cx in
    let normalized_filename = Sys_utils.normalize_filename_dir_sep filename in
    List.exists (fun str -> Base.String.is_prefix ~prefix:str normalized_filename) dirs
  | _ -> false

let resolved_env cx =
  let open Options in
  match cx.metadata.env_mode with
  | SSAEnv { resolved } -> resolved
  | ClassicEnv _ -> false

let pid_prefix cx =
  if max_workers cx > 0 then
    Printf.sprintf ""[%d] "" (Unix.getpid ())
  else
    """"

(* Create a shallow copy of this context, so that mutations to the sig_cx's
 * fields will not affect the copy. *)
let copy_of_context cx = { cx with ccx = { cx.ccx with sig_cx = cx.ccx.sig_cx } }

(* mutators *)

let add_error cx error = cx.ccx.errors <- Flow_error.ErrorSet.add error cx.ccx.errors

let add_error_suppression cx loc codes =
  cx.ccx.error_suppressions <- Error_suppressions.add loc codes cx.ccx.error_suppressions

let add_severity_cover cx filekey severity_cover =
  cx.ccx.severity_cover <- Utils_js.FilenameMap.add filekey severity_cover cx.ccx.severity_cover

let add_lint_suppressions cx suppressions =
  cx.ccx.error_suppressions <-
    Error_suppressions.add_lint_suppressions suppressions cx.ccx.error_suppressions

let add_require cx loc tvar = cx.require_map <- ALocMap.add loc tvar cx.require_map

let add_property_map cx id pmap =
  let property_maps = Type.Properties.Map.add id pmap cx.ccx.sig_cx.property_maps in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with property_maps }

let add_call_prop cx id t =
  let call_props = IMap.add id t cx.ccx.sig_cx.call_props in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with call_props }

let add_export_map cx id tmap =
  let export_maps = Type.Exports.Map.add id tmap cx.ccx.sig_cx.export_maps in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with export_maps }

let add_tvar cx id bounds =
  let graph = IMap.add id bounds cx.ccx.sig_cx.graph in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with graph }

let add_trust_var cx id bounds =
  let trust_graph = IMap.add id bounds cx.ccx.sig_cx.trust_graph in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with trust_graph }

let add_type_assert cx k v = cx.ccx.type_asserts_map <- ALocMap.add k v cx.ccx.type_asserts_map

let add_matching_props cx c = cx.ccx.matching_props <- c :: cx.ccx.matching_props

let add_new_env_matching_props cx c =
  cx.ccx.new_env_matching_props <- c :: cx.ccx.new_env_matching_props

let add_literal_subtypes cx c = cx.ccx.literal_subtypes <- c :: cx.ccx.literal_subtypes

let add_new_env_literal_subtypes cx c =
  cx.ccx.new_env_literal_subtypes <- c :: cx.ccx.new_env_literal_subtypes

let add_constrained_write cx c = cx.ccx.constrained_writes <- c :: cx.ccx.constrained_writes

let add_env_cache_entry cx ~for_value id t =
  if for_value then
    cx.ccx.env_value_cache <- IMap.add id t cx.ccx.env_value_cache
  else
    cx.ccx.env_type_cache <- IMap.add id t cx.ccx.env_type_cache

let add_voidable_check cx voidable_check =
  cx.ccx.voidable_checks <- voidable_check :: cx.ccx.voidable_checks

let add_implicit_instantiation_call cx lhs poly_t use_op reason funcalltype =
  if cx.metadata.run_post_inference_implicit_instantiation then
    let check =
      Implicit_instantiation_check.{ lhs; poly_t; operation = (use_op, reason, Call funcalltype) }
    in
    cx.ccx.implicit_instantiation_checks <- check :: cx.ccx.implicit_instantiation_checks

let add_implicit_instantiation_ctor cx lhs poly_t use_op reason_op args =
  if cx.metadata.run_post_inference_implicit_instantiation then
    let check =
      Implicit_instantiation_check.
        { lhs; poly_t; operation = (use_op, reason_op, Constructor args) }
      
    in

    cx.ccx.implicit_instantiation_checks <- check :: cx.ccx.implicit_instantiation_checks

let add_inferred_indexer cx loc dict =
  cx.ccx.inferred_indexers <-
    ALocMap.update
      loc
      (function
        | Some dicts -> Some (dict :: dicts)
        | None -> Some [dict])
      cx.ccx.inferred_indexers

let set_all_unresolved cx all_unresolved = cx.ccx.all_unresolved <- all_unresolved

let set_evaluated cx evaluated = cx.ccx.sig_cx <- { cx.ccx.sig_cx with evaluated }

let set_goals cx goals = cx.ccx.goal_map <- goals

let set_graph cx graph = cx.ccx.sig_cx <- { cx.ccx.sig_cx with graph }

let set_trust_graph cx trust_graph = cx.ccx.sig_cx <- { cx.ccx.sig_cx with trust_graph }

let set_property_maps cx property_maps = cx.ccx.sig_cx <- { cx.ccx.sig_cx with property_maps }

let set_call_props cx call_props = cx.ccx.sig_cx <- { cx.ccx.sig_cx with call_props }

let set_export_maps cx export_maps = cx.ccx.sig_cx <- { cx.ccx.sig_cx with export_maps }

let set_type_graph cx type_graph = cx.ccx.type_graph <- type_graph

let set_exists_checks cx exists_checks = cx.ccx.exists_checks <- exists_checks

let add_exists_check cx loc t =
  let tset =
    match ALocMap.find_opt loc cx.ccx.exists_checks with
    | Some tset -> Type.TypeSet.add t tset
    | None -> Type.TypeSet.singleton t
  in
  set_exists_checks cx (ALocMap.add loc tset cx.ccx.exists_checks)

let set_exists_excuses cx exists_excuses = cx.ccx.exists_excuses <- exists_excuses

let set_environment cx env = cx.environment <- env

(* Given a sig context, it makes sense to clear the parts that are shared with
   the master sig context. Why? The master sig context, which contains global
   declarations, is an implicit dependency for every file, and so will be
   ""merged in"" anyway, thus making those shared parts redundant to carry around
   in other sig contexts. This saves a lot of shared memory as well as
   deserialization time. *)
let clear_master_shared cx master_cx =
  let { master_sig_cx = master_cx; _ } = master_cx in
  let module PMap = Type.Properties.Map in
  let module EMap = Type.Exports.Map in
  let sig_cx = cx.ccx.sig_cx in
  cx.ccx.sig_cx <-
    {
      graph = IMap.filter (fun id _ -> not (IMap.mem id master_cx.graph)) sig_cx.graph;
      trust_graph =
        IMap.filter (fun id _ -> not (IMap.mem id master_cx.trust_graph)) sig_cx.trust_graph;
      property_maps =
        PMap.filter (fun id _ -> not (PMap.mem id master_cx.property_maps)) sig_cx.property_maps;
      call_props =
        IMap.filter (fun id _ -> not (IMap.mem id master_cx.call_props)) sig_cx.call_props;
      evaluated =
        Type.Eval.Map.filter
          (fun id _ -> not (Type.Eval.Map.mem id master_cx.evaluated))
          sig_cx.evaluated;
      export_maps =
        EMap.filter (fun id _ -> not (EMap.mem id master_cx.export_maps)) sig_cx.export_maps;
    }

let test_prop_hit cx id =
  cx.ccx.test_prop_hits_and_misses <- IMap.add id Hit cx.ccx.test_prop_hits_and_misses

let test_prop_miss cx id name reasons use suggestion =
  if not (IMap.mem id cx.ccx.test_prop_hits_and_misses) then
    cx.ccx.test_prop_hits_and_misses <-
      IMap.add id (Miss (name, reasons, use, suggestion)) cx.ccx.test_prop_hits_and_misses

let test_prop_get_never_hit cx =
  List.fold_left
    (fun acc (_, hit_or_miss) ->
      match hit_or_miss with
      | Hit -> acc
      | Miss (name, reasons, use_op, suggestion) -> (name, reasons, use_op, suggestion) :: acc)
    []
    (IMap.bindings cx.ccx.test_prop_hits_and_misses)

let computed_property_state_for_id cx id = IMap.find_opt id cx.ccx.computed_property_states

let computed_property_add_lower_bound cx id r =
  cx.ccx.computed_property_states <- IMap.add id (ResolvedOnce r) cx.ccx.computed_property_states

let computed_property_add_multiple_lower_bounds cx id =
  cx.ccx.computed_property_states <-
    IMap.add id ResolvedMultipleTimes cx.ccx.computed_property_states

let spread_widened_types_get_widest cx id = IMap.find_opt id cx.ccx.spread_widened_types

let spread_widened_types_add_widest cx id objtype =
  cx.ccx.spread_widened_types <- IMap.add id objtype cx.ccx.spread_widened_types

let mark_optional_chain cx loc lhs_reason ~useful =
  cx.ccx.optional_chains_useful <-
    ALocMap.add
      loc
      (lhs_reason, useful)
      ~combine:(fun (r, u) (_, u') -> (r, u || u'))
      cx.ccx.optional_chains_useful

let unnecessary_optional_chains cx =
  ALocMap.fold
    (fun loc (r, useful) acc ->
      if useful then
        acc
      else
        (loc, r) :: acc)
    cx.ccx.optional_chains_useful
    []

let mark_invariant cx loc reason ~useful =
  cx.ccx.invariants_useful <-
    ALocMap.add
      loc
      (reason, useful)
      ~combine:(fun (r, u) (_, u') -> (r, u || u'))
      cx.ccx.invariants_useful

let unnecessary_invariants cx =
  ALocMap.fold
    (fun loc (r, useful) acc ->
      if useful then
        acc
      else
        (loc, r) :: acc)
    cx.ccx.invariants_useful
    []

(* utils *)
let find_real_props cx id =
  find_props cx id |> NameUtils.Map.filter (fun x _ -> not (Reason.is_internal_name x))

let iter_props cx id f = find_props cx id |> NameUtils.Map.iter f

let iter_real_props cx id f = find_real_props cx id |> NameUtils.Map.iter f

let fold_real_props cx id f = find_real_props cx id |> NameUtils.Map.fold f

let has_prop cx id x = find_props cx id |> NameUtils.Map.mem x

let get_prop cx id x = find_props cx id |> NameUtils.Map.find_opt x

let set_prop cx id x p = find_props cx id |> NameUtils.Map.add x p |> add_property_map cx id

let has_export cx id name = find_exports cx id |> NameUtils.Map.mem name

let set_export cx id name t = find_exports cx id |> NameUtils.Map.add name t |> add_export_map cx id

(* constructors *)
let make_aloc_id cx aloc = ALoc.id_of_aloc cx.aloc_table aloc

let make_generic_id cx name loc = Generic.make_bound_id (make_aloc_id cx loc) name

let generate_property_map cx pmap =
  let id = Reason.mk_id () in
  let id = Type.Properties.id_of_int id in
  add_property_map cx id pmap;
  id

let make_source_property_map cx pmap aloc =
  (* To prevent cases where we might compare a concrete and an abstract
     aloc (like in a cycle) we abstractify all incoming alocs before adding
     them to the map. The only exception is for library files, which have only
     concrete definitions and by definition cannot appear in cycles. *)
  let id = make_aloc_id cx aloc |> Type.Properties.id_of_aloc_id in
  add_property_map cx id pmap;
  id

let make_call_prop cx t =
  let id = Reason.mk_id () in
  add_call_prop cx id t;
  id

let make_export_map cx tmap =
  let id = Type.Exports.mk_id () in
  add_export_map cx id tmap;
  id

let make_source_poly_id cx aloc = make_aloc_id cx aloc |> Type.Poly.id_of_aloc_id

(* Copy context from cx_other to cx *)
let merge_into ccx sig_cx_other =
  let sig_cx = ccx.sig_cx in
  ccx.sig_cx <-
    {
      property_maps = Type.Properties.Map.union sig_cx_other.property_maps sig_cx.property_maps;
      call_props = IMap.union sig_cx_other.call_props sig_cx.call_props;
      export_maps = Type.Exports.Map.union sig_cx_other.export_maps sig_cx.export_maps;
      evaluated = Type.Eval.Map.union sig_cx_other.evaluated sig_cx.evaluated;
      graph = IMap.union sig_cx_other.graph sig_cx.graph;
      trust_graph = IMap.union sig_cx_other.trust_graph sig_cx.trust_graph;
    }

let find_graph cx id =
  let (graph', constraints) = Type.Constraint.find_graph cx.ccx.sig_cx.graph id in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with graph = graph' };
  constraints

let find_constraints cx id =
  let (graph', root_id, constraints) = Type.Constraint.find_constraints cx.ccx.sig_cx.graph id in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with graph = graph' };
  (root_id, constraints)

let find_root cx id =
  let (graph', root_id, constraints) = Type.Constraint.find_root cx.ccx.sig_cx.graph id in
  cx.ccx.sig_cx <- { cx.ccx.sig_cx with graph = graph' };
  (root_id, constraints)

let find_resolved =
  let rec loop cx seen t_in =
    match t_in with
    | Type.OpenT (_, id) ->
      if ISet.mem id seen then
        Some t_in
      else begin
        match find_graph cx id with
        | Type.Constraint.Resolved (_, t)
        | Type.Constraint.FullyResolved (_, (lazy t)) ->
          loop cx (ISet.add id seen) t
        | Type.Constraint.Unresolved _ -> None
      end
    | Type.AnnotT (_, t, _) -> loop cx seen t
    | t -> Some t
  in
  (fun cx t_in -> loop cx ISet.empty t_in)

let rec find_trust_root cx (id : Trust_constraint.ident) =
  Trust_constraint.(
    match IMap.find_opt id (trust_graph cx) with
    | Some (TrustGoto next_id) ->
      let (root_id, root) = find_trust_root cx next_id in
      if root_id != next_id then Trust_constraint.new_goto root_id |> add_trust_var cx id;
      (root_id, root)
    | Some (TrustRoot root) -> (id, root)
    | None ->
      let msg =
        Utils_js.spf
          ""find_trust_root: trust var %d not found in file %s""
          id
          (File_key.to_string @@ file cx)
      in
      Utils_js.assert_false msg
  )

let find_trust_constraints cx id =
  let (root_id, root) = find_trust_root cx id in
  (root_id, Trust_constraint.get_constraints root)

let find_trust_graph cx id =
  let (_, constraints) = find_trust_constraints cx id in
  constraints

let constraint_cache cx = cx.ccx.constraint_cache

let subst_cache cx = cx.ccx.subst_cache

let instantiation_cache cx = cx.ccx.instantiation_cache

let repos_cache cx = cx.ccx.repos_cache

let eval_id_cache cx = cx.ccx.eval_id_cache

let eval_repos_cache cx = cx.ccx.eval_repos_cache

let fix_cache cx = cx.ccx.fix_cache

let spread_cache cx = cx.ccx.spread_cache

let speculation_state cx = cx.ccx.speculation_state

let speculation_id cx =
  let open Speculation_state in
  match !(speculation_state cx) with
  | [] -> None
  | { speculation_id; case = { case_id; _ }; _ } :: _ -> Some (speculation_id, case_id)

let add_avar cx id node = cx.ccx.annot_graph <- IMap.add id node cx.ccx.annot_graph

let find_avar_exn cx id =
  let (annot_graph', root_id, constraints) = Type.AConstraint.find_root cx.ccx.annot_graph id in
  cx.ccx.annot_graph <- annot_graph';
  (root_id, constraints)

let find_avar cx id =
  try find_avar_exn cx id with
  | Union_find.Tvar_not_found root_id ->
    (* When an id is missing in the annot graph, then it _must_ be resolved and
     * part of the type graph. *)
    add_avar cx root_id Type.AConstraint.fully_resolved_node;
    (root_id, Type.AConstraint.fully_resolved_root)

let iter_annot_dependent_set cx f set =
  let (_ : ISet.t) =
    ISet.fold
      (fun i seen ->
        let (root_id, root) = find_avar cx i in
        if ISet.mem root_id seen then
          seen
        else
          let constraints = root.Type.AConstraint.constraints in
          let op = Type.AConstraint.to_annot_op_exn constraints in
          let () = f root_id op in
          ISet.add root_id seen)
      set
      ISet.empty
  in
  ()
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

external realpath : string -> string option = ""hh_realpath""

(** Option type intead of exception throwing. *)
let get_env name =
  try Some (Sys.getenv name) with
  | Not_found -> None

let getenv_home () =
  let home_var =
    if Sys.win32 then
      ""APPDATA""
    else
      ""HOME""
  in
  get_env home_var

let getenv_term () =
  let term_var = ""TERM"" in
  (* This variable does not exist on windows. *)
  get_env term_var

let path_sep =
  if Sys.win32 then
    "";""
  else
    "":""

let null_path =
  if Sys.win32 then
    ""nul""
  else
    ""/dev/null""

let temp_dir_name =
  if Sys.win32 then
    Filename.get_temp_dir_name ()
  else
    ""/tmp""

let getenv_path () =
  let path_var = ""PATH"" in
  (* Same variable on windows *)
  get_env path_var

let cat = Disk.cat

let cat_or_failed file =
  try Some (Disk.cat file) with
  | Sys_error _
  | Failure _ ->
    None

let nl_regexp = Str.regexp ""[\r\n]""

let split_lines = Str.split nl_regexp

(** Returns true if substring occurs somewhere inside str. *)
let string_contains str substring =
  (* regexp_string matches only this string and nothing else. *)
  let re = Str.regexp_string substring in
  try Str.search_forward re str 0 >= 0 with
  | Not_found -> false

let exec_read cmd =
  let ic = Unix.open_process_in cmd in
  let result = input_line ic in
  assert (Unix.close_process_in ic = Unix.WEXITED 0);
  result

let exec_read_lines ?(reverse = false) cmd =
  let ic = Unix.open_process_in cmd in
  let result = ref [] in
  (try
     while true do
       result := input_line ic :: !result
     done
   with
  | End_of_file -> ());
  assert (Unix.close_process_in ic = Unix.WEXITED 0);
  if not reverse then
    Base.List.rev !result
  else
    !result

(**
 * Collects paths that satisfy a predicate, recursively traversing directories.
 *)
let rec collect_paths path_predicate path =
  if Sys.is_directory path then
    path
    |> Sys.readdir
    |> Array.to_list
    |> Base.List.map ~f:(Filename.concat path)
    |> Base.List.concat_map ~f:(collect_paths path_predicate)
  else if path_predicate path then
    [path]
  else
    []

(**
 * Sometimes the user wants to pass a list of paths on the command-line.
 * However, we have enough files in the codebase that sometimes that list
 * exceeds the maximum number of arguments that can be passed on the
 * command-line. To work around this, we can use the convention that some Unix
 * tools use: a `@` before a path name represents a file that should be read
 * to get the necessary information (in this case, containing a list of files,
 * one per line).
 *)
let parse_path_list (paths : string list) : string list =
  Base.List.concat_map paths ~f:(fun path ->
      if String_utils.string_starts_with path ""@"" then
        let path = String_utils.lstrip path ""@"" in
        cat path |> split_lines
      else
        [path]
  )
  |> Base.List.map ~f:(fun path ->
         match realpath path with
         | Some path -> path
         | None -> failwith (Printf.sprintf ""Invalid path: %s"" path)
     )

let rm_dir_tree ?(skip_mocking = false) =
  if skip_mocking then
    RealDisk.rm_dir_tree
  else
    Disk.rm_dir_tree

let restart () =
  let cmd = Sys.argv.(0) in
  let argv = Sys.argv in
  Unix.execv cmd argv

let with_umask umask f =
  if Sys.win32 then
    f ()
  else
    let old_umask = Unix.umask umask in
    Exception.protect ~f ~finally:(fun () ->
        let _ = Unix.umask old_umask in
        ()
    )

let read_stdin_to_string () =
  let buf = Buffer.create 4096 in
  try
    while true do
      Buffer.add_string buf (input_line stdin);
      Buffer.add_char buf '\n'
    done;
    assert false
  with
  | End_of_file -> Buffer.contents buf

let read_all ?(buf_size = 4096) ic =
  let buf = Buffer.create buf_size in
  (try
     while true do
       let data = Bytes.create buf_size in
       let bytes_read = input ic data 0 buf_size in
       if bytes_read = 0 then raise Exit;
       Buffer.add_subbytes buf data 0 bytes_read
     done
   with
  | Exit -> ());
  Buffer.contents buf

(**
 * Like Python's os.path.expanduser, though probably doesn't cover some cases.
 * Roughly follow's bash's tilde expansion:
 * http://www.gnu.org/software/bash/manual/html_node/Tilde-Expansion.html
 *
 * ~/foo -> /home/bob/foo if $HOME = ""/home/bob""
 * ~joe/foo -> /home/joe/foo if joe's home is /home/joe
 *)
let expanduser path =
  Str.substitute_first
    (Str.regexp ""^~\\([^/]*\\)"")
    begin
      fun s ->
      match Str.matched_group 1 s with
      | """" ->
        begin
          match getenv_home () with
          | None -> (Unix.getpwuid (Unix.getuid ())).Unix.pw_dir
          | Some home -> home
        end
      | unixname ->
        (try (Unix.getpwnam unixname).Unix.pw_dir with
        | Not_found -> Str.matched_string s)
    end
    path

(* Turns out it's surprisingly complex to figure out the path to the current
   executable, which we need in order to extract its embedded libraries. If
   argv[0] is a path, then we can use that; sometimes it's just the exe name,
   so we have to search $PATH for it the same way shells do. for example:
   https://www.gnu.org/software/bash/manual/html_node/Command-Search-and-Execution.html

   There are other options which might be more reliable when they exist, like
   using the `_` env var set by bash, or /proc/self/exe on Linux, but they are
   not portable. *)
let executable_path : unit -> string =
  let executable_path_ = ref None in
  let dir_sep = Filename.dir_sep.[0] in
  let search_path path =
    let paths =
      match getenv_path () with
      | None -> failwith ""Unable to determine executable path""
      | Some paths -> Str.split (Str.regexp_string path_sep) paths
    in
    let path =
      Base.List.fold
        paths
        ~f:
          begin
            fun acc p ->
            match acc with
            | Some _ -> acc
            | None -> realpath (expanduser (Filename.concat p path))
          end
        ~init:None
    in
    match path with
    | Some path -> path
    | None -> failwith ""Unable to determine executable path""
  in
  fun () ->
    match !executable_path_ with
    | Some path -> path
    | None ->
      let path = Sys.executable_name in
      let path =
        if String.contains path dir_sep then
          match realpath path with
          | Some path -> path
          | None -> failwith ""Unable to determine executable path""
        else
          search_path path
      in
      executable_path_ := Some path;
      path

let lines_of_in_channel ic =
  let rec loop accum =
    match
      try Some (input_line ic) with
      | _ -> None
    with
    | None -> Base.List.rev accum
    | Some line -> loop (line :: accum)
  in
  loop []

let lines_of_file filename =
  let ic = open_in filename in
  try
    let result = lines_of_in_channel ic in
    let _ = close_in ic in
    result
  with
  | _ ->
    close_in ic;
    []

let read_file file =
  let ic = open_in_bin file in
  let size = in_channel_length ic in
  let buf = Bytes.create size in
  really_input ic buf 0 size;
  close_in ic;
  buf

let write_file ~file s = Disk.write_file ~file ~contents:s

let append_file ~file s =
  let chan = open_out_gen [Open_wronly; Open_append; Open_creat] 0o666 file in
  output_string chan s;
  close_out chan

let write_strings_to_file ~file (ss : string list) =
  let chan = open_out_gen [Open_wronly; Open_creat] 0o666 file in
  Base.List.iter ~f:(output_string chan) ss;
  close_out chan

(* could be in control section too *)

let filemtime file = (Unix.stat file).Unix.st_mtime

external lutimes : string -> unit = ""hh_lutimes""

let try_touch ~follow_symlinks file =
  try
    if follow_symlinks then
      Unix.utimes file 0.0 0.0
    else
      lutimes file
  with
  | _ -> ()

let mkdir_p ?(skip_mocking = false) =
  if skip_mocking then
    RealDisk.mkdir_p
  else
    Disk.mkdir_p

(* Emulate ""mkdir -p"", i.e., no error if already exists. *)
let mkdir_no_fail dir =
  with_umask 0 (fun () ->
      (* Don't set sticky bit since the socket opening code wants to remove any
       * old sockets it finds, which may be owned by a different user. *)
      try Unix.mkdir dir 0o777 with
      | Unix.Unix_error (Unix.EEXIST, _, _) -> ()
  )

let unlink_no_fail fn =
  try Unix.unlink fn with
  | Unix.Unix_error (Unix.ENOENT, _, _) -> ()

let readlink_no_fail fn =
  if Sys.win32 && Sys.file_exists fn then
    cat fn
  else
    try Unix.readlink fn with
    | _ -> fn

let splitext filename =
  let root = Filename.chop_extension filename in
  let root_length = String.length root in
  (* -1 because the extension includes the period, e.g. "".foo"" *)
  let ext_length = String.length filename - root_length - 1 in
  let ext = String.sub filename (root_length + 1) ext_length in
  (root, ext)

let is_test_mode () =
  try
    ignore @@ Sys.getenv ""HH_TEST_MODE"";
    true
  with
  | _ -> false

let sleep ~seconds = ignore @@ Unix.select [] [] [] seconds

let symlink =
  (* Dummy implementation of `symlink` on Windows: we create a text
     file containing the targeted-file's path. Symlink are available
     on Windows since Vista, but until Seven (included), one should
     have administratrive rights in order to create symlink. *)
  let win32_symlink source dest = write_file ~file:dest source in
  if Sys.win32 then
    win32_symlink
  else
    (* 4.03 adds an optional argument to Unix.symlink that we want to ignore
     *)
    fun source dest ->
  Unix.symlink source dest

(* Creates a symlink at <dir>/<linkname.ext> to
 * <dir>/<pluralized ext>/<linkname>-<timestamp>.<ext> *)
let make_link_of_timestamped linkname =
  Unix.(
    let dir = Filename.dirname linkname in
    mkdir_no_fail dir;
    let base = Filename.basename linkname in
    let (base, ext) = splitext base in
    let dir = Filename.concat dir (Printf.sprintf ""%ss"" ext) in
    mkdir_no_fail dir;
    let tm = localtime (time ()) in
    let year = tm.tm_year + 1900 in
    let time_str =
      Printf.sprintf
        ""%d-%02d-%02d-%02d-%02d-%02d""
        year
        (tm.tm_mon + 1)
        tm.tm_mday
        tm.tm_hour
        tm.tm_min
        tm.tm_sec
    in
    let filename = Filename.concat dir (Printf.sprintf ""%s-%s.%s"" base time_str ext) in
    unlink_no_fail linkname;
    symlink filename linkname;
    filename
  )

let setsid =
  (* Not implemented on Windows. Let's just return the pid *)
  if Sys.win32 then
    Unix.getpid
  else
    Unix.setsid

let set_signal =
  if not Sys.win32 then
    Sys.set_signal
  else
    fun _ _ ->
  ()

let signal =
  if not Sys.win32 then
    fun a b ->
  ignore (Sys.signal a b)
  else
    fun _ _ ->
  ()

external is_rosetta : unit -> bool = ""hh_is_rosetta""

let is_rosetta = is_rosetta ()

external get_total_ram : unit -> int = ""hh_sysinfo_totalram""

external uptime : unit -> int = ""hh_sysinfo_uptime""

external nproc : unit -> int = ""nproc""

let total_ram = get_total_ram ()

let nbr_procs = nproc ()

external set_priorities : cpu_priority:int -> io_priority:int -> unit = ""hh_set_priorities""

external pid_of_handle : int -> int = ""pid_of_handle""

external handle_of_pid_for_termination : int -> int = ""handle_of_pid_for_termination""

let terminate_process pid = Unix.kill pid Sys.sigkill

let lstat path =
  (* WTF, on Windows `lstat` fails if a directory path ends with an
     '/' (or a '\', whatever) *)
  Unix.lstat
  @@
  if Sys.win32 && String_utils.string_ends_with path Filename.dir_sep then
    String.sub path 0 (String.length path - 1)
  else
    path

(** Converts platform-specific directory separators to / *)
let normalize_filename_dir_sep =
  let dir_sep_char = Filename.dir_sep.[0] in
  let no_op path = path in
  let normalize path =
    if String.contains path dir_sep_char then
      String.map
        (fun c ->
          if Char.equal dir_sep_char c then
            '/'
          else
            c)
        path
    else
      path
  in
  if Char.equal dir_sep_char '/' then
    no_op
  else
    normalize

let name_of_signal = function
  | s when s = Sys.sigabrt -> ""SIGABRT (Abnormal termination)""
  | s when s = Sys.sigalrm -> ""SIGALRM (Timeout)""
  | s when s = Sys.sigfpe -> ""SIGFPE (Arithmetic exception)""
  | s when s = Sys.sighup -> ""SIGHUP (Hangup on controlling terminal)""
  | s when s = Sys.sigill -> ""SIGILL (Invalid hardware instruction)""
  | s when s = Sys.sigint -> ""SIGINT (Interactive interrupt (ctrl-C))""
  | s when s = Sys.sigkill -> ""SIGKILL (Termination)""
  | s when s = Sys.sigpipe -> ""SIGPIPE (Broken pipe)""
  | s when s = Sys.sigquit -> ""SIGQUIT (Interactive termination)""
  | s when s = Sys.sigsegv -> ""SIGSEGV (Invalid memory reference)""
  | s when s = Sys.sigterm -> ""SIGTERM (Termination)""
  | s when s = Sys.sigusr1 -> ""SIGUSR1 (Application-defined signal 1)""
  | s when s = Sys.sigusr2 -> ""SIGUSR2 (Application-defined signal 2)""
  | s when s = Sys.sigchld -> ""SIGCHLD (Child process terminated)""
  | s when s = Sys.sigcont -> ""SIGCONT (Continue)""
  | s when s = Sys.sigstop -> ""SIGSTOP (Stop)""
  | s when s = Sys.sigtstp -> ""SIGTSTP (Interactive stop)""
  | s when s = Sys.sigttin -> ""SIGTTIN (Terminal read from background process)""
  | s when s = Sys.sigttou -> ""SIGTTOU (Terminal write from background process)""
  | s when s = Sys.sigvtalrm -> ""SIGVTALRM (Timeout in virtual time)""
  | s when s = Sys.sigprof -> ""SIGPROF (Profiling interrupt)""
  | s when s = Sys.sigbus -> ""SIGBUS (Bus error)""
  | s when s = Sys.sigpoll -> ""SIGPOLL (Pollable event)""
  | s when s = Sys.sigsys -> ""SIGSYS (Bad argument to routine)""
  | s when s = Sys.sigtrap -> ""SIGTRAP (Trace/breakpoint trap)""
  | s when s = Sys.sigurg -> ""SIGURG (Urgent condition on socket)""
  | s when s = Sys.sigxcpu -> ""SIGXCPU (Timeout in cpu time)""
  | s when s = Sys.sigxfsz -> ""SIGXFSZ (File size limit exceeded)""
  | other -> string_of_int other

(* The units for each of these fields is seconds, similar to Unix.times().
 * cpu_info and processor_info are constructed by c code (see processor_info.c) so be very
 * careful modifying these types! *)
type cpu_info = {
  cpu_user: float;
  cpu_nice_user: float;
  cpu_system: float;
  cpu_idle: float;
}

type processor_info = {
  proc_totals: cpu_info;
  proc_per_cpu: cpu_info array;
}

external processor_info : unit -> processor_info = ""hh_processor_info""

(* We implement timers using sigalarm which means selects can be interrupted. This is a wrapper
 * around EINTR which continues the select if it gets interrupted by a signal *)
let rec select_non_intr read write exn timeout =
  let start_time = Unix.gettimeofday () in
  try Unix.select read write exn timeout with
  | Unix.Unix_error (Unix.EINTR, _, _) ->
    (* Negative timeouts mean no timeout *)
    let timeout =
      if timeout < 0.0 then
        timeout
      else
        max 0.0 (timeout -. (Unix.gettimeofday () -. start_time))
    in
    select_non_intr read write exn timeout

(* Flow uses lwt, which installs a sigchld handler. So the old pattern of fork & waitpid will hit
 * an EINTR when the forked process dies and the parent gets a sigchld signal. Note: this is only a
 * problem if you're not using the WNOHANG flag, since EINTR isn't thrown for WNOHANG *)
let rec waitpid_non_intr flags pid =
  try Unix.waitpid flags pid with
  | Unix.Unix_error (Unix.EINTR, _, _) -> waitpid_non_intr flags pid

(* Exposing this for a unit test *)
let find_oom_in_dmesg_output pid name lines =
  (* oomd: ""Memory cgroup out of memory: Killed process 4083583 (flow)"" (https://facebookmicrosites.github.io/oomd/)
     oomkiller: ""Out of memory: Kill process 4083583 (flow)"" *)
  let re =
    Str.regexp (Printf.sprintf ""[Oo]ut of memory: Kill\\(ed\\)? process \\([0-9]+\\) (%s)"" name)
  in
  let pid = string_of_int pid in
  Base.List.exists lines ~f:(fun line ->
      try
        ignore @@ Str.search_forward re line 0;
        let pid_s = Str.matched_group 2 line in
        pid_s = pid
      with
      | Not_found -> false
  )

let check_dmesg_for_oom pid name =
  let dmesg = exec_read_lines ~reverse:true ""dmesg"" in
  find_oom_in_dmesg_output pid name dmesg

(* Be careful modifying the rusage type! Like other types that interact with C, the order matters!
 * If you change things here you must update hh_getrusage too! *)
type rusage = {
  ru_maxrss: int;
  (* maximum resident set size *)
  ru_ixrss: int;
  (* integral shared memory size *)
  ru_idrss: int;
  (* integral unshared data size *)
  ru_isrss: int;
  (* integral unshared stack size *)
  ru_minflt: int;
  (* page reclaims (soft page faults) *)
  ru_majflt: int;
  (* page faults (hard page faults) *)
  ru_nswap: int;
  (* swaps *)
  ru_inblock: int;
  (* block input operations *)
  ru_oublock: int;
  (* block output operations *)
  ru_msgsnd: int;
  (* IPC messages sent *)
  ru_msgrcv: int;
  (* IPC messages received *)
  ru_nsignals: int;
  (* signals received *)
  ru_nvcsw: int;
  (* voluntary context switches *)
  ru_nivcsw: int; (* involuntary context switches *)
}

external getrusage : unit -> rusage = ""hh_getrusage""

external start_gc_profiling : unit -> unit = ""hh_start_gc_profiling"" [@@noalloc]

external get_gc_time : unit -> float * float = ""hh_get_gc_time""
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*             Xavier Leroy, projet Cristal, INRIA Rocquencourt           *)
(*                                                                        *)
(*   Copyright 1996 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(** Auxiliary AST types used by parsetree and typedtree.

  {b Warning:} this module is unstable and part of
  {{!Compiler_libs}compiler-libs}.

*)

type constant =
    Const_int of int
  | Const_char of char
  | Const_string of string * Location.t * string option
  | Const_float of string
  | Const_int32 of int32
  | Const_int64 of int64
  | Const_nativeint of nativeint

type rec_flag = Nonrecursive | Recursive

type direction_flag = Upto | Downto

(* Order matters, used in polymorphic comparison *)
type private_flag = Private | Public

type mutable_flag = Immutable | Mutable

type virtual_flag = Virtual | Concrete

type override_flag = Override | Fresh

type closed_flag = Closed | Open

type label = string

type arg_label =
    Nolabel
  | Labelled of string (*  label:T -> ... *)
  | Optional of string (* ?label:T -> ... *)

type 'a loc = 'a Location.loc = {
  txt : 'a;
  loc : Location.t;
}


type variance =
  | Covariant
  | Contravariant
  | NoVariance

type injectivity =
  | Injective
  | NoInjectivity
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

module Ast = Flow_ast
module LMap = Loc_collections.LocMap
module LSet = Loc_collections.LocSet
open Insert_type_utils
open Reason
open Loc_collections
module Codemod_empty_annotator = Codemod_annotator.Make (Insert_type_utils.UnitStats)
module Acc = Insert_type_utils.Acc (Insert_type_utils.UnitStats)

let max_intermediate_type_size = 1000

let mapper ~preserve_literals ~max_type_size ~default_any (cctx : Codemod_context.Typed.t) =
  let lint_severities = Codemod_context.Typed.lint_severities cctx in
  let flowfixme_ast = Codemod_context.Typed.flowfixme_ast ~lint_severities cctx in
  object (this)
    inherit
      Codemod_empty_annotator.mapper
        cctx
        ~default_any
        ~generalize_maybe:false
        ~lint_severities
        ~max_type_size
        ~preserve_literals
        ~merge_arrays:false
        () as super

    method private post_run () = ()

    method private unsealed_annot loc ty =
      let { Codemod_context.Typed.full_cx = cx; file; file_sig; typed_ast; _ } = cctx in
      let aloc = ALoc.of_loc loc in
      let indexers = Context.inferred_indexers cx in
      let validate = function
        | Ok (Ty.Type ty) ->
          Codemod_annotator.validate_ty cctx ~max_type_size:max_intermediate_type_size ty
        | _ -> Error [Error.Missing_annotation_or_normalizer_error]
      in
      let obj_kind =
        match ALocMap.find_opt aloc indexers with
        | Some (_ :: _ as indexers) ->
          let keys =
            List.map (fun { Type.key; _ } -> key) indexers
            |> TypeUtil.union_of_ts (mk_reason RUnion aloc)
          in
          let values =
            List.map (fun { Type.value; _ } -> value) indexers
            |> TypeUtil.union_of_ts (mk_reason RUnion aloc)
          in
          let genv = Ty_normalizer_env.mk_genv ~full_cx:cx ~file ~file_sig ~typed_ast in
          let options = Ty_normalizer_env.default_options in
          (match
             ( Ty_normalizer.from_type ~options ~genv keys |> validate,
               Ty_normalizer.from_type ~options ~genv values |> validate
             )
           with
          | (Ok dict_key, Ok dict_value) ->
            Ty.IndexedObj { Ty.dict_polarity = Ty.Neutral; dict_name = None; dict_key; dict_value }
          | (Error errs, Ok _)
          | (Ok _, Error errs) ->
            this#report_errors loc errs;
            ty.Ty.obj_kind
          | (Error errs_key, Error errs_val) ->
            this#report_errors loc (errs_key @ errs_val);
            ty.Ty.obj_kind)
        | None
        | Some [] ->
          ty.Ty.obj_kind
      in
      { ty with Ty.obj_kind }

    method private get_annot ploc ty annot =
      let f loc _annot ty' = this#annotate_node loc ty' (fun a -> Ast.Type.Available a) in
      let error _ = Ast.Type.Available (Loc.none, flowfixme_ast) in
      this#opt_annotate ~f ~error ~expr:None ploc ty annot

    method private report_errors loc errors =
      Base.List.iter errors ~f:(fun e -> this#update_acc (fun acc -> Acc.error acc loc e));
      codemod_error_locs <- LSet.add loc codemod_error_locs

    method! call cloc expr =
      let open Ast.Expression in
      let open Call in
      let { callee; targs; arguments; comments } = expr in
      let open Member in
      match (callee, arguments, targs) with
      | ( (_, Member { property = PropertyIdentifier (_, { Ast.Identifier.name = ""reduce""; _ }); _ }),
          (_, { ArgList.arguments = [_; Expression (loc, Object { Object.properties = []; _ })]; _ }),
          None
        ) ->
        let ty_result =
          Codemod_annotator.get_validated_ty
            cctx
            ~preserve_literals
            ~max_type_size:max_intermediate_type_size
            loc
        in
        (match ty_result with
        | Ok (Ty.Obj ty) ->
          let ty_obj = this#unsealed_annot loc ty in
          (match ty_obj.Ty.obj_kind with
          | Ty.IndexedObj _ ->
            let ty_obj = { ty_obj with Ty.obj_props = [] } in
            (match Codemod_annotator.validate_ty cctx ~max_type_size (Ty.Obj ty_obj) with
            | Ok ty ->
              (match this#get_annot cloc (Ok ty) (Ast.Type.Missing cloc) with
              | Ast.Type.Available (_, t) ->
                let targlist = [CallTypeArg.Explicit t] in
                let targs = Some (cloc, { CallTypeArgs.arguments = targlist; comments = None }) in
                { callee; arguments; comments; targs }
              | _ -> super#call cloc expr)
            | Error errs ->
              this#report_errors loc errs;
              super#call cloc expr)
          | _ -> super#call cloc expr)
        | Ok _ -> super#call cloc expr
        | Error errs ->
          this#report_errors loc errs;
          super#call cloc expr)
      | _ -> super#call cloc expr

    method! expression expr =
      let open Ast.Expression in
      match expr with
      | (loc, Object { Object.properties = []; _ }) ->
        let ty_result =
          Codemod_annotator.get_validated_ty
            cctx
            ~preserve_literals
            ~max_type_size:max_intermediate_type_size
            loc
        in
        (match ty_result with
        | Ok (Ty.Obj ty) ->
          let ty_obj = this#unsealed_annot loc ty in
          (match ty_obj.Ty.obj_kind with
          | Ty.IndexedObj _ ->
            let ty_obj = { ty_obj with Ty.obj_props = [] } in
            (match Codemod_annotator.validate_ty cctx ~max_type_size (Ty.Obj ty_obj) with
            | Ok ty ->
              (match this#get_annot loc (Ok ty) (Ast.Type.Missing loc) with
              | Ast.Type.Available annot' ->
                ( loc,
                  Ast.Expression.TypeCast
                    { annot = annot'; expression = expr; Ast.Expression.TypeCast.comments = None }
                )
              | _ -> super#expression expr)
            | Error errs ->
              this#report_errors loc errs;
              super#expression expr)
          | _ -> super#expression expr)
        | Ok _ -> super#expression expr
        | Error errs ->
          this#report_errors loc errs;
          super#expression expr)
      | _ -> super#expression expr

    method! variable_declarator ~kind decl =
      let open Ast.Statement.VariableDeclaration.Declarator in
      let (loc, { id; init }) = decl in
      match init with
      | Some (oloc, Ast.Expression.Object Ast.Expression.Object.{ properties = []; comments = _ })
        ->
        let id =
          match id with
          | ( ploc,
              Ast.Pattern.Identifier
                Ast.Pattern.Identifier.{ annot = Ast.Type.Missing _ as annot; name; optional }
            ) ->
            let ty_result =
              Codemod_annotator.get_validated_ty
                cctx
                ~preserve_literals
                ~max_type_size:max_intermediate_type_size
                ploc
            in
            (match ty_result with
            | Ok (Ty.Obj ty) ->
              let ty_obj = this#unsealed_annot oloc ty in
              (match ty_obj.Ty.obj_kind with
              | Ty.IndexedObj _ ->
                let ty_obj = { ty_obj with Ty.obj_props = [] } in
                (match Codemod_annotator.validate_ty cctx ~max_type_size (Ty.Obj ty_obj) with
                | Ok ty ->
                  let annot' = this#get_annot ploc (Ok ty) annot in
                  ( ploc,
                    Ast.Pattern.Identifier Ast.Pattern.Identifier.{ annot = annot'; name; optional }
                  )
                | Error errs ->
                  this#report_errors loc errs;
                  id)
              | _ -> id)
            | Ok _ -> id
            | Error errs ->
              this#report_errors loc errs;
              id)
          | _ -> id
        in
        (loc, { id; init })
      | _ -> super#variable_declarator ~kind decl
  end
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*             Xavier Leroy, projet Cristal, INRIA Rocquencourt           *)
(*                                                                        *)
(*   Copyright 1996 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(** Abstract syntax tree produced by parsing

  {b Warning:} this module is unstable and part of
  {{!Compiler_libs}compiler-libs}.

*)

open Asttypes

type constant =
    Pconst_integer of string * char option
  (* 3 3l 3L 3n

     Suffixes [g-z][G-Z] are accepted by the parser.
     Suffixes except 'l', 'L' and 'n' are rejected by the typechecker
  *)
  | Pconst_char of char
  (* 'c' *)
  | Pconst_string of string * Location.t * string option
  (* ""constant""
     {delim|other constant|delim}

     The location span the content of the string, without the delimiters.
  *)
  | Pconst_float of string * char option
  (* 3.4 2e5 1.4e-4

     Suffixes [g-z][G-Z] are accepted by the parser.
     Suffixes are rejected by the typechecker.
  *)

type location_stack = Location.t list

(** {1 Extension points} *)

type attribute = {
    attr_name : string loc;
    attr_payload : payload;
    attr_loc : Location.t;
  }
       (* [@id ARG]
          [@@id ARG]

          Metadata containers passed around within the AST.
          The compiler ignores unknown attributes.
       *)

and extension = string loc * payload
      (* [%id ARG]
         [%%id ARG]

         Sub-language placeholder -- rejected by the typechecker.
      *)

and attributes = attribute list

and payload =
  | PStr of structure
  | PSig of signature (* : SIG *)
  | PTyp of core_type  (* : T *)
  | PPat of pattern * expression option  (* ? P  or  ? P when E *)

(** {1 Core language} *)

(* Type expressions *)

and core_type =
    {
     ptyp_desc: core_type_desc;
     ptyp_loc: Location.t;
     ptyp_loc_stack: location_stack;
     ptyp_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and core_type_desc =
  | Ptyp_any
        (*  _ *)
  | Ptyp_var of string
        (* 'a *)
  | Ptyp_arrow of arg_label * core_type * core_type
        (* T1 -> T2       Simple
           ~l:T1 -> T2    Labelled
           ?l:T1 -> T2    Optional
         *)
  | Ptyp_tuple of core_type list
        (* T1 * ... * Tn

           Invariant: n >= 2
        *)
  | Ptyp_constr of Longident.t loc * core_type list
        (* tconstr
           T tconstr
           (T1, ..., Tn) tconstr
         *)
  | Ptyp_object of object_field list * closed_flag
        (* < l1:T1; ...; ln:Tn >     (flag = Closed)
           < l1:T1; ...; ln:Tn; .. > (flag = Open)
         *)
  | Ptyp_class of Longident.t loc * core_type list
        (* #tconstr
           T #tconstr
           (T1, ..., Tn) #tconstr
         *)
  | Ptyp_alias of core_type * string
        (* T as 'a *)
  | Ptyp_variant of row_field list * closed_flag * label list option
        (* [ `A|`B ]         (flag = Closed; labels = None)
           [> `A|`B ]        (flag = Open;   labels = None)
           [< `A|`B ]        (flag = Closed; labels = Some [])
           [< `A|`B > `X `Y ](flag = Closed; labels = Some [""X"";""Y""])
         *)
  | Ptyp_poly of string loc list * core_type
        (* 'a1 ... 'an. T

           Can only appear in the following context:

           - As the core_type of a Ppat_constraint node corresponding
             to a constraint on a let-binding: let x : 'a1 ... 'an. T
             = e ...

           - Under Cfk_virtual for methods (not values).

           - As the core_type of a Pctf_method node.

           - As the core_type of a Pexp_poly node.

           - As the pld_type field of a label_declaration.

           - As a core_type of a Ptyp_object node.

           - As the pval_type field of a value_description.
         *)

  | Ptyp_package of package_type
        (* (module S) *)
  | Ptyp_extension of extension
        (* [%id] *)

and package_type = Longident.t loc * (Longident.t loc * core_type) list
      (*
        (module S)
        (module S with type t1 = T1 and ... and tn = Tn)
       *)

and row_field = {
  prf_desc : row_field_desc;
  prf_loc : Location.t;
  prf_attributes : attributes;
}

and row_field_desc =
  | Rtag of label loc * bool * core_type list
        (* [`A]                   ( true,  [] )
           [`A of T]              ( false, [T] )
           [`A of T1 & .. & Tn]   ( false, [T1;...Tn] )
           [`A of & T1 & .. & Tn] ( true,  [T1;...Tn] )

          - The 'bool' field is true if the tag contains a
            constant (empty) constructor.
          - '&' occurs when several types are used for the same constructor
            (see 4.2 in the manual)
        *)
  | Rinherit of core_type
        (* [ | t ] *)

and object_field = {
  pof_desc : object_field_desc;
  pof_loc : Location.t;
  pof_attributes : attributes;
}

and object_field_desc =
  | Otag of label loc * core_type
  | Oinherit of core_type

(* Patterns *)

and pattern =
    {
     ppat_desc: pattern_desc;
     ppat_loc: Location.t;
     ppat_loc_stack: location_stack;
     ppat_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and pattern_desc =
  | Ppat_any
        (* _ *)
  | Ppat_var of string loc
        (* x *)
  | Ppat_alias of pattern * string loc
        (* P as 'a *)
  | Ppat_constant of constant
        (* 1, 'a', ""true"", 1.0, 1l, 1L, 1n *)
  | Ppat_interval of constant * constant
        (* 'a'..'z'

           Other forms of interval are recognized by the parser
           but rejected by the type-checker. *)
  | Ppat_tuple of pattern list
        (* (P1, ..., Pn)

           Invariant: n >= 2
        *)
  | Ppat_construct of
      Longident.t loc * (string loc list * pattern) option
        (* C                    None
           C P                  Some ([], P)
           C (P1, ..., Pn)      Some ([], Ppat_tuple [P1; ...; Pn])
           C (type a b) P       Some ([a; b], P)
         *)
  | Ppat_variant of label * pattern option
        (* `A             (None)
           `A P           (Some P)
         *)
  | Ppat_record of (Longident.t loc * pattern) list * closed_flag
        (* { l1=P1; ...; ln=Pn }     (flag = Closed)
           { l1=P1; ...; ln=Pn; _}   (flag = Open)

           Invariant: n > 0
         *)
  | Ppat_array of pattern list
        (* [| P1; ...; Pn |] *)
  | Ppat_or of pattern * pattern
        (* P1 | P2 *)
  | Ppat_constraint of pattern * core_type
        (* (P : T) *)
  | Ppat_type of Longident.t loc
        (* #tconst *)
  | Ppat_lazy of pattern
        (* lazy P *)
  | Ppat_unpack of string option loc
        (* (module P)        Some ""P""
           (module _)        None

           Note: (module P : S) is represented as
           Ppat_constraint(Ppat_unpack, Ptyp_package)
         *)
  | Ppat_exception of pattern
        (* exception P *)
  | Ppat_extension of extension
        (* [%id] *)
  | Ppat_open of Longident.t loc * pattern
        (* M.(P) *)

(* Value expressions *)

and expression =
    {
     pexp_desc: expression_desc;
     pexp_loc: Location.t;
     pexp_loc_stack: location_stack;
     pexp_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and expression_desc =
  | Pexp_ident of Longident.t loc
        (* x
           M.x
         *)
  | Pexp_constant of constant
        (* 1, 'a', ""true"", 1.0, 1l, 1L, 1n *)
  | Pexp_let of rec_flag * value_binding list * expression
        (* let P1 = E1 and ... and Pn = EN in E       (flag = Nonrecursive)
           let rec P1 = E1 and ... and Pn = EN in E   (flag = Recursive)
         *)
  | Pexp_function of case list
        (* function P1 -> E1 | ... | Pn -> En *)
  | Pexp_fun of arg_label * expression option * pattern * expression
        (* fun P -> E1                          (Simple, None)
           fun ~l:P -> E1                       (Labelled l, None)
           fun ?l:P -> E1                       (Optional l, None)
           fun ?l:(P = E0) -> E1                (Optional l, Some E0)

           Notes:
           - If E0 is provided, only Optional is allowed.
           - ""fun P1 P2 .. Pn -> E1"" is represented as nested Pexp_fun.
           - ""let f P = E"" is represented using Pexp_fun.
         *)
  | Pexp_apply of expression * (arg_label * expression) list
        (* E0 ~l1:E1 ... ~ln:En
           li can be empty (non labeled argument) or start with '?'
           (optional argument).

           Invariant: n > 0
         *)
  | Pexp_match of expression * case list
        (* match E0 with P1 -> E1 | ... | Pn -> En *)
  | Pexp_try of expression * case list
        (* try E0 with P1 -> E1 | ... | Pn -> En *)
  | Pexp_tuple of expression list
        (* (E1, ..., En)

           Invariant: n >= 2
        *)
  | Pexp_construct of Longident.t loc * expression option
        (* C                None
           C E              Some E
           C (E1, ..., En)  Some (Pexp_tuple[E1;...;En])
        *)
  | Pexp_variant of label * expression option
        (* `A             (None)
           `A E           (Some E)
         *)
  | Pexp_record of (Longident.t loc * expression) list * expression option
        (* { l1=P1; ...; ln=Pn }     (None)
           { E0 with l1=P1; ...; ln=Pn }   (Some E0)

           Invariant: n > 0
         *)
  | Pexp_field of expression * Longident.t loc
        (* E.l *)
  | Pexp_setfield of expression * Longident.t loc * expression
        (* E1.l <- E2 *)
  | Pexp_array of expression list
        (* [| E1; ...; En |] *)
  | Pexp_ifthenelse of expression * expression * expression option
        (* if E1 then E2 else E3 *)
  | Pexp_sequence of expression * expression
        (* E1; E2 *)
  | Pexp_while of expression * expression
        (* while E1 do E2 done *)
  | Pexp_for of
      pattern *  expression * expression * direction_flag * expression
        (* for i = E1 to E2 do E3 done      (flag = Upto)
           for i = E1 downto E2 do E3 done  (flag = Downto)
         *)
  | Pexp_constraint of expression * core_type
        (* (E : T) *)
  | Pexp_coerce of expression * core_type option * core_type
        (* (E :> T)        (None, T)
           (E : T0 :> T)   (Some T0, T)
         *)
  | Pexp_send of expression * label loc
        (*  E # m *)
  | Pexp_new of Longident.t loc
        (* new M.c *)
  | Pexp_setinstvar of label loc * expression
        (* x <- 2 *)
  | Pexp_override of (label loc * expression) list
        (* {< x1 = E1; ...; Xn = En >} *)
  | Pexp_letmodule of string option loc * module_expr * expression
        (* let module M = ME in E *)
  | Pexp_letexception of extension_constructor * expression
        (* let exception C in E *)
  | Pexp_assert of expression
        (* assert E
           Note: ""assert false"" is treated in a special way by the
           type-checker. *)
  | Pexp_lazy of expression
        (* lazy E *)
  | Pexp_poly of expression * core_type option
        (* Used for method bodies.

           Can only be used as the expression under Cfk_concrete
           for methods (not values). *)
  | Pexp_object of class_structure
        (* object ... end *)
  | Pexp_newtype of string loc * expression
        (* fun (type t) -> E *)
  | Pexp_pack of module_expr
        (* (module ME)

           (module ME : S) is represented as
           Pexp_constraint(Pexp_pack, Ptyp_package S) *)
  | Pexp_open of open_declaration * expression
        (* M.(E)
           let open M in E
           let open! M in E *)
  | Pexp_letop of letop
        (* let* P = E in E
           let* P = E and* P = E in E *)
  | Pexp_extension of extension
        (* [%id] *)
  | Pexp_unreachable
        (* . *)
  | Pexp_hole
        (* _ *)

and case =   (* (P -> E) or (P when E0 -> E) *)
    {
     pc_lhs: pattern;
     pc_guard: expression option;
     pc_rhs: expression;
   }

and letop =
  {
    let_ : binding_op;
    ands : binding_op list;
    body : expression;
  }

and binding_op =
  {
    pbop_op : string loc;
    pbop_pat : pattern;
    pbop_exp : expression;
    pbop_loc : Location.t;
  }

(* Value descriptions *)

and value_description =
    {
     pval_name: string loc;
     pval_type: core_type;
     pval_prim: string list;
     pval_attributes: attributes;  (* ... [@@id1] [@@id2] *)
     pval_loc: Location.t;
    }

(*
  val x: T                            (prim = [])
  external x: T = ""s1"" ... ""sn""       (prim = [""s1"";...""sn""])
*)

(* Type declarations *)

and type_declaration =
    {
     ptype_name: string loc;
     ptype_params: (core_type * (variance * injectivity)) list;
           (* ('a1,...'an) t; None represents  _*)
     ptype_cstrs: (core_type * core_type * Location.t) list;
           (* ... constraint T1=T1'  ... constraint Tn=Tn' *)
     ptype_kind: type_kind;
     ptype_private: private_flag;   (* = private ... *)
     ptype_manifest: core_type option;  (* = T *)
     ptype_attributes: attributes;   (* ... [@@id1] [@@id2] *)
     ptype_loc: Location.t;
    }

(*
  type t                     (abstract, no manifest)
  type t = T0                (abstract, manifest=T0)
  type t = C of T | ...      (variant,  no manifest)
  type t = T0 = C of T | ... (variant,  manifest=T0)
  type t = {l: T; ...}       (record,   no manifest)
  type t = T0 = {l : T; ...} (record,   manifest=T0)
  type t = ..                (open,     no manifest)
*)

and type_kind =
  | Ptype_abstract
  | Ptype_variant of constructor_declaration list
  | Ptype_record of label_declaration list
        (* Invariant: non-empty list *)
  | Ptype_open

and label_declaration =
    {
     pld_name: string loc;
     pld_mutable: mutable_flag;
     pld_type: core_type;
     pld_loc: Location.t;
     pld_attributes: attributes; (* l : T [@id1] [@id2] *)
    }

(*  { ...; l: T; ... }            (mutable=Immutable)
    { ...; mutable l: T; ... }    (mutable=Mutable)

    Note: T can be a Ptyp_poly.
*)

and constructor_declaration =
    {
     pcd_name: string loc;
     pcd_vars: string loc list;
     pcd_args: constructor_arguments;
     pcd_res: core_type option;
     pcd_loc: Location.t;
     pcd_attributes: attributes; (* C of ... [@id1] [@id2] *)
    }

and constructor_arguments =
  | Pcstr_tuple of core_type list
  | Pcstr_record of label_declaration list

(*
  | C of T1 * ... * Tn     (res = None,    args = Pcstr_tuple [])
  | C: T0                  (res = Some T0, args = [])
  | C: T1 * ... * Tn -> T0 (res = Some T0, args = Pcstr_tuple)
  | C of {...}             (res = None,    args = Pcstr_record)
  | C: {...} -> T0         (res = Some T0, args = Pcstr_record)
  | C of {...} as t        (res = None,    args = Pcstr_record)
*)

and type_extension =
    {
     ptyext_path: Longident.t loc;
     ptyext_params: (core_type * (variance * injectivity)) list;
     ptyext_constructors: extension_constructor list;
     ptyext_private: private_flag;
     ptyext_loc: Location.t;
     ptyext_attributes: attributes;   (* ... [@@id1] [@@id2] *)
    }
(*
  type t += ...
*)

and extension_constructor =
    {
     pext_name: string loc;
     pext_kind : extension_constructor_kind;
     pext_loc : Location.t;
     pext_attributes: attributes; (* C of ... [@id1] [@id2] *)
   }

(* exception E *)
and type_exception =
  {
    ptyexn_constructor: extension_constructor;
    ptyexn_loc: Location.t;
    ptyexn_attributes: attributes; (* ... [@@id1] [@@id2] *)
  }

and extension_constructor_kind =
    Pext_decl of string loc list * constructor_arguments * core_type option
      (*
         | C of T1 * ... * Tn     ([], [T1; ...; Tn], None)
         | C: T0                  ([], [], Some T0)
         | C: T1 * ... * Tn -> T0 ([], [T1; ...; Tn], Some T0)
         | C: 'a... . T1... -> T0 (['a;...]; [T1;...], Some T0)
       *)
  | Pext_rebind of Longident.t loc
      (*
         | C = D
       *)

(** {1 Class language} *)

(* Type expressions for the class language *)

and class_type =
    {
     pcty_desc: class_type_desc;
     pcty_loc: Location.t;
     pcty_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and class_type_desc =
  | Pcty_constr of Longident.t loc * core_type list
        (* c
           ['a1, ..., 'an] c *)
  | Pcty_signature of class_signature
        (* object ... end *)
  | Pcty_arrow of arg_label * core_type * class_type
        (* T -> CT       Simple
           ~l:T -> CT    Labelled l
           ?l:T -> CT    Optional l
         *)
  | Pcty_extension of extension
        (* [%id] *)
  | Pcty_open of open_description * class_type
        (* let open M in CT *)

and class_signature =
    {
     pcsig_self: core_type;
     pcsig_fields: class_type_field list;
    }
(* object('selfpat) ... end
   object ... end             (self = Ptyp_any)
 *)

and class_type_field =
    {
     pctf_desc: class_type_field_desc;
     pctf_loc: Location.t;
     pctf_attributes: attributes; (* ... [@@id1] [@@id2] *)
    }

and class_type_field_desc =
  | Pctf_inherit of class_type
        (* inherit CT *)
  | Pctf_val of (label loc * mutable_flag * virtual_flag * core_type)
        (* val x: T *)
  | Pctf_method  of (label loc * private_flag * virtual_flag * core_type)
        (* method x: T

           Note: T can be a Ptyp_poly.
         *)
  | Pctf_constraint  of (core_type * core_type)
        (* constraint T1 = T2 *)
  | Pctf_attribute of attribute
        (* [@@@id] *)
  | Pctf_extension of extension
        (* [%%id] *)

and 'a class_infos =
    {
     pci_virt: virtual_flag;
     pci_params: (core_type * (variance * injectivity)) list;
     pci_name: string loc;
     pci_expr: 'a;
     pci_loc: Location.t;
     pci_attributes: attributes;  (* ... [@@id1] [@@id2] *)
    }
(* class c = ...
   class ['a1,...,'an] c = ...
   class virtual c = ...

   Also used for ""class type"" declaration.
*)

and class_description = class_type class_infos

and class_type_declaration = class_type class_infos

(* Value expressions for the class language *)

and class_expr =
    {
     pcl_desc: class_expr_desc;
     pcl_loc: Location.t;
     pcl_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and class_expr_desc =
  | Pcl_constr of Longident.t loc * core_type list
        (* c
           ['a1, ..., 'an] c *)
  | Pcl_structure of class_structure
        (* object ... end *)
  | Pcl_fun of arg_label * expression option * pattern * class_expr
        (* fun P -> CE                          (Simple, None)
           fun ~l:P -> CE                       (Labelled l, None)
           fun ?l:P -> CE                       (Optional l, None)
           fun ?l:(P = E0) -> CE                (Optional l, Some E0)
         *)
  | Pcl_apply of class_expr * (arg_label * expression) list
        (* CE ~l1:E1 ... ~ln:En
           li can be empty (non labeled argument) or start with '?'
           (optional argument).

           Invariant: n > 0
         *)
  | Pcl_let of rec_flag * value_binding list * class_expr
        (* let P1 = E1 and ... and Pn = EN in CE      (flag = Nonrecursive)
           let rec P1 = E1 and ... and Pn = EN in CE  (flag = Recursive)
         *)
  | Pcl_constraint of class_expr * class_type
        (* (CE : CT) *)
  | Pcl_extension of extension
  (* [%id] *)
  | Pcl_open of open_description * class_expr
  (* let open M in CE *)


and class_structure =
    {
     pcstr_self: pattern;
     pcstr_fields: class_field list;
    }
(* object(selfpat) ... end
   object ... end           (self = Ppat_any)
 *)

and class_field =
    {
     pcf_desc: class_field_desc;
     pcf_loc: Location.t;
     pcf_attributes: attributes; (* ... [@@id1] [@@id2] *)
    }

and class_field_desc =
  | Pcf_inherit of override_flag * class_expr * string loc option
        (* inherit CE
           inherit CE as x
           inherit! CE
           inherit! CE as x
         *)
  | Pcf_val of (label loc * mutable_flag * class_field_kind)
        (* val x = E
           val virtual x: T
         *)
  | Pcf_method of (label loc * private_flag * class_field_kind)
        (* method x = E            (E can be a Pexp_poly)
           method virtual x: T     (T can be a Ptyp_poly)
         *)
  | Pcf_constraint of (core_type * core_type)
        (* constraint T1 = T2 *)
  | Pcf_initializer of expression
        (* initializer E *)
  | Pcf_attribute of attribute
        (* [@@@id] *)
  | Pcf_extension of extension
        (* [%%id] *)

and class_field_kind =
  | Cfk_virtual of core_type
  | Cfk_concrete of override_flag * expression

and class_declaration = class_expr class_infos

(** {1 Module language} *)

(* Type expressions for the module language *)

and module_type =
    {
     pmty_desc: module_type_desc;
     pmty_loc: Location.t;
     pmty_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and module_type_desc =
  | Pmty_ident of Longident.t loc
        (* S *)
  | Pmty_signature of signature
        (* sig ... end *)
  | Pmty_functor of functor_parameter * module_type
        (* functor(X : MT1) -> MT2 *)
  | Pmty_with of module_type * with_constraint list
        (* MT with ... *)
  | Pmty_typeof of module_expr
        (* module type of ME *)
  | Pmty_extension of extension
        (* [%id] *)
  | Pmty_alias of Longident.t loc
        (* (module M) *)

and functor_parameter =
  | Unit
        (* () *)
  | Named of string option loc * module_type
        (* (X : MT)          Some X, MT
           (_ : MT)          None, MT *)

and signature = signature_item list

and signature_item =
    {
     psig_desc: signature_item_desc;
     psig_loc: Location.t;
    }

and signature_item_desc =
  | Psig_value of value_description
        (*
          val x: T
          external x: T = ""s1"" ... ""sn""
         *)
  | Psig_type of rec_flag * type_declaration list
        (* type t1 = ... and ... and tn  = ... *)
  | Psig_typesubst of type_declaration list
        (* type t1 := ... and ... and tn := ...  *)
  | Psig_typext of type_extension
        (* type t1 += ... *)
  | Psig_exception of type_exception
        (* exception C of T *)
  | Psig_module of module_declaration
        (* module X = M
           module X : MT *)
  | Psig_modsubst of module_substitution
        (* module X := M *)
  | Psig_recmodule of module_declaration list
        (* module rec X1 : MT1 and ... and Xn : MTn *)
  | Psig_modtype of module_type_declaration
        (* module type S = MT
           module type S *)
  | Psig_modtypesubst of module_type_declaration
        (* module type S :=  ...  *)
  | Psig_open of open_description
        (* open X *)
  | Psig_include of include_description
        (* include MT *)
  | Psig_class of class_description list
        (* class c1 : ... and ... and cn : ... *)
  | Psig_class_type of class_type_declaration list
        (* class type ct1 = ... and ... and ctn = ... *)
  | Psig_attribute of attribute
        (* [@@@id] *)
  | Psig_extension of extension * attributes
        (* [%%id] *)

and module_declaration =
    {
     pmd_name: string option loc;
     pmd_type: module_type;
     pmd_attributes: attributes; (* ... [@@id1] [@@id2] *)
     pmd_loc: Location.t;
    }
(* S : MT *)

and module_substitution =
    {
     pms_name: string loc;
     pms_manifest: Longident.t loc;
     pms_attributes: attributes; (* ... [@@id1] [@@id2] *)
     pms_loc: Location.t;
    }
(* S := M *)

and module_type_declaration =
    {
     pmtd_name: string loc;
     pmtd_type: module_type option;
     pmtd_attributes: attributes; (* ... [@@id1] [@@id2] *)
     pmtd_loc: Location.t;
    }
(* S = MT
   S       (abstract module type declaration, pmtd_type = None)
*)

and 'a open_infos =
    {
     popen_expr: 'a;
     popen_override: override_flag;
     popen_loc: Location.t;
     popen_attributes: attributes;
    }
(* open! X - popen_override = Override (silences the 'used identifier
                              shadowing' warning)
   open  X - popen_override = Fresh
 *)

and open_description = Longident.t loc open_infos
(* open M.N
   open M(N).O *)

and open_declaration = module_expr open_infos
(* open M.N
   open M(N).O
   open struct ... end *)

and 'a include_infos =
    {
     pincl_mod: 'a;
     pincl_loc: Location.t;
     pincl_attributes: attributes;
    }

and include_description = module_type include_infos
(* include MT *)

and include_declaration = module_expr include_infos
(* include ME *)

and with_constraint =
  | Pwith_type of Longident.t loc * type_declaration
        (* with type X.t = ...

           Note: the last component of the longident must match
           the name of the type_declaration. *)
  | Pwith_module of Longident.t loc * Longident.t loc
        (* with module X.Y = Z *)
  | Pwith_modtype of Longident.t loc * module_type
        (* with module type X.Y = Z *)
  | Pwith_modtypesubst of Longident.t loc * module_type
        (* with module type X.Y := sig end *)
  | Pwith_typesubst of Longident.t loc * type_declaration
        (* with type X.t := ..., same format as [Pwith_type] *)
  | Pwith_modsubst of Longident.t loc * Longident.t loc
        (* with module X.Y := Z *)

(* Value expressions for the module language *)

and module_expr =
    {
     pmod_desc: module_expr_desc;
     pmod_loc: Location.t;
     pmod_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and module_expr_desc =
  | Pmod_ident of Longident.t loc
        (* X *)
  | Pmod_structure of structure
        (* struct ... end *)
  | Pmod_functor of functor_parameter * module_expr
        (* functor(X : MT1) -> ME *)
  | Pmod_apply of module_expr * module_expr
        (* ME1(ME2) *)
  | Pmod_constraint of module_expr * module_type
        (* (ME : MT) *)
  | Pmod_unpack of expression
        (* (val E) *)
  | Pmod_extension of extension
        (* [%id] *)
  | Pmod_hole
        (* _ *)

and structure = structure_item list

and structure_item =
    {
     pstr_desc: structure_item_desc;
     pstr_loc: Location.t;
    }

and structure_item_desc =
  | Pstr_eval of expression * attributes
        (* E *)
  | Pstr_value of rec_flag * value_binding list
        (* let P1 = E1 and ... and Pn = EN       (flag = Nonrecursive)
           let rec P1 = E1 and ... and Pn = EN   (flag = Recursive)
         *)
  | Pstr_primitive of value_description
        (*  val x: T
            external x: T = ""s1"" ... ""sn"" *)
  | Pstr_type of rec_flag * type_declaration list
        (* type t1 = ... and ... and tn = ... *)
  | Pstr_typext of type_extension
        (* type t1 += ... *)
  | Pstr_exception of type_exception
        (* exception C of T
           exception C = M.X *)
  | Pstr_module of module_binding
        (* module X = ME *)
  | Pstr_recmodule of module_binding list
        (* module rec X1 = ME1 and ... and Xn = MEn *)
  | Pstr_modtype of module_type_declaration
        (* module type S = MT *)
  | Pstr_open of open_declaration
        (* open X *)
  | Pstr_class of class_declaration list
        (* class c1 = ... and ... and cn = ... *)
  | Pstr_class_type of class_type_declaration list
        (* class type ct1 = ... and ... and ctn = ... *)
  | Pstr_include of include_declaration
        (* include ME *)
  | Pstr_attribute of attribute
        (* [@@@id] *)
  | Pstr_extension of extension * attributes
        (* [%%id] *)

and value_binding =
  {
    pvb_pat: pattern;
    pvb_expr: expression;
    pvb_attributes: attributes;
    pvb_loc: Location.t;
  }

and module_binding =
    {
     pmb_name: string option loc;
     pmb_expr: module_expr;
     pmb_attributes: attributes;
     pmb_loc: Location.t;
    }
(* X = ME *)

(** {1 Toplevel} *)

(* Toplevel phrases *)

type toplevel_phrase =
  | Ptop_def of structure
  | Ptop_dir of toplevel_directive
     (* #use, #load ... *)

and toplevel_directive =
  {
    pdir_name : string loc;
    pdir_arg : directive_argument option;
    pdir_loc : Location.t;
  }

and directive_argument =
  {
    pdira_desc : directive_argument_desc;
    pdira_loc : Location.t;
  }

and directive_argument_desc =
  | Pdir_string of string
  | Pdir_int of string * char option
  | Pdir_ident of Longident.t
  | Pdir_bool of bool
",ocaml
"module Pre = struct
  (* 和集合 *)
  let union (xs: 'a list) (ys: 'a list):'a list =
    List.filter begin fun x ->
      not (List.mem x ys)
    end xs @ ys

  (* 積集合 *)
  let intersect (xs: 'a list) (ys: 'a list): 'a list =
    List.filter begin fun x ->
      List.mem x ys
    end xs

  (* リストをセットにする。要素が１つずつにまとめる *)
  let nub (xs : 'a list): 'a list =
    List.fold_left begin fun ys y ->
      if List.mem y ys
      then ys
      else y :: ys
    end [] xs

  let show_list show sep xs =
    begin
      let rec loop xs =
        begin match xs with
          | [] -> """"
          | [x] -> show x
          | x::xs -> show x ^ sep ^ loop xs
        end
    in
      Printf.sprintf ""[%s]"" (loop xs)
    end
  let show_int_list xs =
    show_list string_of_int ""; "" xs
end

module Id = struct
  type id = string

  (* 数値に対するidを取得する *)
  let enumId (n:int) : id =
    ""v"" ^ string_of_int n
end

(* 3 Kinds *)
module Kind = struct
  type kind =
    | Star
    | Kfun of kind * kind

  let rec show (k:kind):string =
    begin match k with
      | Star -> ""*""
      | Kfun(Kfun _ as k1,k2) -> Printf.sprintf ""(%s) -> %s"" (show k1) (show k2) 
      | Kfun(k1,k2) -> Printf.sprintf ""%s -> %s"" (show k1) (show k2) 
    end
end

(* 4 Types *)
module Type = struct
  open Kind
  (* 型変数 *)
  type tyvar = Tyvar of Id.id * kind
  (* 型コンストラクタ *)
  type tycon = Tycon of Id.id * kind
  (* 型 *)
  type type_ =
    | TVar of tyvar
    | TCon of tycon
    | TAp of type_ * type_
    | TGen of int

  let tUnit :type_ = TCon(Tycon(""()"", Star))
  let tChar :type_ = TCon(Tycon(""Char"", Star))
  let tInt :type_ = TCon(Tycon(""Int"", Star))
  let tInteger :type_ = TCon(Tycon(""Integer"", Star))
  let tFloat :type_ = TCon(Tycon(""Float"", Star))
  let tDouble :type_ = TCon(Tycon(""Double"", Star))

  let tList :type_ = TCon(Tycon(""[]"", Kfun(Star, Star)))
  let tArrow :type_ = TCon(Tycon(""(->)"", Kfun(Star, Kfun(Star, Star))))
  let tTuple2 :type_ = TCon(Tycon(""(,)"", Kfun(Star, Kfun(Star, Star))))

  let fn (a:type_) (b:type_) :type_ = TAp(TAp(tArrow, a), b)

  let list t :type_ = TAp(tList, t)

  let tString :type_ = list tChar

  let pair a b :type_ = TAp(TAp(tTuple2, a), b)

  let tyvarKind (Tyvar(_, k)) :kind = k
  let tyconKind (Tycon(_, k)) :kind = k
  let rec typeKind t:kind =
    match t with
    | TCon tc -> tyconKind tc
    | TVar u -> tyvarKind u
    | TAp(t, _) ->
      begin match typeKind t with
        | Kfun(_, k) -> k
        | _ -> failwith ""inconsistent type""
      end
    | TGen _ -> failwith ""generic type variables have no kind""

  let rec show (t:type_): string =
    begin match t with
      | TVar(Tyvar(id,kind)) -> Printf.sprintf ""TVar(Tyvar(%s,%s))"" id (Kind.show kind)
      | TCon(Tycon(id,kind)) -> Printf.sprintf ""TCon(Tycon(%s,%s))"" id (Kind.show kind)
      | TAp(t1,t2)           -> Printf.sprintf ""TAp(%s,%s)"" (show t1) (show t2)
      | TGen(i)              -> Printf.sprintf ""TGen(%d)"" i
    end
end

(* 5 Substitutions *)
module Subst = struct
  open Type

  type subst = (tyvar * type_) list

  let nullSubst : subst = []

  let (+->) u t : subst = [(u, t)]

  (* 型変数を展開する *)
  let rec typeApply (s : subst) (t:type_):type_ = 
    begin match t with
      | TVar u as t ->
        begin try
          List.assoc u s
        with
          Not_found -> t
        end
      | TAp(l, r) -> TAp(typeApply s l, typeApply s r)
      | t -> t
    end

  let rec typeTv (t:type_):tyvar list =
    begin match t with
      | TVar u -> [u]
      | TAp(l, r) -> Pre.union (typeTv l) (typeTv r)
      | _ -> []
    end

  let listApply (apply : subst -> 'a -> 'b) (s : subst) (xs:'a list):'b list =
    List.map (apply s) xs

  let listTv (tv:'a -> tyvar list) (xs:'a list) : tyvar list =
    Pre.nub (List.concat (List.map tv xs))

  let (@@) (s1:subst) (s2 : subst) : subst =
    List.map begin fun (u, t) ->
      (u, typeApply s1 t)
    end s2 @ s1

  let merge s1 s2 : subst =
    let agree =
      let agreeOnVar v =
        typeApply s1 (TVar v) = typeApply s2 (TVar v)
      in
      List.for_all agreeOnVar (Pre.intersect (List.map fst s1) (List.map fst s2))
    in
    if agree
    then s1 @ s2
    else failwith ""substitutions do not agree""

  let show (subst:subst):string =
    Pre.show_list begin fun (Tyvar(id,kind),type_) ->
      Printf.sprintf ""Tyvar(%s,%s),%s"" id (Kind.show kind) (Type.show type_)
    end ""; "" subst

  let rec show_tyvar(tv:tyvar): string = 
    begin match tv with
      | Tyvar(id,kind) -> Printf.sprintf ""Tyvar(%s,%s)"" id (Kind.show kind)
    end

  let show_tyvar_list xs :string =
    Pre.show_list begin fun (Tyvar(id,kind)) ->
      Printf.sprintf ""Tyvar(%s,%s)"" id (Kind.show kind)
    end ""; "" xs
end

(* 6 Unification and Matching *)
module Unify = struct
  open List
  open Kind
  open Type
  open Subst
  
  let rec mgu (t1:type_) (t2:type_):subst =
    match t1, t2 with
    | TAp(l, r), TAp(l', r') ->
      let s1 = mgu l l' in
      let s2 = mgu (typeApply s1 r) (typeApply s1 r') in
      s2 @@ s1
    | TVar u, t | t, TVar u -> varBind u t
    | TCon tc1, TCon tc2 when tc1 = tc2 -> nullSubst
    | _ -> failwith ""types do not unify""

  and varBind (u:tyvar) (t:type_):subst =
    match t with
    | _ when t = TVar u                -> nullSubst
    | _ when mem u (typeTv t)          -> failwith ""occurs check fails""
    | _ when tyvarKind u <> typeKind t -> failwith ""kinds do not match""
    | _                                -> u +-> t

  let rec match_ (t1:type_) (t2:type_):subst =
    match t1, t2 with
    | TAp(l, r), TAp(l', r') ->
      let sl = match_ l l' in
      let sr = match_ r r' in
      merge sl sr
    | TVar u, t when tyvarKind u = typeKind t -> u +-> t
    | TCon tc1, TCon tc2 when tc1 = tc2 -> nullSubst
    | _ -> failwith ""types do not match""
end

(* 7 Type Classes, Predicates and Qualified Types *)
module Pred = struct
  open List
  open Kind
  open Type
  open Subst


  (* 7.1 Basic definitions *)
  type pred = IsIn of Id.id * type_

  let p (IsIn(s, t)) =
    s  ^ "" "" ^ (Type.show t)

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    Printf.printf ""pred %s\n"" (p pred)

  let ps pred =
    Pre.show_list p "", "" pred

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let preds = [IsIn(""Num"", ty);IsIn(""B"", ty)] in
    Printf.printf ""preds %s\n"" (ps preds)

  type 't qual = Qual of pred list * 't

  let p_qual q =
    begin match q with
      | Qual(preds,ty) -> ps preds ^ "" => "" ^ Type.show ty
    end

  let _ =

    (* (Num a) => a -> Int *)

    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    Printf.printf ""pred %s\n"" (p pred);
    (* Qual *)
    let q = Qual([pred], fn ty tInt) in
    Printf.printf ""qual = %s\n"" (p_qual q)

  let predApply (s:subst) (pred:pred):pred =
    match pred with
    | IsIn(i, t) -> IsIn(i, Subst.typeApply s t)

  let _ =
    let s = [Tyvar(""a"", Star), tInt] in
    let pred = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let pred2 = predApply s pred in
    Printf.printf ""pred2 = %s\n"" (p pred2)

  let predTv (pred:pred):tyvar list =
    match pred with
    | IsIn(_, t) -> Subst.typeTv t

  let _ =
    let pred = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let tvs = predTv pred in
    Printf.printf ""tvs = %s\n"" (Subst.show_tyvar_list tvs)

  let predsApply (s:subst) (xs:pred list):pred list =
    Subst.listApply predApply s xs

  let _ =
    let s = [Tyvar(""a"", Star), tInt] in
    let preds = [IsIn(""Num"", TVar(Tyvar(""a"", Star)))] in
    let preds2 = predsApply s preds in
    Printf.printf ""preds2 = %s\n"" (ps preds2)

  let predsTv (xs:'a list) : tyvar list =
    Subst.listTv predTv xs

  let _ =
    let preds = [IsIn(""Num"", TVar(Tyvar(""a"", Star)))] in
    let tvs = predsTv preds in
    Printf.printf ""tvs = %s\n"" (Subst.show_tyvar_list tvs)

  let qualTypeApply (s:subst) (qual:type_ qual):type_ qual =
    match qual with
    | Qual(ps, t) -> Qual(predsApply s ps, Subst.typeApply s t)

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    let q = Qual([pred], fn ty tInt) in
    Printf.printf ""qual = %s\n"" (p_qual q);
    let qual2 = qualTypeApply ((Tyvar(""a"", Star)) +-> tInt) q in
    Printf.printf ""qual2 = %s\n"" (p_qual qual2)

  let qualTypeTv qual =
    match qual with
    | Qual(ps, t) ->
      Pre.union (predsTv ps) (Subst.typeTv t)

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    let q = Qual([pred], fn ty tInt) in
    let tvs = qualTypeTv q in
    Printf.printf ""tvs = %s\n"" (Subst.show_tyvar_list tvs)

  let lift (m:type_->type_->'a) (p:pred) (p':pred):'a =
    match (p, p') with
    | IsIn(i, t), IsIn(i', t') ->
      if i = i' then m t t'
      else failwith ""classes differ""

  let mguPred = lift Unify.mgu

  let _ =
    let pred1 = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let pred2 = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let s = mguPred pred1 pred2 in
    Printf.printf ""mguPred = %s\n"" (Subst.show s)

  let matchPred = lift Unify.match_

  let _ =
    let pred1 = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let pred2 = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let s = matchPred pred1 pred2 in
    Printf.printf ""matchPred = %s\n"" (Subst.show s)

  type inst = pred qual

  let p_inst i =
    begin match i with
    | Qual(preds,pred) -> Printf.sprintf ""Qual(%s,%s)"" (ps preds) (p pred)
    end

  let _ =
    let inst = Qual([IsIn(""Ord"",tUnit);IsIn(""Ord"",tChar)],IsIn(""Ord"",tChar)) in
    Printf.printf ""inst=%s\n"" (p_inst inst)

  type class_ = Id.id list * inst list

  let (==>) ps p = Qual(ps, p)

  let _ =
    let (cls:class_) = (
      [""Eq""], (* クラス名 *)
      [
      (* インスタンスの列挙 型の実装の列挙 *)
        [] ==> IsIn(""Ord"", tUnit);
        [] ==> IsIn(""Ord"", tChar);
        (* int *)
        [] ==> IsIn(""Ord"", tInt);
        (* Ord a, Ord b => pair a b *)
        [
          IsIn(""Ord"",TVar(Tyvar(""a"", Star)));
          IsIn(""Ord"",TVar(Tyvar(""b"", Star)))
        ] ==>
        IsIn(""Ord"", (pair (TVar(Tyvar(""a"",Star))) (TVar(Tyvar(""b"",Star)))))
        
      ]
    ) in ()

  (* 7.2 Class Environments *)

  type classEnv = {
    classes : (Id.id -> class_);
    defaults : type_ list;
  }

  let initialEnv :classEnv = {
    classes = (fun i -> raise Not_found);
    defaults = [tInteger; tDouble]
  }

  let modify (ce:classEnv) i c =
    { ce with classes = fun j -> if i = j then c else ce.classes j; }

  let _ =
    let b = modify initialEnv ""ABC"" ([""A""],[[] ==> IsIn(""Ord"",tUnit)]) in
    ()

  let super (ce:classEnv) i = fst (ce.classes i)

  let _ =
    let b = modify initialEnv ""ABC"" ([""A""],[[] ==> IsIn(""Ord"",tUnit)]) in
    let s = super b ""ABC"" in
    ()

  let insts (ce:classEnv) i = snd (ce.classes i)

  let _ =
    let b = modify initialEnv ""ABC"" ([""A""],[[] ==> IsIn(""Ord"",tUnit)]) in
    let s = insts b ""ABC"" in
    ()

  let defined (ce:classEnv) i =
    try
      ignore (ce.classes i);
      true
    with Not_found -> false

  let _ =
    let b = modify initialEnv ""ABC"" ([""A""],[[] ==> IsIn(""Ord"",tUnit)]) in
    let s = defined b ""ABC"" in
    ()

  type envTransformer = classEnv -> classEnv

  let addClass i is : envTransformer =
    fun (ce:classEnv) ->
      if defined ce i then failwith ""class already defined""
      else if exists (fun i -> not (defined ce i)) is then
        failwith ""superclass not defined""
      else modify ce i (is, [])

  let _ =
    let c1 :envTransformer = addClass ""Eq"" [] in
    let c1s = c1 initialEnv in
    ()

  let (<:>) (f : envTransformer) (g : envTransformer) : envTransformer =
    fun (ce:classEnv) -> g (f ce)

  let _ =
    let c1 :envTransformer = addClass ""Eq"" [] in
    let c2 :envTransformer = addClass ""Eq2"" [] in
    let c3 :envTransformer = c1 <:> c2 in
    let c4 :envTransformer = addClass ""Eq"" [] <:> addClass ""Eq2"" [] in
    ()

  let addCoreClasses :envTransformer =
    addClass ""Eq"" [] (* Eqは == /=で同値判定できる *)
    <:> addClass ""Ord"" [""Eq""] (* Ord は比較出来るクラスで、Eqを継承し < > <= >= *)
    <:> addClass ""Show"" [] (* Show 文字列化できる *)
    <:> addClass ""Read"" [] 
    <:> addClass ""Bounded"" []
    <:> addClass ""Enum"" []
    <:> addClass ""Functor"" []
    <:> addClass ""Monad"" []

  let addNumClasses :envTransformer =
    addClass ""Num"" [""Eq""; ""Show""] (* Numは数字で、同値判定出来て、表示出来る *)
    <:> addClass ""Real"" [""Num""; ""Ord""] (* Realは数字で比較も出来る *)
    <:> addClass ""Fractional"" [""Num""] (* 大小関係はない *)
    <:> addClass ""Integral"" [""Real""; ""Enum""] (* 列挙可能 *)
    <:> addClass ""RealFrac"" [""Real""; ""Fractional""] (*大小関係ありのFractional*)
    <:> addClass ""Floating"" [""Fractional""] (* 大小関係はない *)
    <:> addClass ""RealFloat"" [""RealFrac""; ""Floating""] (* 大小関係がある *)

  let addPreludeClasses :envTransformer =
    addCoreClasses <:> addNumClasses

  let overlap (p:pred) (q:pred) : bool =
    try
      ignore (mguPred p q);
      true
    with _ -> false

  let _ =
    let pred1 = IsIn(""Ord"", tUnit) in
    let pred2 = IsIn(""Ord"", tChar) in
    Printf.printf ""overlap pred1 pred2 %b\n"" (overlap pred1 pred2);
    Printf.printf ""overlap pred1 pred1 %b\n"" (overlap pred1 pred1)

  let addInst ps (IsIn(i, _) as p) : envTransformer =
    fun (ce:classEnv) ->
      if not (defined ce i) then failwith ""no class for instance"";
      let its = insts ce i in
      let qs = map (fun (Qual(_, q)) -> q) its in
      if exists (overlap p) qs then failwith ""overlapping instance"";      
      let c = super ce i, Qual(ps, p) :: its in
      modify ce i c

  let exampleInsts : envTransformer =
    addPreludeClasses
    <:> addInst [] (IsIn(""Ord"", tUnit))
    <:> addInst [] (IsIn(""Ord"", tChar))
    <:> addInst [] (IsIn(""Ord"", tInt))
    <:> addInst [IsIn(""Ord"", TVar(Tyvar(""a"", Star)));
                 IsIn(""Ord"", TVar(Tyvar(""b"", Star)))]
                (IsIn(""Ord"", pair (TVar(Tyvar(""a"", Star)))
                                  (TVar(Tyvar(""b"", Star)))))

  (* 7.3 Entailment *)

  let rec bySuper (ce:classEnv) (IsIn(i, t) as p) =
    p :: concat (map (fun i' -> bySuper ce (IsIn(i', t))) (super ce i))

  let _ =
    let preds = bySuper (exampleInsts initialEnv) (IsIn(""Num"", TVar(Tyvar(""a"", Star)))) in
    Printf.printf ""ps = %s\n"" (ps preds)

  let byInst (ce:classEnv) (IsIn(i, t) as p) =
    let tryInst (Qual(ps, h)) =
      try
       let u = matchPred h p in
       Some (map (predApply u) ps)
      with _ -> None in
    let rec msum = function
      | [] -> None
      | None :: xs -> msum xs
      | x :: _ -> x in
    msum (map tryInst (insts ce i))

  let _ =
    let preds = byInst (exampleInsts initialEnv) (IsIn(""Num"", TVar(Tyvar(""a"", Star)))) in
    match preds with
    | Some(preds) -> Printf.printf ""ps = some(%s)\n"" (ps preds)
    | None -> Printf.printf ""ps = none\n""

  let rec entail (ce:classEnv) ps p =
    exists (mem p) (map (bySuper ce) ps) ||
    match byInst ce p with
    | None -> false
    | Some qs -> for_all (entail ce ps) qs

  let _ =
    let p = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let ps = [p] in
    let result = entail (exampleInsts initialEnv) ps p in
    Printf.printf ""result = %b\n"" result

  (* 7.4 Context Reduction *)

  let inHnf (p:pred):bool =
    match p with
    | IsIn(_, t) ->
      let rec hnf = function
        | TVar _ -> true
        | TCon _ -> false
        | TAp(t, _) -> hnf t
        | TGen _ -> failwith ""context reduction on generic variable""
      in
      hnf t

  let _ =
    let r = inHnf (IsIn(""Num"",TVar(Tyvar(""a"", Star)))) in
    Printf.printf ""inHnf %b\n"" r; (* true *)
    let r = inHnf (IsIn(""Num"",tInt)) in
    Printf.printf ""inHnf %b\n"" r (* false *)

  let rec toHnfs (ce:classEnv) ps = concat (map (toHnf ce) ps)
  and toHnf (ce:classEnv) p =
    if inHnf p then [p]
    else
      match byInst ce p with
      | None -> failwith ""context reduction""
      | Some ps -> toHnfs ce ps

  let _ =
    let preds = [IsIn(""Num"",TVar(Tyvar(""a"", Star)))] in
    let preds = toHnfs initialEnv preds in
    Printf.printf ""toHnf %s\n"" (ps preds)

  let _ =
    let pred = IsIn(""Num"",TVar(Tyvar(""a"", Star))) in
    let preds = toHnf initialEnv pred in
    Printf.printf ""toHnf %s\n"" (ps preds)

  let simplify (ce:classEnv) ps =
    let rec loop rs = function
      | [] -> rs
      | p :: ps ->
        if entail ce (rs @ ps) p then loop rs ps
        else loop (p :: rs) ps in
    loop [] ps

  let _ =
    let pred = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let preds = [pred] in
    let preds = simplify (exampleInsts initialEnv) preds in
    Printf.printf ""simplify = %s\n"" (ps preds)

  let reduce (ce:classEnv) ps =
    simplify ce (toHnfs ce ps)

  let _ =
    let pred = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let preds = [pred] in
    let preds = reduce (exampleInsts initialEnv) preds in
    Printf.printf ""reduce = %s\n"" (ps preds)

  let scEntail (ce:classEnv) ps p =
    exists (mem p) (map (bySuper ce) ps)

  let _ =
    let pred = IsIn(""Num"", TVar(Tyvar(""a"", Star))) in
    let preds = [pred] in
    let result = scEntail (exampleInsts initialEnv) preds pred in
    Printf.printf ""scEntail = %b\n"" result
end

open Kind
open Type
open Subst
open Pred
(* 7.1 Basic definitions *)
let _ =

  (* predTv *)

  (* predsTv *)

  (* qualTypeTv *)

  (* lift *)

  (* mguPred *)
  (* matchPred *)

  (* class_ = Id.id list * inst list *)

  ()
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* The Flow server monitor needs to deal with multiple connections. There's the connection to the
 * server (a pipe), there's 0 or more connections to ephemeral clients (over a socket), and there's
 * 0 or more connections to persistent clients (over a socket). We need to be able to read and write
 * to all of these clients in a non-blocking and race-condition free manner.
 *
 * This module wraps a connection. The basic idea is as follows:
 *
 * 1. There is a loop which reads from the connection. When a message is received, we pass it to the
 *    on_read callback
 * 2. There is a stream of things to write to the connection. Other threads can add things to this
 *    stream
 * 3. There is a loop which reads from the stream and writes to the connection
 *
 * We didn't **really** need to make this a functor. CONNECTION.t could in theory be parameterized.
 * However, glevi liked writing `ServerConnection.write conn` over `Connection.write conn`. So it's
 * a minor stylistic choice.
 *)

module Logger = FlowServerMonitorLogger

module type CONNECTION_PROCESSOR = sig
  type in_message

  type out_message
end

type 'out_message command =
  | Write of 'out_message
  | WriteAndClose of 'out_message

module type CONNECTION = sig
  type t

  type in_message

  type out_message

  val create :
    name:(* A name for this connection for debugging messages *)
         string ->
    in_fd:(* The fd from which we should read *)
          Lwt_unix.file_descr ->
    out_fd:(* The fd to which we should write *)
           Lwt_unix.file_descr ->
    close:((* A function that closes the in and out fds *)
           unit -> unit Lwt.t) ->
    on_read:
      (msg:(* A callback for when we read a message from the in_fd *)
           in_message ->
      connection:t ->
      unit Lwt.t
      ) ->
    (* Returns the tuple (start, conn), where conn is the connection and `start ()` tells the
     * connection to reading from and writing to the fds *)
    ((unit -> unit) * t) Lwt.t

  val write : msg:out_message -> t -> bool

  val write_and_close : msg:out_message -> t -> bool

  val close_immediately : t -> unit Lwt.t

  val try_flush_and_close : t -> unit Lwt.t

  val is_closed : t -> bool

  val wait_for_closed : t -> unit Lwt.t
end

module Make (ConnectionProcessor : CONNECTION_PROCESSOR) :
  CONNECTION
    with type in_message := ConnectionProcessor.in_message
     and type out_message := ConnectionProcessor.out_message = struct
  type t = {
    name: string;
    in_fd: Lwt_unix.file_descr;
    out_fd: Lwt_unix.file_descr;
    command_stream: ConnectionProcessor.out_message command Lwt_stream.t;
    push_to_stream: ConnectionProcessor.out_message command option -> unit;
    close: unit -> unit Lwt.t;
    on_read: msg:ConnectionProcessor.in_message -> connection:t -> unit Lwt.t;
    read_thread: unit Lwt.t;
    command_thread: unit Lwt.t;
    wait_for_closed_thread: unit Lwt.t;
  }

  let send_command conn command =
    try
      conn.push_to_stream (Some command);
      true
    with
    | Lwt_stream.Closed -> false

  let close_stream conn =
    try conn.push_to_stream None with
    | Lwt_stream.Closed -> ()

  let write ~msg conn = send_command conn (Write msg)

  let write_and_close ~msg conn =
    let result = send_command conn (WriteAndClose msg) in
    close_stream conn;
    result

  (* Doesn't actually close the file descriptors, but does stop all the loops and streams *)
  let stop_everything conn =
    close_stream conn;
    Lwt.cancel conn.read_thread;
    Lwt.cancel conn.command_thread

  let close_immediately conn =
    stop_everything conn;
    conn.close ()

  let handle_command conn = function
    | Write msg ->
      let%lwt _size = Marshal_tools_lwt.to_fd_with_preamble conn.out_fd msg in
      Lwt.return_unit
    | WriteAndClose msg ->
      Lwt.cancel conn.command_thread;
      let%lwt _size = Marshal_tools_lwt.to_fd_with_preamble conn.out_fd msg in
      close_immediately conn

  (** Attempts to write everything available in the stream and then close the connection,
      but it's ok if we can't write because the socket is already closed. *)
  let try_flush_and_close conn =
    stop_everything conn;
    let%lwt () =
      try%lwt
        Lwt_list.iter_s (handle_command conn) (Lwt_stream.get_available conn.command_stream)
      with
      | Unix.Unix_error (Unix.EBADF, _, _)
      | Unix.Unix_error (Unix.EPIPE, _, _) ->
        (* connection already closed, ignore *)
        Lwt.return_unit
      | exn ->
        let exn = Exception.wrap exn in
        let%lwt () = conn.close () in
        Exception.reraise exn
    in
    conn.close ()

  let is_closed conn = Lwt_stream.is_closed conn.command_stream

  let wait_for_closed conn = conn.wait_for_closed_thread

  module CommandLoop = LwtLoop.Make (struct
    type acc = t

    let main conn =
      let%lwt command = Lwt_stream.next conn.command_stream in
      let%lwt () = handle_command conn command in
      Lwt.return conn

    let catch conn exn =
      match Exception.unwrap exn with
      (* The command stream has been closed. This means the command loop should gracefully exit *)
      | Lwt_stream.Empty -> Lwt.return_unit
      | _ ->
        let exn = Exception.to_exn exn in
        Logger.error
          ~exn
          ""Closing connection '%s' due to uncaught exception in command loop""
          conn.name;
        close_immediately conn
  end)

  module ReadLoop = LwtLoop.Make (struct
    type acc = t

    let main connection =
      let%lwt msg =
        ( Marshal_tools_lwt.from_fd_with_preamble connection.in_fd
          : ConnectionProcessor.in_message Lwt.t
          )
      in
      let%lwt () = connection.on_read ~msg ~connection in
      Lwt.return connection

    let catch connection exn =
      (match Exception.unwrap exn with
      | End_of_file
      | Unix.Unix_error (Unix.ECONNRESET, _, _) ->
        Logger.error ""Connection '%s' was closed from the other side"" connection.name
      | _ ->
        let exn = Exception.to_exn exn in
        Logger.error
          ~exn
          ""Closing connection '%s' due to uncaught exception in read loop""
          connection.name);
      close_immediately connection
  end)

  let create ~name ~in_fd ~out_fd ~close ~on_read =
    let (wait_for_closed_thread, close) =
      (* Lwt.wait creates a thread that can't be canceled *)
      let (wait_for_closed_thread, wakener) = Lwt.wait () in
      (* If we've already woken the thread, then do nothing *)
      let wakeup () =
        try Lwt.wakeup wakener () with
        | Invalid_argument _ -> ()
      in
      (* On close, wake wait_for_closed_thread *)
      let close () =
        let%lwt () = close () in
        wakeup ();
        Lwt.return_unit
      in
      (wait_for_closed_thread, close)
    in
    let (command_stream, push_to_stream) = Lwt_stream.create () in
    (* Lwt.task creates a thread that can be canceled *)
    let (paused_thread, wakener) = Lwt.task () in
    let conn =
      {
        name;
        in_fd;
        out_fd;
        command_stream;
        push_to_stream;
        close;
        on_read;
        command_thread =
          (let%lwt conn = paused_thread in
           CommandLoop.run conn
          );
        read_thread =
          (let%lwt conn = paused_thread in
           ReadLoop.run conn
          );
        wait_for_closed_thread;
      }
    in
    let start () = Lwt.wakeup wakener conn in
    Lwt.return (start, conn)
end
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*             Xavier Leroy, projet Cristal, INRIA Rocquencourt           *)
(*                                                                        *)
(*   Copyright 1996 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(* Entry points in the parser *)

(* Skip tokens to the end of the phrase *)

let last_token = ref Parser.EOF

let token lexbuf =
  let token = Lexer.token lexbuf in
  last_token := token;
  token

let rec skip_phrase lexbuf =
  match token lexbuf with
  | Parser.SEMISEMI | Parser.EOF -> ()
  | _ -> skip_phrase lexbuf
  | exception (Lexer.Error (Lexer.Unterminated_comment _, _)
              | Lexer.Error (Lexer.Unterminated_string, _)
              | Lexer.Error (Lexer.Reserved_sequence _, _)
              | Lexer.Error (Lexer.Unterminated_string_in_comment _, _)
              | Lexer.Error (Lexer.Illegal_character _, _)) ->
      skip_phrase lexbuf

let maybe_skip_phrase lexbuf =
  match !last_token with
  | Parser.SEMISEMI | Parser.EOF -> ()
  | _ -> skip_phrase lexbuf

type 'a parser =
  (Lexing.lexbuf -> Parser.token) -> Lexing.lexbuf -> 'a

let wrap (parser : 'a parser) lexbuf : 'a =
  try
    Docstrings.init ();
    Lexer.init ();
    let ast = parser token lexbuf in
    Parsing.clear_parser();
    Docstrings.warn_bad_docstrings ();
    last_token := Parser.EOF;
    ast
  with
  | Lexer.Error(Lexer.Illegal_character _, _) as err
    when !Location.input_name = ""//toplevel//""->
      skip_phrase lexbuf;
      raise err
  | Syntaxerr.Error _ as err
    when !Location.input_name = ""//toplevel//"" ->
      maybe_skip_phrase lexbuf;
      raise err
  | Parsing.Parse_error | Syntaxerr.Escape_error ->
      let loc = Location.curr lexbuf in
      if !Location.input_name = ""//toplevel//""
      then maybe_skip_phrase lexbuf;
      raise(Syntaxerr.Error(Syntaxerr.Other loc))

(* We pass [--strategy simplified] to Menhir, which means that we wish to use
   its ""simplified"" strategy for handling errors. When a syntax error occurs,
   the current token is replaced with an [error] token. The parser then
   continues shifting and reducing, as far as possible. After (possibly)
   shifting the [error] token, though, the parser remains in error-handling
   mode, and does not request the next token, so the current token remains
   [error].

   In OCaml's grammar, the [error] token always appears at the end of a
   production, and this production always raises an exception. In such
   a situation, the strategy described above means that:

   - either the parser will not be able to shift [error],
     and will raise [Parser.Error];

   - or it will be able to shift [error] and will then reduce
     a production whose semantic action raises an exception.

   In either case, the parser will not attempt to read one token past
   the syntax error. *)

let implementation = wrap Parser.implementation
and interface = wrap Parser.interface
and toplevel_phrase = wrap Parser.toplevel_phrase
and use_file = wrap Parser.use_file
and core_type = wrap Parser.parse_core_type
and expression = wrap Parser.parse_expression
and pattern = wrap Parser.parse_pattern
let module_type = wrap Parser.parse_module_type
let module_expr = wrap Parser.parse_module_expr

let longident = wrap Parser.parse_any_longident
let val_ident = wrap Parser.parse_val_longident
let constr_ident= wrap Parser.parse_constr_longident
let extended_module_path = wrap Parser.parse_mod_ext_longident
let simple_module_path = wrap Parser.parse_mod_longident
let type_ident = wrap Parser.parse_mty_longident

(* Error reporting for Syntaxerr *)
(* The code has been moved here so that one can reuse Pprintast.tyvar *)

let prepare_error err =
  let open Syntaxerr in
  match err with
  | Unclosed(opening_loc, opening, closing_loc, closing) ->
      Location.errorf
        ~loc:closing_loc
        ~sub:[
          Location.msg ~loc:opening_loc
            ""This '%s' might be unmatched"" opening
        ]
        ""Syntax error: '%s' expected"" closing

  | Expecting (loc, nonterm) ->
      Location.errorf ~loc ""Syntax error: %s expected."" nonterm
  | Not_expecting (loc, nonterm) ->
      Location.errorf ~loc ""Syntax error: %s not expected."" nonterm
  | Applicative_path loc ->
      Location.errorf ~loc
        ""Syntax error: applicative paths of the form F(X).t \
         are not supported when the option -no-app-func is set.""
  | Variable_in_scope (loc, var) ->
      Location.errorf ~loc
        ""In this scoped type, variable %a \
         is reserved for the local type %s.""
        Pprintast.tyvar var var
  | Other loc ->
      Location.errorf ~loc ""Syntax error""
  | Ill_formed_ast (loc, s) ->
      Location.errorf ~loc
        ""broken invariant in parsetree: %s"" s
  | Invalid_package_type (loc, s) ->
      Location.errorf ~loc ""invalid package type: %s"" s

let () =
  Location.register_error_of_exn
    (function
      | Syntaxerr.Error err -> Some (prepare_error err)
      | _ -> None
    )
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*             Xavier Leroy, projet Cristal, INRIA Rocquencourt           *)
(*                                                                        *)
(*   Copyright 1996 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(** Abstract syntax tree produced by parsing

  {b Warning:} this module is unstable and part of
  {{!Compiler_libs}compiler-libs}.

*)

open Asttypes

type constant =
    Pconst_integer of string * char option
  (* 3 3l 3L 3n

     Suffixes [g-z][G-Z] are accepted by the parser.
     Suffixes except 'l', 'L' and 'n' are rejected by the typechecker
  *)
  | Pconst_char of char
  (* 'c' *)
  | Pconst_string of string * Location.t * string option
  (* ""constant""
     {delim|other constant|delim}

     The location span the content of the string, without the delimiters.
  *)
  | Pconst_float of string * char option
  (* 3.4 2e5 1.4e-4

     Suffixes [g-z][G-Z] are accepted by the parser.
     Suffixes are rejected by the typechecker.
  *)

type location_stack = Location.t list

(** {1 Extension points} *)

type attribute = {
    attr_name : string loc;
    attr_payload : payload;
    attr_loc : Location.t;
  }
       (* [@id ARG]
          [@@id ARG]

          Metadata containers passed around within the AST.
          The compiler ignores unknown attributes.
       *)

and extension = string loc * payload
      (* [%id ARG]
         [%%id ARG]

         Sub-language placeholder -- rejected by the typechecker.
      *)

and attributes = attribute list

and payload =
  | PStr of structure
  | PSig of signature (* : SIG *)
  | PTyp of core_type  (* : T *)
  | PPat of pattern * expression option  (* ? P  or  ? P when E *)

(** {1 Core language} *)

(* Type expressions *)

and core_type =
    {
     ptyp_desc: core_type_desc;
     ptyp_loc: Location.t;
     ptyp_loc_stack: location_stack;
     ptyp_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and core_type_desc =
  | Ptyp_any
        (*  _ *)
  | Ptyp_var of string
        (* 'a *)
  | Ptyp_arrow of arg_label * core_type * core_type
        (* T1 -> T2       Simple
           ~l:T1 -> T2    Labelled
           ?l:T1 -> T2    Optional
         *)
  | Ptyp_tuple of core_type list
        (* T1 * ... * Tn

           Invariant: n >= 2
        *)
  | Ptyp_constr of Longident.t loc * core_type list
        (* tconstr
           T tconstr
           (T1, ..., Tn) tconstr
         *)
  | Ptyp_object of object_field list * closed_flag
        (* < l1:T1; ...; ln:Tn >     (flag = Closed)
           < l1:T1; ...; ln:Tn; .. > (flag = Open)
         *)
  | Ptyp_class of Longident.t loc * core_type list
        (* #tconstr
           T #tconstr
           (T1, ..., Tn) #tconstr
         *)
  | Ptyp_alias of core_type * string
        (* T as 'a *)
  | Ptyp_variant of row_field list * closed_flag * label list option
        (* [ `A|`B ]         (flag = Closed; labels = None)
           [> `A|`B ]        (flag = Open;   labels = None)
           [< `A|`B ]        (flag = Closed; labels = Some [])
           [< `A|`B > `X `Y ](flag = Closed; labels = Some [""X"";""Y""])
         *)
  | Ptyp_poly of string loc list * core_type
        (* 'a1 ... 'an. T

           Can only appear in the following context:

           - As the core_type of a Ppat_constraint node corresponding
             to a constraint on a let-binding: let x : 'a1 ... 'an. T
             = e ...

           - Under Cfk_virtual for methods (not values).

           - As the core_type of a Pctf_method node.

           - As the core_type of a Pexp_poly node.

           - As the pld_type field of a label_declaration.

           - As a core_type of a Ptyp_object node.

           - As the pval_type field of a value_description.
         *)

  | Ptyp_package of package_type
        (* (module S) *)
  | Ptyp_extension of extension
        (* [%id] *)

and package_type = Longident.t loc * (Longident.t loc * core_type) list
      (*
        (module S)
        (module S with type t1 = T1 and ... and tn = Tn)
       *)

and row_field = {
  prf_desc : row_field_desc;
  prf_loc : Location.t;
  prf_attributes : attributes;
}

and row_field_desc =
  | Rtag of label loc * bool * core_type list
        (* [`A]                   ( true,  [] )
           [`A of T]              ( false, [T] )
           [`A of T1 & .. & Tn]   ( false, [T1;...Tn] )
           [`A of & T1 & .. & Tn] ( true,  [T1;...Tn] )

          - The 'bool' field is true if the tag contains a
            constant (empty) constructor.
          - '&' occurs when several types are used for the same constructor
            (see 4.2 in the manual)
        *)
  | Rinherit of core_type
        (* [ | t ] *)

and object_field = {
  pof_desc : object_field_desc;
  pof_loc : Location.t;
  pof_attributes : attributes;
}

and object_field_desc =
  | Otag of label loc * core_type
  | Oinherit of core_type

(* Patterns *)

and pattern =
    {
     ppat_desc: pattern_desc;
     ppat_loc: Location.t;
     ppat_loc_stack: location_stack;
     ppat_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and pattern_desc =
  | Ppat_any
        (* _ *)
  | Ppat_var of string loc
        (* x *)
  | Ppat_alias of pattern * string loc
        (* P as 'a *)
  | Ppat_constant of constant
        (* 1, 'a', ""true"", 1.0, 1l, 1L, 1n *)
  | Ppat_interval of constant * constant
        (* 'a'..'z'

           Other forms of interval are recognized by the parser
           but rejected by the type-checker. *)
  | Ppat_tuple of pattern list
        (* (P1, ..., Pn)

           Invariant: n >= 2
        *)
  | Ppat_construct of
      Longident.t loc * (string loc list * pattern) option
        (* C                    None
           C P                  Some ([], P)
           C (P1, ..., Pn)      Some ([], Ppat_tuple [P1; ...; Pn])
           C (type a b) P       Some ([a; b], P)
         *)
  | Ppat_variant of label * pattern option
        (* `A             (None)
           `A P           (Some P)
         *)
  | Ppat_record of (Longident.t loc * pattern) list * closed_flag
        (* { l1=P1; ...; ln=Pn }     (flag = Closed)
           { l1=P1; ...; ln=Pn; _}   (flag = Open)

           Invariant: n > 0
         *)
  | Ppat_array of pattern list
        (* [| P1; ...; Pn |] *)
  | Ppat_or of pattern * pattern
        (* P1 | P2 *)
  | Ppat_constraint of pattern * core_type
        (* (P : T) *)
  | Ppat_type of Longident.t loc
        (* #tconst *)
  | Ppat_lazy of pattern
        (* lazy P *)
  | Ppat_unpack of string option loc
        (* (module P)        Some ""P""
           (module _)        None

           Note: (module P : S) is represented as
           Ppat_constraint(Ppat_unpack, Ptyp_package)
         *)
  | Ppat_exception of pattern
        (* exception P *)
  | Ppat_extension of extension
        (* [%id] *)
  | Ppat_open of Longident.t loc * pattern
        (* M.(P) *)

(* Value expressions *)

and expression =
    {
     pexp_desc: expression_desc;
     pexp_loc: Location.t;
     pexp_loc_stack: location_stack;
     pexp_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and expression_desc =
  | Pexp_ident of Longident.t loc
        (* x
           M.x
         *)
  | Pexp_constant of constant
        (* 1, 'a', ""true"", 1.0, 1l, 1L, 1n *)
  | Pexp_let of rec_flag * value_binding list * expression
        (* let P1 = E1 and ... and Pn = EN in E       (flag = Nonrecursive)
           let rec P1 = E1 and ... and Pn = EN in E   (flag = Recursive)
         *)
  | Pexp_function of case list
        (* function P1 -> E1 | ... | Pn -> En *)
  | Pexp_fun of arg_label * expression option * pattern * expression
        (* fun P -> E1                          (Simple, None)
           fun ~l:P -> E1                       (Labelled l, None)
           fun ?l:P -> E1                       (Optional l, None)
           fun ?l:(P = E0) -> E1                (Optional l, Some E0)

           Notes:
           - If E0 is provided, only Optional is allowed.
           - ""fun P1 P2 .. Pn -> E1"" is represented as nested Pexp_fun.
           - ""let f P = E"" is represented using Pexp_fun.
         *)
  | Pexp_apply of expression * (arg_label * expression) list
        (* E0 ~l1:E1 ... ~ln:En
           li can be empty (non labeled argument) or start with '?'
           (optional argument).

           Invariant: n > 0
         *)
  | Pexp_match of expression * case list
        (* match E0 with P1 -> E1 | ... | Pn -> En *)
  | Pexp_try of expression * case list
        (* try E0 with P1 -> E1 | ... | Pn -> En *)
  | Pexp_tuple of expression list
        (* (E1, ..., En)

           Invariant: n >= 2
        *)
  | Pexp_construct of Longident.t loc * expression option
        (* C                None
           C E              Some E
           C (E1, ..., En)  Some (Pexp_tuple[E1;...;En])
        *)
  | Pexp_variant of label * expression option
        (* `A             (None)
           `A E           (Some E)
         *)
  | Pexp_record of (Longident.t loc * expression) list * expression option
        (* { l1=P1; ...; ln=Pn }     (None)
           { E0 with l1=P1; ...; ln=Pn }   (Some E0)

           Invariant: n > 0
         *)
  | Pexp_field of expression * Longident.t loc
        (* E.l *)
  | Pexp_setfield of expression * Longident.t loc * expression
        (* E1.l <- E2 *)
  | Pexp_array of expression list
        (* [| E1; ...; En |] *)
  | Pexp_ifthenelse of expression * expression * expression option
        (* if E1 then E2 else E3 *)
  | Pexp_sequence of expression * expression
        (* E1; E2 *)
  | Pexp_while of expression * expression
        (* while E1 do E2 done *)
  | Pexp_for of
      pattern *  expression * expression * direction_flag * expression
        (* for i = E1 to E2 do E3 done      (flag = Upto)
           for i = E1 downto E2 do E3 done  (flag = Downto)
         *)
  | Pexp_constraint of expression * core_type
        (* (E : T) *)
  | Pexp_coerce of expression * core_type option * core_type
        (* (E :> T)        (None, T)
           (E : T0 :> T)   (Some T0, T)
         *)
  | Pexp_send of expression * label loc
        (*  E # m *)
  | Pexp_new of Longident.t loc
        (* new M.c *)
  | Pexp_setinstvar of label loc * expression
        (* x <- 2 *)
  | Pexp_override of (label loc * expression) list
        (* {< x1 = E1; ...; Xn = En >} *)
  | Pexp_letmodule of string option loc * module_expr * expression
        (* let module M = ME in E *)
  | Pexp_letexception of extension_constructor * expression
        (* let exception C in E *)
  | Pexp_assert of expression
        (* assert E
           Note: ""assert false"" is treated in a special way by the
           type-checker. *)
  | Pexp_lazy of expression
        (* lazy E *)
  | Pexp_poly of expression * core_type option
        (* Used for method bodies.

           Can only be used as the expression under Cfk_concrete
           for methods (not values). *)
  | Pexp_object of class_structure
        (* object ... end *)
  | Pexp_newtype of string loc * expression
        (* fun (type t) -> E *)
  | Pexp_pack of module_expr
        (* (module ME)

           (module ME : S) is represented as
           Pexp_constraint(Pexp_pack, Ptyp_package S) *)
  | Pexp_open of open_declaration * expression
        (* M.(E)
           let open M in E
           let open! M in E *)
  | Pexp_letop of letop
        (* let* P = E in E
           let* P = E and* P = E in E *)
  | Pexp_extension of extension
        (* [%id] *)
  | Pexp_unreachable
        (* . *)

and case =   (* (P -> E) or (P when E0 -> E) *)
    {
     pc_lhs: pattern;
     pc_guard: expression option;
     pc_rhs: expression;
   }

and letop =
  {
    let_ : binding_op;
    ands : binding_op list;
    body : expression;
  }

and binding_op =
  {
    pbop_op : string loc;
    pbop_pat : pattern;
    pbop_exp : expression;
    pbop_loc : Location.t;
  }

(* Value descriptions *)

and value_description =
    {
     pval_name: string loc;
     pval_type: core_type;
     pval_prim: string list;
     pval_attributes: attributes;  (* ... [@@id1] [@@id2] *)
     pval_loc: Location.t;
    }

(*
  val x: T                            (prim = [])
  external x: T = ""s1"" ... ""sn""       (prim = [""s1"";...""sn""])
*)

(* Type declarations *)

and type_declaration =
    {
     ptype_name: string loc;
     ptype_params: (core_type * (variance * injectivity)) list;
           (* ('a1,...'an) t; None represents  _*)
     ptype_cstrs: (core_type * core_type * Location.t) list;
           (* ... constraint T1=T1'  ... constraint Tn=Tn' *)
     ptype_kind: type_kind;
     ptype_private: private_flag;   (* = private ... *)
     ptype_manifest: core_type option;  (* = T *)
     ptype_attributes: attributes;   (* ... [@@id1] [@@id2] *)
     ptype_loc: Location.t;
    }

(*
  type t                     (abstract, no manifest)
  type t = T0                (abstract, manifest=T0)
  type t = C of T | ...      (variant,  no manifest)
  type t = T0 = C of T | ... (variant,  manifest=T0)
  type t = {l: T; ...}       (record,   no manifest)
  type t = T0 = {l : T; ...} (record,   manifest=T0)
  type t = ..                (open,     no manifest)
*)

and type_kind =
  | Ptype_abstract
  | Ptype_variant of constructor_declaration list
  | Ptype_record of label_declaration list
        (* Invariant: non-empty list *)
  | Ptype_open

and label_declaration =
    {
     pld_name: string loc;
     pld_mutable: mutable_flag;
     pld_type: core_type;
     pld_loc: Location.t;
     pld_attributes: attributes; (* l : T [@id1] [@id2] *)
    }

(*  { ...; l: T; ... }            (mutable=Immutable)
    { ...; mutable l: T; ... }    (mutable=Mutable)

    Note: T can be a Ptyp_poly.
*)

and constructor_declaration =
    {
     pcd_name: string loc;
     pcd_vars: string loc list;
     pcd_args: constructor_arguments;
     pcd_res: core_type option;
     pcd_loc: Location.t;
     pcd_attributes: attributes; (* C of ... [@id1] [@id2] *)
    }

and constructor_arguments =
  | Pcstr_tuple of core_type list
  | Pcstr_record of label_declaration list

(*
  | C of T1 * ... * Tn     (res = None,    args = Pcstr_tuple [])
  | C: T0                  (res = Some T0, args = [])
  | C: T1 * ... * Tn -> T0 (res = Some T0, args = Pcstr_tuple)
  | C of {...}             (res = None,    args = Pcstr_record)
  | C: {...} -> T0         (res = Some T0, args = Pcstr_record)
  | C of {...} as t        (res = None,    args = Pcstr_record)
*)

and type_extension =
    {
     ptyext_path: Longident.t loc;
     ptyext_params: (core_type * (variance * injectivity)) list;
     ptyext_constructors: extension_constructor list;
     ptyext_private: private_flag;
     ptyext_loc: Location.t;
     ptyext_attributes: attributes;   (* ... [@@id1] [@@id2] *)
    }
(*
  type t += ...
*)

and extension_constructor =
    {
     pext_name: string loc;
     pext_kind : extension_constructor_kind;
     pext_loc : Location.t;
     pext_attributes: attributes; (* C of ... [@id1] [@id2] *)
   }

(* exception E *)
and type_exception =
  {
    ptyexn_constructor: extension_constructor;
    ptyexn_loc: Location.t;
    ptyexn_attributes: attributes; (* ... [@@id1] [@@id2] *)
  }

and extension_constructor_kind =
    Pext_decl of string loc list * constructor_arguments * core_type option
      (*
         | C of T1 * ... * Tn     ([], [T1; ...; Tn], None)
         | C: T0                  ([], [], Some T0)
         | C: T1 * ... * Tn -> T0 ([], [T1; ...; Tn], Some T0)
         | C: 'a... . T1... -> T0 (['a;...]; [T1;...], Some T0)
       *)
  | Pext_rebind of Longident.t loc
      (*
         | C = D
       *)

(** {1 Class language} *)

(* Type expressions for the class language *)

and class_type =
    {
     pcty_desc: class_type_desc;
     pcty_loc: Location.t;
     pcty_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and class_type_desc =
  | Pcty_constr of Longident.t loc * core_type list
        (* c
           ['a1, ..., 'an] c *)
  | Pcty_signature of class_signature
        (* object ... end *)
  | Pcty_arrow of arg_label * core_type * class_type
        (* T -> CT       Simple
           ~l:T -> CT    Labelled l
           ?l:T -> CT    Optional l
         *)
  | Pcty_extension of extension
        (* [%id] *)
  | Pcty_open of open_description * class_type
        (* let open M in CT *)

and class_signature =
    {
     pcsig_self: core_type;
     pcsig_fields: class_type_field list;
    }
(* object('selfpat) ... end
   object ... end             (self = Ptyp_any)
 *)

and class_type_field =
    {
     pctf_desc: class_type_field_desc;
     pctf_loc: Location.t;
     pctf_attributes: attributes; (* ... [@@id1] [@@id2] *)
    }

and class_type_field_desc =
  | Pctf_inherit of class_type
        (* inherit CT *)
  | Pctf_val of (label loc * mutable_flag * virtual_flag * core_type)
        (* val x: T *)
  | Pctf_method  of (label loc * private_flag * virtual_flag * core_type)
        (* method x: T

           Note: T can be a Ptyp_poly.
         *)
  | Pctf_constraint  of (core_type * core_type)
        (* constraint T1 = T2 *)
  | Pctf_attribute of attribute
        (* [@@@id] *)
  | Pctf_extension of extension
        (* [%%id] *)

and 'a class_infos =
    {
     pci_virt: virtual_flag;
     pci_params: (core_type * (variance * injectivity)) list;
     pci_name: string loc;
     pci_expr: 'a;
     pci_loc: Location.t;
     pci_attributes: attributes;  (* ... [@@id1] [@@id2] *)
    }
(* class c = ...
   class ['a1,...,'an] c = ...
   class virtual c = ...

   Also used for ""class type"" declaration.
*)

and class_description = class_type class_infos

and class_type_declaration = class_type class_infos

(* Value expressions for the class language *)

and class_expr =
    {
     pcl_desc: class_expr_desc;
     pcl_loc: Location.t;
     pcl_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and class_expr_desc =
  | Pcl_constr of Longident.t loc * core_type list
        (* c
           ['a1, ..., 'an] c *)
  | Pcl_structure of class_structure
        (* object ... end *)
  | Pcl_fun of arg_label * expression option * pattern * class_expr
        (* fun P -> CE                          (Simple, None)
           fun ~l:P -> CE                       (Labelled l, None)
           fun ?l:P -> CE                       (Optional l, None)
           fun ?l:(P = E0) -> CE                (Optional l, Some E0)
         *)
  | Pcl_apply of class_expr * (arg_label * expression) list
        (* CE ~l1:E1 ... ~ln:En
           li can be empty (non labeled argument) or start with '?'
           (optional argument).

           Invariant: n > 0
         *)
  | Pcl_let of rec_flag * value_binding list * class_expr
        (* let P1 = E1 and ... and Pn = EN in CE      (flag = Nonrecursive)
           let rec P1 = E1 and ... and Pn = EN in CE  (flag = Recursive)
         *)
  | Pcl_constraint of class_expr * class_type
        (* (CE : CT) *)
  | Pcl_extension of extension
  (* [%id] *)
  | Pcl_open of open_description * class_expr
  (* let open M in CE *)


and class_structure =
    {
     pcstr_self: pattern;
     pcstr_fields: class_field list;
    }
(* object(selfpat) ... end
   object ... end           (self = Ppat_any)
 *)

and class_field =
    {
     pcf_desc: class_field_desc;
     pcf_loc: Location.t;
     pcf_attributes: attributes; (* ... [@@id1] [@@id2] *)
    }

and class_field_desc =
  | Pcf_inherit of override_flag * class_expr * string loc option
        (* inherit CE
           inherit CE as x
           inherit! CE
           inherit! CE as x
         *)
  | Pcf_val of (label loc * mutable_flag * class_field_kind)
        (* val x = E
           val virtual x: T
         *)
  | Pcf_method of (label loc * private_flag * class_field_kind)
        (* method x = E            (E can be a Pexp_poly)
           method virtual x: T     (T can be a Ptyp_poly)
         *)
  | Pcf_constraint of (core_type * core_type)
        (* constraint T1 = T2 *)
  | Pcf_initializer of expression
        (* initializer E *)
  | Pcf_attribute of attribute
        (* [@@@id] *)
  | Pcf_extension of extension
        (* [%%id] *)

and class_field_kind =
  | Cfk_virtual of core_type
  | Cfk_concrete of override_flag * expression

and class_declaration = class_expr class_infos

(** {1 Module language} *)

(* Type expressions for the module language *)

and module_type =
    {
     pmty_desc: module_type_desc;
     pmty_loc: Location.t;
     pmty_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and module_type_desc =
  | Pmty_ident of Longident.t loc
        (* S *)
  | Pmty_signature of signature
        (* sig ... end *)
  | Pmty_functor of functor_parameter * module_type
        (* functor(X : MT1) -> MT2 *)
  | Pmty_with of module_type * with_constraint list
        (* MT with ... *)
  | Pmty_typeof of module_expr
        (* module type of ME *)
  | Pmty_extension of extension
        (* [%id] *)
  | Pmty_alias of Longident.t loc
        (* (module M) *)

and functor_parameter =
  | Unit
        (* () *)
  | Named of string option loc * module_type
        (* (X : MT)          Some X, MT
           (_ : MT)          None, MT *)

and signature = signature_item list

and signature_item =
    {
     psig_desc: signature_item_desc;
     psig_loc: Location.t;
    }

and signature_item_desc =
  | Psig_value of value_description
        (*
          val x: T
          external x: T = ""s1"" ... ""sn""
         *)
  | Psig_type of rec_flag * type_declaration list
        (* type t1 = ... and ... and tn  = ... *)
  | Psig_typesubst of type_declaration list
        (* type t1 := ... and ... and tn := ...  *)
  | Psig_typext of type_extension
        (* type t1 += ... *)
  | Psig_exception of type_exception
        (* exception C of T *)
  | Psig_module of module_declaration
        (* module X = M
           module X : MT *)
  | Psig_modsubst of module_substitution
        (* module X := M *)
  | Psig_recmodule of module_declaration list
        (* module rec X1 : MT1 and ... and Xn : MTn *)
  | Psig_modtype of module_type_declaration
        (* module type S = MT
           module type S *)
  | Psig_modtypesubst of module_type_declaration
        (* module type S :=  ...  *)
  | Psig_open of open_description
        (* open X *)
  | Psig_include of include_description
        (* include MT *)
  | Psig_class of class_description list
        (* class c1 : ... and ... and cn : ... *)
  | Psig_class_type of class_type_declaration list
        (* class type ct1 = ... and ... and ctn = ... *)
  | Psig_attribute of attribute
        (* [@@@id] *)
  | Psig_extension of extension * attributes
        (* [%%id] *)

and module_declaration =
    {
     pmd_name: string option loc;
     pmd_type: module_type;
     pmd_attributes: attributes; (* ... [@@id1] [@@id2] *)
     pmd_loc: Location.t;
    }
(* S : MT *)

and module_substitution =
    {
     pms_name: string loc;
     pms_manifest: Longident.t loc;
     pms_attributes: attributes; (* ... [@@id1] [@@id2] *)
     pms_loc: Location.t;
    }
(* S := M *)

and module_type_declaration =
    {
     pmtd_name: string loc;
     pmtd_type: module_type option;
     pmtd_attributes: attributes; (* ... [@@id1] [@@id2] *)
     pmtd_loc: Location.t;
    }
(* S = MT
   S       (abstract module type declaration, pmtd_type = None)
*)

and 'a open_infos =
    {
     popen_expr: 'a;
     popen_override: override_flag;
     popen_loc: Location.t;
     popen_attributes: attributes;
    }
(* open! X - popen_override = Override (silences the 'used identifier
                              shadowing' warning)
   open  X - popen_override = Fresh
 *)

and open_description = Longident.t loc open_infos
(* open M.N
   open M(N).O *)

and open_declaration = module_expr open_infos
(* open M.N
   open M(N).O
   open struct ... end *)

and 'a include_infos =
    {
     pincl_mod: 'a;
     pincl_loc: Location.t;
     pincl_attributes: attributes;
    }

and include_description = module_type include_infos
(* include MT *)

and include_declaration = module_expr include_infos
(* include ME *)

and with_constraint =
  | Pwith_type of Longident.t loc * type_declaration
        (* with type X.t = ...

           Note: the last component of the longident must match
           the name of the type_declaration. *)
  | Pwith_module of Longident.t loc * Longident.t loc
        (* with module X.Y = Z *)
  | Pwith_modtype of Longident.t loc * module_type
        (* with module type X.Y = Z *)
  | Pwith_modtypesubst of Longident.t loc * module_type
        (* with module type X.Y := sig end *)
  | Pwith_typesubst of Longident.t loc * type_declaration
        (* with type X.t := ..., same format as [Pwith_type] *)
  | Pwith_modsubst of Longident.t loc * Longident.t loc
        (* with module X.Y := Z *)

(* Value expressions for the module language *)

and module_expr =
    {
     pmod_desc: module_expr_desc;
     pmod_loc: Location.t;
     pmod_attributes: attributes; (* ... [@id1] [@id2] *)
    }

and module_expr_desc =
  | Pmod_ident of Longident.t loc
        (* X *)
  | Pmod_structure of structure
        (* struct ... end *)
  | Pmod_functor of functor_parameter * module_expr
        (* functor(X : MT1) -> ME *)
  | Pmod_apply of module_expr * module_expr
        (* ME1(ME2) *)
  | Pmod_constraint of module_expr * module_type
        (* (ME : MT) *)
  | Pmod_unpack of expression
        (* (val E) *)
  | Pmod_extension of extension
        (* [%id] *)

and structure = structure_item list

and structure_item =
    {
     pstr_desc: structure_item_desc;
     pstr_loc: Location.t;
    }

and structure_item_desc =
  | Pstr_eval of expression * attributes
        (* E *)
  | Pstr_value of rec_flag * value_binding list
        (* let P1 = E1 and ... and Pn = EN       (flag = Nonrecursive)
           let rec P1 = E1 and ... and Pn = EN   (flag = Recursive)
         *)
  | Pstr_primitive of value_description
        (*  val x: T
            external x: T = ""s1"" ... ""sn"" *)
  | Pstr_type of rec_flag * type_declaration list
        (* type t1 = ... and ... and tn = ... *)
  | Pstr_typext of type_extension
        (* type t1 += ... *)
  | Pstr_exception of type_exception
        (* exception C of T
           exception C = M.X *)
  | Pstr_module of module_binding
        (* module X = ME *)
  | Pstr_recmodule of module_binding list
        (* module rec X1 = ME1 and ... and Xn = MEn *)
  | Pstr_modtype of module_type_declaration
        (* module type S = MT *)
  | Pstr_open of open_declaration
        (* open X *)
  | Pstr_class of class_declaration list
        (* class c1 = ... and ... and cn = ... *)
  | Pstr_class_type of class_type_declaration list
        (* class type ct1 = ... and ... and ctn = ... *)
  | Pstr_include of include_declaration
        (* include ME *)
  | Pstr_attribute of attribute
        (* [@@@id] *)
  | Pstr_extension of extension * attributes
        (* [%%id] *)

and value_binding =
  {
    pvb_pat: pattern;
    pvb_expr: expression;
    pvb_attributes: attributes;
    pvb_loc: Location.t;
  }

and module_binding =
    {
     pmb_name: string option loc;
     pmb_expr: module_expr;
     pmb_attributes: attributes;
     pmb_loc: Location.t;
    }
(* X = ME *)

(** {1 Toplevel} *)

(* Toplevel phrases *)

type toplevel_phrase =
  | Ptop_def of structure
  | Ptop_dir of toplevel_directive
     (* #use, #load ... *)

and toplevel_directive =
  {
    pdir_name : string loc;
    pdir_arg : directive_argument option;
    pdir_loc : Location.t;
  }

and directive_argument =
  {
    pdira_desc : directive_argument_desc;
    pdira_loc : Location.t;
  }

and directive_argument_desc =
  | Pdir_string of string
  | Pdir_int of string * char option
  | Pdir_ident of Longident.t
  | Pdir_bool of bool
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*                         Alain Frisch, LexiFi                           *)
(*                                                                        *)
(*   Copyright 2012 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(* A generic Parsetree mapping class *)

(*
[@@@ocaml.warning ""+9""]
  (* Ensure that record patterns don't miss any field. *)
*)

open Parsetree
open Ast_helper
open Location

module String = Misc.Stdlib.String

type mapper = {
  attribute: mapper -> attribute -> attribute;
  attributes: mapper -> attribute list -> attribute list;
  binding_op: mapper -> binding_op -> binding_op;
  case: mapper -> case -> case;
  cases: mapper -> case list -> case list;
  class_declaration: mapper -> class_declaration -> class_declaration;
  class_description: mapper -> class_description -> class_description;
  class_expr: mapper -> class_expr -> class_expr;
  class_field: mapper -> class_field -> class_field;
  class_signature: mapper -> class_signature -> class_signature;
  class_structure: mapper -> class_structure -> class_structure;
  class_type: mapper -> class_type -> class_type;
  class_type_declaration: mapper -> class_type_declaration
                          -> class_type_declaration;
  class_type_field: mapper -> class_type_field -> class_type_field;
  constant: mapper -> constant -> constant;
  constructor_declaration: mapper -> constructor_declaration
                           -> constructor_declaration;
  expr: mapper -> expression -> expression;
  extension: mapper -> extension -> extension;
  extension_constructor: mapper -> extension_constructor
                         -> extension_constructor;
  include_declaration: mapper -> include_declaration -> include_declaration;
  include_description: mapper -> include_description -> include_description;
  label_declaration: mapper -> label_declaration -> label_declaration;
  location: mapper -> Location.t -> Location.t;
  module_binding: mapper -> module_binding -> module_binding;
  module_declaration: mapper -> module_declaration -> module_declaration;
  module_substitution: mapper -> module_substitution -> module_substitution;
  module_expr: mapper -> module_expr -> module_expr;
  module_type: mapper -> module_type -> module_type;
  module_type_declaration: mapper -> module_type_declaration
                           -> module_type_declaration;
  open_declaration: mapper -> open_declaration -> open_declaration;
  open_description: mapper -> open_description -> open_description;
  pat: mapper -> pattern -> pattern;
  payload: mapper -> payload -> payload;
  signature: mapper -> signature -> signature;
  signature_item: mapper -> signature_item -> signature_item;
  structure: mapper -> structure -> structure;
  structure_item: mapper -> structure_item -> structure_item;
  typ: mapper -> core_type -> core_type;
  type_declaration: mapper -> type_declaration -> type_declaration;
  type_extension: mapper -> type_extension -> type_extension;
  type_exception: mapper -> type_exception -> type_exception;
  type_kind: mapper -> type_kind -> type_kind;
  value_binding: mapper -> value_binding -> value_binding;
  value_description: mapper -> value_description -> value_description;
  with_constraint: mapper -> with_constraint -> with_constraint;
  directive_argument: mapper -> directive_argument -> directive_argument;
  toplevel_directive: mapper -> toplevel_directive -> toplevel_directive;
  toplevel_phrase: mapper -> toplevel_phrase -> toplevel_phrase;
  repl_phrase: mapper -> repl_phrase -> repl_phrase;
}

let map_fst f (x, y) = (f x, y)
let map_snd f (x, y) = (x, f y)
let map_tuple f1 f2 (x, y) = (f1 x, f2 y)
let map_tuple3 f1 f2 f3 (x, y, z) = (f1 x, f2 y, f3 z)
let map_opt f = function None -> None | Some x -> Some (f x)

let map_loc sub {loc; txt} = {loc = sub.location sub loc; txt}

module C = struct
  (* Constants *)

  let map sub { pconst_desc; pconst_loc } =
    let loc = sub.location sub pconst_loc in
    let desc =
      match pconst_desc with
      | Pconst_integer _
      | Pconst_char _
      | Pconst_float _ ->
          pconst_desc
      | Pconst_string (s, loc, quotation_delimiter) ->
          Pconst_string (s, sub.location sub loc, quotation_delimiter)
    in
    Const.mk ~loc desc
end

module T = struct
  (* Type expressions for the core language *)

  let row_field sub {
      prf_desc;
      prf_loc;
      prf_attributes;
    } =
    let loc = sub.location sub prf_loc in
    let attrs = sub.attributes sub prf_attributes in
    let desc = match prf_desc with
      | Rtag (l, b, tl) -> Rtag (map_loc sub l, b, List.map (sub.typ sub) tl)
      | Rinherit t -> Rinherit (sub.typ sub t)
    in
    Rf.mk ~loc ~attrs desc

  let object_field sub {
      pof_desc;
      pof_loc;
      pof_attributes;
    } =
    let loc = sub.location sub pof_loc in
    let attrs = sub.attributes sub pof_attributes in
    let desc = match pof_desc with
      | Otag (l, t) -> Otag (map_loc sub l, sub.typ sub t)
      | Oinherit t -> Oinherit (sub.typ sub t)
    in
    Of.mk ~loc ~attrs desc

  let map sub {ptyp_desc = desc; ptyp_loc = loc; ptyp_attributes = attrs} =
    let open Typ in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Ptyp_any -> any ~loc ~attrs ()
    | Ptyp_var s -> var ~loc ~attrs s
    | Ptyp_arrow (lab, t1, t2) ->
        arrow ~loc ~attrs lab (sub.typ sub t1) (sub.typ sub t2)
    | Ptyp_tuple tyl -> tuple ~loc ~attrs (List.map (sub.typ sub) tyl)
    | Ptyp_constr (lid, tl) ->
        constr ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tl)
    | Ptyp_object (l, o) ->
        object_ ~loc ~attrs (List.map (object_field sub) l) o
    | Ptyp_class (lid, tl) ->
        class_ ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tl)
    | Ptyp_alias (t, s) -> alias ~loc ~attrs (sub.typ sub t) s
    | Ptyp_variant (rl, b, ll) ->
        variant ~loc ~attrs (List.map (row_field sub) rl) b ll
    | Ptyp_poly (sl, t) -> poly ~loc ~attrs
                             (List.map (map_loc sub) sl) (sub.typ sub t)
    | Ptyp_package (lid, l) ->
        package ~loc ~attrs (map_loc sub lid)
          (List.map (map_tuple (map_loc sub) (sub.typ sub)) l)
    | Ptyp_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_type_declaration sub
      {ptype_name; ptype_params; ptype_cstrs;
       ptype_kind;
       ptype_private;
       ptype_manifest;
       ptype_attributes;
       ptype_loc} =
    let loc = sub.location sub ptype_loc in
    let attrs = sub.attributes sub ptype_attributes in
    Type.mk ~loc ~attrs (map_loc sub ptype_name)
      ~params:(List.map (map_fst (sub.typ sub)) ptype_params)
      ~priv:ptype_private
      ~cstrs:(List.map
                (map_tuple3 (sub.typ sub) (sub.typ sub) (sub.location sub))
                ptype_cstrs)
      ~kind:(sub.type_kind sub ptype_kind)
      ?manifest:(map_opt (sub.typ sub) ptype_manifest)

  let map_type_kind sub = function
    | Ptype_abstract -> Ptype_abstract
    | Ptype_variant l ->
        Ptype_variant (List.map (sub.constructor_declaration sub) l)
    | Ptype_record l -> Ptype_record (List.map (sub.label_declaration sub) l)
    | Ptype_open -> Ptype_open

  let map_constructor_arguments sub = function
    | Pcstr_tuple l -> Pcstr_tuple (List.map (sub.typ sub) l)
    | Pcstr_record l ->
        Pcstr_record (List.map (sub.label_declaration sub) l)

  let map_type_extension sub
      {ptyext_path; ptyext_params;
       ptyext_constructors;
       ptyext_private;
       ptyext_loc;
       ptyext_attributes} =
    let loc = sub.location sub ptyext_loc in
    let attrs = sub.attributes sub ptyext_attributes in
    Te.mk ~loc ~attrs
      (map_loc sub ptyext_path)
      (List.map (sub.extension_constructor sub) ptyext_constructors)
      ~params:(List.map (map_fst (sub.typ sub)) ptyext_params)
      ~priv:ptyext_private

  let map_type_exception sub
      {ptyexn_constructor; ptyexn_loc; ptyexn_attributes} =
    let loc = sub.location sub ptyexn_loc in
    let attrs = sub.attributes sub ptyexn_attributes in
    Te.mk_exception ~loc ~attrs
      (sub.extension_constructor sub ptyexn_constructor)

  let map_extension_constructor_kind sub = function
      Pext_decl(vars, ctl, cto) ->
        Pext_decl(List.map (map_loc sub) vars,
                  map_constructor_arguments sub ctl,
                  map_opt (sub.typ sub) cto)
    | Pext_rebind li ->
        Pext_rebind (map_loc sub li)

  let map_extension_constructor sub
      {pext_name;
       pext_kind;
       pext_loc;
       pext_attributes} =
    let loc = sub.location sub pext_loc in
    let attrs = sub.attributes sub pext_attributes in
    Te.constructor ~loc ~attrs
      (map_loc sub pext_name)
      (map_extension_constructor_kind sub pext_kind)

end

module CT = struct
  (* Type expressions for the class language *)

  let map sub {pcty_loc = loc; pcty_desc = desc; pcty_attributes = attrs} =
    let open Cty in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pcty_constr (lid, tys) ->
        constr ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tys)
    | Pcty_signature x -> signature ~loc ~attrs (sub.class_signature sub x)
    | Pcty_arrow (lab, t, ct) ->
        arrow ~loc ~attrs lab (sub.typ sub t) (sub.class_type sub ct)
    | Pcty_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pcty_open (o, ct) ->
        open_ ~loc ~attrs (sub.open_description sub o) (sub.class_type sub ct)

  let map_field sub {pctf_desc = desc; pctf_loc = loc; pctf_attributes = attrs}
    =
    let open Ctf in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pctf_inherit ct -> inherit_ ~loc ~attrs (sub.class_type sub ct)
    | Pctf_val (s, m, v, t) ->
        val_ ~loc ~attrs (map_loc sub s) m v (sub.typ sub t)
    | Pctf_method (s, p, v, t) ->
        method_ ~loc ~attrs (map_loc sub s) p v (sub.typ sub t)
    | Pctf_constraint (t1, t2) ->
        constraint_ ~loc ~attrs (sub.typ sub t1) (sub.typ sub t2)
    | Pctf_attribute x -> attribute ~loc (sub.attribute sub x)
    | Pctf_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_signature sub {pcsig_self; pcsig_fields} =
    Csig.mk
      (sub.typ sub pcsig_self)
      (List.map (sub.class_type_field sub) pcsig_fields)
end

let map_functor_param sub = function
  | Unit -> Unit
  | Named (s, mt) -> Named (map_loc sub s, sub.module_type sub mt)

module MT = struct
  (* Type expressions for the module language *)

  let map sub {pmty_desc = desc; pmty_loc = loc; pmty_attributes = attrs} =
    let open Mty in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pmty_ident s -> ident ~loc ~attrs (map_loc sub s)
    | Pmty_alias s -> alias ~loc ~attrs (map_loc sub s)
    | Pmty_signature sg -> signature ~loc ~attrs (sub.signature sub sg)
    | Pmty_functor (param, mt) ->
        functor_ ~loc ~attrs
          (map_functor_param sub param)
          (sub.module_type sub mt)
    | Pmty_with (mt, l) ->
        with_ ~loc ~attrs (sub.module_type sub mt)
          (List.map (sub.with_constraint sub) l)
    | Pmty_typeof me -> typeof_ ~loc ~attrs (sub.module_expr sub me)
    | Pmty_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_with_constraint sub = function
    | Pwith_type (lid, d) ->
        Pwith_type (map_loc sub lid, sub.type_declaration sub d)
    | Pwith_module (lid, lid2) ->
        Pwith_module (map_loc sub lid, map_loc sub lid2)
    | Pwith_modtype (lid, mty) ->
        Pwith_modtype (map_loc sub lid, sub.module_type sub mty)
    | Pwith_typesubst (lid, d) ->
        Pwith_typesubst (map_loc sub lid, sub.type_declaration sub d)
    | Pwith_modsubst (s, lid) ->
        Pwith_modsubst (map_loc sub s, map_loc sub lid)
    | Pwith_modtypesubst (lid, mty) ->
        Pwith_modtypesubst (map_loc sub lid, sub.module_type sub mty)

  let map_signature_item sub {psig_desc = desc; psig_loc = loc} =
    let open Sig in
    let loc = sub.location sub loc in
    match desc with
    | Psig_value vd -> value ~loc (sub.value_description sub vd)
    | Psig_type (rf, l) ->
        type_ ~loc rf (List.map (sub.type_declaration sub) l)
    | Psig_typesubst l ->
        type_subst ~loc (List.map (sub.type_declaration sub) l)
    | Psig_typext te -> type_extension ~loc (sub.type_extension sub te)
    | Psig_exception ed -> exception_ ~loc (sub.type_exception sub ed)
    | Psig_module x -> module_ ~loc (sub.module_declaration sub x)
    | Psig_modsubst x -> mod_subst ~loc (sub.module_substitution sub x)
    | Psig_recmodule l ->
        rec_module ~loc (List.map (sub.module_declaration sub) l)
    | Psig_modtype x -> modtype ~loc (sub.module_type_declaration sub x)
    | Psig_modtypesubst x ->
        modtype_subst ~loc (sub.module_type_declaration sub x)
    | Psig_open x -> open_ ~loc (sub.open_description sub x)
    | Psig_include x -> include_ ~loc (sub.include_description sub x)
    | Psig_class l -> class_ ~loc (List.map (sub.class_description sub) l)
    | Psig_class_type l ->
        class_type ~loc (List.map (sub.class_type_declaration sub) l)
    | Psig_extension (x, attrs) ->
        let attrs = sub.attributes sub attrs in
        extension ~loc ~attrs (sub.extension sub x)
    | Psig_attribute x -> attribute ~loc (sub.attribute sub x)
end


module M = struct
  (* Value expressions for the module language *)

  let map sub {pmod_loc = loc; pmod_desc = desc; pmod_attributes = attrs} =
    let open Mod in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pmod_ident x -> ident ~loc ~attrs (map_loc sub x)
    | Pmod_structure str -> structure ~loc ~attrs (sub.structure sub str)
    | Pmod_functor (param, body) ->
        functor_ ~loc ~attrs
          (map_functor_param sub param)
          (sub.module_expr sub body)
    | Pmod_apply (m1, m2) ->
        apply ~loc ~attrs (sub.module_expr sub m1) (sub.module_expr sub m2)
    | Pmod_constraint (m, mty) ->
        constraint_ ~loc ~attrs (sub.module_expr sub m)
                    (sub.module_type sub mty)
    | Pmod_unpack e -> unpack ~loc ~attrs (sub.expr sub e)
    | Pmod_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pmod_hole -> hole ~loc ~attrs ()

  let map_structure_item sub {pstr_loc = loc; pstr_desc = desc} =
    let open Str in
    let loc = sub.location sub loc in
    match desc with
    | Pstr_eval (x, attrs) ->
        let attrs = sub.attributes sub attrs in
        eval ~loc ~attrs (sub.expr sub x)
    | Pstr_value (r, vbs) -> value ~loc r (List.map (sub.value_binding sub) vbs)
    | Pstr_primitive vd -> primitive ~loc (sub.value_description sub vd)
    | Pstr_type (rf, l) -> type_ ~loc rf (List.map (sub.type_declaration sub) l)
    | Pstr_typext te -> type_extension ~loc (sub.type_extension sub te)
    | Pstr_exception ed -> exception_ ~loc (sub.type_exception sub ed)
    | Pstr_module x -> module_ ~loc (sub.module_binding sub x)
    | Pstr_recmodule l -> rec_module ~loc (List.map (sub.module_binding sub) l)
    | Pstr_modtype x -> modtype ~loc (sub.module_type_declaration sub x)
    | Pstr_open x -> open_ ~loc (sub.open_declaration sub x)
    | Pstr_class l -> class_ ~loc (List.map (sub.class_declaration sub) l)
    | Pstr_class_type l ->
        class_type ~loc (List.map (sub.class_type_declaration sub) l)
    | Pstr_include x -> include_ ~loc (sub.include_declaration sub x)
    | Pstr_extension (x, attrs) ->
        let attrs = sub.attributes sub attrs in
        extension ~loc ~attrs (sub.extension sub x)
    | Pstr_attribute x -> attribute ~loc (sub.attribute sub x)
end

module E = struct
  (* Value expressions for the core language *)

  let map sub {pexp_loc = loc; pexp_desc = desc; pexp_attributes = attrs} =
    let open Exp in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pexp_ident x -> ident ~loc ~attrs (map_loc sub x)
    | Pexp_constant x -> constant ~loc ~attrs (sub.constant sub x)
    | Pexp_let (r, vbs, e) ->
        let_ ~loc ~attrs r (List.map (sub.value_binding sub) vbs)
          (sub.expr sub e)
    | Pexp_fun (lab, def, p, e) ->
        fun_ ~loc ~attrs lab (map_opt (sub.expr sub) def) (sub.pat sub p)
          (sub.expr sub e)
    | Pexp_function pel -> function_ ~loc ~attrs (sub.cases sub pel)
    | Pexp_apply (e, l) ->
        apply ~loc ~attrs (sub.expr sub e) (List.map (map_snd (sub.expr sub)) l)
    | Pexp_match (e, pel) ->
        match_ ~loc ~attrs (sub.expr sub e) (sub.cases sub pel)
    | Pexp_try (e, pel) -> try_ ~loc ~attrs (sub.expr sub e) (sub.cases sub pel)
    | Pexp_tuple el -> tuple ~loc ~attrs (List.map (sub.expr sub) el)
    | Pexp_construct (lid, arg) ->
        construct ~loc ~attrs (map_loc sub lid) (map_opt (sub.expr sub) arg)
    | Pexp_variant (lab, eo) ->
        variant ~loc ~attrs lab (map_opt (sub.expr sub) eo)
    | Pexp_record (l, eo) ->
        record ~loc ~attrs (List.map (map_tuple (map_loc sub) (sub.expr sub)) l)
          (map_opt (sub.expr sub) eo)
    | Pexp_field (e, lid) ->
        field ~loc ~attrs (sub.expr sub e) (map_loc sub lid)
    | Pexp_setfield (e1, lid, e2) ->
        setfield ~loc ~attrs (sub.expr sub e1) (map_loc sub lid)
          (sub.expr sub e2)
    | Pexp_array el -> array ~loc ~attrs (List.map (sub.expr sub) el)
    | Pexp_list el -> list ~loc ~attrs (List.map (sub.expr sub) el)
    | Pexp_ifthenelse (e1, e2, e3) ->
        ifthenelse ~loc ~attrs (sub.expr sub e1) (sub.expr sub e2)
          (map_opt (sub.expr sub) e3)
    | Pexp_sequence (e1, e2) ->
        sequence ~loc ~attrs (sub.expr sub e1) (sub.expr sub e2)
    | Pexp_while (e1, e2) ->
        while_ ~loc ~attrs (sub.expr sub e1) (sub.expr sub e2)
    | Pexp_for (p, e1, e2, d, e3) ->
        for_ ~loc ~attrs (sub.pat sub p) (sub.expr sub e1) (sub.expr sub e2) d
          (sub.expr sub e3)
    | Pexp_coerce (e, t1, t2) ->
        coerce ~loc ~attrs (sub.expr sub e) (map_opt (sub.typ sub) t1)
          (sub.typ sub t2)
    | Pexp_constraint (e, t) ->
        constraint_ ~loc ~attrs (sub.expr sub e) (sub.typ sub t)
    | Pexp_send (e, s) ->
        send ~loc ~attrs (sub.expr sub e) (map_loc sub s)
    | Pexp_new lid -> new_ ~loc ~attrs (map_loc sub lid)
    | Pexp_setinstvar (s, e) ->
        setinstvar ~loc ~attrs (map_loc sub s) (sub.expr sub e)
    | Pexp_override sel ->
        override ~loc ~attrs
          (List.map (map_tuple (map_loc sub) (sub.expr sub)) sel)
    | Pexp_letmodule (s, me, e) ->
        letmodule ~loc ~attrs (map_loc sub s) (sub.module_expr sub me)
          (sub.expr sub e)
    | Pexp_letexception (cd, e) ->
        letexception ~loc ~attrs
          (sub.extension_constructor sub cd)
          (sub.expr sub e)
    | Pexp_assert e -> assert_ ~loc ~attrs (sub.expr sub e)
    | Pexp_lazy e -> lazy_ ~loc ~attrs (sub.expr sub e)
    | Pexp_poly (e, t) ->
        poly ~loc ~attrs (sub.expr sub e) (map_opt (sub.typ sub) t)
    | Pexp_object cls -> object_ ~loc ~attrs (sub.class_structure sub cls)
    | Pexp_newtype (s, e) ->
        newtype ~loc ~attrs (map_loc sub s) (sub.expr sub e)
    | Pexp_pack me -> pack ~loc ~attrs (sub.module_expr sub me)
    | Pexp_open (o, e) ->
        open_ ~loc ~attrs (sub.open_declaration sub o) (sub.expr sub e)
    | Pexp_letop {let_; ands; body} ->
        letop ~loc ~attrs (sub.binding_op sub let_)
          (List.map (sub.binding_op sub) ands) (sub.expr sub body)
    | Pexp_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pexp_unreachable -> unreachable ~loc ~attrs ()
    | Pexp_hole -> hole ~loc ~attrs ()
    | Pexp_beginend e -> beginend ~loc ~attrs (sub.expr sub e)

  let map_binding_op sub {pbop_op; pbop_pat; pbop_exp; pbop_loc} =
    let open Exp in
    let op = map_loc sub pbop_op in
    let pat = sub.pat sub pbop_pat in
    let exp = sub.expr sub pbop_exp in
    let loc = sub.location sub pbop_loc in
    binding_op op pat exp loc

end

module P = struct
  (* Patterns *)

  let map sub {ppat_desc = desc; ppat_loc = loc; ppat_attributes = attrs} =
    let open Pat in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Ppat_any -> any ~loc ~attrs ()
    | Ppat_var s -> var ~loc ~attrs (map_loc sub s)
    | Ppat_alias (p, s) -> alias ~loc ~attrs (sub.pat sub p) (map_loc sub s)
    | Ppat_constant c -> constant ~loc ~attrs (sub.constant sub c)
    | Ppat_interval (c1, c2) ->
        interval ~loc ~attrs (sub.constant sub c1) (sub.constant sub c2)
    | Ppat_tuple pl -> tuple ~loc ~attrs (List.map (sub.pat sub) pl)
    | Ppat_construct (l, p) ->
        construct ~loc ~attrs (map_loc sub l)
          (map_opt
             (fun (vl, p) -> List.map (map_loc sub) vl, sub.pat sub p)
             p)
    | Ppat_variant (l, p) -> variant ~loc ~attrs l (map_opt (sub.pat sub) p)
    | Ppat_record (lpl, cf) ->
        record ~loc ~attrs
               (List.map (map_tuple (map_loc sub) (sub.pat sub)) lpl)
               (match cf with
                | Closed -> Closed
                | Open loc -> Open (sub.location sub loc))
    | Ppat_array pl -> array ~loc ~attrs (List.map (sub.pat sub) pl)
    | Ppat_list pl -> list ~loc ~attrs (List.map (sub.pat sub) pl)
    | Ppat_or (p1, p2) -> or_ ~loc ~attrs (sub.pat sub p1) (sub.pat sub p2)
    | Ppat_constraint (p, t) ->
        constraint_ ~loc ~attrs (sub.pat sub p) (sub.typ sub t)
    | Ppat_type s -> type_ ~loc ~attrs (map_loc sub s)
    | Ppat_lazy p -> lazy_ ~loc ~attrs (sub.pat sub p)
    | Ppat_unpack s -> unpack ~loc ~attrs (map_loc sub s)
    | Ppat_open (lid,p) -> open_ ~loc ~attrs (map_loc sub lid) (sub.pat sub p)
    | Ppat_exception p -> exception_ ~loc ~attrs (sub.pat sub p)
    | Ppat_extension x -> extension ~loc ~attrs (sub.extension sub x)
end

module CE = struct
  (* Value expressions for the class language *)

  let map sub {pcl_loc = loc; pcl_desc = desc; pcl_attributes = attrs} =
    let open Cl in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pcl_constr (lid, tys) ->
        constr ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tys)
    | Pcl_structure s ->
        structure ~loc ~attrs (sub.class_structure sub s)
    | Pcl_fun (lab, e, p, ce) ->
        fun_ ~loc ~attrs lab
          (map_opt (sub.expr sub) e)
          (sub.pat sub p)
          (sub.class_expr sub ce)
    | Pcl_apply (ce, l) ->
        apply ~loc ~attrs (sub.class_expr sub ce)
          (List.map (map_snd (sub.expr sub)) l)
    | Pcl_let (r, vbs, ce) ->
        let_ ~loc ~attrs r (List.map (sub.value_binding sub) vbs)
          (sub.class_expr sub ce)
    | Pcl_constraint (ce, ct) ->
        constraint_ ~loc ~attrs (sub.class_expr sub ce) (sub.class_type sub ct)
    | Pcl_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pcl_open (o, ce) ->
        open_ ~loc ~attrs (sub.open_description sub o) (sub.class_expr sub ce)

  let map_kind sub = function
    | Cfk_concrete (o, e) -> Cfk_concrete (o, sub.expr sub e)
    | Cfk_virtual t -> Cfk_virtual (sub.typ sub t)

  let map_field sub {pcf_desc = desc; pcf_loc = loc; pcf_attributes = attrs} =
    let open Cf in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pcf_inherit (o, ce, s) ->
        inherit_ ~loc ~attrs o (sub.class_expr sub ce)
          (map_opt (map_loc sub) s)
    | Pcf_val (s, m, k) -> val_ ~loc ~attrs (map_loc sub s) m (map_kind sub k)
    | Pcf_method (s, p, k) ->
        method_ ~loc ~attrs (map_loc sub s) p (map_kind sub k)
    | Pcf_constraint (t1, t2) ->
        constraint_ ~loc ~attrs (sub.typ sub t1) (sub.typ sub t2)
    | Pcf_initializer e -> initializer_ ~loc ~attrs (sub.expr sub e)
    | Pcf_attribute x -> attribute ~loc (sub.attribute sub x)
    | Pcf_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_structure sub {pcstr_self; pcstr_fields} =
    {
      pcstr_self = sub.pat sub pcstr_self;
      pcstr_fields = List.map (sub.class_field sub) pcstr_fields;
    }

  let class_infos sub f {pci_virt; pci_params = pl; pci_name; pci_expr;
                         pci_loc; pci_attributes} =
    let loc = sub.location sub pci_loc in
    let attrs = sub.attributes sub pci_attributes in
    Ci.mk ~loc ~attrs
     ~virt:pci_virt
     ~params:(List.map (map_fst (sub.typ sub)) pl)
      (map_loc sub pci_name)
      (f pci_expr)
end

(* Now, a generic AST mapper, to be extended to cover all kinds and
   cases of the OCaml grammar.  The default behavior of the mapper is
   the identity. *)

let default_mapper =
  {
    constant = C.map;
    structure = (fun this l -> List.map (this.structure_item this) l);
    structure_item = M.map_structure_item;
    module_expr = M.map;
    signature = (fun this l -> List.map (this.signature_item this) l);
    signature_item = MT.map_signature_item;
    module_type = MT.map;
    with_constraint = MT.map_with_constraint;
    class_declaration =
      (fun this -> CE.class_infos this (this.class_expr this));
    class_expr = CE.map;
    class_field = CE.map_field;
    class_structure = CE.map_structure;
    class_type = CT.map;
    class_type_field = CT.map_field;
    class_signature = CT.map_signature;
    class_type_declaration =
      (fun this -> CE.class_infos this (this.class_type this));
    class_description =
      (fun this -> CE.class_infos this (this.class_type this));
    type_declaration = T.map_type_declaration;
    type_kind = T.map_type_kind;
    typ = T.map;
    type_extension = T.map_type_extension;
    type_exception = T.map_type_exception;
    extension_constructor = T.map_extension_constructor;
    value_description =
      (fun this {pval_name; pval_type; pval_prim; pval_loc;
                 pval_attributes} ->
        Val.mk
          (map_loc this pval_name)
          (this.typ this pval_type)
          ~attrs:(this.attributes this pval_attributes)
          ~loc:(this.location this pval_loc)
          ~prim:pval_prim
      );

    pat = P.map;
    expr = E.map;
    binding_op = E.map_binding_op;

    module_declaration =
      (fun this {pmd_name; pmd_type; pmd_attributes; pmd_loc} ->
         Md.mk
           (map_loc this pmd_name)
           (this.module_type this pmd_type)
           ~attrs:(this.attributes this pmd_attributes)
           ~loc:(this.location this pmd_loc)
      );

    module_substitution =
      (fun this {pms_name; pms_manifest; pms_attributes; pms_loc} ->
         Ms.mk
           (map_loc this pms_name)
           (map_loc this pms_manifest)
           ~attrs:(this.attributes this pms_attributes)
           ~loc:(this.location this pms_loc)
      );

    module_type_declaration =
      (fun this {pmtd_name; pmtd_type; pmtd_attributes; pmtd_loc} ->
         Mtd.mk
           (map_loc this pmtd_name)
           ?typ:(map_opt (this.module_type this) pmtd_type)
           ~attrs:(this.attributes this pmtd_attributes)
           ~loc:(this.location this pmtd_loc)
      );

    module_binding =
      (fun this {pmb_name; pmb_expr; pmb_attributes; pmb_loc} ->
         Mb.mk (map_loc this pmb_name) (this.module_expr this pmb_expr)
           ~attrs:(this.attributes this pmb_attributes)
           ~loc:(this.location this pmb_loc)
      );


    open_declaration =
      (fun this {popen_expr; popen_override; popen_attributes; popen_loc} ->
         Opn.mk (this.module_expr this popen_expr)
           ~override:popen_override
           ~loc:(this.location this popen_loc)
           ~attrs:(this.attributes this popen_attributes)
      );

    open_description =
      (fun this {popen_expr; popen_override; popen_attributes; popen_loc} ->
         Opn.mk (map_loc this popen_expr)
           ~override:popen_override
           ~loc:(this.location this popen_loc)
           ~attrs:(this.attributes this popen_attributes)
      );

    include_description =
      (fun this {pincl_mod; pincl_attributes; pincl_loc} ->
         Incl.mk (this.module_type this pincl_mod)
           ~loc:(this.location this pincl_loc)
           ~attrs:(this.attributes this pincl_attributes)
      );

    include_declaration =
      (fun this {pincl_mod; pincl_attributes; pincl_loc} ->
         Incl.mk (this.module_expr this pincl_mod)
           ~loc:(this.location this pincl_loc)
           ~attrs:(this.attributes this pincl_attributes)
      );


    value_binding =
      (fun this {pvb_pat; pvb_expr; pvb_attributes; pvb_loc} ->
         Vb.mk
           (this.pat this pvb_pat)
           (this.expr this pvb_expr)
           ~loc:(this.location this pvb_loc)
           ~attrs:(this.attributes this pvb_attributes)
      );


    constructor_declaration =
      (fun this {pcd_name; pcd_vars; pcd_args;
                 pcd_res; pcd_loc; pcd_attributes} ->
        Type.constructor
          (map_loc this pcd_name)
          ~vars:(List.map (map_loc this) pcd_vars)
          ~args:(T.map_constructor_arguments this pcd_args)
          ?res:(map_opt (this.typ this) pcd_res)
          ~loc:(this.location this pcd_loc)
          ~attrs:(this.attributes this pcd_attributes)
      );

    label_declaration =
      (fun this {pld_name; pld_type; pld_loc; pld_mutable; pld_attributes} ->
         Type.field
           (map_loc this pld_name)
           (this.typ this pld_type)
           ~mut:pld_mutable
           ~loc:(this.location this pld_loc)
           ~attrs:(this.attributes this pld_attributes)
      );

    cases = (fun this l -> List.map (this.case this) l);
    case =
      (fun this {pc_lhs; pc_guard; pc_rhs} ->
         {
           pc_lhs = this.pat this pc_lhs;
           pc_guard = map_opt (this.expr this) pc_guard;
           pc_rhs = this.expr this pc_rhs;
         }
      );



    location = (fun _this l -> l);

    extension = (fun this (s, e) -> (map_loc this s, this.payload this e));
    attribute = (fun this a ->
      {
        attr_name = map_loc this a.attr_name;
        attr_payload = this.payload this a.attr_payload;
        attr_loc = this.location this a.attr_loc
      }
    );
    attributes = (fun this l -> List.map (this.attribute this) l);
    payload =
      (fun this -> function
         | PStr x -> PStr (this.structure this x)
         | PSig x -> PSig (this.signature this x)
         | PTyp x -> PTyp (this.typ this x)
         | PPat (x, g) -> PPat (this.pat this x, map_opt (this.expr this) g)
      );

    directive_argument =
      (fun this a ->
         { pdira_desc= a.pdira_desc
         ; pdira_loc= this.location this a.pdira_loc} );

    toplevel_directive =
      (fun this d ->
         { pdir_name= map_loc this d.pdir_name
         ; pdir_arg= map_opt (this.directive_argument this) d.pdir_arg
         ; pdir_loc= this.location this d.pdir_loc } );

    toplevel_phrase =
      (fun this -> function
         | Ptop_def s -> Ptop_def (this.structure this s)
         | Ptop_dir d -> Ptop_dir (this.toplevel_directive this d) );

    repl_phrase =
      (fun this p ->
         { prepl_phrase= this.toplevel_phrase this p.prepl_phrase
         ; prepl_output= p.prepl_output } );
  }

let extension_of_error {kind; main; sub} =
  if kind <> Location.Report_error then
    raise (Invalid_argument ""extension_of_error: expected kind Report_error"");
  let str_of_pp pp_msg = Format.asprintf ""%t"" pp_msg in
  let extension_of_sub sub =
    { loc = sub.loc; txt = ""ocaml.error"" },
    PStr ([Str.eval (Exp.constant
                       (Const.mk (Pconst_string (str_of_pp sub.txt, sub.loc, None))))])
  in
  { loc = main.loc; txt = ""ocaml.error"" },
  PStr (Str.eval (Exp.constant
                    (Const.mk (Pconst_string (str_of_pp main.txt, main.loc, None)))) ::
        List.map (fun msg -> Str.extension (extension_of_sub msg)) sub)

let attribute_of_warning loc s =
  Attr.mk
    {loc; txt = ""ocaml.ppwarning"" }
    (PStr ([Str.eval ~loc (Exp.constant (Const.mk (Pconst_string (s, loc, None))))]))

let cookies = ref String.Map.empty

let get_cookie k =
  try Some (String.Map.find k !cookies)
  with Not_found -> None

let set_cookie k v =
  cookies := String.Map.add k v !cookies

let tool_name_ref = ref ""_none_""

let tool_name () = !tool_name_ref


module PpxContext = struct
  open Longident
  open Asttypes
  open Ast_helper

  let lid name = { txt = Lident name; loc = Location.none }

  let make_string s = Exp.constant (Const.string s)

  let make_bool x =
    if x
    then Exp.construct (lid ""true"") None
    else Exp.construct (lid ""false"") None

  let rec make_list f lst =
    match lst with
    | x :: rest ->
      Exp.construct (lid ""::"") (Some (Exp.tuple [f x; make_list f rest]))
    | [] ->
      Exp.construct (lid ""[]"") None

  let make_pair f1 f2 (x1, x2) =
    Exp.tuple [f1 x1; f2 x2]

  let make_option f opt =
    match opt with
    | Some x -> Exp.construct (lid ""Some"") (Some (f x))
    | None   -> Exp.construct (lid ""None"") None

  let get_cookies () =
    lid ""cookies"",
    make_list (make_pair make_string (fun x -> x))
      (String.Map.bindings !cookies)

  let mk fields =
    {
      attr_name = { txt = ""ocaml.ppx.context""; loc = Location.none };
      attr_payload = Parsetree.PStr [Str.eval (Exp.record fields None)];
      attr_loc = Location.none
    }

  let make ~tool_name () =
    let fields =
      [
        lid ""tool_name"",    make_string tool_name;
        lid ""include_dirs"", make_list make_string !Clflags.include_dirs;
        lid ""load_path"",    make_list make_string (Load_path.get_paths ());
        lid ""open_modules"", make_list make_string !Clflags.open_modules;
        lid ""for_package"",  make_option make_string !Clflags.for_package;
        lid ""debug"",        make_bool !Clflags.debug;
        lid ""use_threads"",  make_bool !Clflags.use_threads;
        lid ""use_vmthreads"", make_bool false;
        lid ""recursive_types"", make_bool !Clflags.recursive_types;
        lid ""principal"", make_bool !Clflags.principal;
        lid ""transparent_modules"", make_bool !Clflags.transparent_modules;
        lid ""unboxed_types"", make_bool !Clflags.unboxed_types;
        lid ""unsafe_string"", make_bool false; (* kept for compatibility *)
        get_cookies ()
      ]
    in
    mk fields

  let get_fields = function
    | PStr [{pstr_desc = Pstr_eval
                 ({ pexp_desc = Pexp_record (fields, None) }, [])}] ->
        fields
    | _ ->
        raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context] syntax""

  let restore fields =
    let field name payload =
      let rec get_string = function
        | { pexp_desc = Pexp_constant {pconst_desc= Pconst_string (str, _, None); _ } } -> str
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] string syntax"" name
      and get_bool pexp =
        match pexp with
        | {pexp_desc = Pexp_construct ({txt = Longident.Lident ""true""},
                                       None)} ->
            true
        | {pexp_desc = Pexp_construct ({txt = Longident.Lident ""false""},
                                       None)} ->
            false
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] bool syntax"" name
      and get_list elem = function
        | {pexp_desc =
             Pexp_construct ({txt = Longident.Lident ""::""},
                             Some {pexp_desc = Pexp_tuple [exp; rest]}) } ->
            elem exp :: get_list elem rest
        | {pexp_desc =
             Pexp_construct ({txt = Longident.Lident ""[]""}, None)} ->
            []
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] list syntax"" name
      and get_pair f1 f2 = function
        | {pexp_desc = Pexp_tuple [e1; e2]} ->
            (f1 e1, f2 e2)
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] pair syntax"" name
      and get_option elem = function
        | { pexp_desc =
              Pexp_construct ({ txt = Longident.Lident ""Some"" }, Some exp) } ->
            Some (elem exp)
        | { pexp_desc =
              Pexp_construct ({ txt = Longident.Lident ""None"" }, None) } ->
            None
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] option syntax"" name
      in
      match name with
      | ""tool_name"" ->
          tool_name_ref := get_string payload
      | ""include_dirs"" ->
          Clflags.include_dirs := get_list get_string payload
      | ""load_path"" ->
          Load_path.init (get_list get_string payload)
      | ""open_modules"" ->
          Clflags.open_modules := get_list get_string payload
      | ""for_package"" ->
          Clflags.for_package := get_option get_string payload
      | ""debug"" ->
          Clflags.debug := get_bool payload
      | ""use_threads"" ->
          Clflags.use_threads := get_bool payload
      | ""use_vmthreads"" ->
          if get_bool payload then
            raise_errorf ""Internal error: vmthreads not supported after 4.09.0""
      | ""recursive_types"" ->
          Clflags.recursive_types := get_bool payload
      | ""principal"" ->
          Clflags.principal := get_bool payload
      | ""transparent_modules"" ->
          Clflags.transparent_modules := get_bool payload
      | ""unboxed_types"" ->
          Clflags.unboxed_types := get_bool payload
      | ""cookies"" ->
          let l = get_list (get_pair get_string (fun x -> x)) payload in
          cookies :=
            List.fold_left
              (fun s (k, v) -> String.Map.add k v s) String.Map.empty
              l
      | _ ->
          ()
    in
    List.iter (function ({txt=Lident name}, x) -> field name x | _ -> ()) fields

  let update_cookies fields =
    let fields =
      List.filter
        (function ({txt=Lident ""cookies""}, _) -> false | _ -> true)
        fields
    in
    fields @ [get_cookies ()]
end

let ppx_context = PpxContext.make

let extension_of_exn exn =
  match error_of_exn exn with
  | Some (`Ok error) -> extension_of_error error
  | Some `Already_displayed ->
      { loc = Location.none; txt = ""ocaml.error"" }, PStr []
  | None -> raise exn


let apply_lazy ~source ~target mapper =
  let implem ast =
    let fields, ast =
      match ast with
      | {pstr_desc = Pstr_attribute ({attr_name = {txt = ""ocaml.ppx.context""};
                                      attr_payload = x})} :: l ->
          PpxContext.get_fields x, l
      | _ -> [], ast
    in
    PpxContext.restore fields;
    let ast =
      try
        let mapper = mapper () in
        mapper.structure mapper ast
      with exn ->
        [{pstr_desc = Pstr_extension (extension_of_exn exn, []);
          pstr_loc  = Location.none}]
    in
    let fields = PpxContext.update_cookies fields in
    Str.attribute (PpxContext.mk fields) :: ast
  in
  let iface ast =
    let fields, ast =
      match ast with
      | {psig_desc = Psig_attribute ({attr_name = {txt = ""ocaml.ppx.context""};
                                      attr_payload = x;
                                      attr_loc = _})} :: l ->
          PpxContext.get_fields x, l
      | _ -> [], ast
    in
    PpxContext.restore fields;
    let ast =
      try
        let mapper = mapper () in
        mapper.signature mapper ast
      with exn ->
        [{psig_desc = Psig_extension (extension_of_exn exn, []);
          psig_loc  = Location.none}]
    in
    let fields = PpxContext.update_cookies fields in
    Sig.attribute (PpxContext.mk fields) :: ast
  in

  let ic = open_in_bin source in
  let magic =
    really_input_string ic (String.length Config.ast_impl_magic_number)
  in

  let rewrite transform =
    Location.input_name := input_value ic;
    let ast = input_value ic in
    close_in ic;
    let ast = transform ast in
    let oc = open_out_bin target in
    output_string oc magic;
    output_value oc !Location.input_name;
    output_value oc ast;
    close_out oc
  and fail () =
    close_in ic;
    failwith ""Ast_mapper: OCaml version mismatch or malformed input"";
  in

  if magic = Config.ast_impl_magic_number then
    rewrite (implem : structure -> structure)
  else if magic = Config.ast_intf_magic_number then
    rewrite (iface : signature -> signature)
  else fail ()

let drop_ppx_context_str ~restore = function
  | {pstr_desc = Pstr_attribute
                   {attr_name = {Location.txt = ""ocaml.ppx.context""};
                    attr_payload = a;
                    attr_loc = _}}
    :: items ->
      if restore then
        PpxContext.restore (PpxContext.get_fields a);
      items
  | items -> items

let drop_ppx_context_sig ~restore = function
  | {psig_desc = Psig_attribute
                   {attr_name = {Location.txt = ""ocaml.ppx.context""};
                    attr_payload = a;
                    attr_loc = _}}
    :: items ->
      if restore then
        PpxContext.restore (PpxContext.get_fields a);
      items
  | items -> items

let add_ppx_context_str ~tool_name ast =
  Ast_helper.Str.attribute (ppx_context ~tool_name ()) :: ast

let add_ppx_context_sig ~tool_name ast =
  Ast_helper.Sig.attribute (ppx_context ~tool_name ()) :: ast


let apply ~source ~target mapper =
  apply_lazy ~source ~target (fun () -> mapper)

let run_main mapper =
  try
    let a = Sys.argv in
    let n = Array.length a in
    if n > 2 then
      let mapper () =
        try mapper (Array.to_list (Array.sub a 1 (n - 3)))
        with exn ->
          (* PR#6463 *)
          let f _ _ = raise exn in
          {default_mapper with structure = f; signature = f}
      in
      apply_lazy ~source:a.(n - 2) ~target:a.(n - 1) mapper
    else begin
      Printf.eprintf ""Usage: %s [extra_args] <infile> <outfile>\n%!""
                     Sys.executable_name;
      exit 2
    end
  with exn ->
    prerr_endline (Printexc.to_string exn);
    exit 2

let register_function = ref (fun _name f -> run_main f)
let register name f = !register_function name f
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

type 'a member_info = {
  ty: 'a;
  def_loc: ALoc.t option;
  from_proto: bool;
      (** Autocomplete ranks members from primitive prototypes below user-defined members.
          [from_proto] indicates that the member is from a primitive prototype. *)
  from_nullable: bool;
      (** If a member came from a possibly-null/undefined object, autocomplete may suggest
          that the user use optional chaining to access it.
          [from_nullable] indicates that the member is from a possibly-null/undefined object. *)
}

let map_member_info f info = { info with ty = f info.ty }

(** Special cases we'll consider when recursively getting the members of a constituent type
    in a union/intersection *)
type membership_behavior =
  | EmptyOrAny
      (** the given type's member set is the universal set, where each member's type is the given type. *)
  | Nullish  (** the given type is Void or Null *)
  | Normal  (** a type which falls into neither of these special cases *)

let membership_behavior =
  let open Ty in
  function
  | Bot _
  | Any _ ->
    EmptyOrAny
  | Void
  | Null ->
    Nullish
  | _ -> Normal

let rec members_of_ty : Ty.t -> Ty.t member_info NameUtils.Map.t * string list =
  let open Ty in
  let ty_of_named_prop = function
    | Field { t; optional = false; _ }
    | Get t
    | Set t ->
      t
    | Field { t; optional = true; _ } -> Union (false, t, Void, [])
    | Method ft -> Fun ft
  in
  let members_of_obj obj_props =
    obj_props
    |> Base.List.fold_left ~init:(NameUtils.Map.empty, []) ~f:(fun (mems1, errs1) prop ->
           let (mems2, errs2) =
             match prop with
             | NamedProp { name; prop; from_proto; def_loc } ->
               ( NameUtils.Map.singleton
                   name
                   { ty = ty_of_named_prop prop; from_proto; from_nullable = false; def_loc },
                 []
               )
             | SpreadProp ty -> members_of_ty ty
             | CallProp _ -> (NameUtils.Map.empty, [])
           in
           (NameUtils.Map.union ~combine:(fun _ _ snd -> Some snd) mems1 mems2, errs1 @ errs2)
       )
  in
  (* given a list of objects, collates the members that exist in all of them *)
  let intersection_of_members ((t1_members, ts_members) : 'a member_info NameUtils.Map.t Nel.t) =
    NameUtils.Map.map (map_member_info Nel.one) t1_members
    |> List.fold_right
         (NameUtils.Map.merge (fun _ ty_opt tys_opt ->
              match (ty_opt, tys_opt) with
              | ( Some { ty; from_proto = fp; from_nullable = fn; def_loc = dl },
                  Some { ty = tys; from_proto = fps; from_nullable = fns; def_loc = dls }
                ) ->
                (* We say that a member formed by unioning other members should be treated:
                 * - as from a prototype only if all its constituent members are.
                 * - as from a nullable object if any of its constituent members are.
                 * we say its def_loc is that of an arbitrary constituent member. *)
                Some
                  {
                    ty = Nel.cons ty tys;
                    from_proto = fp && fps;
                    from_nullable = fn || fns;
                    def_loc = Base.Option.first_some dl dls;
                  }
              | (None, _)
              | (_, None) ->
                None
          )
         )
         ts_members
  in
  (* given a list of objects, collates the members that exist in any of them *)
  let union_of_members ((t1_members, ts_members) : 'a member_info NameUtils.Map.t Nel.t) =
    NameUtils.Map.map (map_member_info Nel.one) t1_members
    |> List.fold_right
         (NameUtils.Map.merge (fun _ ty_opt tys_opt ->
              match (ty_opt, tys_opt) with
              | ( Some { ty; from_proto = fp; from_nullable = fn; def_loc = dl },
                  Some { ty = tys; from_proto = fps; from_nullable = fns; def_loc = dls }
                ) ->
                (* We say that a member formed by intersecting other members should be treated:
                 * - as from a prototype only if all its constituent members are.
                 * - as from a nullable object only if all its constituent members are.
                 * we say its def_loc is that of an arbitrary constituent member. *)
                Some
                  {
                    ty = Nel.cons ty tys;
                    from_proto = fp && fps;
                    from_nullable = fn && fns;
                    def_loc = Base.Option.first_some dl dls;
                  }
              | (Some info, None) -> Some (map_member_info Nel.one info)
              | (None, Some info) -> Some info
              | (None, None) -> None
          )
         )
         ts_members
  in
  let intersection_of_member_types =
    NameUtils.Map.map
      (map_member_info (function
          | (t, []) -> t
          | (t1, t2 :: ts) -> Ty_utils.simplify_type ~merge_kinds:true (Inter (t1, t2, ts))
          )
          )
  in
  let union_of_member_types ~from_bounds =
    NameUtils.Map.map
      (map_member_info (function
          | (t, []) -> t
          | (t1, t2 :: ts) ->
            Ty_utils.simplify_type ~merge_kinds:true (Union (from_bounds, t1, t2, ts))
          )
          )
  in
  let add_special_cases special_cases =
    NameUtils.Map.map (map_member_info (List.fold_right Nel.cons special_cases))
  in
  let members_of_union ~from_bounds (t1, t2, ts) =
    let ((t1_members, errs1), (t2_members, errs2), (ts_members, errss)) =
      (members_of_ty t1, members_of_ty t2, Base.List.map ~f:members_of_ty ts |> List.split)
    in
    let errs = Base.List.concat (errs1 :: errs2 :: errss) in
    let universe =
      (* set union of all child members *)
      List.fold_right
        (NameUtils.Map.merge (fun _ _ _ -> Some ()))
        (t1_members :: t2_members :: ts_members)
        NameUtils.Map.empty
    in
    (* empty and any have all possible members *)
    let (t1_members, t2_members, ts_members) =
      let f ty ty_members =
        match membership_behavior ty with
        | EmptyOrAny ->
          NameUtils.Map.map
            (Fn.const { ty; from_proto = true; from_nullable = false; def_loc = None })
            universe
        | Nullish ->
          NameUtils.Map.map
            (* Bot is the identity of type union *)
            (Fn.const
               { ty = Bot EmptyType; from_proto = true; from_nullable = true; def_loc = None }
            )
            universe
        | Normal -> ty_members
      in
      (f t1 t1_members, f t2 t2_members, List.map2 f ts ts_members)
    in
    let mems =
      (* set intersection of members; type union upon overlaps *)
      (t1_members, t2_members :: ts_members)
      |> intersection_of_members
      |> union_of_member_types ~from_bounds
    in
    (mems, errs)
  in
  let members_of_intersection (t1, t2, ts) =
    let ((t1_members, errs1), (t2_members, errs2), (ts_members, errss)) =
      (members_of_ty t1, members_of_ty t2, Base.List.map ~f:members_of_ty ts |> List.split)
    in
    let errs = Base.List.concat (errs1 :: errs2 :: errss) in
    let special_cases =
      Base.List.filter_map
        ~f:(fun ty ->
          match membership_behavior ty with
          | EmptyOrAny -> Some ty
          | Nullish
          | Normal ->
            None)
        (t1 :: t2 :: ts)
    in
    let mems =
      (* set union of members; type intersection upon overlaps *)
      union_of_members (t1_members, t2_members :: ts_members)
      |> add_special_cases special_cases
      |> intersection_of_member_types
    in
    (mems, errs)
  in
  function
  | Mu (_, t) -> members_of_ty t
  | Obj { obj_props; _ } -> members_of_obj obj_props
  | Fun { fun_static; _ } -> members_of_ty fun_static
  | Union (from_bounds, t1, t2, ts) -> members_of_union ~from_bounds (t1, t2, ts)
  | Inter (t1, t2, ts) -> members_of_intersection (t1, t2, ts)
  | ( TVar _ | Bound _ | Generic _ | Symbol | Num _ | Str _ | Bool _ | NumLit _ | StrLit _
    | BoolLit _ | Arr _ | Tup _ ) as t ->
    ( NameUtils.Map.empty,
      [Printf.sprintf ""members_of_ty unexpectedly applied to (%s)"" (Ty_debug.dump_t t)]
    )
  | Any _
  | Top
  | Bot _
  | Void
  | Null
  | InlineInterface _
  | TypeOf _
  | Utility _
  | IndexedAccess _
  | CharSet _ ->
    (NameUtils.Map.empty, [])

type ty_members = {
  members: Ty.t member_info NameUtils.Map.t;
  errors: string list;
  in_idx: bool;
}

let ty_normalizer_options =
  Ty_normalizer_env.
    {
      expand_internal_types = true;
      flag_shadowed_type_params = true;
      preserve_inferred_literal_types = false;
      evaluate_type_destructors = false;
      optimize_types = true;
      omit_targ_defaults = false;
      merge_bot_and_any_kinds = true;
      verbose_normalizer = false;
      max_depth = Some 50;
    }
  

let extract ~include_proto_members ~cx ~typed_ast ~file_sig scheme =
  let genv = Ty_normalizer_env.mk_genv ~full_cx:cx ~file:(Context.file cx) ~typed_ast ~file_sig in
  let in_idx_ref = ref false in
  let idx_hook () = in_idx_ref := true in
  match
    Ty_normalizer.expand_members
      ~include_proto_members
      ~idx_hook
      ~options:ty_normalizer_options
      ~genv
      scheme
  with
  | Error error -> Error (Ty_normalizer.error_to_string error)
  | Ok (Ty.Any _) -> Error ""not enough type information to extract members""
  | Ok this_ty ->
    let (members, errors) = members_of_ty this_ty in
    let in_idx = !in_idx_ref in
    Ok { members; errors; in_idx }
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Scope

module LookupMode = struct
  type t =
    | ForValue
    | ForType
    | ForTypeof
end

module type S = sig
  type scope

  type t = scope list

  val new_env : bool

  val in_toplevel_scope : unit -> bool

  val in_global_scope : unit -> bool

  val peek_env : unit -> t

  val clone_env : t -> t

  val string_of_env : Context.t -> t -> string

  val var_scope_kind : unit -> Scope.var_scope_kind

  val in_async_scope : unit -> bool

  val in_generator_scope : unit -> bool

  val in_predicate_scope : unit -> bool

  val find_entry :
    Context.t -> Reason.name -> ?desc:Reason.reason_desc -> ALoc.t -> Scope.t * Entry.t

  val push_var_scope : Scope.t -> unit

  val pop_var_scope : unit -> unit

  val in_lex_scope : (unit -> 'a) -> 'a

  val env_depth : unit -> int

  val trunc_env : int -> unit

  val init_env : ?exclude_syms:NameUtils.Set.t -> Context.t -> Scope.t -> unit

  val update_env : ALoc.t -> t -> unit

  val save_excluded_symbols : unit -> NameUtils.Set.t

  val restore_excluded_symbols : NameUtils.Set.t -> unit

  (***)

  val bind_class :
    Context.t ->
    ALoc.id ->
    Type.Properties.id ->
    Type.Properties.id ->
    Type.Properties.id ->
    Type.Properties.id ->
    unit

  val bind_var :
    ?state:State.t -> Context.t -> string -> Type.annotated_or_inferred -> ALoc.t -> unit

  val bind_let :
    ?state:State.t -> Context.t -> string -> Type.annotated_or_inferred -> ALoc.t -> unit

  val bind_implicit_let :
    ?state:State.t ->
    Entry.let_binding_kind ->
    Context.t ->
    Reason.name ->
    Type.annotated_or_inferred ->
    ALoc.t ->
    unit

  val bind_fun : ?state:State.t -> Context.t -> Reason.name -> Type.t -> ALoc.t -> unit

  val bind_implicit_const :
    ?state:State.t ->
    Entry.const_binding_kind ->
    Context.t ->
    string ->
    Type.annotated_or_inferred ->
    ALoc.t ->
    unit

  val bind_const :
    ?state:State.t -> Context.t -> string -> Type.annotated_or_inferred -> ALoc.t -> unit

  val bind_import : Context.t -> string -> Type.t -> ALoc.t -> unit

  val bind_type : ?state:State.t -> Context.t -> string -> Type.t -> ALoc.t -> unit

  val bind_this_tparam : state:State.t -> Context.t -> Type.t -> ALoc.t -> unit

  val bind_import_type : Context.t -> string -> Type.t -> ALoc.t -> unit

  val bind_declare_var : Context.t -> Reason.name -> Type.t -> ALoc.t -> unit

  val bind_declare_fun : Context.t -> predicate:bool -> Reason.name -> Type.t -> ALoc.t -> unit

  val declare_let : Context.t -> Reason.name -> ALoc.t -> unit

  val declare_implicit_let : Entry.let_binding_kind -> Context.t -> Reason.name -> ALoc.t -> unit

  val declare_const : Context.t -> Reason.name -> ALoc.t -> unit

  val declare_implicit_const :
    Entry.const_binding_kind -> Context.t -> Reason.name -> ALoc.t -> unit

  val init_var :
    Context.t -> use_op:Type.use_op -> Reason.name -> has_anno:bool -> Type.t -> ALoc.t -> unit

  val init_let :
    Context.t -> use_op:Type.use_op -> Reason.name -> has_anno:bool -> Type.t -> ALoc.t -> unit

  val init_implicit_let :
    Entry.let_binding_kind ->
    Context.t ->
    use_op:Type.use_op ->
    Reason.name ->
    has_anno:bool ->
    Type.t ->
    ALoc.t ->
    unit

  val init_fun : Context.t -> use_op:Type.use_op -> Reason.name -> Type.t -> ALoc.t -> unit

  val init_const :
    Context.t -> use_op:Type.use_op -> Reason.name -> has_anno:bool -> Type.t -> ALoc.t -> unit

  val init_implicit_const :
    Entry.const_binding_kind ->
    Context.t ->
    use_op:Type.use_op ->
    Reason.name ->
    has_anno:bool ->
    Type.t ->
    ALoc.t ->
    unit

  val init_type : Context.t -> string -> Type.t -> ALoc.t -> unit

  val init_import : lookup_mode:LookupMode.t -> Context.t -> Reason.name -> ALoc.t -> Type.t -> unit

  val pseudo_init_declared_type : Context.t -> string -> ALoc.t -> unit

  val is_provider : Context.t -> ALoc.t -> bool

  val install_provider : Context.t -> Type.t -> Reason.name -> ALoc.t -> unit

  val local_scope_entry_exists : Context.t -> ALoc.t -> string -> bool

  val is_global_var : Context.t -> string -> ALoc.t -> bool

  val get_current_env_refi : Key.t -> Scope.refi_binding option

  val get_class_entries : unit -> Type.class_binding list

  val get_var : ?lookup_mode:LookupMode.t -> Context.t -> string -> ALoc.t -> Type.t

  val get_internal_var : Context.t -> string -> ALoc.t -> Type.t

  val get_var_annotation : Context.t -> Reason.name -> ALoc.t -> Type.t option

  val get_var_declared_type :
    ?lookup_mode:LookupMode.t -> Context.t -> Reason.name -> ALoc.t -> Type.t

  val constraining_type : default:Type.t -> Context.t -> Reason.name -> ALoc.t -> Type.t

  val unify_declared_type :
    ?lookup_mode:LookupMode.t ->
    ?is_func:bool ->
    Context.t ->
    Reason.name ->
    ALoc.t ->
    Type.t ->
    unit

  val unify_declared_fun_type : Context.t -> Reason.name -> ALoc.t -> Type.t -> unit

  val var_ref :
    ?lookup_mode:LookupMode.t ->
    Context.t ->
    ?desc:Reason.reason_desc ->
    Reason.name ->
    ALoc.t ->
    Type.t

  val query_var :
    ?lookup_mode:LookupMode.t ->
    Context.t ->
    Reason.name ->
    ?desc:Reason.reason_desc ->
    ALoc.t ->
    Type.t

  val query_var_non_specific : Context.t -> Reason.name -> ALoc.t -> Type.t

  val set_var : Context.t -> use_op:Type.use_op -> string -> Type.t -> ALoc.t -> unit

  val set_internal_var : Context.t -> string -> Type.t -> ALoc.t -> unit

  val set_expr : Context.t -> Key.t -> ALoc.t -> refined:Type.t -> original:Type.t -> unit

  val refine_expr : Key.t -> ALoc.t -> Type.t -> Type.t -> int * Key.t * Changeset.op

  val refine_with_preds :
    Context.t -> ALoc.t -> Type.predicate Key_map.t -> Type.t Key_map.t -> Changeset.t

  val in_refined_env :
    Context.t -> ALoc.t -> Type.predicate Key_map.t -> Type.t Key_map.t -> (unit -> 'a) -> 'a

  val merge_env : Context.t -> ALoc.t -> t * t * t -> Changeset.t -> unit

  val widen_env : Context.t -> ALoc.t -> unit

  val copy_env : Context.t -> ALoc.t -> t * t -> Changeset.t -> unit

  val havoc_all : unit -> unit

  val reset_current_activation : ALoc.t -> unit

  val havoc_vars : Changeset.t -> unit

  val havoc_heap_refinements : unit -> unit

  val havoc_local_refinements : ?all:bool -> Context.t -> unit

  val havoc_heap_refinements_with_propname : private_:bool -> string -> unit

  val get_refinement : Context.t -> Key.t -> ALoc.t -> Type.t option

  val record_expression_type_if_needed : Context.t -> ALoc.t -> Type.t -> unit

  val discriminant_after_negated_cases :
    Context.t ->
    ALoc.t ->
    (Reason.name * Key.proj list) option ->
    (ALoc.t, ALoc.t) Flow_ast.Expression.t ->
    Type.t option

  val valid_declaration_check : Context.t -> Reason.name -> ALoc.t -> unit
end
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Utils_js

let ( >>= ) = Base.Result.( >>= )

type line = int * string

type section = line * line list

type warning = int * string

type error = int * string

type file_watcher =
  | NoFileWatcher
  | DFind
  | Watchman

type lazy_mode =
  | Lazy
  | Non_lazy
  | Watchman_DEPRECATED  (** lazy_mode=watchman is deprecated, but implies file_watcher=Watchman *)

let default_temp_dir = Filename.concat Sys_utils.temp_dir_name ""flow""

let map_add map (key, value) = SMap.add key value map

module Opts = struct
  type raw_value = int * string

  type raw_values = raw_value list

  type raw_options = raw_values SMap.t

  type error_kind =
    | Failed_to_parse_value of string
    | Failed_to_set of string
    | Duplicate_option

  type opt_error = int * error_kind

  type t = {
    abstract_locations: bool option;
    all: bool option;
    autoimports: bool option;
    automatic_require_default: bool option;
    babel_loose_array_spread: bool option;
    cycle_errors: bool;
    direct_dependent_files_fix: bool option;
    disable_live_non_parse_errors: bool option;
    emoji: bool option;
    enable_const_params: bool;
    enforce_local_inference_annotations: bool;
    enforce_strict_call_arity: bool;
    enforce_this_annotations: bool;
    enums: bool;
    env_mode: Options.env_mode;
    env_mode_constrain_write_dirs: string list;
    exact_by_default: bool;
    exact_empty_objects: bool option;
    facebook_fbs: string option;
    facebook_fbt: string option;
    facebook_module_interop: bool;
    file_watcher: file_watcher option;
    file_watcher_mergebase_with: string option;
    file_watcher_mergebase_with_git: string option;
    file_watcher_mergebase_with_hg: string option;
    file_watcher_timeout: int option;
    format_bracket_spacing: bool option;  (** print spaces between brackets in object literals *)
    format_single_quotes: bool option;  (** prefer single-quoted strings *)
    gc_worker_custom_major_ratio: int option;  (** Gc.control's custom_major_ratio *)
    gc_worker_custom_minor_max_size: int option;  (** Gc.control's custom_minor_max_size *)
    gc_worker_custom_minor_ratio: int option;  (** Gc.control's custom_minor_ratio *)
    gc_worker_major_heap_increment: int option;  (** Gc.control's major_heap_increment *)
    gc_worker_minor_heap_size: int option;  (** Gc.control's minor_heap_size *)
    gc_worker_space_overhead: int option;  (** Gc.control's space_overhead *)
    gc_worker_window_size: int option;  (** Gc.control's window_size *)
    generate_tests: bool;
    haste_module_ref_prefix: string option;
    haste_name_reducers: (Str.regexp * string) list;
    haste_paths_excludes: string list;
    haste_paths_includes: string list;
    haste_use_name_reducers: bool;
    ignore_non_literal_requires: bool;
    include_warnings: bool;
    lazy_mode: lazy_mode option;
    local_inference_annotation_dirs: string list;
    log_file: Path.t option;
    log_saving: Options.log_saving SMap.t;
    max_files_checked_per_worker: int;
    max_header_tokens: int;
    max_literal_length: int;
    max_rss_bytes_for_check_per_worker: int;
    max_seconds_for_check_per_worker: float;
    max_workers: int;
    merge_timeout: int option;
    missing_module_generators: (Str.regexp * string) list;
    module_file_exts: string list;
    module_name_mappers: (Str.regexp * string) list;
    module_resource_exts: SSet.t;
    module_system: Options.module_system;
    modules_are_use_strict: bool;
    munge_underscores: bool;
    no_flowlib: bool;
    node_main_fields: string list;
    node_resolver_allow_root_relative: bool;
    node_resolver_dirnames: string list;
    node_resolver_root_relative_dirnames: string list;
    react_runtime: Options.react_runtime;
    react_server_component_exts: SSet.t;
    recursion_limit: int;
    refactor: bool option;
    relay_integration: bool;
    relay_integration_excludes: string list;
    relay_integration_module_prefix: string option;
    relay_integration_module_prefix_includes: string list;
    root_name: string option;
    run_post_inference_implicit_instantiation: bool;
    saved_state_fetcher: Options.saved_state_fetcher;
    shm_hash_table_pow: int;
    shm_heap_size: int;
    shm_log_level: int;
    statement_reorder_checking: Options.statement_order_mode;
    strict_es6_import_export: bool;
    strict_es6_import_export_excludes: string list;
    suppress_types: SSet.t;
    temp_dir: string;
    traces: int;
    trust_mode: Options.trust_mode;
    type_asserts: bool;
    wait_for_recheck: bool;
    watchman_defer_states: string list;
    watchman_survive_restarts: bool option;
    watchman_sync_timeout: int option;
  }
  [@@warning ""-69""]

  let warn_on_unknown_opts (raw_opts, config) : (t * warning list, error) result =
    (* If the user specified any options that aren't defined, issue a warning *)
    let warnings =
      SMap.elements raw_opts
      |> Base.List.fold_left
           ~f:(fun acc (k, v) ->
             let msg = spf ""Unsupported option specified! (%s)"" k in
             Base.List.fold_left ~f:(fun acc (line_num, _) -> (line_num, msg) :: acc) ~init:acc v)
           ~init:[]
    in
    Ok (config, warnings)

  (** the order of this list determines precedence. ./foo resolves to foo.js before foo.json *)
  let module_file_exts = ["".js""; "".jsx""; "".mjs""; "".cjs""; "".json""]

  let module_resource_exts =
    SSet.empty
    |> SSet.add "".css""
    |> SSet.add "".jpg""
    |> SSet.add "".png""
    |> SSet.add "".gif""
    |> SSet.add "".eot""
    |> SSet.add "".svg""
    |> SSet.add "".ttf""
    |> SSet.add "".woff""
    |> SSet.add "".woff2""
    |> SSet.add "".mp4""
    |> SSet.add "".webm""
    |> SSet.add "".webp""

  let react_server_component_exts = SSet.empty

  let default_options =
    {
      abstract_locations = None;
      all = None;
      autoimports = None;
      automatic_require_default = None;
      babel_loose_array_spread = None;
      cycle_errors = false;
      direct_dependent_files_fix = None;
      disable_live_non_parse_errors = None;
      emoji = None;
      enable_const_params = false;
      enforce_local_inference_annotations = false;
      enforce_strict_call_arity = true;
      enforce_this_annotations = false;
      enums = false;
      env_mode = Options.ClassicEnv [];
      env_mode_constrain_write_dirs = [];
      exact_by_default = false;
      exact_empty_objects = None;
      facebook_fbs = None;
      facebook_fbt = None;
      facebook_module_interop = false;
      file_watcher = None;
      file_watcher_mergebase_with = None;
      file_watcher_mergebase_with_git = None;
      file_watcher_mergebase_with_hg = None;
      file_watcher_timeout = None;
      format_bracket_spacing = None;
      format_single_quotes = None;
      gc_worker_custom_major_ratio = None;
      gc_worker_custom_minor_max_size = None;
      gc_worker_custom_minor_ratio = None;
      gc_worker_major_heap_increment = None;
      gc_worker_minor_heap_size = None;
      gc_worker_space_overhead = None;
      gc_worker_window_size = None;
      generate_tests = false;
      haste_module_ref_prefix = None;
      haste_name_reducers =
        [(Str.regexp ""^\\(.*/\\)?\\([a-zA-Z0-9$_.-]+\\)\\.js\\(\\.flow\\)?$"", ""\\2"")];
      haste_paths_excludes = [""\\(.*\\)?/node_modules/.*""];
      haste_paths_includes = [""<PROJECT_ROOT>/.*""];
      haste_use_name_reducers = false;
      ignore_non_literal_requires = false;
      include_warnings = false;
      lazy_mode = None;
      local_inference_annotation_dirs = [];
      log_file = None;
      log_saving = SMap.empty;
      max_files_checked_per_worker = 100;
      max_header_tokens = 10;
      max_literal_length = 100;
      max_rss_bytes_for_check_per_worker = (* 200MB *) 200 * 1024 * 1024;
      max_seconds_for_check_per_worker = 5.0;
      max_workers = Sys_utils.nbr_procs;
      merge_timeout = Some 100;
      missing_module_generators = [];
      module_file_exts;
      module_name_mappers = [];
      module_resource_exts;
      module_system = Options.Node;
      modules_are_use_strict = false;
      munge_underscores = false;
      no_flowlib = false;
      node_main_fields = [""main""];
      node_resolver_allow_root_relative = false;
      node_resolver_dirnames = [""node_modules""];
      node_resolver_root_relative_dirnames = [""""];
      react_runtime = Options.ReactRuntimeClassic;
      react_server_component_exts;
      recursion_limit = 10000;
      refactor = None;
      relay_integration = false;
      relay_integration_excludes = [];
      relay_integration_module_prefix = None;
      relay_integration_module_prefix_includes = [""<PROJECT_ROOT>/.*""];
      root_name = None;
      run_post_inference_implicit_instantiation = false;
      saved_state_fetcher = Options.Dummy_fetcher;
      shm_hash_table_pow = 19;
      shm_heap_size = (* 25GB *) 1024 * 1024 * 1024 * 25;
      shm_log_level = 0;
      statement_reorder_checking = Options.Lexical;
      strict_es6_import_export = false;
      strict_es6_import_export_excludes = [];
      suppress_types = SSet.empty |> SSet.add ""$FlowFixMe"";
      temp_dir = default_temp_dir;
      traces = 0;
      trust_mode = Options.NoTrust;
      type_asserts = false;
      wait_for_recheck = false;
      watchman_defer_states = [];
      watchman_survive_restarts = None;
      watchman_sync_timeout = None;
    }

  let parse_lines : line list -> (raw_options, error) result =
    let rec loop acc lines =
      acc >>= fun map ->
      match lines with
      | [] -> Ok map
      | (line_num, line) :: rest ->
        if Str.string_match (Str.regexp ""^\\([a-zA-Z0-9._]+\\)=\\(.*\\)$"") line 0 then
          let key = Str.matched_group 1 line in
          let value = Str.matched_group 2 line in
          let map =
            SMap.add
              key
              ((line_num, value)
               ::
               (match SMap.find_opt key map with
               | Some values -> values
               | None -> [])
              )
              map
          in
          loop (Ok map) rest
        else
          Error (line_num, ""Unable to parse line."")
    in
    fun lines ->
      let lines =
        lines
        |> Base.List.map ~f:(fun (ln, line) -> (ln, String.trim line))
        |> Base.List.filter ~f:(fun (_, s) -> s <> """")
      in
      loop (Ok SMap.empty) lines

  (**
    * `init` gets called on the options object immediately before
    * parsing the *first* occurrence of the user-specified config option. This
    * is useful in cases where the user's value should blow away the default
    * value (rather than being aggregated to it).
    *
    * For example: We want the default value of 'module.file_ext' to be
    * ['.js'; '.jsx'], but if the user specifies any 'module.file_ext'
    * settings, we want to start from a clean list.
    *)
  let opt =
    let rec loop optparser setter values config =
      match values with
      | [] -> Ok config
      | (line_num, value_str) :: rest ->
        let value =
          optparser value_str
          |> Base.Result.map_error ~f:(fun msg -> (line_num, Failed_to_parse_value msg))
        in
        let config =
          value >>= fun value ->
          setter config value |> Base.Result.map_error ~f:(fun msg -> (line_num, Failed_to_set msg))
        in
        config >>= loop optparser setter rest
    in
    fun (optparser : string -> ('a, string) result)
        ?init
        ?(multiple = false)
        (setter : t -> 'a -> (t, string) result)
        (values : raw_values)
        config : (t, opt_error) result ->
      let config =
        match init with
        | None -> config
        | Some f -> f config
      in
      (* Error when duplicate options were incorrectly given *)
      match (multiple, values) with
      | (false, _ :: (dupe_ln, _) :: _) -> Error (dupe_ln, Duplicate_option)
      | _ -> loop optparser setter values config

  let optparse_string str =
    try Ok (Scanf.unescaped str) with
    | Scanf.Scan_failure reason -> Error (spf ""Invalid ocaml string: %s"" reason)

  let optparse_regexp str =
    try Ok (Str.regexp str) with
    | Failure reason -> Error (spf ""Invalid ocaml regular expression: %s"" reason)

  let enum values =
    opt (fun str ->
        let values = Base.List.fold_left ~f:map_add ~init:SMap.empty values in
        match SMap.find_opt str values with
        | Some v -> Ok v
        | None ->
          Error
            (spf
               ""Unsupported value: \""%s\"". Supported values are: %s""
               str
               (String.concat "", "" (SMap.keys values))
            )
    )

  let filepath = opt (fun str -> Ok (Path.make str))

  let optparse_mapping =
    let regexp_str = ""^'\\([^']*\\)'[ \t]*->[ \t]*'\\([^']*\\)'$"" in
    let regexp = Str.regexp regexp_str in
    fun str ->
      if Str.string_match regexp str 0 then
        Ok (Str.matched_group 1 str, Str.matched_group 2 str)
      else
        Error (""Expected a mapping of form: "" ^ ""'single-quoted-string' -> 'single-quoted-string'"")

  let boolean = enum [(""true"", true); (""false"", false)]

  let string = opt optparse_string

  let uint =
    opt (fun str ->
        let v = int_of_string str in
        if v < 0 then
          Error ""Number cannot be negative!""
        else
          Ok v
    )

  let mapping fn = opt (fun str -> optparse_mapping str >>= fn)

  let optparse_json str =
    try Ok (Hh_json.json_of_string str) with
    | Hh_json.Syntax_error msg -> Error (spf ""Failed to parse JSON: %s"" msg)

  let json = opt optparse_json

  (* TODO: remove once .flowconfigs no longer use this setting *)
  let new_check_parser =
    boolean (fun opts v ->
        if v then
          Ok opts
        else
          Error ""New check mode can no longer be disabled.""
    )

  let max_files_checked_per_worker_parser =
    uint (fun opts v -> Ok { opts with max_files_checked_per_worker = v })

  let max_seconds_for_check_per_worker_parser =
    uint (fun opts v -> Ok { opts with max_seconds_for_check_per_worker = float v })

  let max_rss_bytes_for_check_per_worker_parser =
    uint (fun opts v -> Ok { opts with max_rss_bytes_for_check_per_worker = v })

  let file_ext_parser =
    string
      ~init:(fun opts -> { opts with module_file_exts = [] })
      ~multiple:true
      (fun opts v ->
        if String_utils.string_ends_with v Files.flow_ext then
          Error
            (""Cannot use file extension '""
            ^ v
            ^ ""' since it ends with the reserved extension '""
            ^ Files.flow_ext
            ^ ""'""
            )
        else if Base.List.mem opts.module_file_exts v ~equal:String.equal then
          (* ignore duplicates. doesn't seem super important to error. *)
          Ok opts
        else
          let module_file_exts = v :: opts.module_file_exts in
          Ok { opts with module_file_exts })

  let haste_name_reducers_parser =
    mapping
      ~init:(fun opts -> { opts with haste_name_reducers = [] })
      ~multiple:true
      (fun (pattern, template) -> optparse_regexp pattern >>= fun pattern -> Ok (pattern, template))
      (fun opts v -> Ok { opts with haste_name_reducers = v :: opts.haste_name_reducers })

  let haste_paths_excludes_parser =
    string
      ~init:(fun opts -> { opts with haste_paths_excludes = [] })
      ~multiple:true
      (fun opts v -> Ok { opts with haste_paths_excludes = v :: opts.haste_paths_excludes })

  let log_saving_parser =
    let init opts = { opts with log_saving = SMap.empty } in
    let multiple = true in
    let parse opts json =
      let open Hh_json in
      let open Base.Result.Let_syntax in
      let%bind (method_name, threshold_time_ms_str, limit_json, rate_str) =
        match json with
        | JSON_Array [JSON_String a; JSON_Number b; c; JSON_Number d] -> Ok (a, b, c, d)
        | JSON_Array [JSON_String ""timeout""; JSON_Null; c; JSON_Number d] ->
          (* timeout threshold is currently hardcoded as LspInteraction.max_age *)
          Ok (""timeout"", ""-1"", c, d)
        | _ -> Error ""must be of the form [\""method name\"", threshold_time_ms, limit, rate]""
      in
      let threshold_time_ms = int_of_string threshold_time_ms_str in
      let%bind limit =
        match limit_json with
        | JSON_Null -> Ok None
        | JSON_Number limit_str -> Ok (Some (int_of_string limit_str))
        | _ -> Error ""limit (third element) must be either number or null""
      in
      let rate = float_of_string rate_str in
      let%bind () =
        Base.Result.ok_if_true
          (0. <= rate && rate <= 100.)
          ~error:""rate (fourth element) means a percentage, so must be within 0 to 100""
      in
      let log_saving =
        SMap.add method_name Options.{ threshold_time_ms; limit; rate } opts.log_saving
      in
      return { opts with log_saving }
    in
    json ~init ~multiple parse

  let haste_paths_includes_parser =
    string
      ~init:(fun opts -> { opts with haste_paths_includes = [] })
      ~multiple:true
      (fun opts v -> Ok { opts with haste_paths_includes = v :: opts.haste_paths_includes })

  let enforce_local_inference_annotations =
    boolean (fun opts v -> Ok { opts with enforce_local_inference_annotations = v })

  let local_inference_annotation_dirs =
    string
      ~init:(fun opts -> { opts with local_inference_annotation_dirs = [] })
      ~multiple:true
      (fun opts v ->
        if opts.enforce_local_inference_annotations then
          Ok
            {
              opts with
              local_inference_annotation_dirs = v :: opts.local_inference_annotation_dirs;
            }
        else
          Error
            ""Option \""enforce_local_inference_annotations\"" must be set to true to set \""local_inference_annotation_dirs\""."")

  let enforce_this_annotations =
    boolean (fun opts v -> Ok { opts with enforce_this_annotations = v })

  let statement_reorder_checking_parser =
    enum
      [
        (""lexical"", Options.Lexical);
        (""dependency"", Options.Dependency);
        (""lexical_with_dependency_validation"", Options.LexicalWithDependencyValidation);
      ]
      (fun opts v -> Ok { opts with statement_reorder_checking = v }
    )

  let post_inference_implicit_instantiation_parser =
    boolean (fun opts v -> Ok { opts with run_post_inference_implicit_instantiation = v })

  let abstract_locations_parser =
    boolean (fun opts v -> Ok { opts with abstract_locations = Some v })

  let automatic_require_default_parser =
    boolean (fun opts v -> Ok { opts with automatic_require_default = Some v })

  let babel_loose_array_spread_parser =
    boolean (fun opts v -> Ok { opts with babel_loose_array_spread = Some v })

  let direct_dependent_files_fix_parser =
    boolean (fun opts v -> Ok { opts with direct_dependent_files_fix = Some v })

  let disable_live_non_parse_errors_parser =
    boolean (fun opts v -> Ok { opts with disable_live_non_parse_errors = Some v })

  let enforce_strict_call_arity_parser =
    boolean (fun opts v -> Ok { opts with enforce_strict_call_arity = v })

  let facebook_module_interop_parser =
    boolean (fun opts v -> Ok { opts with facebook_module_interop = v })

  let file_watcher_parser =
    enum [(""none"", NoFileWatcher); (""dfind"", DFind); (""watchman"", Watchman)] (fun opts v ->
        Ok { opts with file_watcher = Some v }
    )

  let file_watcher_mergebase_with_parser =
    string (fun opts v -> Ok { opts with file_watcher_mergebase_with = Some v })

  let file_watcher_mergebase_with_git_parser =
    string (fun opts v -> Ok { opts with file_watcher_mergebase_with_git = Some v })

  let file_watcher_mergebase_with_hg_parser =
    string (fun opts v -> Ok { opts with file_watcher_mergebase_with_hg = Some v })

  let format_bracket_spacing_parser =
    boolean (fun opts v -> Ok { opts with format_bracket_spacing = Some v })

  let format_single_quotes_parser =
    boolean (fun opts v -> Ok { opts with format_single_quotes = Some v })

  let haste_module_ref_prefix_parser =
    string (fun opts v -> Ok { opts with haste_module_ref_prefix = Some v })

  let haste_use_name_reducers_parser =
    boolean
      ~init:(fun opts -> { opts with haste_use_name_reducers = false })
      (fun opts v -> Ok { opts with haste_use_name_reducers = v })

  let gc_worker_major_heap_increment_parser =
    uint (fun opts v -> Ok { opts with gc_worker_major_heap_increment = Some v })

  let gc_worker_minor_heap_size_parser =
    uint (fun opts v -> Ok { opts with gc_worker_minor_heap_size = Some v })

  let gc_worker_space_overhead_parser =
    uint (fun opts v -> Ok { opts with gc_worker_space_overhead = Some v })

  let gc_worker_window_size_parser =
    uint (fun opts v -> Ok { opts with gc_worker_window_size = Some v })

  let gc_worker_custom_major_ratio_parser =
    uint (fun opts v -> Ok { opts with gc_worker_custom_major_ratio = Some v })

  let gc_worker_custom_minor_ratio_parser =
    uint (fun opts v -> Ok { opts with gc_worker_custom_minor_ratio = Some v })

  let gc_worker_custom_minor_max_size_parser =
    uint (fun opts v -> Ok { opts with gc_worker_custom_minor_max_size = Some v })

  let ignore_non_literal_requires_parser =
    boolean (fun opts v -> Ok { opts with ignore_non_literal_requires = v })

  let lazy_mode_parser =
    enum
      [
        (""true"", Lazy);
        (""false"", Non_lazy);
        (* legacy, deprecated *)
        (""fs"", Lazy);
        (""watchman"", Watchman_DEPRECATED);
        (""none"", Non_lazy);
      ]
      (fun opts v -> Ok { opts with lazy_mode = Some v }
    )

  let merge_timeout_parser =
    uint (fun opts v ->
        let merge_timeout =
          if v = 0 then
            None
          else
            Some v
        in
        Ok { opts with merge_timeout }
    )

  let missing_module_generators_parser =
    mapping
      ~init:(fun opts -> { opts with missing_module_generators = [] })
      ~multiple:true
      (fun (pattern, generator) ->
        optparse_regexp pattern >>= fun pattern -> Ok (pattern, generator))
      (fun opts v ->
        Ok { opts with missing_module_generators = v :: opts.missing_module_generators })

  let module_system_parser =
    enum [(""node"", Options.Node); (""haste"", Options.Haste)] (fun opts v ->
        Ok { opts with module_system = v }
    )

  let name_mapper_parser =
    mapping
      ~multiple:true
      (fun (pattern, template) -> optparse_regexp pattern >>= fun pattern -> Ok (pattern, template))
      (fun opts v ->
        let module_name_mappers = v :: opts.module_name_mappers in
        Ok { opts with module_name_mappers })

  let name_mapper_extension_parser =
    mapping
      ~multiple:true
      (fun (file_ext, template) ->
        optparse_regexp (""^\\(.*\\)\\."" ^ Str.quote file_ext ^ ""$"") >>= fun pattern ->
        Ok (pattern, template))
      (fun opts v ->
        let module_name_mappers = v :: opts.module_name_mappers in
        Ok { opts with module_name_mappers })

  let node_main_field_parser =
    string
      ~init:(fun opts -> { opts with node_main_fields = [] })
      ~multiple:true
      (fun opts v ->
        let node_main_fields = v :: opts.node_main_fields in
        Ok { opts with node_main_fields })

  let node_resolve_dirname_parser =
    string
      ~init:(fun opts -> { opts with node_resolver_dirnames = [] })
      ~multiple:true
      (fun opts v ->
        if v = Filename.current_dir_name || v = Filename.parent_dir_name then
          Error
            (spf
               ""%S is not a valid value for `module.system.node.resolve_dirname`. Each value must be a valid directory name. Maybe try `module.system.node.allow_root_relative=true`?""
               v
            )
        else
          let node_resolver_dirnames = v :: opts.node_resolver_dirnames in
          Ok { opts with node_resolver_dirnames })

  let node_resolver_allow_root_relative_parser =
    boolean (fun opts v -> Ok { opts with node_resolver_allow_root_relative = v })

  let node_resolver_root_relative_dirnames_parser =
    string
      ~init:(fun opts -> { opts with node_resolver_root_relative_dirnames = [] })
      ~multiple:true
      (fun opts v ->
        let node_resolver_root_relative_dirnames = v :: opts.node_resolver_root_relative_dirnames in
        Ok { opts with node_resolver_root_relative_dirnames })

  let react_runtime_parser =
    enum
      [(""classic"", Options.ReactRuntimeClassic); (""automatic"", Options.ReactRuntimeAutomatic)]
      (fun opts react_runtime -> Ok { opts with react_runtime }
    )

  let react_server_component_exts_parser =
    string
      ~init:(fun opts -> { opts with react_server_component_exts = SSet.empty })
      ~multiple:true
      (fun opts v ->
        let react_server_component_exts = SSet.add v opts.react_server_component_exts in
        Ok { opts with react_server_component_exts })

  let relay_integration_excludes_parser =
    string
      ~init:(fun opts -> { opts with relay_integration_excludes = [] })
      ~multiple:true
      (fun opts v ->
        Ok { opts with relay_integration_excludes = v :: opts.relay_integration_excludes })

  let relay_integration_module_prefix_includes_parser =
    string
      ~init:(fun opts -> { opts with relay_integration_module_prefix_includes = [] })
      ~multiple:true
      (fun opts v ->
        Ok
          {
            opts with
            relay_integration_module_prefix_includes =
              v :: opts.relay_integration_module_prefix_includes;
          })

  let root_name_parser =
    string (fun opts v ->
        FlowEventLogger.set_root_name (Some v);
        Ok { opts with root_name = Some v }
    )

  let saved_state_fetcher_parser =
    enum
      [
        (""none"", Options.Dummy_fetcher); (""local"", Options.Local_fetcher); (""fb"", Options.Fb_fetcher);
      ]
      (fun opts saved_state_fetcher -> Ok { opts with saved_state_fetcher }
    )

  let shm_hash_table_pow_parser =
    uint (fun opts shm_hash_table_pow -> Ok { opts with shm_hash_table_pow })

  let strict_es6_import_export_excludes_parser =
    string
      ~init:(fun opts -> { opts with strict_es6_import_export_excludes = [] })
      ~multiple:true
      (fun opts v ->
        Ok
          {
            opts with
            strict_es6_import_export_excludes = v :: opts.strict_es6_import_export_excludes;
          })

  let strict_es6_import_export_parser =
    boolean (fun opts v -> Ok { opts with strict_es6_import_export = v })

  let suppress_types_parser =
    string
      ~init:(fun opts -> { opts with suppress_types = SSet.empty })
      ~multiple:true
      (fun opts v -> Ok { opts with suppress_types = SSet.add v opts.suppress_types })

  let trust_mode_parser =
    enum
      [(""check"", Options.CheckTrust); (""silent"", Options.SilentTrust); (""none"", Options.NoTrust)]
      (fun opts trust_mode -> Ok { opts with trust_mode }
    )

  let env_mode_parser =
    string (fun opts s ->
        match String.split_on_char ',' s |> Base.List.filter ~f:(( <> ) """") with
        | [] -> Error ""env_mode requires an argument""
        | [""ssa""] ->
          if List.length opts.env_mode_constrain_write_dirs = 0 then
            Ok { opts with env_mode = Options.SSAEnv { resolved = false } }
          else
            Error
              ""Option \""env_mode\"" must not be set to \""ssa\"" when \""constrain_write_dirs\"" is set.""
        | [""resolved""] ->
          if List.length opts.env_mode_constrain_write_dirs = 0 then
            Ok { opts with env_mode = Options.SSAEnv { resolved = true } }
          else
            Error
              ""Option \""env_mode\"" must not be set to \""resolved\"" when \""constrain_write_dirs\"" is set.""
        | [""classic""] -> Ok { opts with env_mode = Options.ClassicEnv [] }
        | options ->
          let options =
            Base.List.fold_result options ~init:[] ~f:(fun acc opt ->
                match opt with
                | ""constrain_writes"" when List.length opts.env_mode_constrain_write_dirs = 0 ->
                  Ok (Options.ConstrainWrites :: acc)
                | ""constrain_writes"" ->
                  Error
                    ""Option \""env_mode\"" should not set \""constrain_writes\"" when \""env_mode.constrain_writes.includes\"" is also set.""
                | ""ssa"" -> Error ""\""ssa\"" must be the first and only env_mode option if present""
                | ""resolved"" ->
                  Error ""\""resolved\"" must be the first and only env_mode option if present""
                | ""classic"" ->
                  Error ""\""classic\"" must be the first and only env_mode option if present""
                | opt -> Error (spf ""\""%s\"" is not a valid env_mode option"" opt)
            )
          in
          Base.Result.map
            ~f:(fun options -> { opts with env_mode = Options.ClassicEnv options })
            options
    )

  let env_mode_constrain_write_dirs_parser =
    string
      ~init:(fun opts -> { opts with env_mode_constrain_write_dirs = [] })
      ~multiple:true
      (fun opts v ->
        match opts.env_mode with
        | Options.SSAEnv { resolved = false } ->
          Error
            ""Option \""env_mode\"" must not be set to \""ssa\"" when \""constrain_writes.includes\"" is set.""
        | Options.SSAEnv { resolved = true } ->
          Error
            ""Option \""env_mode\"" must not be set to \""resolved\"" when \""constrain_writes.includes\"" is set.""
        | Options.ClassicEnv opts when List.mem Options.ConstrainWrites opts ->
          Error
            ""Option \""env_mode\"" should not set \""constrain_writes\"" when \""env_mode.constrain_writes.includes\"" is also set.""
        | _ ->
          Ok { opts with env_mode_constrain_write_dirs = v :: opts.env_mode_constrain_write_dirs })

  let watchman_defer_states_parser =
    string ~multiple:true (fun opts v ->
        Ok { opts with watchman_defer_states = v :: opts.watchman_defer_states }
    )

  let watchman_survive_restarts_parser =
    boolean (fun opts v -> Ok { opts with watchman_survive_restarts = Some v })

  let watchman_sync_timeout_parser =
    uint (fun opts v -> Ok { opts with watchman_sync_timeout = Some v })

  let parsers =
    [
      (""all"", boolean (fun opts v -> Ok { opts with all = Some v }));
      (""autoimports"", boolean (fun opts v -> Ok { opts with autoimports = Some v }));
      (""babel_loose_array_spread"", babel_loose_array_spread_parser);
      (""emoji"", boolean (fun opts v -> Ok { opts with emoji = Some v }));
      (""enums"", boolean (fun opts v -> Ok { opts with enums = v }));
      (""exact_by_default"", boolean (fun opts v -> Ok { opts with exact_by_default = v }));
      (""exact_empty_objects"", boolean (fun opts v -> Ok { opts with exact_empty_objects = Some v }));
      (""experimental.abstract_locations"", abstract_locations_parser);
      (""experimental.const_params"", boolean (fun opts v -> Ok { opts with enable_const_params = v }));
      (""experimental.cycle_errors"", boolean (fun opts v -> Ok { opts with cycle_errors = v }));
      (""experimental.direct_dependent_files_fix"", direct_dependent_files_fix_parser);
      (""experimental.disable_live_non_parse_errors"", disable_live_non_parse_errors_parser);
      (""experimental.enforce_local_inference_annotations"", enforce_local_inference_annotations);
      (""experimental.enforce_this_annotations"", enforce_this_annotations);
      (""experimental.enums"", boolean (fun opts v -> Ok { opts with enums = v }));
      (""experimental.env_mode"", env_mode_parser);
      (""experimental.env_mode.constrain_writes.includes"", env_mode_constrain_write_dirs_parser);
      (""experimental.facebook_module_interop"", facebook_module_interop_parser);
      (""experimental.local_inference_annotation_dirs"", local_inference_annotation_dirs);
      (""experimental.module.automatic_require_default"", automatic_require_default_parser);
      (""experimental.new_check"", new_check_parser);
      (""experimental.react.server_component_ext"", react_server_component_exts_parser);
      (""experimental.refactor"", boolean (fun opts v -> Ok { opts with refactor = Some v }));
      ( ""experimental.run_post_inference_implicit_instantiation"",
        post_inference_implicit_instantiation_parser
      );
      (""experimental.statement_reorder_checking"", statement_reorder_checking_parser);
      (""experimental.strict_call_arity"", enforce_strict_call_arity_parser);
      (""experimental.strict_es6_import_export"", strict_es6_import_export_parser);
      (""experimental.strict_es6_import_export.excludes"", strict_es6_import_export_excludes_parser);
      (""experimental.type_asserts"", boolean (fun opts v -> Ok { opts with type_asserts = v }));
      (""facebook.fbs"", string (fun opts v -> Ok { opts with facebook_fbs = Some v }));
      (""facebook.fbt"", string (fun opts v -> Ok { opts with facebook_fbt = Some v }));
      (""file_watcher"", file_watcher_parser);
      (""file_watcher.mergebase_with"", file_watcher_mergebase_with_parser);
      (""file_watcher.mergebase_with_git"", file_watcher_mergebase_with_git_parser);
      (""file_watcher.mergebase_with_hg"", file_watcher_mergebase_with_hg_parser);
      (""file_watcher.watchman.defer_state"", watchman_defer_states_parser);
      (""file_watcher.watchman.survive_restarts"", watchman_survive_restarts_parser);
      (""file_watcher.watchman.sync_timeout"", watchman_sync_timeout_parser);
      (""file_watcher_timeout"", uint (fun opts v -> Ok { opts with file_watcher_timeout = Some v }));
      (""format.bracket_spacing"", format_bracket_spacing_parser);
      (""format.single_quotes"", format_single_quotes_parser);
      (""gc.worker.custom_major_ratio"", gc_worker_custom_major_ratio_parser);
      (""gc.worker.custom_minor_max_size"", gc_worker_custom_minor_max_size_parser);
      (""gc.worker.custom_minor_ratio"", gc_worker_custom_minor_ratio_parser);
      (""gc.worker.major_heap_increment"", gc_worker_major_heap_increment_parser);
      (""gc.worker.minor_heap_size"", gc_worker_minor_heap_size_parser);
      (""gc.worker.space_overhead"", gc_worker_space_overhead_parser);
      (""gc.worker.window_size"", gc_worker_window_size_parser);
      (""include_warnings"", boolean (fun opts v -> Ok { opts with include_warnings = v }));
      (""lazy_mode"", lazy_mode_parser);
      (""log.file"", filepath (fun opts v -> Ok { opts with log_file = Some v }));
      (""log_saving"", log_saving_parser);
      (""max_header_tokens"", uint (fun opts v -> Ok { opts with max_header_tokens = v }));
      (""max_literal_length"", uint (fun opts v -> Ok { opts with max_literal_length = v }));
      (""merge_timeout"", merge_timeout_parser);
      (""module.file_ext"", file_ext_parser);
      (""module.ignore_non_literal_requires"", ignore_non_literal_requires_parser);
      (""module.name_mapper"", name_mapper_parser);
      (""module.name_mapper.extension"", name_mapper_extension_parser);
      (""module.missing_module_generators"", missing_module_generators_parser);
      (""module.system"", module_system_parser);
      (""module.system.haste.module_ref_prefix"", haste_module_ref_prefix_parser);
      (""module.system.haste.name_reducers"", haste_name_reducers_parser);
      (""module.system.haste.paths.excludes"", haste_paths_excludes_parser);
      (""module.system.haste.paths.includes"", haste_paths_includes_parser);
      (""module.system.haste.use_name_reducers"", haste_use_name_reducers_parser);
      (""module.system.node.allow_root_relative"", node_resolver_allow_root_relative_parser);
      (""module.system.node.main_field"", node_main_field_parser);
      (""module.system.node.resolve_dirname"", node_resolve_dirname_parser);
      (""module.system.node.root_relative_dirname"", node_resolver_root_relative_dirnames_parser);
      (""module.use_strict"", boolean (fun opts v -> Ok { opts with modules_are_use_strict = v }));
      (""munge_underscores"", boolean (fun opts v -> Ok { opts with munge_underscores = v }));
      (""name"", root_name_parser);
      (""no_flowlib"", boolean (fun opts v -> Ok { opts with no_flowlib = v }));
      (""react.runtime"", react_runtime_parser);
      (""recursion_limit"", uint (fun opts v -> Ok { opts with recursion_limit = v }));
      (""relay_integration"", boolean (fun opts v -> Ok { opts with relay_integration = v }));
      (""relay_integration.excludes"", relay_integration_excludes_parser);
      ( ""relay_integration.module_prefix"",
        string (fun opts v -> Ok { opts with relay_integration_module_prefix = Some v })
      );
      (""relay_integration.module_prefix.includes"", relay_integration_module_prefix_includes_parser);
      (""saved_state.fetcher"", saved_state_fetcher_parser);
      (""server.max_workers"", uint (fun opts v -> Ok { opts with max_workers = v }));
      (""sharedmemory.hash_table_pow"", shm_hash_table_pow_parser);
      (""sharedmemory.heap_size"", uint (fun opts shm_heap_size -> Ok { opts with shm_heap_size }));
      (""sharedmemory.log_level"", uint (fun opts shm_log_level -> Ok { opts with shm_log_level }));
      (""suppress_type"", suppress_types_parser);
      (""temp_dir"", string (fun opts v -> Ok { opts with temp_dir = v }));
      (""traces"", uint (fun opts v -> Ok { opts with traces = v }));
      (""trust_mode"", trust_mode_parser);
      (""types_first.max_files_checked_per_worker"", max_files_checked_per_worker_parser);
      (""types_first.max_rss_bytes_for_check_per_worker"", max_rss_bytes_for_check_per_worker_parser);
      (""types_first.max_seconds_for_check_per_worker"", max_seconds_for_check_per_worker_parser);
      (""wait_for_recheck"", boolean (fun opts v -> Ok { opts with wait_for_recheck = v }));
    ]

  let parse =
    let error_of_opt_error key (line_num, opt_error) =
      let msg =
        match opt_error with
        | Failed_to_parse_value msg -> spf ""Error parsing value for \""%s\"". %s"" key msg
        | Failed_to_set msg -> spf ""Error setting value for \""%s\"". %s"" key msg
        | Duplicate_option -> spf ""Duplicate option: \""%s\"""" key
      in
      (line_num, msg)
    in
    let rec loop
        (acc : (raw_options * t, error) result)
        (parsers : (string * (raw_values -> t -> (t, opt_error) result)) list) =
      acc >>= fun (raw_opts, config) ->
      match parsers with
      | [] -> Ok (raw_opts, config)
      | (key, f) :: rest ->
        let acc =
          match SMap.find_opt key raw_opts with
          | None -> Ok (raw_opts, config)
          | Some values ->
            f values config |> Base.Result.map_error ~f:(error_of_opt_error key) >>= fun config ->
            let new_raw_opts = SMap.remove key raw_opts in
            Ok (new_raw_opts, config)
        in
        loop acc rest
    in
    fun (init : t) (lines : line list) : (t * warning list, error) result ->
      parse_lines lines >>= fun raw_options ->
      loop (Ok (raw_options, init)) parsers >>= warn_on_unknown_opts
end

type rollout = {
  enabled_group: string;
  disabled_groups: SSet.t;
}

type config = {
  rollouts: rollout SMap.t;
  (* completely ignored files (both module resolving and typing) *)
  ignores: string list;
  (* files that should be treated as untyped *)
  untyped: string list;
  (* files that should be treated as declarations *)
  declarations: string list;
  (* non-root include paths *)
  includes: string list;
  (* library paths. no wildcards *)
  libs: string list;
  (* lint severities *)
  lint_severities: Severity.severity LintSettings.t;
  (* strict mode *)
  strict_mode: StrictModeSettings.t;
  (* config options *)
  options: Opts.t;
  (* version constraint *)
  version: string option;
}

type config_result = (config * warning list, error) result

module Pp : sig
  val config : out_channel -> config -> unit
end = struct
  open Printf

  let section_header o section = fprintf o ""[%s]\n"" section

  let ignores o = Base.List.iter ~f:(fprintf o ""%s\n"")

  let untyped o = Base.List.iter ~f:(fprintf o ""%s\n"")

  let declarations o = Base.List.iter ~f:(fprintf o ""%s\n"")

  let includes o = Base.List.iter ~f:(fprintf o ""%s\n"")

  let libs o = Base.List.iter ~f:(fprintf o ""%s\n"")

  let options =
    let pp_opt o name value = fprintf o ""%s=%s\n"" name value in
    let module_system = function
      | Options.Node -> ""node""
      | Options.Haste -> ""haste""
    in
    fun o config ->
      Opts.(
        let options = config.options in
        if options.module_system <> default_options.module_system then
          pp_opt o ""module.system"" (module_system options.module_system);
        if options.all <> default_options.all then
          pp_opt o ""all"" (string_of_bool (Base.Option.value options.all ~default:false));
        if options.temp_dir <> default_options.temp_dir then pp_opt o ""temp_dir"" options.temp_dir;
        if options.include_warnings <> default_options.include_warnings then
          pp_opt o ""include_warnings"" (string_of_bool options.include_warnings)
      )

  let lints o config =
    let lint_severities = config.lint_severities in
    let lint_default = LintSettings.get_default lint_severities in
    (* Don't print an 'all' setting if it matches the default setting. *)
    if lint_default <> LintSettings.get_default LintSettings.empty_severities then
      fprintf o ""all=%s\n"" (Severity.string_of_severity lint_default);
    LintSettings.iter
      (fun kind (state, _) ->
        fprintf o ""%s=%s\n"" (Lints.string_of_kind kind) (Severity.string_of_severity state))
      lint_severities

  let strict o config =
    Lints.(
      let strict_mode = config.strict_mode in
      StrictModeSettings.iter (fun kind -> fprintf o ""%s\n"" (string_of_kind kind)) strict_mode
    )

  let section_if_nonempty o header f = function
    | [] -> ()
    | xs ->
      section_header o header;
      f o xs;
      fprintf o ""\n""

  let config o config =
    section_header o ""ignore"";
    ignores o config.ignores;
    fprintf o ""\n"";
    section_if_nonempty o ""untyped"" untyped config.untyped;
    section_if_nonempty o ""declarations"" declarations config.declarations;
    section_header o ""include"";
    includes o config.includes;
    fprintf o ""\n"";
    section_header o ""libs"";
    libs o config.libs;
    fprintf o ""\n"";
    section_header o ""lints"";
    lints o config;
    fprintf o ""\n"";
    section_header o ""options"";
    options o config;
    fprintf o ""\n"";
    section_header o ""strict"";
    strict o config
end

let empty_config =
  {
    rollouts = SMap.empty;
    ignores = [];
    untyped = [];
    declarations = [];
    includes = [];
    libs = [];
    lint_severities = LintSettings.empty_severities;
    strict_mode = StrictModeSettings.empty;
    options = Opts.default_options;
    version = None;
  }

let group_into_sections : line list -> (section list, error) result =
  let is_section_header = Str.regexp ""^\\[\\(.*\\)\\]$"" in
  let rec loop acc lines =
    acc >>= fun (seen, sections, (section_name, section_lines)) ->
    match lines with
    | [] ->
      let section = (section_name, Base.List.rev section_lines) in
      Ok (Base.List.rev (section :: sections))
    | (ln, line) :: rest ->
      if Str.string_match is_section_header line 0 then
        let sections = (section_name, Base.List.rev section_lines) :: sections in
        let section_name = Str.matched_group 1 line in
        if SSet.mem section_name seen then
          Error (ln, spf ""contains duplicate section: \""%s\"""" section_name)
        else
          let seen = SSet.add section_name seen in
          let section = ((ln, section_name), []) in
          let acc = Ok (seen, sections, section) in
          loop acc rest
      else
        let acc = Ok (seen, sections, (section_name, (ln, line) :: section_lines)) in
        loop acc rest
  in
  (fun lines -> loop (Ok (SSet.empty, [], ((0, """"), []))) lines)

let trim_lines lines =
  lines
  |> Base.List.map ~f:(fun (_, line) -> String.trim line)
  |> Base.List.filter ~f:(fun s -> s <> """")

let trim_labeled_lines lines =
  lines
  |> Base.List.map ~f:(fun (label, line) -> (label, String.trim line))
  |> Base.List.filter ~f:(fun (_, s) -> s <> """")

(* parse [include] lines *)
let parse_includes lines config =
  let includes = trim_lines lines in
  Ok ({ config with includes }, [])

let parse_libs lines config : (config * warning list, error) result =
  let libs = trim_lines lines in
  Ok ({ config with libs }, [])

let parse_ignores lines config =
  let ignores = trim_lines lines in
  Ok ({ config with ignores }, [])

let parse_untyped lines config =
  let untyped = trim_lines lines in
  Ok ({ config with untyped }, [])

let parse_declarations lines config =
  let declarations = trim_lines lines in
  Ok ({ config with declarations }, [])

let parse_options lines config : (config * warning list, error) result =
  Opts.parse config.options lines >>= fun (options, warnings) ->
  Ok ({ config with options }, warnings)

let parse_version lines config =
  let potential_versions =
    lines
    |> Base.List.map ~f:(fun (ln, line) -> (ln, String.trim line))
    |> Base.List.filter ~f:(fun (_, s) -> s <> """")
  in
  match potential_versions with
  | (ln, version_str) :: _ ->
    if not (Semver.is_valid_range version_str) then
      Error
        ( ln,
          spf
            ""Expected version to match %%d.%%d.%%d, with an optional leading ^, got %s""
            version_str
        )
    else
      Ok ({ config with version = Some version_str }, [])
  | _ -> Ok (config, [])

let parse_lints lines config : (config * warning list, error) result =
  let lines = trim_labeled_lines lines in
  LintSettings.of_lines config.lint_severities lines >>= fun (lint_severities, warnings) ->
  Ok ({ config with lint_severities }, warnings)

let parse_strict lines config =
  let lines = trim_labeled_lines lines in
  StrictModeSettings.of_lines lines >>= fun strict_mode -> Ok ({ config with strict_mode }, [])

(* Basically fold_left but with early exit when f returns an Error *)
let rec fold_left_stop_on_error
    (l : 'elem list) ~(acc : 'acc) ~(f : 'acc -> 'elem -> ('acc, 'error) result) :
    ('acc, 'error) result =
  match l with
  | [] -> Ok acc
  | elem :: rest -> f acc elem >>= fun acc -> fold_left_stop_on_error rest ~acc ~f

(* Rollouts are based on randomness, but we want it to be stable from run to run. So we seed our
 * pseudo random number generator with
 *
 * 1. The hostname
 * 2. The user
 * 3. The name of the rollout
 *)
let calculate_pct rollout_name =
  let state = Xx.init 0L in
  Xx.update state (Unix.gethostname ());
  Xx.update_int state (Unix.getuid ());
  Xx.update state rollout_name;
  let hash = Xx.digest state in
  Xx.modulo hash 100

(* The optional rollout section has 0 or more lines. Each line defines a single rollout. For example
 *
 * [rollouts]
 *
 * testA=40% on, 60% off
 * testB=50% blue, 20% yellow, 30% pink
 *
 * The first line defines a rollout named ""testA"" with two groups.
 * The second line defines a rollout named ""testB"" with three groups.
 *
 * Each rollout's groups must sum to 100.
 *)
let parse_rollouts config lines =
  Base.Option.value_map lines ~default:(Ok config) ~f:(fun lines ->
      let lines = trim_labeled_lines lines in
      fold_left_stop_on_error lines ~acc:SMap.empty ~f:(fun rollouts (line_num, line) ->
          (* A rollout's name is can only contain [a-zA-Z0-9._] *)
          if Str.string_match (Str.regexp ""^\\([a-zA-Z0-9._]+\\)=\\(.*\\)$"") line 0 then
            let rollout_name = Str.matched_group 1 line in
            let rollout_values_raw = Str.matched_group 2 line in
            let my_pct = calculate_pct rollout_name in
            fold_left_stop_on_error
              (* Groups are delimited with commas *)
              Str.(split (regexp "","") rollout_values_raw)
              ~acc:(None, SSet.empty, 0)
              ~f:(fun (enabled_group, disabled_groups, pct_total) raw_group ->
                let raw_group = String.trim raw_group in
                (* A rollout group has the for ""X% label"", where label can only contain
                 * [a-zA-Z0-9._] *)
                if Str.string_match (Str.regexp ""^\\([0-9]+\\)% \\([a-zA-Z0-9._]+\\)$"") raw_group 0
                then
                  let group_pct = Str.matched_group 1 raw_group |> int_of_string in
                  let group_name = Str.matched_group 2 raw_group in
                  if enabled_group = Some group_name || SSet.mem group_name disabled_groups then
                    Error
                      ( line_num,
                        spf
                          ""Groups must have unique names. There is more than one %S group""
                          group_name
                      )
                  else
                    let (enabled_group, disabled_groups) =
                      match enabled_group with
                      | None when my_pct < group_pct + pct_total ->
                        (* This is the first group that passes my_pct, so we enable it *)
                        (Some group_name, disabled_groups)
                      | _ ->
                        (* Either we've already chosen the enabled group or we haven't passed my_pct *)
                        (enabled_group, SSet.add group_name disabled_groups)
                    in
                    Ok (enabled_group, disabled_groups, pct_total + group_pct)
                else
                  Error
                    ( line_num,
                      ""Malformed rollout group. A group should be a percentage and an identifier, ""
                      ^ ""like `50% on`""
                    ))
            >>= fun (enabled_group, disabled_groups, pct_total) ->
            if pct_total = 100 then
              if SMap.mem rollout_name rollouts then
                Error
                  ( line_num,
                    spf
                      ""Rollouts must have unique names. There already is a %S rollout""
                      rollout_name
                  )
              else
                match enabled_group with
                | None -> Error (line_num, ""Invariant violation: failed to choose a group"")
                | Some enabled_group ->
                  Ok (SMap.add rollout_name { enabled_group; disabled_groups } rollouts)
            else
              Error
                ( line_num,
                  spf ""Rollout groups must sum to 100%%. %S sums to %d%%"" rollout_name pct_total
                )
          else
            Error
              ( line_num,
                ""Malformed rollout. A rollout should be an identifier followed by a list of groups, ""
                ^ ""like `myRollout=10% on, 50% off`""
              )
      )
      >>= fun rollouts -> Ok { config with rollouts }
  )

let parse_section config ((section_ln, section), lines) : (config * warning list, error) result =
  match (section, lines) with
  | ("""", []) when section_ln = 0 -> Ok (config, [])
  | ("""", (ln, _) :: _) when section_ln = 0 -> Error (ln, ""Unexpected config line not in any section"")
  | (""include"", _) -> parse_includes lines config
  | (""ignore"", _) -> parse_ignores lines config
  | (""libs"", _) -> parse_libs lines config
  | (""lints"", _) -> parse_lints lines config
  | (""declarations"", _) -> parse_declarations lines config
  | (""strict"", _) -> parse_strict lines config
  | (""options"", _) -> parse_options lines config
  | (""untyped"", _) -> parse_untyped lines config
  | (""version"", _) -> parse_version lines config
  | _ -> Ok (config, [(section_ln, spf ""Unsupported config section: \""%s\"""" section)])

let parse =
  (* Filter every section (except the rollouts section) for disabled rollouts. For example, if a
   * line starts with (my_rollout=on) and the ""on"" group is not enabled for the ""my_rollout""
   * rollout, then drop the line completely.
   *
   * Lines with enabled rollouts just have the prefix stripped
   *)
  let filter_sections_by_rollout sections config =
    (* The rollout prefix looks like `(rollout_name=group_name)` *)
    let rollout_regex = Str.regexp ""^(\\([a-zA-Z0-9._]+\\)=\\([a-zA-Z0-9._]+\\))\\(.*\\)$"" in
    fold_left_stop_on_error sections ~acc:[] ~f:(fun acc (section_name, lines) ->
        fold_left_stop_on_error lines ~acc:[] ~f:(fun acc (line_num, line) ->
            if Str.string_match rollout_regex line 0 then
              let rollout_name = Str.matched_group 1 line in
              let group_name = Str.matched_group 2 line in
              let line = Str.matched_group 3 line in
              match SMap.find_opt rollout_name config.rollouts with
              | None -> Error (line_num, spf ""Unknown rollout %S"" rollout_name)
              | Some { enabled_group; disabled_groups } ->
                if enabled_group = group_name then
                  Ok ((line_num, line) :: acc)
                else if SSet.mem group_name disabled_groups then
                  Ok acc
                else
                  Error (line_num, spf ""Unknown group %S in rollout %S"" group_name rollout_name)
            else
              Ok ((line_num, line) :: acc)
        )
        >>= fun lines -> Ok ((section_name, Base.List.rev lines) :: acc)
    )
    >>= fun sections -> Ok (config, Base.List.rev sections)
  in
  let process_rollouts config sections =
    let rollout_section_lines = ref None in
    let sections =
      Base.List.filter sections ~f:(function
          | ((_, ""rollouts""), lines) ->
            rollout_section_lines := Some lines;
            false
          | _ -> true
          )
    in
    parse_rollouts config !rollout_section_lines >>= filter_sections_by_rollout sections
  in
  let rec loop acc sections =
    acc >>= fun (config, warn_acc) ->
    match sections with
    | [] -> Ok (config, Base.List.rev warn_acc)
    | section :: rest ->
      parse_section config section >>= fun (config, warnings) ->
      let acc = Ok (config, Base.List.rev_append warnings warn_acc) in
      loop acc rest
  in
  fun config lines ->
    group_into_sections lines >>= process_rollouts config >>= fun (config, sections) ->
    loop (Ok (config, [])) sections

let is_not_comment =
  let comment_regexps =
    [
      Str.regexp_string ""#"";
      (* Line starts with # *)
      Str.regexp_string "";"";
      (* Line starts with ; *)
      Str.regexp_string ""\240\159\146\169"";
      (* Line starts with poop emoji *)
    ]
  in
  fun (_, line) ->
    not (Base.List.exists ~f:(fun regexp -> Str.string_match regexp line 0) comment_regexps)

let read filename =
  let contents = Sys_utils.cat filename in
  let hash =
    let xx_state = Xx.init 0L in
    Xx.update xx_state contents;
    Xx.digest xx_state
  in
  let lines =
    contents
    |> Sys_utils.split_lines
    |> Base.List.mapi ~f:(fun i line -> (i + 1, String.trim line))
    |> Base.List.filter ~f:is_not_comment
  in
  (lines, hash)

let init ~ignores ~untyped ~declarations ~includes ~libs ~options ~lints =
  let ( >>= )
      (acc : (config * warning list, error) result)
      (fn : config -> (config * warning list, error) result) =
    let ( >>= ) = Base.Result.( >>= ) in
    acc >>= fun (config, warn_acc) ->
    fn config >>= fun (config, warnings) -> Ok (config, Base.List.rev_append warnings warn_acc)
  in
  let ignores_lines = Base.List.map ~f:(fun s -> (1, s)) ignores in
  let untyped_lines = Base.List.map ~f:(fun s -> (1, s)) untyped in
  let declarations_lines = Base.List.map ~f:(fun s -> (1, s)) declarations in
  let includes_lines = Base.List.map ~f:(fun s -> (1, s)) includes in
  let options_lines = Base.List.map ~f:(fun s -> (1, s)) options in
  let lib_lines = Base.List.map ~f:(fun s -> (1, s)) libs in
  let lint_lines = Base.List.map ~f:(fun s -> (1, s)) lints in
  Ok (empty_config, [])
  >>= parse_ignores ignores_lines
  >>= parse_untyped untyped_lines
  >>= parse_declarations declarations_lines
  >>= parse_includes includes_lines
  >>= parse_options options_lines
  >>= parse_libs lib_lines
  >>= parse_lints lint_lines

let write config oc = Pp.config oc config

(* We should restart every time the config changes, so it's generally cool to cache it *)
let cache = ref None

let get_from_cache ?(allow_cache = true) filename =
  match !cache with
  | Some ((cached_filename, _, _) as cached_data) when allow_cache ->
    assert (filename = cached_filename);
    cached_data
  | _ ->
    let (lines, hash) = read filename in
    let config = { empty_config with lint_severities = LintSettings.default_severities } in
    let config = parse config lines in
    let cached_data = (filename, config, hash) in
    cache := Some cached_data;
    cached_data

let get ?allow_cache filename =
  let (_, config, _) = get_from_cache ?allow_cache filename in
  config

let get_hash ?allow_cache filename =
  let (_, _, hash) = get_from_cache ?allow_cache filename in
  hash

let get_with_hash ?allow_cache filename =
  let (_, config, hash) = get_from_cache ?allow_cache filename in
  (config, hash)

(* Accessors *)

let enabled_rollouts config = SMap.map (fun { enabled_group; _ } -> enabled_group) config.rollouts

(* completely ignored files (both module resolving and typing) *)
let ignores config = config.ignores

(* files that should be treated as untyped *)
let untyped config = config.untyped

(* files that should be treated as declarations *)
let declarations config = config.declarations

(* non-root include paths *)
let includes config = config.includes

(* library paths. no wildcards *)
let libs config = config.libs

(* options *)
let abstract_locations c = c.options.Opts.abstract_locations

let all c = c.options.Opts.all

let autoimports c = c.options.Opts.autoimports

let automatic_require_default c = c.options.Opts.automatic_require_default

let babel_loose_array_spread c = c.options.Opts.babel_loose_array_spread

let cycle_errors c = c.options.Opts.cycle_errors

let direct_dependent_files_fix c = c.options.Opts.direct_dependent_files_fix

let disable_live_non_parse_errors c = c.options.Opts.disable_live_non_parse_errors

let emoji c = c.options.Opts.emoji

let enable_const_params c = c.options.Opts.enable_const_params

let enforce_local_inference_annotations c = c.options.Opts.enforce_local_inference_annotations

let enforce_strict_call_arity c = c.options.Opts.enforce_strict_call_arity

let enforce_this_annotations c = c.options.Opts.enforce_this_annotations

let enums c = c.options.Opts.enums

let env_mode c = c.options.Opts.env_mode

let env_mode_constrain_write_dirs c = c.options.Opts.env_mode_constrain_write_dirs

let exact_by_default c = c.options.Opts.exact_by_default

let exact_empty_objects c = c.options.Opts.exact_empty_objects

let facebook_fbs c = c.options.Opts.facebook_fbs

let facebook_fbt c = c.options.Opts.facebook_fbt

let facebook_module_interop c = c.options.Opts.facebook_module_interop

let file_watcher c = c.options.Opts.file_watcher

let file_watcher_mergebase_with c = c.options.Opts.file_watcher_mergebase_with

let file_watcher_mergebase_with_git c = c.options.Opts.file_watcher_mergebase_with_git

let file_watcher_mergebase_with_hg c = c.options.Opts.file_watcher_mergebase_with_hg

let file_watcher_timeout c = c.options.Opts.file_watcher_timeout

let format_bracket_spacing c = c.options.Opts.format_bracket_spacing

let format_single_quotes c = c.options.Opts.format_single_quotes

let gc_worker_custom_major_ratio c = c.options.Opts.gc_worker_custom_major_ratio

let gc_worker_custom_minor_max_size c = c.options.Opts.gc_worker_custom_minor_max_size

let gc_worker_custom_minor_ratio c = c.options.Opts.gc_worker_custom_minor_ratio

let gc_worker_major_heap_increment c = c.options.Opts.gc_worker_major_heap_increment

let gc_worker_minor_heap_size c = c.options.Opts.gc_worker_minor_heap_size

let gc_worker_space_overhead c = c.options.Opts.gc_worker_space_overhead

let gc_worker_window_size c = c.options.Opts.gc_worker_window_size

let haste_module_ref_prefix c = c.options.Opts.haste_module_ref_prefix

let haste_name_reducers c = c.options.Opts.haste_name_reducers

let haste_paths_excludes c = c.options.Opts.haste_paths_excludes

let haste_paths_includes c = c.options.Opts.haste_paths_includes

let haste_use_name_reducers c = c.options.Opts.haste_use_name_reducers

let ignore_non_literal_requires c = c.options.Opts.ignore_non_literal_requires

let include_warnings c = c.options.Opts.include_warnings

let lazy_mode c = c.options.Opts.lazy_mode

(* global defaults for lint severities and strict mode *)
let lint_severities c = c.lint_severities

let local_inference_annotation_dirs c = c.options.Opts.local_inference_annotation_dirs

let log_file c = c.options.Opts.log_file

let log_saving c = c.options.Opts.log_saving

let max_files_checked_per_worker c = c.options.Opts.max_files_checked_per_worker

let max_header_tokens c = c.options.Opts.max_header_tokens

let max_literal_length c = c.options.Opts.max_literal_length

let max_rss_bytes_for_check_per_worker c = c.options.Opts.max_rss_bytes_for_check_per_worker

let max_seconds_for_check_per_worker c = c.options.Opts.max_seconds_for_check_per_worker

let max_workers c = c.options.Opts.max_workers

let merge_timeout c = c.options.Opts.merge_timeout

let missing_module_generators c = c.options.Opts.missing_module_generators

let module_file_exts c = c.options.Opts.module_file_exts

let module_name_mappers c = c.options.Opts.module_name_mappers

let module_resource_exts c = c.options.Opts.module_resource_exts

let module_system c = c.options.Opts.module_system

let modules_are_use_strict c = c.options.Opts.modules_are_use_strict

let munge_underscores c = c.options.Opts.munge_underscores

let no_flowlib c = c.options.Opts.no_flowlib

let node_main_fields c = c.options.Opts.node_main_fields

let node_resolver_allow_root_relative c = c.options.Opts.node_resolver_allow_root_relative

let node_resolver_dirnames c = c.options.Opts.node_resolver_dirnames

let node_resolver_root_relative_dirnames c = c.options.Opts.node_resolver_root_relative_dirnames

let react_runtime c = c.options.Opts.react_runtime

let react_server_component_exts c = c.options.Opts.react_server_component_exts

let recursion_limit c = c.options.Opts.recursion_limit

let refactor c = c.options.Opts.refactor

let relay_integration c = c.options.Opts.relay_integration

let relay_integration_excludes c = c.options.Opts.relay_integration_excludes

let relay_integration_module_prefix c = c.options.Opts.relay_integration_module_prefix

let relay_integration_module_prefix_includes c =
  c.options.Opts.relay_integration_module_prefix_includes

let required_version c = c.version

let root_name c = c.options.Opts.root_name

let run_post_inference_implicit_instantiation c =
  c.options.Opts.run_post_inference_implicit_instantiation

let saved_state_fetcher c = c.options.Opts.saved_state_fetcher

let shm_hash_table_pow c = c.options.Opts.shm_hash_table_pow

let shm_heap_size c = c.options.Opts.shm_heap_size

let shm_log_level c = c.options.Opts.shm_log_level

let statement_reorder_checking c = c.options.Opts.statement_reorder_checking

let strict_es6_import_export c = c.options.Opts.strict_es6_import_export

let strict_es6_import_export_excludes c = c.options.Opts.strict_es6_import_export_excludes

let strict_mode c = c.strict_mode

let suppress_types c = c.options.Opts.suppress_types

let temp_dir c = c.options.Opts.temp_dir

let traces c = c.options.Opts.traces

let trust_mode c = c.options.Opts.trust_mode

let type_asserts c = c.options.Opts.type_asserts

let wait_for_recheck c = c.options.Opts.wait_for_recheck

let watchman_defer_states c = c.options.Opts.watchman_defer_states

let watchman_survive_restarts c = c.options.Opts.watchman_survive_restarts

let watchman_sync_timeout c = c.options.Opts.watchman_sync_timeout
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*             Xavier Leroy, projet Cristal, INRIA Rocquencourt           *)
(*                                                                        *)
(*   Copyright 1996 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(* The lexer definition *)

{
open Lexing
open Misc
open Parser

type error =
  | Illegal_character of char
  | Illegal_escape of string * string option
  | Reserved_sequence of string * string option
  | Unterminated_comment of Location.t
  | Unterminated_string
  | Unterminated_string_in_comment of Location.t * Location.t
  | Empty_character_literal
  | Keyword_as_label of string
  | Invalid_literal of string
  | Invalid_directive of string * string option

exception Error of error * Location.t

(* The table of keywords *)

let keyword_table =
  create_hashtable 149 [
    ""and"", AND;
    ""as"", AS;
    ""assert"", ASSERT;
    ""begin"", BEGIN;
    ""class"", CLASS;
    ""constraint"", CONSTRAINT;
    ""do"", DO;
    ""done"", DONE;
    ""downto"", DOWNTO;
    ""else"", ELSE;
    ""end"", END;
    ""exception"", EXCEPTION;
    ""external"", EXTERNAL;
    ""false"", FALSE;
    ""for"", FOR;
    ""fun"", FUN;
    ""function"", FUNCTION;
    ""functor"", FUNCTOR;
    ""if"", IF;
    ""in"", IN;
    ""include"", INCLUDE;
    ""inherit"", INHERIT;
    ""initializer"", INITIALIZER;
    ""lazy"", LAZY;
    ""let"", LET;
    ""match"", MATCH;
    ""method"", METHOD;
    ""module"", MODULE;
    ""mutable"", MUTABLE;
    ""new"", NEW;
    ""nonrec"", NONREC;
    ""object"", OBJECT;
    ""of"", OF;
    ""open"", OPEN;
    ""or"", OR;
(*  ""parser"", PARSER; *)
    ""private"", PRIVATE;
    ""rec"", REC;
    ""sig"", SIG;
    ""struct"", STRUCT;
    ""then"", THEN;
    ""to"", TO;
    ""true"", TRUE;
    ""try"", TRY;
    ""type"", TYPE;
    ""val"", VAL;
    ""virtual"", VIRTUAL;
    ""when"", WHEN;
    ""while"", WHILE;
    ""with"", WITH;

    ""lor"", INFIXOP3(""lor""); (* Should be INFIXOP2 *)
    ""lxor"", INFIXOP3(""lxor""); (* Should be INFIXOP2 *)
    ""mod"", INFIXOP3(""mod"");
    ""land"", INFIXOP3(""land"");
    ""lsl"", INFIXOP4(""lsl"");
    ""lsr"", INFIXOP4(""lsr"");
    ""asr"", INFIXOP4(""asr"")
]

(* To buffer string literals *)

let string_buffer = Buffer.create 256
let reset_string_buffer () = Buffer.reset string_buffer
let get_stored_string () = Buffer.contents string_buffer

let store_string_char c = Buffer.add_char string_buffer c
let store_string_utf_8_uchar u = Buffer.add_utf_8_uchar string_buffer u
let store_string s = Buffer.add_string string_buffer s
let store_lexeme lexbuf = store_string (Lexing.lexeme lexbuf)

(* To store the position of the beginning of a string and comment *)
let string_start_loc = ref Location.none
let comment_start_loc = ref []
let in_comment () = !comment_start_loc <> []
let is_in_string = ref false
let in_string () = !is_in_string
let print_warnings = ref true

(* Escaped chars are interpreted in strings unless they are in comments. *)
let store_escaped_char lexbuf c =
  if in_comment () then store_lexeme lexbuf else store_string_char c

let store_escaped_uchar lexbuf u =
  if in_comment () then store_lexeme lexbuf else store_string_utf_8_uchar u

let compute_quoted_string_idloc {Location.loc_start = orig_loc } shift id =
  let id_start_pos = orig_loc.Lexing.pos_cnum + shift in
  let loc_start =
    Lexing.{orig_loc with pos_cnum = id_start_pos }
  in
  let loc_end =
    Lexing.{orig_loc with pos_cnum = id_start_pos + String.length id}
  in
  {Location. loc_start ; loc_end ; loc_ghost = false }

let wrap_string_lexer f lexbuf =
  let loc_start = lexbuf.lex_curr_p in
  reset_string_buffer();
  is_in_string := true;
  let string_start = lexbuf.lex_start_p in
  string_start_loc := Location.curr lexbuf;
  let loc_end = f lexbuf in
  is_in_string := false;
  lexbuf.lex_start_p <- string_start;
  let loc = Location.{loc_ghost= false; loc_start; loc_end} in
  get_stored_string (), loc

let wrap_comment_lexer comment lexbuf =
  let start_loc = Location.curr lexbuf  in
  comment_start_loc := [start_loc];
  reset_string_buffer ();
  let end_loc = comment lexbuf in
  let s = get_stored_string () in
  reset_string_buffer ();
  s,
  { start_loc with Location.loc_end = end_loc.Location.loc_end }

let error lexbuf e = raise (Error(e, Location.curr lexbuf))
let error_loc loc e = raise (Error(e, loc))

(* to translate escape sequences *)

let digit_value c =
  match c with
  | 'a' .. 'f' -> 10 + Char.code c - Char.code 'a'
  | 'A' .. 'F' -> 10 + Char.code c - Char.code 'A'
  | '0' .. '9' -> Char.code c - Char.code '0'
  | _ -> assert false

let num_value lexbuf ~base ~first ~last =
  let c = ref 0 in
  for i = first to last do
    let v = digit_value (Lexing.lexeme_char lexbuf i) in
    assert(v < base);
    c := (base * !c) + v
  done;
  !c

let char_for_backslash = function
  | 'n' -> '\010'
  | 'r' -> '\013'
  | 'b' -> '\008'
  | 't' -> '\009'
  | c   -> c

let illegal_escape lexbuf reason =
  let error = Illegal_escape (Lexing.lexeme lexbuf, Some reason) in
  raise (Error (error, Location.curr lexbuf))

let char_for_decimal_code lexbuf i =
  let c = num_value lexbuf ~base:10 ~first:i ~last:(i+2) in
  if (c < 0 || c > 255) then
    if in_comment ()
    then 'x'
    else
      illegal_escape lexbuf
        (Printf.sprintf
          ""%d is outside the range of legal characters (0-255)."" c)
  else Char.chr c

let char_for_octal_code lexbuf i =
  let c = num_value lexbuf ~base:8 ~first:i ~last:(i+2) in
  if (c < 0 || c > 255) then
    if in_comment ()
    then 'x'
    else
      illegal_escape lexbuf
        (Printf.sprintf
          ""o%o (=%d) is outside the range of legal characters (0-255)."" c c)
  else Char.chr c

let char_for_hexadecimal_code lexbuf i =
  Char.chr (num_value lexbuf ~base:16 ~first:i ~last:(i+1))

let uchar_for_uchar_escape lexbuf =
  let len = Lexing.lexeme_end lexbuf - Lexing.lexeme_start lexbuf in
  let first = 3 (* skip opening \u{ *) in
  let last = len - 2 (* skip closing } *) in
  let digit_count = last - first + 1 in
  match digit_count > 6 with
  | true ->
      illegal_escape lexbuf
        ""too many digits, expected 1 to 6 hexadecimal digits""
  | false ->
      let cp = num_value lexbuf ~base:16 ~first ~last in
      if Uchar.is_valid cp then Uchar.unsafe_of_int cp else
      illegal_escape lexbuf
        (Printf.sprintf ""%X is not a Unicode scalar value"" cp)

let is_keyword name = Hashtbl.mem keyword_table name

let check_label_name lexbuf name =
  if is_keyword name then error lexbuf (Keyword_as_label name)

(* Update the current location with file name and line number. *)

let update_loc lexbuf file line absolute chars =
  let pos = lexbuf.lex_curr_p in
  let new_file = match file with
                 | None -> pos.pos_fname
                 | Some s -> s
  in
  lexbuf.lex_curr_p <- { pos with
    pos_fname = new_file;
    pos_lnum = if absolute then line else pos.pos_lnum + line;
    pos_bol = pos.pos_cnum - chars;
  }

let preprocessor = ref None

let escaped_newlines = ref false

(* Warn about Latin-1 characters used in idents *)

let warn_latin1 lexbuf = ignore lexbuf
  (*Location.deprecated
    (Location.curr lexbuf)
    ""ISO-Latin1 characters in identifiers""*)

let handle_docstrings = ref true
let comment_list = ref []

let add_comment com =
  comment_list := com :: !comment_list

let add_docstring_comment ds =
  let com =
    (""*"" ^ Docstrings.docstring_body ds, Docstrings.docstring_loc ds)
  in
    add_comment com

let comments () = List.rev !comment_list

(*
(* Error report *)

open Format

let prepare_error loc = function
  | Illegal_character c ->
      Location.errorf ~loc ""Illegal character (%s)"" (Char.escaped c)
  | Illegal_escape (s, explanation) ->
      Location.errorf ~loc
        ""Illegal backslash escape in string or character (%s)%t"" s
        (fun ppf -> match explanation with
           | None -> ()
           | Some expl -> fprintf ppf "": %s"" expl)
  | Reserved_sequence (s, explanation) ->
      Location.errorf ~loc
        ""Reserved character sequence: %s%t"" s
        (fun ppf -> match explanation with
           | None -> ()
           | Some expl -> fprintf ppf "" %s"" expl)
  | Unterminated_comment _ ->
      Location.errorf ~loc ""Comment not terminated""
  | Unterminated_string ->
      Location.errorf ~loc ""String literal not terminated""
  | Unterminated_string_in_comment (_, literal_loc) ->
      Location.errorf ~loc
        ""This comment contains an unterminated string literal""
        ~sub:[Location.msg ~loc:literal_loc ""String literal begins here""]
  | Empty_character_literal ->
      let msg = ""Illegal empty character literal ''"" in
      let sub =
        [Location.msg
           ""Hint: Did you mean ' ' or a type variable 'a?""] in
      Location.error ~loc ~sub msg
  | Keyword_as_label kwd ->
      Location.errorf ~loc
        ""`%s' is a keyword, it cannot be used as label name"" kwd
  | Invalid_literal s ->
      Location.errorf ~loc ""Invalid literal %s"" s
  | Invalid_directive (dir, explanation) ->
      Location.errorf ~loc ""Invalid lexer directive %S%t"" dir
        (fun ppf -> match explanation with
           | None -> ()
           | Some expl -> fprintf ppf "": %s"" expl)

let () =
  Location.register_error_of_exn
    (function
      | Error (err, loc) ->
          Some (prepare_error loc err)
      | _ ->
          None
    )
*)

}

let newline = ('\013'* '\010')
let blank = [' ' '\009' '\012']
let lowercase = ['a'-'z' '_']
let uppercase = ['A'-'Z']
let identchar = ['A'-'Z' 'a'-'z' '_' '\'' '0'-'9']
let lowercase_latin1 = ['a'-'z' '\223'-'\246' '\248'-'\255' '_']
let uppercase_latin1 = ['A'-'Z' '\192'-'\214' '\216'-'\222']
let identchar_latin1 =
  ['A'-'Z' 'a'-'z' '_' '\192'-'\214' '\216'-'\246' '\248'-'\255' '\'' '0'-'9']
(* This should be kept in sync with the [is_identchar] function in [env.ml] *)

let symbolchar =
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~']
let dotsymbolchar =
  ['!' '$' '%' '&' '*' '+' '-' '/' ':' '=' '>' '?' '@' '^' '|']
let symbolchar_or_hash =
  symbolchar | '#'
let kwdopchar =
  ['$' '&' '*' '+' '-' '/' '<' '=' '>' '@' '^' '|']

let ident = (lowercase | uppercase) identchar*
let extattrident = ident ('.' ident)*

let decimal_literal =
  ['0'-'9'] ['0'-'9' '_']*
let hex_digit =
  ['0'-'9' 'A'-'F' 'a'-'f']
let hex_literal =
  '0' ['x' 'X'] ['0'-'9' 'A'-'F' 'a'-'f']['0'-'9' 'A'-'F' 'a'-'f' '_']*
let oct_literal =
  '0' ['o' 'O'] ['0'-'7'] ['0'-'7' '_']*
let bin_literal =
  '0' ['b' 'B'] ['0'-'1'] ['0'-'1' '_']*
let int_literal =
  decimal_literal | hex_literal | oct_literal | bin_literal
let float_literal =
  ['0'-'9'] ['0'-'9' '_']*
  ('.' ['0'-'9' '_']* )?
  (['e' 'E'] ['+' '-']? ['0'-'9'] ['0'-'9' '_']* )?
let hex_float_literal =
  '0' ['x' 'X']
  ['0'-'9' 'A'-'F' 'a'-'f'] ['0'-'9' 'A'-'F' 'a'-'f' '_']*
  ('.' ['0'-'9' 'A'-'F' 'a'-'f' '_']* )?
  (['p' 'P'] ['+' '-']? ['0'-'9'] ['0'-'9' '_']* )?
let literal_modifier = ['G'-'Z' 'g'-'z']

rule token = parse
  | ('\\' as bs) newline {
      if not !escaped_newlines then error lexbuf (Illegal_character bs);
      update_loc lexbuf None 1 false 0;
      token lexbuf }
  | newline
      { update_loc lexbuf None 1 false 0;
        EOL }
  | blank +
      { token lexbuf }
  | ""_""
      { UNDERSCORE }
  | ""~""
      { TILDE }
  | "".~""
      { error lexbuf
          (Reserved_sequence ("".~"", Some ""is reserved for use in MetaOCaml"")) }
  | ""~"" (lowercase identchar * as name) ':'
      { check_label_name lexbuf name;
        LABEL name }
  | ""~"" (lowercase_latin1 identchar_latin1 * as name) ':'
      { warn_latin1 lexbuf;
        LABEL name }
  | ""?""
      { QUESTION }
  | ""?"" (lowercase identchar * as name) ':'
      { check_label_name lexbuf name;
        OPTLABEL name }
  | ""?"" (lowercase_latin1 identchar_latin1 * as name) ':'
      { warn_latin1 lexbuf;
        OPTLABEL name }
  | lowercase identchar * as name
      { try Hashtbl.find keyword_table name
        with Not_found -> LIDENT name }
  | lowercase_latin1 identchar_latin1 * as name
      { warn_latin1 lexbuf; LIDENT name }
  | uppercase identchar * as name
      { UIDENT name } (* No capitalized keywords *)
  | uppercase_latin1 identchar_latin1 * as name
      { warn_latin1 lexbuf; UIDENT name }
  | int_literal as lit { INT (lit, None) }
  | (int_literal as lit) (literal_modifier as modif)
      { INT (lit, Some modif) }
  | float_literal | hex_float_literal as lit
      { FLOAT (lit, None) }
  | (float_literal | hex_float_literal as lit) (literal_modifier as modif)
      { FLOAT (lit, Some modif) }
  | (float_literal | hex_float_literal | int_literal) identchar+ as invalid
      { error lexbuf (Invalid_literal invalid) }
  | ""\""""
      { let s, loc = wrap_string_lexer string lexbuf in
        STRING (s, loc, None) }
  | ""{"" (lowercase* as delim) ""|""
      { let s, loc = wrap_string_lexer (quoted_string delim) lexbuf in
        STRING (s, loc, Some delim) }
  | ""{%"" (extattrident as id) ""|""
      { let orig_loc = Location.curr lexbuf in
        let s, loc = wrap_string_lexer (quoted_string """") lexbuf in
        let idloc = compute_quoted_string_idloc orig_loc 2 id in
        QUOTED_STRING_EXPR (id, idloc, s, loc, Some """") }
  | ""{%"" (extattrident as id) blank+ (lowercase* as delim) ""|""
      { let orig_loc = Location.curr lexbuf in
        let s, loc = wrap_string_lexer (quoted_string delim) lexbuf in
        let idloc = compute_quoted_string_idloc orig_loc 2 id in
        QUOTED_STRING_EXPR (id, idloc, s, loc, Some delim) }
  | ""{%%"" (extattrident as id) ""|""
      { let orig_loc = Location.curr lexbuf in
        let s, loc = wrap_string_lexer (quoted_string """") lexbuf in
        let idloc = compute_quoted_string_idloc orig_loc 3 id in
        QUOTED_STRING_ITEM (id, idloc, s, loc, Some """") }
  | ""{%%"" (extattrident as id) blank+ (lowercase* as delim) ""|""
      { let orig_loc = Location.curr lexbuf in
        let s, loc = wrap_string_lexer (quoted_string delim) lexbuf in
        let idloc = compute_quoted_string_idloc orig_loc 3 id in
        QUOTED_STRING_ITEM (id, idloc, s, loc, Some delim) }
  | ""\'"" newline ""\'""
      { update_loc lexbuf None 1 false 1;
        (* newline is ('\013'* '\010') *)
        CHAR '\n' }
  | ""\'"" ([^ '\\' '\'' '\010' '\013'] as c) ""\'""
      { CHAR c }
  | ""\'\\"" (['\\' '\'' '\""' 'n' 't' 'b' 'r' ' '] as c) ""\'""
      { CHAR (char_for_backslash c) }
  | ""\'\\"" ['0'-'9'] ['0'-'9'] ['0'-'9'] ""\'""
      { CHAR(char_for_decimal_code lexbuf 2) }
  | ""\'\\"" 'o' ['0'-'7'] ['0'-'7'] ['0'-'7'] ""\'""
      { CHAR(char_for_octal_code lexbuf 3) }
  | ""\'\\"" 'x' ['0'-'9' 'a'-'f' 'A'-'F'] ['0'-'9' 'a'-'f' 'A'-'F'] ""\'""
      { CHAR(char_for_hexadecimal_code lexbuf 3) }
  | ""\'"" (""\\"" _ as esc)
      { error lexbuf (Illegal_escape (esc, None)) }
  | ""\'\'""
      { error lexbuf Empty_character_literal }
  | ""(*""
      { let s, loc = wrap_comment_lexer comment lexbuf in
        COMMENT (s, loc) }
  | ""(**""
      { let s, loc = wrap_comment_lexer comment lexbuf in
        if !handle_docstrings then
          DOCSTRING (Docstrings.docstring s loc)
        else
          COMMENT (""*"" ^ s, loc)
      }
  | ""(**"" (('*'+) as stars)
      { let s, loc =
          wrap_comment_lexer
            (fun lexbuf ->
               store_string (""*"" ^ stars);
               comment lexbuf)
            lexbuf
        in
        COMMENT (s, loc) }
  | ""(*)""
      { (*if !print_warnings then
          Location.prerr_warning (Location.curr lexbuf) Warnings.Comment_start;*)
        let s, loc = wrap_comment_lexer comment lexbuf in
        COMMENT (s, loc) }
  | ""(*"" (('*'*) as stars) ""*)""
      { if !handle_docstrings && stars="""" then
         (* (**) is an empty docstring *)
          DOCSTRING(Docstrings.docstring """" (Location.curr lexbuf))
        else
          COMMENT (stars, Location.curr lexbuf) }
  | ""*)""
      { (*let loc = Location.curr lexbuf in
        Location.prerr_warning loc Warnings.Comment_not_end;*)
        lexbuf.Lexing.lex_curr_pos <- lexbuf.Lexing.lex_curr_pos - 1;
        let curpos = lexbuf.lex_curr_p in
        lexbuf.lex_curr_p <- { curpos with pos_cnum = curpos.pos_cnum - 1 };
        STAR
      }
  | ""#""
      { let at_beginning_of_line pos = (pos.pos_cnum = pos.pos_bol) in
        if not (at_beginning_of_line lexbuf.lex_start_p)
        then HASH
        else try directive lexbuf with Failure _ -> HASH
      }
  | ""&""  { AMPERSAND }
  | ""&&"" { AMPERAMPER }
  | ""`""  { BACKQUOTE }
  | ""\'"" { QUOTE }
  | ""(""  { LPAREN }
  | "")""  { RPAREN }
  | ""*""  { STAR }
  | "",""  { COMMA }
  | ""->"" { MINUSGREATER }
  | "".""  { DOT }
  | "".."" { DOTDOT }
  | ""."" (dotsymbolchar symbolchar* as op) { DOTOP op }
  | "":""  { COLON }
  | ""::"" { COLONCOLON }
  | "":="" { COLONEQUAL }
  | "":>"" { COLONGREATER }
  | "";""  { SEMI }
  | "";;"" { SEMISEMI }
  | ""<""  { LESS }
  | ""<-"" { LESSMINUS }
  | ""=""  { EQUAL }
  | ""[""  { LBRACKET }
  | ""[|"" { LBRACKETBAR }
  | ""[<"" { LBRACKETLESS }
  | ""[>"" { LBRACKETGREATER }
  | ""]""  { RBRACKET }
  | ""{""  { LBRACE }
  | ""{<"" { LBRACELESS }
  | ""|""  { BAR }
  | ""||"" { BARBAR }
  | ""|]"" { BARRBRACKET }
  | "">""  { GREATER }
  | "">]"" { GREATERRBRACKET }
  | ""}""  { RBRACE }
  | "">}"" { GREATERRBRACE }
  | ""[@"" { LBRACKETAT }
  | ""[@@""  { LBRACKETATAT }
  | ""[@@@"" { LBRACKETATATAT }
  | ""[%""   { LBRACKETPERCENT }
  | ""[%%""  { LBRACKETPERCENTPERCENT }
  | ""!""  { BANG }
  | ""!="" { INFIXOP0 ""!="" }
  | ""+""  { PLUS }
  | ""+."" { PLUSDOT }
  | ""+="" { PLUSEQ }
  | ""-""  { MINUS }
  | ""-."" { MINUSDOT }

  | ""!"" symbolchar_or_hash + as op
            { PREFIXOP op }
  | ['~' '?'] symbolchar_or_hash + as op
            { PREFIXOP op }
  | ['=' '<' '>' '|' '&' '$'] symbolchar * as op
            { INFIXOP0 op }
  | ['@' '^'] symbolchar * as op
            { INFIXOP1 op }
  | ['+' '-'] symbolchar * as op
            { INFIXOP2 op }
  | ""**"" symbolchar * as op
            { INFIXOP4 op }
  | '%'     { PERCENT }
  | ['*' '/' '%'] symbolchar * as op
            { INFIXOP3 op }
  | '#' symbolchar_or_hash + as op
            { HASHOP op }
  | ""let"" kwdopchar dotsymbolchar * as op
            { LETOP op }
  | ""and"" kwdopchar dotsymbolchar * as op
            { ANDOP op }
  | eof { EOF }
  | (_ as illegal_char)
      { error lexbuf (Illegal_character illegal_char) }

and directive = parse
  | ([' ' '\t']* (['0'-'9']+ as _num) [' ' '\t']*
        (""\"""" ([^ '\010' '\013' '\""' ] * as _name) ""\"""") as directive)
        [^ '\010' '\013'] *
      {
        (* Line directives are not preserved by the lexer so we error out. *)
        let explanation = ""line directives are not supported"" in
        error lexbuf (Invalid_directive (""#"" ^ directive, Some explanation))
      }
and comment = parse
    ""(*""
      { comment_start_loc := (Location.curr lexbuf) :: !comment_start_loc;
        store_lexeme lexbuf;
        comment lexbuf
      }
  | ""*)""
      { match !comment_start_loc with
        | [] -> assert false
        | [_] -> comment_start_loc := []; Location.curr lexbuf
        | _ :: l -> comment_start_loc := l;
                  store_lexeme lexbuf;
                  comment lexbuf
       }
  | ""\""""
      {
        string_start_loc := Location.curr lexbuf;
        store_string_char '\""';
        is_in_string := true;
        let _loc = try string lexbuf
        with Error (Unterminated_string, str_start) ->
          match !comment_start_loc with
          | [] -> assert false
          | loc :: _ ->
            let start = List.hd (List.rev !comment_start_loc) in
            comment_start_loc := [];
            error_loc loc (Unterminated_string_in_comment (start, str_start))
        in
        is_in_string := false;
        store_string_char '\""';
        comment lexbuf }
  | ""{"" ('%' '%'? extattrident blank*)? (lowercase* as delim) ""|""
      {
        string_start_loc := Location.curr lexbuf;
        store_lexeme lexbuf;
        is_in_string := true;
        let _loc = try quoted_string delim lexbuf
        with Error (Unterminated_string, str_start) ->
          match !comment_start_loc with
          | [] -> assert false
          | loc :: _ ->
            let start = List.hd (List.rev !comment_start_loc) in
            comment_start_loc := [];
            error_loc loc (Unterminated_string_in_comment (start, str_start))
        in
        is_in_string := false;
        store_string_char '|';
        store_string delim;
        store_string_char '}';
        comment lexbuf }
  | ""\'\'""
      { store_lexeme lexbuf; comment lexbuf }
  | ""\'"" newline ""\'""
      { update_loc lexbuf None 1 false 1;
        store_lexeme lexbuf;
        comment lexbuf
      }
  | ""\'"" [^ '\\' '\'' '\010' '\013' ] ""\'""
      { store_lexeme lexbuf; comment lexbuf }
  | ""\'\\"" ['\\' '\""' '\'' 'n' 't' 'b' 'r' ' '] ""\'""
      { store_lexeme lexbuf; comment lexbuf }
  | ""\'\\"" ['0'-'9'] ['0'-'9'] ['0'-'9'] ""\'""
      { store_lexeme lexbuf; comment lexbuf }
  | ""\'\\"" 'o' ['0'-'3'] ['0'-'7'] ['0'-'7'] ""\'""
      { store_lexeme lexbuf; comment lexbuf }
  | ""\'\\"" 'x' ['0'-'9' 'a'-'f' 'A'-'F'] ['0'-'9' 'a'-'f' 'A'-'F'] ""\'""
      { store_lexeme lexbuf; comment lexbuf }
  | eof
      { match !comment_start_loc with
        | [] -> assert false
        | loc :: _ ->
          let start = List.hd (List.rev !comment_start_loc) in
          comment_start_loc := [];
          error_loc loc (Unterminated_comment start)
      }
  | newline
      { update_loc lexbuf None 1 false 0;
        store_lexeme lexbuf;
        comment lexbuf
      }
  | ident
      { store_lexeme lexbuf; comment lexbuf }
  | _
      { store_lexeme lexbuf; comment lexbuf }

and string = parse
    '\""'
      { lexbuf.lex_start_p }
  | '\\' newline ([' ' '\t'] * as space)
      { update_loc lexbuf None 1 false (String.length space);
        if in_comment () then store_lexeme lexbuf;
        string lexbuf
      }
  | '\\' (['\\' '\'' '\""' 'n' 't' 'b' 'r' ' '] as c)
      { store_escaped_char lexbuf (char_for_backslash c);
        string lexbuf }
  | '\\' ['0'-'9'] ['0'-'9'] ['0'-'9']
      { store_escaped_char lexbuf (char_for_decimal_code lexbuf 1);
         string lexbuf }
  | '\\' 'o' ['0'-'7'] ['0'-'7'] ['0'-'7']
      { store_escaped_char lexbuf (char_for_octal_code lexbuf 2);
         string lexbuf }
  | '\\' 'x' ['0'-'9' 'a'-'f' 'A'-'F'] ['0'-'9' 'a'-'f' 'A'-'F']
      { store_escaped_char lexbuf (char_for_hexadecimal_code lexbuf 2);
         string lexbuf }
  | '\\' 'u' '{' hex_digit+ '}'
        { store_escaped_uchar lexbuf (uchar_for_uchar_escape lexbuf);
          string lexbuf }
  | '\\' _
      { if not (in_comment ()) then begin
(*  Should be an error, but we are very lax.
          error lexbuf (Illegal_escape (Lexing.lexeme lexbuf, None))
*)
          (*let loc = Location.curr lexbuf in
          Location.prerr_warning loc Warnings.Illegal_backslash;*)
        end;
        store_lexeme lexbuf;
        string lexbuf
      }
  | newline
      { (*if not (in_comment ()) then
          Location.prerr_warning (Location.curr lexbuf) Warnings.Eol_in_string;*)
        update_loc lexbuf None 1 false 0;
        store_lexeme lexbuf;
        string lexbuf
      }
  | eof
      { is_in_string := false;
        error_loc !string_start_loc Unterminated_string }
  | (_ as c)
      { store_string_char c;
        string lexbuf }

and quoted_string delim = parse
  | newline
      { update_loc lexbuf None 1 false 0;
        store_lexeme lexbuf;
        quoted_string delim lexbuf
      }
  | eof
      { is_in_string := false;
        error_loc !string_start_loc Unterminated_string }
  | ""|"" (lowercase* as edelim) ""}""
      {
        if delim = edelim then lexbuf.lex_start_p
        else (store_lexeme lexbuf; quoted_string delim lexbuf)
      }
  | (_ as c)
      { store_string_char c;
        quoted_string delim lexbuf }

and skip_hash_bang = parse
  | ""#!"" [^ '\n']* '\n' [^ '\n']* ""\n!#\n""
      { update_loc lexbuf None 3 false 0 }
  | ""#!"" [^ '\n']* '\n'
      { update_loc lexbuf None 1 false 0 }
  | """" { () }

{

  let token_with_comments lexbuf =
    match !preprocessor with
    | None -> token lexbuf
    | Some (_init, preprocess) -> preprocess token lexbuf

  type newline_state =
    | NoLine (* There have been no blank lines yet. *)
    | NewLine
        (* There have been no blank lines, and the previous
           token was a newline. *)
    | BlankLine (* There have been blank lines. *)

  type doc_state =
    | Initial  (* There have been no docstrings yet *)
    | After of docstring list
        (* There have been docstrings, none of which were
           preceded by a blank line *)
    | Before of docstring list * docstring list * docstring list
        (* There have been docstrings, some of which were
           preceded by a blank line *)

  and docstring = Docstrings.docstring

  let token lexbuf =
    let post_pos = lexeme_end_p lexbuf in
    let attach lines docs pre_pos =
      let open Docstrings in
        match docs, lines with
        | Initial, _ -> ()
        | After a, (NoLine | NewLine) ->
            set_post_docstrings post_pos (List.rev a);
            set_pre_docstrings pre_pos a;
        | After a, BlankLine ->
            set_post_docstrings post_pos (List.rev a);
            set_pre_extra_docstrings pre_pos (List.rev a)
        | Before(a, f, b), (NoLine | NewLine) ->
            set_post_docstrings post_pos (List.rev a);
            set_post_extra_docstrings post_pos
              (List.rev_append f (List.rev b));
            set_floating_docstrings pre_pos (List.rev f);
            set_pre_extra_docstrings pre_pos (List.rev a);
            set_pre_docstrings pre_pos b
        | Before(a, f, b), BlankLine ->
            set_post_docstrings post_pos (List.rev a);
            set_post_extra_docstrings post_pos
              (List.rev_append f (List.rev b));
            set_floating_docstrings pre_pos
              (List.rev_append f (List.rev b));
            set_pre_extra_docstrings pre_pos (List.rev a)
    in
    let rec loop lines docs lexbuf =
      match token_with_comments lexbuf with
      | COMMENT (s, loc) ->
          add_comment (s, loc);
          let lines' =
            match lines with
            | NoLine -> NoLine
            | NewLine -> NoLine
            | BlankLine -> BlankLine
          in
          loop lines' docs lexbuf
      | EOL ->
          let lines' =
            match lines with
            | NoLine -> NewLine
            | NewLine -> BlankLine
            | BlankLine -> BlankLine
          in
          loop lines' docs lexbuf
      | DOCSTRING doc ->
          Docstrings.register doc;
          add_docstring_comment doc;
          let docs' =
            if Docstrings.docstring_body doc = ""/*"" then
              match docs with
              | Initial -> Before([], [doc], [])
              | After a -> Before (a, [doc], [])
              | Before(a, f, b) -> Before(a, doc :: b @ f, [])
            else
              match docs, lines with
              | Initial, (NoLine | NewLine) -> After [doc]
              | Initial, BlankLine -> Before([], [], [doc])
              | After a, (NoLine | NewLine) -> After (doc :: a)
              | After a, BlankLine -> Before (a, [], [doc])
              | Before(a, f, b), (NoLine | NewLine) -> Before(a, f, doc :: b)
              | Before(a, f, b), BlankLine -> Before(a, b @ f, [doc])
          in
          loop NoLine docs' lexbuf
      | tok ->
          attach lines docs (lexeme_start_p lexbuf);
          tok
    in
      loop NoLine Initial lexbuf

  let init () =
    is_in_string := false;
    comment_start_loc := [];
    comment_list := [];
    match !preprocessor with
    | None -> ()
    | Some (init, _preprocess) -> init ()

  let set_preprocessor init preprocess =
    escaped_newlines := true;
    preprocessor := Some (init, preprocess)

}
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

type locs_tbl = Loc.t Type_sig_collections.Locs.t

type type_sig = Type_sig_collections.Locs.index Packed_type_sig.Module.t

type file_addr = SharedMem.NewAPI.file SharedMem.addr

type +'a parse_addr = 'a SharedMem.NewAPI.parse SharedMem.addr

type haste_info_addr = SharedMem.NewAPI.haste_info SharedMem.addr

type haste_module_addr = SharedMem.NewAPI.haste_module SharedMem.addr

type file_module_addr = SharedMem.NewAPI.file_module SharedMem.addr

type provider_addr = SharedMem.NewAPI.file SharedMem.NewAPI.entity SharedMem.addr

type resolved_requires = {
  resolved_modules: Modulename.t SMap.t;
  phantom_dependencies: SSet.t;
  hash: Xx.hash;
}
[@@deriving show]

val mk_resolved_requires :
  resolved_modules:Modulename.t SMap.t -> phantom_dependencies:SSet.t -> resolved_requires

val get_file_addr : File_key.t -> file_addr option

val get_file_addr_unsafe : File_key.t -> file_addr

val get_haste_module : string -> haste_module_addr option

val get_haste_module_unsafe : string -> haste_module_addr

val get_file_module_unsafe : File_key.t -> file_module_addr

val read_file_name : file_addr -> string

val read_file_key : file_addr -> File_key.t

val read_file_hash : [> ] parse_addr -> Xx.hash

val read_module_name : haste_info_addr -> string

val read_ast_unsafe : File_key.t -> [ `typed ] parse_addr -> (Loc.t, Loc.t) Flow_ast.Program.t

val read_docblock_unsafe : File_key.t -> [ `typed ] parse_addr -> Docblock.t

val read_aloc_table_unsafe : File_key.t -> [ `typed ] parse_addr -> ALoc.table

val read_type_sig_unsafe : File_key.t -> [ `typed ] parse_addr -> type_sig

val read_tolerable_file_sig_unsafe :
  File_key.t -> [ `typed ] parse_addr -> File_sig.With_Loc.tolerable_t

val read_file_sig_unsafe : File_key.t -> [ `typed ] parse_addr -> File_sig.With_Loc.t

val read_exports : [ `typed ] parse_addr -> Exports.t

module type READER = sig
  type reader

  val get_provider : reader:reader -> Modulename.t -> file_addr option

  val is_typed_file : reader:reader -> file_addr -> bool

  val get_parse : reader:reader -> file_addr -> [ `typed | `untyped ] parse_addr option

  val get_typed_parse : reader:reader -> file_addr -> [ `typed ] parse_addr option

  val get_haste_info : reader:reader -> file_addr -> haste_info_addr option

  val get_haste_name : reader:reader -> file_addr -> string option

  val has_ast : reader:reader -> File_key.t -> bool

  val get_ast : reader:reader -> File_key.t -> (Loc.t, Loc.t) Flow_ast.Program.t option

  val get_aloc_table : reader:reader -> File_key.t -> ALoc.table option

  val get_docblock : reader:reader -> File_key.t -> Docblock.t option

  val get_exports : reader:reader -> File_key.t -> Exports.t option

  val get_tolerable_file_sig : reader:reader -> File_key.t -> File_sig.With_Loc.tolerable_t option

  val get_file_sig : reader:reader -> File_key.t -> File_sig.With_Loc.t option

  val get_type_sig : reader:reader -> File_key.t -> type_sig option

  val get_file_hash : reader:reader -> File_key.t -> Xx.hash option

  val get_parse_unsafe :
    reader:reader -> File_key.t -> file_addr -> [ `typed | `untyped ] parse_addr

  val get_typed_parse_unsafe : reader:reader -> File_key.t -> file_addr -> [ `typed ] parse_addr

  val get_resolved_requires_unsafe :
    reader:reader -> File_key.t -> [ `typed ] parse_addr -> resolved_requires

  val get_ast_unsafe : reader:reader -> File_key.t -> (Loc.t, Loc.t) Flow_ast.Program.t

  val get_aloc_table_unsafe : reader:reader -> File_key.t -> ALoc.table

  val get_docblock_unsafe : reader:reader -> File_key.t -> Docblock.t

  val get_exports_unsafe : reader:reader -> File_key.t -> Exports.t

  val get_tolerable_file_sig_unsafe : reader:reader -> File_key.t -> File_sig.With_Loc.tolerable_t

  val get_file_sig_unsafe : reader:reader -> File_key.t -> File_sig.With_Loc.t

  val get_type_sig_unsafe : reader:reader -> File_key.t -> type_sig

  val get_file_hash_unsafe : reader:reader -> File_key.t -> Xx.hash

  val loc_of_aloc : reader:reader -> ALoc.t -> Loc.t
end

module Mutator_reader : sig
  include READER with type reader = Mutator_state_reader.t

  val get_old_parse : reader:reader -> file_addr -> [ `typed | `untyped ] parse_addr option

  val get_old_typed_parse : reader:reader -> file_addr -> [ `typed ] parse_addr option

  val get_old_haste_info : reader:reader -> file_addr -> haste_info_addr option

  val get_old_file_hash : reader:reader -> File_key.t -> Xx.hash option

  val get_old_exports : reader:reader -> File_key.t -> Exports.t option
end

module Reader : READER with type reader = State_reader.t

module Reader_dispatcher : READER with type reader = Abstract_state_reader.t

(* For use by a worker process *)
type worker_mutator = {
  add_parsed:
    File_key.t ->
    file_addr option ->
    exports:Exports.t ->
    Xx.hash ->
    string option ->
    Docblock.t ->
    (Loc.t, Loc.t) Flow_ast.Program.t ->
    File_sig.With_Loc.tolerable_t ->
    locs_tbl ->
    type_sig ->
    Modulename.Set.t;
  add_unparsed: File_key.t -> file_addr option -> Xx.hash -> string option -> Modulename.Set.t;
  clear_not_found: File_key.t -> Modulename.Set.t;
}

module Parse_mutator : sig
  val create : unit -> worker_mutator
end

module Reparse_mutator : sig
  type master_mutator (* Used by the master process *)

  val create : Transaction.t -> Utils_js.FilenameSet.t -> master_mutator * worker_mutator

  val record_unchanged : master_mutator -> Utils_js.FilenameSet.t -> unit

  val record_not_found : master_mutator -> Utils_js.FilenameSet.t -> unit
end

module Commit_modules_mutator : sig
  type t

  val create : Transaction.t -> t

  val record_no_providers : t -> Modulename.Set.t -> unit
end

module Resolved_requires_mutator : sig
  type t

  val create : Transaction.t -> Utils_js.FilenameSet.t -> t

  val add_resolved_requires : t -> file_addr -> [ `typed ] parse_addr -> resolved_requires -> bool
end

module From_saved_state : sig
  val add_parsed :
    File_key.t -> Xx.hash -> string option -> Exports.t -> resolved_requires -> Modulename.Set.t

  val add_unparsed : File_key.t -> Xx.hash -> string option -> Modulename.Set.t
end

val iter_resolved_requires : (file_addr -> resolved_requires -> unit) -> unit
",ocaml
"open Quartic
open Base
open Js_of_ocaml

let draw_prime_graph cy parent (id_graph : Tree.id_graph) =
  let () = List.iter id_graph.nodes ~f:(fun id ->
    let rep_id = String.concat [(Int.to_string id); ""-rep""] |> Js.string in
    let node = object%js 
      val group = Js.string ""nodes""
      val data = object%js
        val label = Js.string """"
        val polarisation = true
        val id = rep_id
        val parent = parent
      end
    end
    in
    let added_node = cy##add (Js.Unsafe.coerce node) in
    let edge = object%js
      val data = object%js
        val source = rep_id
        val target = Int.to_string id |> Js.string
      end
    end
    in
    let added_edge = cy##add (Js.Unsafe.coerce edge) in
    let () = (Js.Unsafe.coerce added_edge)##addClass (Js.string ""compoundOut"") in
    (Js.Unsafe.coerce added_node)##addClass (Js.string ""inCompound""))
  in
  let () = List.iter id_graph.edges ~f:(fun (id1, id2) ->
    let edge = object%js
      val data = object%js
        val source = String.concat [(Int.to_string id1); ""-rep""] |> Js.string
        val target = String.concat [(Int.to_string id2); ""-rep""] |> Js.string
      end
    end
    in
    let added_edge = cy##add (Js.Unsafe.coerce edge) in
    (Js.Unsafe.coerce added_edge)##addClass (Js.string ""compoundIn""))
  in
  ()

let draw_before cy parent tl =
  let rep_id_list = List.map tl ~f:(fun t ->
    let id = Int.to_string t.Tree.id in
    let rep_id = String.concat [id; ""-rep""] |> Js.string in
    let node = object%js 
      val group = Js.string ""nodes""
      val data = object%js
        val label = Js.string """"
        val polarisation = true
        val id = rep_id
        val parent = parent
      end
    end
    in
    let added_node = cy##add (Js.Unsafe.coerce node) in
    let edge = object%js
      val data = object%js
        val source = rep_id
        val target = Js.string id
      end
    end
    in
    let added_edge = cy##add (Js.Unsafe.coerce edge) in
    let () = (Js.Unsafe.coerce added_edge)##addClass (Js.string ""compoundOut"") in
    let () = (Js.Unsafe.coerce added_node)##addClass (Js.string ""inCompound"") in
    rep_id)
  in

  let rec draw_inner il =
    match il with
    | [] -> ()
    | [_] -> ()
    | h1 :: h2 :: t ->
      let edge = object%js
        val data = object%js
          val source =  h2
          val target =  h1
        end
      end
      in
      let added_edge = cy##add (Js.Unsafe.coerce edge) in
      let () = (Js.Unsafe.coerce added_edge)##addClass (Js.string ""before"") in
      let () = if List.is_empty t then (cy##getElementById h2)##addClass (Js.string ""before-root"") in 
      draw_inner (h2 :: t)
  in
  draw_inner rep_id_list

let rec draw_tree cy (tree : Tree.tree) =
  let id = Int.to_string tree.id |> Js.string in
  let group = Js.string ""nodes"" in
  let label, polarisation, id_list, class_ =
    match tree.connective with
    | Atom atom -> Js.string atom.label, Js.bool atom.pol, None, ""atom""
    | Tensor tl ->
      let id_list = List.map tl ~f:(draw_tree cy) in
      Js.string ""⊗"", Js.bool true, Some id_list, ""tensor""
    | Par tl ->
      let id_list = List.map tl ~f:(draw_tree cy) in
      Js.string ""⅋"", Js.bool true, Some id_list, ""par""
    | Before tl ->
      let id_list = List.map tl ~f:(draw_tree cy) in
      Js.string """", Js.bool true, Some id_list, ""before""
    | Prime (_, tl) ->
      let id_list = List.map tl ~f:(draw_tree cy) in
      Js.string """", Js.bool true, Some id_list, ""prime""
  in
  let node = object%js
    val group = group
    val data = object%js
      val id = id
      val label = label
      val polarisation = polarisation
    end
  end
  in
  let added = cy##add (Js.Unsafe.coerce node) in
  let () = (Js.Unsafe.coerce added)##addClass (Js.string class_) in
  let () = 
    match id_list with
    | None -> ()
    | Some ids ->
      match tree.connective with
      | Prime (id_graph,_) -> draw_prime_graph (Js.Unsafe.coerce cy) id id_graph 
      | Before tl -> draw_before (Js.Unsafe.coerce cy) id tl
      | _ ->
        List.iter ids ~f:(fun target_id ->
          let edge = object%js 
            val data = object%js
              val source = id
              val target = target_id
            end
          end
          in
          let _ = cy##add (Js.Unsafe.coerce edge) in ())
  in    
  (Int.to_string tree.id) |> Js.string

let draw_graph ?directed cy (graph : Graph.graph) =
  Set.iter graph.nodes ~f:(fun v ->
    match v.connective with
    | Atom atom -> 
      let node = object%js
        val group = Js.string ""nodes""
        val data = object%js
          val id = Int.to_string v.id |> Js.string
          val label = Js.string atom.label
          val polarisation = Js.bool atom.pol
        end
      end
      in
      cy##add node 
    | _ -> ());
  let edge_list = Graph.edge_tuple_list ?directed:directed graph.edges in
  List.iter edge_list ~f:(fun (src, trgt) ->
    let edge = object%js
      val group = Js.string ""edges""
      val data = object%js
        val source = Int.to_string src.id |> Js.string
        val target = Int.to_string trgt.id |> Js.string
      end
    end
    in
    (Js.Unsafe.coerce cy)##add edge)",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* patternlint-disable flow-prefer-sharedmem-js *)

open OUnit2
open SharedMem
open NewAPI

module H1 =
  NoCacheAddr
    (StringKey)
    (struct
      type t = heap_string
    end)

module H2 =
  NoCacheAddr
    (StringKey)
    (struct
      type t = heap_string addr_tbl
    end)

module H3 =
  NoCacheAddr
    (StringKey)
    (struct
      type t = heap_string addr_tbl addr_tbl
    end)

module Ent =
  NoCacheAddr
    (StringKey)
    (struct
      type t = heap_string entity
    end)

let assert_heap_size wsize =
  let bsize = wsize * (Sys.word_size / 8) in
  assert (SharedMem.heap_size () = bsize)

let assert_null_committed entity = assert (Option.is_none (entity_read_committed entity))

let assert_committed f entity data = assert (data = f (Option.get (entity_read_committed entity)))

let assert_latest f entity data = assert (data = f (Option.get (entity_read_latest entity)))

let assert_latest_opt f entity data = assert (data = Option.map f (entity_read_latest entity))

let collect_test _ctxt =
  let foo = ""foo"" in
  let bar = ""bar"" in
  let tbl1 = [| bar |] in
  let tbl2 = [| tbl1 |] in

  (* calculate size for heap writes *)
  let foo_size = header_size + string_size foo in
  let bar_size = header_size + string_size bar in
  let tbl1_size = header_size + addr_tbl_size tbl1 in
  let tbl2_size = header_size + addr_tbl_size tbl2 in
  let size = foo_size + bar_size + tbl1_size + tbl2_size in

  (* write four objects into the heap
   * 1. the string ""foo""
   * 2. the string ""bar""
   * 3. an addr tbl containing a single reference to (2)
   * 4. an addr tbl containing a single reference to (3)
   *
   * add (1) and (4) to the hash table
   *)
  let foo_key = ""foo_key"" in
  let tbl2_key = ""tbl2_key"" in
  alloc size (fun chunk ->
      let foo_addr = write_string chunk foo in
      let tbl2_addr = write_addr_tbl (write_addr_tbl write_string) chunk tbl2 in
      assert (foo_addr = H1.add foo_key foo_addr);
      assert (tbl2_addr = H3.add tbl2_key tbl2_addr)
  );
  assert_heap_size size;

  (* all objects reachable via live roots foo, tbl2 *)
  SharedMem.compact ();
  assert_heap_size size;

  (* foo dead, tbl2 -> tbl1 -> bar kept alive *)
  H1.remove_batch (SSet.singleton foo_key);
  SharedMem.compact ();
  assert_heap_size (size - foo_size);

  (* confirm tbl2 -> tbl1 -> bar pointers still valid *)
  let () =
    let tbl2_addr = Base.Option.value_exn (H3.get tbl2_key) in
    let tbl2' = read_addr_tbl (read_addr_tbl read_string) tbl2_addr in
    assert (tbl2' = tbl2)
  in

  (* tbl2 dead, tbl1, bar no longer reachable *)
  H3.remove_batch (SSet.singleton tbl2_key);
  SharedMem.compact ();
  assert_heap_size 0

let entities_test _ctxt =
  let foo = ""foo"" in
  let bar = ""bar"" in

  (* write foo, bar, and ent=foo to heap *)
  let size = (3 * header_size) + string_size foo + string_size bar + entity_size in
  let (foo, bar, ent) =
    alloc size (fun chunk ->
        let foo = write_string chunk foo in
        let bar = write_string chunk bar in
        let ent = write_entity chunk (Some foo) in
        (foo, bar, ent)
    )
  in

  (* uncommitted *)
  assert_null_committed ent;
  assert_latest Fun.id ent foo;

  (* commit foo *)
  commit_transaction ();
  assert_committed Fun.id ent foo;
  assert_latest Fun.id ent foo;

  (* advance ent=bar, foo still committed *)
  entity_advance ent (Some bar);
  assert_committed Fun.id ent foo;
  assert_latest Fun.id ent bar;

  (* commit bar *)
  commit_transaction ();
  assert_committed Fun.id ent bar;
  assert_latest Fun.id ent bar;

  (* clean up *)
  compact ();
  assert_heap_size 0

let entities_compact_test _ctxt =
  let foo = ""foo"" in
  let bar = ""bar"" in
  let foo_size = header_size + string_size foo in
  let bar_size = header_size + string_size bar in
  let size = foo_size + bar_size + header_size + entity_size in
  let (bar, ent) =
    alloc size (fun chunk ->
        let foo = write_string chunk foo in
        let bar = write_string chunk bar in
        let ent = write_entity chunk (Some foo) in
        (bar, ent)
    )
  in

  (* keep ent alive *)
  let key = ""ent_key"" in
  assert (ent = Ent.add key ent);

  commit_transaction ();
  entity_advance ent (Some bar);

  (* compact before commit: both foo, bar reachable *)
  compact ();
  assert_heap_size size;
  let ent = Option.get (Ent.get key) in
  assert_committed read_string ent ""foo"";
  assert_latest read_string ent ""bar"";

  (* compact after commit: foo unreachable *)
  commit_transaction ();
  compact ();
  assert_heap_size (size - foo_size);
  let ent = Option.get (Ent.get key) in
  assert_committed read_string ent ""bar"";
  assert_latest read_string ent ""bar"";

  Ent.remove_batch (SSet.singleton key);
  compact ();
  assert_heap_size 0

let entities_rollback_test _ctxt =
  (* init *)
  commit_transaction ();

  let foo = ""foo"" in
  let bar = ""bar"" in
  let foo_size = header_size + string_size foo in
  let bar_size = header_size + string_size bar in
  let size = foo_size + bar_size + header_size + entity_size in
  let (foo, bar, ent) =
    alloc size (fun chunk ->
        let foo = write_string chunk foo in
        let bar = write_string chunk bar in
        let ent = write_entity chunk (Some foo) in
        (foo, bar, ent)
    )
  in
  assert_latest Fun.id ent foo;

  entity_rollback ent;
  assert_latest_opt Fun.id ent None;

  (* advance ent -> foo, commit *)
  entity_advance ent (Some foo);
  commit_transaction ();

  (* rollback after commit: no change *)
  entity_rollback ent;
  assert_latest Fun.id ent foo;

  (* advance ent -> bar, rollback *)
  entity_advance ent (Some bar);
  entity_rollback ent;
  assert_latest Fun.id ent foo;

  (* clean up *)
  compact ();
  assert_heap_size 0

let slot_taken_test _ =
  let foo = ""foo"" in
  let bar = ""bar"" in
  let key = ""key"" in
  let size = (2 * header_size) + string_size foo + string_size bar in
  alloc size (fun chunk ->
      let foo = write_string chunk foo in
      let bar = write_string chunk bar in
      assert (foo = H1.add key foo);
      (* add returns foo, because already taken *)
      assert (foo = H1.add key bar);
      (* add returns bar, because slot was freed via delete *)
      H1.remove key;
      assert (bar = H1.add key bar)
  );
  (* clean up *)
  H1.remove key;
  compact ();
  assert_heap_size 0

let tests =
  ""heap_tests""
  >::: [
         ""collect"" >:: collect_test;
         ""entities"" >:: entities_test;
         ""entities_compact"" >:: entities_compact_test;
         ""entities_rollback"" >:: entities_rollback_test;
         ""slot_taken"" >:: slot_taken_test;
       ]

let () =
  let config = { heap_size = 1024 * 1024 * 1024; hash_table_pow = 14; log_level = 0 } in
  ignore (init ~num_workers:0 config : (handle, unit) result);
  run_test_tt_main tests
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*                      Thomas Gazagnaire, OCamlPro                       *)
(*                   Fabrice Le Fessant, INRIA Saclay                     *)
(*               Hongbo Zhang, University of Pennsylvania                 *)
(*                                                                        *)
(*   Copyright 2007 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(* Original Code from Ber-metaocaml, modified for 3.12.0 and fixed *)
(* Printing code expressions *)
(* Authors:  Ed Pizzi, Fabrice Le Fessant *)
(* Extensive Rewrite: Hongbo Zhang: University of Pennsylvania *)
(* TODO more fine-grained precedence pretty-printing *)

open Asttypes
open Format
open Location
open Longident
open Parsetree
open Ast_helper

let prefix_symbols  = [ '!'; '?'; '~' ]
let infix_symbols = [ '='; '<'; '>'; '@'; '^'; '|'; '&'; '+'; '-'; '*'; '/';
                      '$'; '%'; '#' ]

(* type fixity = Infix| Prefix  *)
let special_infix_strings =
  [""asr""; ""land""; ""lor""; ""lsl""; ""lsr""; ""lxor""; ""mod""; ""or""; "":=""; ""!=""; ""::"" ]

let letop s =
  String.length s > 3
  && s.[0] = 'l'
  && s.[1] = 'e'
  && s.[2] = 't'
  && List.mem s.[3] infix_symbols

let andop s =
  String.length s > 3
  && s.[0] = 'a'
  && s.[1] = 'n'
  && s.[2] = 'd'
  && List.mem s.[3] infix_symbols

(* determines if the string is an infix string.
   checks backwards, first allowing a renaming postfix (""_102"") which
   may have resulted from Pexp -> Texp -> Pexp translation, then checking
   if all the characters in the beginning of the string are valid infix
   characters. *)
let fixity_of_string  = function
  | """" -> `Normal
  | s when List.mem s special_infix_strings -> `Infix s
  | s when List.mem s.[0] infix_symbols -> `Infix s
  | s when List.mem s.[0] prefix_symbols -> `Prefix s
  | s when s.[0] = '.' -> `Mixfix s
  | s when letop s -> `Letop s
  | s when andop s -> `Andop s
  | _ -> `Normal

let view_fixity_of_exp = function
  | {pexp_desc = Pexp_ident {txt=Lident l;_}; pexp_attributes = []} ->
      fixity_of_string l
  | _ -> `Normal

let is_infix  = function `Infix _ -> true | _  -> false
let is_mixfix = function `Mixfix _ -> true | _ -> false
let is_kwdop = function `Letop _ | `Andop _ -> true | _ -> false

let first_is c str =
  str <> """" && str.[0] = c
let last_is c str =
  str <> """" && str.[String.length str - 1] = c

let first_is_in cs str =
  str <> """" && List.mem str.[0] cs

(* which identifiers are in fact operators needing parentheses *)
let needs_parens txt =
  let fix = fixity_of_string txt in
  is_infix fix
  || is_mixfix fix
  || is_kwdop fix
  || first_is_in prefix_symbols txt

(* some infixes need spaces around parens to avoid clashes with comment
   syntax *)
let needs_spaces txt =
  first_is '*' txt || last_is '*' txt

let string_loc ppf x = fprintf ppf ""%s"" x.txt

(* add parentheses to binders when they are in fact infix or prefix operators *)
let protect_ident ppf txt =
  let format : (_, _, _) format =
    if not (needs_parens txt) then ""%s""
    else if needs_spaces txt then ""(@;%s@;)""
    else ""(%s)""
  in fprintf ppf format txt

let protect_longident ppf print_longident longprefix txt =
  let format : (_, _, _) format =
    if not (needs_parens txt) then ""%a.%s""
    else if needs_spaces txt then  ""%a.(@;%s@;)""
    else ""%a.(%s)"" in
  fprintf ppf format print_longident longprefix txt

type space_formatter = (unit, Format.formatter, unit) format

let override = function
  | Override -> ""!""
  | Fresh -> """"

(* variance encoding: need to sync up with the [parser.mly] *)
let type_variance = function
  | NoVariance -> """"
  | Covariant -> ""+""
  | Contravariant -> ""-""

let type_injectivity = function
  | NoInjectivity -> """"
  | Injective -> ""!""

type construct =
  [ `cons of expression list
  | `list of expression list
  | `nil
  | `normal
  | `simple of Longident.t
  | `tuple ]

let view_expr x =
  match x.pexp_desc with
  | Pexp_construct ( {txt= Lident ""()""; _},_) -> `tuple
  | Pexp_construct ( {txt= Lident ""[]"";_},_) -> `nil
  | Pexp_construct ( {txt= Lident""::"";_},Some _) ->
      let rec loop exp acc = match exp with
          | {pexp_desc=Pexp_construct ({txt=Lident ""[]"";_},_);
             pexp_attributes = []} ->
              (List.rev acc,true)
          | {pexp_desc=
             Pexp_construct ({txt=Lident ""::"";_},
                             Some ({pexp_desc= Pexp_tuple([e1;e2]);
                                    pexp_attributes = []}));
             pexp_attributes = []}
            ->
              loop e2 (e1::acc)
          | e -> (List.rev (e::acc),false) in
      let (ls,b) = loop x []  in
      if b then
        `list ls
      else `cons ls
  | Pexp_construct (x,None) -> `simple (x.txt)
  | _ -> `normal

let is_simple_construct :construct -> bool = function
  | `nil | `tuple | `list _ | `simple _  -> true
  | `cons _ | `normal -> false

let pp = fprintf

type ctxt = {
  pipe : bool;
  semi : bool;
  ifthenelse : bool;
}

let reset_ctxt = { pipe=false; semi=false; ifthenelse=false }
let under_pipe ctxt = { ctxt with pipe=true }
let under_semi ctxt = { ctxt with semi=true }
let under_ifthenelse ctxt = { ctxt with ifthenelse=true }
(*
let reset_semi ctxt = { ctxt with semi=false }
let reset_ifthenelse ctxt = { ctxt with ifthenelse=false }
let reset_pipe ctxt = { ctxt with pipe=false }
*)

let list : 'a . ?sep:space_formatter -> ?first:space_formatter ->
  ?last:space_formatter -> (Format.formatter -> 'a -> unit) ->
  Format.formatter -> 'a list -> unit
  = fun ?sep ?first ?last fu f xs ->
    let first = match first with Some x -> x |None -> ("""": _ format6)
    and last = match last with Some x -> x |None -> ("""": _ format6)
    and sep = match sep with Some x -> x |None -> (""@ "": _ format6) in
    let aux f = function
      | [] -> ()
      | [x] -> fu f x
      | xs ->
          let rec loop  f = function
            | [x] -> fu f x
            | x::xs ->  fu f x; pp f sep; loop f xs;
            | _ -> assert false in begin
            pp f first; loop f xs; pp f last;
          end in
    aux f xs

let option : 'a. ?first:space_formatter -> ?last:space_formatter ->
  (Format.formatter -> 'a -> unit) -> Format.formatter -> 'a option -> unit
  = fun  ?first  ?last fu f a ->
    let first = match first with Some x -> x | None -> ("""": _ format6)
    and last = match last with Some x -> x | None -> ("""": _ format6) in
    match a with
    | None -> ()
    | Some x -> pp f first; fu f x; pp f last

let paren: 'a . ?first:space_formatter -> ?last:space_formatter ->
  bool -> (Format.formatter -> 'a -> unit) -> Format.formatter -> 'a -> unit
  = fun  ?(first=("""": _ format6)) ?(last=("""": _ format6)) b fu f x ->
    if b then (pp f ""(""; pp f first; fu f x; pp f last; pp f "")"")
    else fu f x

let rec longident f = function
  | Lident s -> protect_ident f s
  | Ldot(y,s) -> protect_longident f longident y s
  | Lapply (y,s) ->
      pp f ""%a(%a)"" longident y longident s

let longident_loc f x = pp f ""%a"" longident x.txt

let constant f = function
  | Pconst_char i ->
      pp f ""%C""  i
  | Pconst_string (i, _, None) ->
      pp f ""%S"" i
  | Pconst_string (i, _, Some delim) ->
      pp f ""{%s|%s|%s}"" delim i delim
  | Pconst_integer (i, None) ->
      paren (first_is '-' i) (fun f -> pp f ""%s"") f i
  | Pconst_integer (i, Some m) ->
      paren (first_is '-' i) (fun f (i, m) -> pp f ""%s%c"" i m) f (i,m)
  | Pconst_float (i, None) ->
      paren (first_is '-' i) (fun f -> pp f ""%s"") f i
  | Pconst_float (i, Some m) ->
      paren (first_is '-' i) (fun f (i,m) -> pp f ""%s%c"" i m) f (i,m)

(* trailing space*)
let mutable_flag f = function
  | Immutable -> ()
  | Mutable -> pp f ""mutable@;""
let virtual_flag f  = function
  | Concrete -> ()
  | Virtual -> pp f ""virtual@;""

(* trailing space added *)
let rec_flag f rf =
  match rf with
  | Nonrecursive -> ()
  | Recursive -> pp f ""rec ""
let nonrec_flag f rf =
  match rf with
  | Nonrecursive -> pp f ""nonrec ""
  | Recursive -> ()
let direction_flag f = function
  | Upto -> pp f ""to@ ""
  | Downto -> pp f ""downto@ ""
let private_flag f = function
  | Public -> ()
  | Private -> pp f ""private@ ""

let iter_loc f ctxt {txt; loc = _} = f ctxt txt

let constant_string f s = pp f ""%S"" s

let tyvar ppf s =
  if String.length s >= 2 && s.[1] = '\'' then
    (* without the space, this would be parsed as
       a character literal *)
    Format.fprintf ppf ""' %s"" s
  else
    Format.fprintf ppf ""'%s"" s

let tyvar_loc f str = tyvar f str.txt
let string_quot f x = pp f ""`%s"" x

(* c ['a,'b] *)
let rec class_params_def ctxt f =  function
  | [] -> ()
  | l ->
      pp f ""[%a] "" (* space *)
        (list (type_param ctxt) ~sep:"","") l

and type_with_label ctxt f (label, c) =
  match label with
  | Nolabel    -> core_type1 ctxt f c (* otherwise parenthesize *)
  | Labelled s -> pp f ""%s:%a"" s (core_type1 ctxt) c
  | Optional s -> pp f ""?%s:%a"" s (core_type1 ctxt) c

and core_type ctxt f x =
  if x.ptyp_attributes <> [] then begin
    pp f ""((%a)%a)"" (core_type ctxt) {x with ptyp_attributes=[]}
      (attributes ctxt) x.ptyp_attributes
  end
  else match x.ptyp_desc with
    | Ptyp_arrow (l, ct1, ct2) ->
        pp f ""@[<2>%a@;->@;%a@]"" (* FIXME remove parens later *)
          (type_with_label ctxt) (l,ct1) (core_type ctxt) ct2
    | Ptyp_alias (ct, s) ->
        pp f ""@[<2>%a@;as@;%a@]"" (core_type1 ctxt) ct tyvar s
    | Ptyp_poly ([], ct) ->
        core_type ctxt f ct
    | Ptyp_poly (sl, ct) ->
        pp f ""@[<2>%a%a@]""
          (fun f l ->
             pp f ""%a""
               (fun f l -> match l with
                  | [] -> ()
                  | _ ->
                      pp f ""%a@;.@;""
                        (list tyvar_loc ~sep:""@;"")  l)
               l)
          sl (core_type ctxt) ct
    | _ -> pp f ""@[<2>%a@]"" (core_type1 ctxt) x

and core_type1 ctxt f x =
  if x.ptyp_attributes <> [] then core_type ctxt f x
  else match x.ptyp_desc with
    | Ptyp_any -> pp f ""_"";
    | Ptyp_var s -> tyvar f  s;
    | Ptyp_tuple l ->  pp f ""(%a)"" (list (core_type1 ctxt) ~sep:""@;*@;"") l
    | Ptyp_constr (li, l) ->
        pp f (* ""%a%a@;"" *) ""%a%a""
          (fun f l -> match l with
             |[] -> ()
             |[x]-> pp f ""%a@;"" (core_type1 ctxt)  x
             | _ -> list ~first:""("" ~last:"")@;"" (core_type ctxt) ~sep:"",@;"" f l)
          l longident_loc li
    | Ptyp_variant (l, closed, low) ->
        let first_is_inherit = match l with
          | {Parsetree.prf_desc = Rinherit _}::_ -> true
          | _ -> false in
        let type_variant_helper f x =
          match x.prf_desc with
          | Rtag (l, _, ctl) ->
              pp f ""@[<2>%a%a@;%a@]"" (iter_loc string_quot) l
                (fun f l -> match l with
                   |[] -> ()
                   | _ -> pp f ""@;of@;%a""
                            (list (core_type ctxt) ~sep:""&"")  ctl) ctl
                (attributes ctxt) x.prf_attributes
          | Rinherit ct -> core_type ctxt f ct in
        pp f ""@[<2>[%a%a]@]""
          (fun f l ->
             match l, closed with
             | [], Closed -> ()
             | [], Open -> pp f "">"" (* Cf #7200: print [>] correctly *)
             | _ ->
                 pp f ""%s@;%a""
                   (match (closed,low) with
                    | (Closed,None) -> if first_is_inherit then "" |"" else """"
                    | (Closed,Some _) -> ""<"" (* FIXME desugar the syntax sugar*)
                    | (Open,_) -> "">"")
                   (list type_variant_helper ~sep:""@;<1 -2>| "") l) l
          (fun f low -> match low with
             |Some [] |None -> ()
             |Some xs ->
                 pp f "">@ %a""
                   (list string_quot) xs) low
    | Ptyp_object (l, o) ->
        let core_field_type f x = match x.pof_desc with
          | Otag (l, ct) ->
            (* Cf #7200 *)
            pp f ""@[<hov2>%s: %a@ %a@ @]"" l.txt
              (core_type ctxt) ct (attributes ctxt) x.pof_attributes
          | Oinherit ct ->
            pp f ""@[<hov2>%a@ @]"" (core_type ctxt) ct
        in
        let field_var f = function
          | Asttypes.Closed -> ()
          | Asttypes.Open ->
              match l with
              | [] -> pp f ""..""
              | _ -> pp f "" ;..""
        in
        pp f ""@[<hov2><@ %a%a@ > @]""
          (list core_field_type ~sep:"";"") l
          field_var o (* Cf #7200 *)
    | Ptyp_class (li, l) ->   (*FIXME*)
        pp f ""@[<hov2>%a#%a@]""
          (list (core_type ctxt) ~sep:"","" ~first:""("" ~last:"")"") l
          longident_loc li
    | Ptyp_package (lid, cstrs) ->
        let aux f (s, ct) =
          pp f ""type %a@ =@ %a"" longident_loc s (core_type ctxt) ct  in
        (match cstrs with
         |[] -> pp f ""@[<hov2>(module@ %a)@]"" longident_loc lid
         |_ ->
             pp f ""@[<hov2>(module@ %a@ with@ %a)@]"" longident_loc lid
               (list aux  ~sep:""@ and@ "")  cstrs)
    | Ptyp_extension e -> extension ctxt f e
    | _ -> paren true (core_type ctxt) f x

(********************pattern********************)
(* be cautious when use [pattern], [pattern1] is preferred *)
and pattern ctxt f x =
  if x.ppat_attributes <> [] then begin
    pp f ""((%a)%a)"" (pattern ctxt) {x with ppat_attributes=[]}
      (attributes ctxt) x.ppat_attributes
  end
  else match x.ppat_desc with
    | Ppat_alias (p, s) ->
        pp f ""@[<2>%a@;as@;%a@]"" (pattern ctxt) p protect_ident s.txt
    | _ -> pattern_or ctxt f x

and pattern_or ctxt f x =
  let rec left_associative x acc = match x with
    | {ppat_desc=Ppat_or (p1,p2); ppat_attributes = []} ->
        left_associative p1 (p2 :: acc)
    | x -> x :: acc
  in
  match left_associative x [] with
  | [] -> assert false
  | [x] -> pattern1 ctxt f x
  | orpats ->
      pp f ""@[<hov0>%a@]"" (list ~sep:""@ | "" (pattern1 ctxt)) orpats

and pattern1 ctxt (f:Format.formatter) (x:pattern) : unit =
  let rec pattern_list_helper f = function
    | {ppat_desc =
         Ppat_construct
           ({ txt = Lident(""::"") ;_},
            Some ([], {ppat_desc = Ppat_tuple([pat1; pat2]);_}));
       ppat_attributes = []}

      ->
        pp f ""%a::%a"" (simple_pattern ctxt) pat1 pattern_list_helper pat2 (*RA*)
    | p -> pattern1 ctxt f p
  in
  if x.ppat_attributes <> [] then pattern ctxt f x
  else match x.ppat_desc with
    | Ppat_variant (l, Some p) ->
        pp f ""@[<2>`%s@;%a@]"" l (simple_pattern ctxt) p
    | Ppat_construct (({txt=Lident(""()""|""[]"");_}), _) ->
        simple_pattern ctxt f x
    | Ppat_construct (({txt;_} as li), po) ->
        (* FIXME The third field always false *)
        if txt = Lident ""::"" then
          pp f ""%a"" pattern_list_helper x
        else
          (match po with
           | Some ([], x) ->
               pp f ""%a@;%a""  longident_loc li (simple_pattern ctxt) x
           | Some (vl, x) ->
               pp f ""%a@ (type %a)@;%a"" longident_loc li
                 (list ~sep:""@ "" string_loc) vl
                 (simple_pattern ctxt) x
           | None -> pp f ""%a"" longident_loc li)
    | _ -> simple_pattern ctxt f x

and simple_pattern ctxt (f:Format.formatter) (x:pattern) : unit =
  if x.ppat_attributes <> [] then pattern ctxt f x
  else match x.ppat_desc with
    | Ppat_construct (({txt=Lident (""()""|""[]"" as x);_}), None) ->
        pp f  ""%s"" x
    | Ppat_any -> pp f ""_"";
    | Ppat_var ({txt = txt;_}) -> protect_ident f txt
    | Ppat_array l ->
        pp f ""@[<2>[|%a|]@]""  (list (pattern1 ctxt) ~sep:"";"") l
    | Ppat_unpack { txt = None } ->
        pp f ""(module@ _)@ ""
    | Ppat_unpack { txt = Some s } ->
        pp f ""(module@ %s)@ "" s
    | Ppat_type li ->
        pp f ""#%a"" longident_loc li
    | Ppat_record (l, closed) ->
        let longident_x_pattern f (li, p) =
          match (li,p) with
          | ({txt=Lident s;_ },
             {ppat_desc=Ppat_var {txt;_};
              ppat_attributes=[]; _})
            when s = txt ->
              pp f ""@[<2>%a@]""  longident_loc li
          | _ ->
              pp f ""@[<2>%a@;=@;%a@]"" longident_loc li (pattern1 ctxt) p
        in
        begin match closed with
        | Closed ->
            pp f ""@[<2>{@;%a@;}@]"" (list longident_x_pattern ~sep:"";@;"") l
        | _ ->
            pp f ""@[<2>{@;%a;_}@]"" (list longident_x_pattern ~sep:"";@;"") l
        end
    | Ppat_tuple l ->
        pp f ""@[<1>(%a)@]"" (list  ~sep:"",@;"" (pattern1 ctxt))  l (* level1*)
    | Ppat_constant (c) -> pp f ""%a"" constant c
    | Ppat_interval (c1, c2) -> pp f ""%a..%a"" constant c1 constant c2
    | Ppat_variant (l,None) ->  pp f ""`%s"" l
    | Ppat_constraint (p, ct) ->
        pp f ""@[<2>(%a@;:@;%a)@]"" (pattern1 ctxt) p (core_type ctxt) ct
    | Ppat_lazy p ->
        pp f ""@[<2>(lazy@;%a)@]"" (simple_pattern ctxt) p
    | Ppat_exception p ->
        pp f ""@[<2>exception@;%a@]"" (pattern1 ctxt) p
    | Ppat_extension e -> extension ctxt f e
    | Ppat_open (lid, p) ->
        let with_paren =
        match p.ppat_desc with
        | Ppat_array _ | Ppat_record _
        | Ppat_construct (({txt=Lident (""()""|""[]"");_}), None) -> false
        | _ -> true in
        pp f ""@[<2>%a.%a @]"" longident_loc lid
          (paren with_paren @@ pattern1 ctxt) p
    | _ -> paren true (pattern ctxt) f x

and label_exp ctxt f (l,opt,p) =
  match l with
  | Nolabel ->
      (* single case pattern parens needed here *)
      pp f ""%a@ "" (simple_pattern ctxt) p
  | Optional rest ->
      begin match p with
      | {ppat_desc = Ppat_var {txt;_}; ppat_attributes = []}
        when txt = rest ->
          (match opt with
           | Some o -> pp f ""?(%s=@;%a)@;"" rest  (expression ctxt) o
           | None -> pp f ""?%s@ "" rest)
      | _ ->
          (match opt with
           | Some o ->
               pp f ""?%s:(%a=@;%a)@;""
                 rest (pattern1 ctxt) p (expression ctxt) o
           | None -> pp f ""?%s:%a@;"" rest (simple_pattern ctxt) p)
      end
  | Labelled l -> match p with
    | {ppat_desc  = Ppat_var {txt;_}; ppat_attributes = []}
      when txt = l ->
        pp f ""~%s@;"" l
    | _ ->  pp f ""~%s:%a@;"" l (simple_pattern ctxt) p

and sugar_expr ctxt f e =
  if e.pexp_attributes <> [] then false
  else match e.pexp_desc with
  | Pexp_apply ({ pexp_desc = Pexp_ident {txt = id; _};
                  pexp_attributes=[]; _}, args)
    when List.for_all (fun (lab, _) -> lab = Nolabel) args -> begin
      let print_indexop a path_prefix assign left sep right print_index indices
          rem_args =
        let print_path ppf = function
          | None -> ()
          | Some m -> pp ppf "".%a"" longident m in
        match assign, rem_args with
            | false, [] ->
              pp f ""@[%a%a%s%a%s@]""
                (simple_expr ctxt) a print_path path_prefix
                left (list ~sep print_index) indices right; true
            | true, [v] ->
              pp f ""@[%a%a%s%a%s@ <-@;<1 2>%a@]""
                (simple_expr ctxt) a print_path path_prefix
                left (list ~sep print_index) indices right
                (simple_expr ctxt) v; true
            | _ -> false in
      match id, List.map snd args with
      | Lident ""!"", [e] ->
        pp f ""@[<hov>!%a@]"" (simple_expr ctxt) e; true
      | Ldot (path, (""get""|""set"" as func)), a :: other_args -> begin
          let assign = func = ""set"" in
          let print = print_indexop a None assign in
          match path, other_args with
          | Lident ""Array"", i :: rest ->
            print "".("" """" "")"" (expression ctxt) [i] rest
          | Lident ""String"", i :: rest ->
            print "".["" """" ""]"" (expression ctxt) [i] rest
          | Ldot (Lident ""Bigarray"", ""Array1""), i1 :: rest ->
            print "".{"" "","" ""}"" (simple_expr ctxt) [i1] rest
          | Ldot (Lident ""Bigarray"", ""Array2""), i1 :: i2 :: rest ->
            print "".{"" "","" ""}"" (simple_expr ctxt) [i1; i2] rest
          | Ldot (Lident ""Bigarray"", ""Array3""), i1 :: i2 :: i3 :: rest ->
            print "".{"" "","" ""}"" (simple_expr ctxt) [i1; i2; i3] rest
          | Ldot (Lident ""Bigarray"", ""Genarray""),
            {pexp_desc = Pexp_array indexes; pexp_attributes = []} :: rest ->
              print "".{"" "","" ""}"" (simple_expr ctxt) indexes rest
          | _ -> false
        end
      | (Lident s | Ldot(_,s)) , a :: i :: rest
        when first_is '.' s ->
          (* extract operator:
             assignment operators end with [right_bracket ^ ""<-""],
             access operators end with [right_bracket] directly
          *)
          let multi_indices = String.contains s ';' in
          let i =
              match i.pexp_desc with
                | Pexp_array l when multi_indices -> l
                | _ -> [ i ] in
          let assign = last_is '-' s in
          let kind =
            (* extract the right end bracket *)
            let n = String.length s in
            if assign then s.[n - 3] else s.[n - 1] in
          let left, right = match kind with
            | ')' -> '(', "")""
            | ']' -> '[', ""]""
            | '}' -> '{', ""}""
            | _ -> assert false in
          let path_prefix = match id with
            | Ldot(m,_) -> Some m
            | _ -> None in
          let left = String.sub s 0 (1+String.index s left) in
          print_indexop a path_prefix assign left "";"" right
            (if multi_indices then expression ctxt else simple_expr ctxt)
            i rest
      | _ -> false
    end
  | _ -> false

and expression ctxt f x =
  if x.pexp_attributes <> [] then
    pp f ""((%a)@,%a)"" (expression ctxt) {x with pexp_attributes=[]}
      (attributes ctxt) x.pexp_attributes
  else match x.pexp_desc with
    | Pexp_function _ | Pexp_fun _ | Pexp_match _ | Pexp_try _ | Pexp_sequence _
    | Pexp_newtype _
      when ctxt.pipe || ctxt.semi ->
        paren true (expression reset_ctxt) f x
    | Pexp_ifthenelse _ | Pexp_sequence _ when ctxt.ifthenelse ->
        paren true (expression reset_ctxt) f x
    | Pexp_let _ | Pexp_letmodule _ | Pexp_open _
      | Pexp_letexception _ | Pexp_letop _
        when ctxt.semi ->
        paren true (expression reset_ctxt) f x
    | Pexp_fun (l, e0, p, e) ->
        pp f ""@[<2>fun@;%a->@;%a@]""
          (label_exp ctxt) (l, e0, p)
          (expression ctxt) e
    | Pexp_newtype (lid, e) ->
        pp f ""@[<2>fun@;(type@;%s)@;->@;%a@]"" lid.txt
          (expression ctxt) e
    | Pexp_function l ->
        pp f ""@[<hv>function%a@]"" (case_list ctxt) l
    | Pexp_match (e, l) ->
        pp f ""@[<hv0>@[<hv0>@[<2>match %a@]@ with@]%a@]""
          (expression reset_ctxt) e (case_list ctxt) l

    | Pexp_try (e, l) ->
        pp f ""@[<0>@[<hv2>try@ %a@]@ @[<0>with%a@]@]""
             (* ""try@;@[<2>%a@]@\nwith@\n%a""*)
          (expression reset_ctxt) e  (case_list ctxt) l
    | Pexp_let (rf, l, e) ->
        (* pp f ""@[<2>let %a%a in@;<1 -2>%a@]""
           (*no indentation here, a new line*) *)
        (*   rec_flag rf *)
        pp f ""@[<2>%a in@;<1 -2>%a@]""
          (bindings reset_ctxt) (rf,l)
          (expression ctxt) e
    | Pexp_apply (e, l) ->
        begin if not (sugar_expr ctxt f x) then
            match view_fixity_of_exp e with
            | `Infix s ->
                begin match l with
                | [ (Nolabel, _) as arg1; (Nolabel, _) as arg2 ] ->
                    (* FIXME associativity label_x_expression_param *)
                    pp f ""@[<2>%a@;%s@;%a@]""
                      (label_x_expression_param reset_ctxt) arg1 s
                      (label_x_expression_param ctxt) arg2
                | _ ->
                    pp f ""@[<2>%a %a@]""
                      (simple_expr ctxt) e
                      (list (label_x_expression_param ctxt)) l
                end
            | `Prefix s ->
                let s =
                  if List.mem s [""~+"";""~-"";""~+."";""~-.""] &&
                   (match l with
                    (* See #7200: avoid turning (~- 1) into (- 1) which is
                       parsed as an int literal *)
                    |[(_,{pexp_desc=Pexp_constant _})] -> false
                    | _ -> true)
                  then String.sub s 1 (String.length s -1)
                  else s in
                begin match l with
                | [(Nolabel, x)] ->
                  pp f ""@[<2>%s@;%a@]"" s (simple_expr ctxt) x
                | _   ->
                  pp f ""@[<2>%a %a@]"" (simple_expr ctxt) e
                    (list (label_x_expression_param ctxt)) l
                end
            | _ ->
                pp f ""@[<hov2>%a@]"" begin fun f (e,l) ->
                  pp f ""%a@ %a"" (expression2 ctxt) e
                    (list (label_x_expression_param reset_ctxt))  l
                    (* reset here only because [function,match,try,sequence]
                       are lower priority *)
                end (e,l)
        end

    | Pexp_construct (li, Some eo)
      when not (is_simple_construct (view_expr x))-> (* Not efficient FIXME*)
        (match view_expr x with
         | `cons ls -> list (simple_expr ctxt) f ls ~sep:""@;::@;""
         | `normal ->
             pp f ""@[<2>%a@;%a@]"" longident_loc li
               (simple_expr ctxt) eo
         | _ -> assert false)
    | Pexp_setfield (e1, li, e2) ->
        pp f ""@[<2>%a.%a@ <-@ %a@]""
          (simple_expr ctxt) e1 longident_loc li (simple_expr ctxt) e2
    | Pexp_ifthenelse (e1, e2, eo) ->
        (* @;@[<2>else@ %a@]@] *)
        let fmt:(_,_,_)format =""@[<hv0>@[<2>if@ %a@]@;@[<2>then@ %a@]%a@]"" in
        let expression_under_ifthenelse = expression (under_ifthenelse ctxt) in
        pp f fmt expression_under_ifthenelse e1 expression_under_ifthenelse e2
          (fun f eo -> match eo with
             | Some x ->
                 pp f ""@;@[<2>else@;%a@]"" (expression (under_semi ctxt)) x
             | None -> () (* pp f ""()"" *)) eo
    | Pexp_sequence _ ->
        let rec sequence_helper acc = function
          | {pexp_desc=Pexp_sequence(e1,e2); pexp_attributes = []} ->
              sequence_helper (e1::acc) e2
          | v -> List.rev (v::acc) in
        let lst = sequence_helper [] x in
        pp f ""@[<hv>%a@]""
          (list (expression (under_semi ctxt)) ~sep:"";@;"") lst
    | Pexp_new (li) ->
        pp f ""@[<hov2>new@ %a@]"" longident_loc li;
    | Pexp_setinstvar (s, e) ->
        pp f ""@[<hov2>%s@ <-@ %a@]"" s.txt (expression ctxt) e
    | Pexp_override l -> (* FIXME *)
        let string_x_expression f (s, e) =
          pp f ""@[<hov2>%s@ =@ %a@]"" s.txt (expression ctxt) e in
        pp f ""@[<hov2>{<%a>}@]""
          (list string_x_expression  ~sep:"";""  )  l;
    | Pexp_letmodule (s, me, e) ->
        pp f ""@[<hov2>let@ module@ %s@ =@ %a@ in@ %a@]""
          (Option.value s.txt ~default:""_"")
          (module_expr reset_ctxt) me (expression ctxt) e
    | Pexp_letexception (cd, e) ->
        pp f ""@[<hov2>let@ exception@ %a@ in@ %a@]""
          (extension_constructor ctxt) cd
          (expression ctxt) e
    | Pexp_assert e ->
        pp f ""@[<hov2>assert@ %a@]"" (simple_expr ctxt) e
    | Pexp_lazy (e) ->
        pp f ""@[<hov2>lazy@ %a@]"" (simple_expr ctxt) e
    (* Pexp_poly: impossible but we should print it anyway, rather than
       assert false *)
    | Pexp_poly (e, None) ->
        pp f ""@[<hov2>!poly!@ %a@]"" (simple_expr ctxt) e
    | Pexp_poly (e, Some ct) ->
        pp f ""@[<hov2>(!poly!@ %a@ : %a)@]""
          (simple_expr ctxt) e (core_type ctxt) ct
    | Pexp_open (o, e) ->
        pp f ""@[<2>let open%s %a in@;%a@]""
          (override o.popen_override) (module_expr ctxt) o.popen_expr
          (expression ctxt) e
    | Pexp_variant (l,Some eo) ->
        pp f ""@[<2>`%s@;%a@]"" l (simple_expr ctxt) eo
    | Pexp_letop {let_; ands; body} ->
        pp f ""@[<2>@[<v>%a@,%a@] in@;<1 -2>%a@]""
          (binding_op ctxt) let_
          (list ~sep:""@,"" (binding_op ctxt)) ands
          (expression ctxt) body
    | Pexp_extension e -> extension ctxt f e
    | Pexp_unreachable -> pp f "".""
    | _ -> expression1 ctxt f x

and expression1 ctxt f x =
  if x.pexp_attributes <> [] then expression ctxt f x
  else match x.pexp_desc with
    | Pexp_object cs -> pp f ""%a"" (class_structure ctxt) cs
    | _ -> expression2 ctxt f x
(* used in [Pexp_apply] *)

and expression2 ctxt f x =
  if x.pexp_attributes <> [] then expression ctxt f x
  else match x.pexp_desc with
    | Pexp_field (e, li) ->
        pp f ""@[<hov2>%a.%a@]"" (simple_expr ctxt) e longident_loc li
    | Pexp_send (e, s) -> pp f ""@[<hov2>%a#%s@]"" (simple_expr ctxt) e s.txt

    | _ -> simple_expr ctxt f x

and simple_expr ctxt f x =
  if x.pexp_attributes <> [] then expression ctxt f x
  else match x.pexp_desc with
    | Pexp_construct _  when is_simple_construct (view_expr x) ->
        (match view_expr x with
         | `nil -> pp f ""[]""
         | `tuple -> pp f ""()""
         | `list xs ->
             pp f ""@[<hv0>[%a]@]""
               (list (expression (under_semi ctxt)) ~sep:"";@;"") xs
         | `simple x -> longident f x
         | _ -> assert false)
    | Pexp_ident li ->
        longident_loc f li
    (* (match view_fixity_of_exp x with *)
    (* |`Normal -> longident_loc f li *)
    (* | `Prefix _ | `Infix _ -> pp f ""( %a )"" longident_loc li) *)
    | Pexp_constant c -> constant f c;
    | Pexp_pack me ->
        pp f ""(module@;%a)"" (module_expr ctxt) me
    | Pexp_tuple l ->
        pp f ""@[<hov2>(%a)@]"" (list (simple_expr ctxt) ~sep:"",@;"") l
    | Pexp_constraint (e, ct) ->
        pp f ""(%a : %a)"" (expression ctxt) e (core_type ctxt) ct
    | Pexp_coerce (e, cto1, ct) ->
        pp f ""(%a%a :> %a)"" (expression ctxt) e
          (option (core_type ctxt) ~first:"" : "" ~last:"" "") cto1 (* no sep hint*)
          (core_type ctxt) ct
    | Pexp_variant (l, None) -> pp f ""`%s"" l
    | Pexp_record (l, eo) ->
        let longident_x_expression f ( li, e) =
          match e with
          |  {pexp_desc=Pexp_ident {txt;_};
              pexp_attributes=[]; _} when li.txt = txt ->
              pp f ""@[<hov2>%a@]"" longident_loc li
          | _ ->
              pp f ""@[<hov2>%a@;=@;%a@]"" longident_loc li (simple_expr ctxt) e
        in
        pp f ""@[<hv0>@[<hv2>{@;%a%a@]@;}@]""(* ""@[<hov2>{%a%a}@]"" *)
          (option ~last:"" with@;"" (simple_expr ctxt)) eo
          (list longident_x_expression ~sep:"";@;"") l
    | Pexp_array (l) ->
        pp f ""@[<0>@[<2>[|%a|]@]@]""
          (list (simple_expr (under_semi ctxt)) ~sep:"";"") l
    | Pexp_while (e1, e2) ->
        let fmt : (_,_,_) format = ""@[<2>while@;%a@;do@;%a@;done@]"" in
        pp f fmt (expression ctxt) e1 (expression ctxt) e2
    | Pexp_for (s, e1, e2, df, e3) ->
        let fmt:(_,_,_)format =
          ""@[<hv0>@[<hv2>@[<2>for %a =@;%a@;%a%a@;do@]@;%a@]@;done@]"" in
        let expression = expression ctxt in
        pp f fmt (pattern ctxt) s expression e1 direction_flag
          df expression e2 expression e3
    | _ ->  paren true (expression ctxt) f x

and attributes ctxt f l =
  List.iter (attribute ctxt f) l

and item_attributes ctxt f l =
  List.iter (item_attribute ctxt f) l

and attribute ctxt f a =
  pp f ""@[<2>[@@%s@ %a]@]"" a.attr_name.txt (payload ctxt) a.attr_payload

and item_attribute ctxt f a =
  pp f ""@[<2>[@@@@%s@ %a]@]"" a.attr_name.txt (payload ctxt) a.attr_payload

and floating_attribute ctxt f a =
  pp f ""@[<2>[@@@@@@%s@ %a]@]"" a.attr_name.txt (payload ctxt) a.attr_payload

and value_description ctxt f x =
  (* note: value_description has an attribute field,
           but they're already printed by the callers this method *)
  pp f ""@[<hov2>%a%a@]"" (core_type ctxt) x.pval_type
    (fun f x ->
       if x.pval_prim <> []
       then pp f ""@ =@ %a"" (list constant_string) x.pval_prim
    ) x

and extension ctxt f (s, e) =
  pp f ""@[<2>[%%%s@ %a]@]"" s.txt (payload ctxt) e

and item_extension ctxt f (s, e) =
  pp f ""@[<2>[%%%%%s@ %a]@]"" s.txt (payload ctxt) e

and exception_declaration ctxt f x =
  pp f ""@[<hov2>exception@ %a@]%a""
    (extension_constructor ctxt) x.ptyexn_constructor
    (item_attributes ctxt) x.ptyexn_attributes

and class_type_field ctxt f x =
  match x.pctf_desc with
  | Pctf_inherit (ct) ->
      pp f ""@[<2>inherit@ %a@]%a"" (class_type ctxt) ct
        (item_attributes ctxt) x.pctf_attributes
  | Pctf_val (s, mf, vf, ct) ->
      pp f ""@[<2>val @ %a%a%s@ :@ %a@]%a""
        mutable_flag mf virtual_flag vf s.txt (core_type ctxt) ct
        (item_attributes ctxt) x.pctf_attributes
  | Pctf_method (s, pf, vf, ct) ->
      pp f ""@[<2>method %a %a%s :@;%a@]%a""
        private_flag pf virtual_flag vf s.txt (core_type ctxt) ct
        (item_attributes ctxt) x.pctf_attributes
  | Pctf_constraint (ct1, ct2) ->
      pp f ""@[<2>constraint@ %a@ =@ %a@]%a""
        (core_type ctxt) ct1 (core_type ctxt) ct2
        (item_attributes ctxt) x.pctf_attributes
  | Pctf_attribute a -> floating_attribute ctxt f a
  | Pctf_extension e ->
      item_extension ctxt f e;
      item_attributes ctxt f x.pctf_attributes

and class_signature ctxt f { pcsig_self = ct; pcsig_fields = l ;_} =
  pp f ""@[<hv0>@[<hv2>object@[<1>%a@]@ %a@]@ end@]""
    (fun f -> function
         {ptyp_desc=Ptyp_any; ptyp_attributes=[]; _} -> ()
       | ct -> pp f "" (%a)"" (core_type ctxt) ct) ct
    (list (class_type_field ctxt) ~sep:""@;"") l

(* call [class_signature] called by [class_signature] *)
and class_type ctxt f x =
  match x.pcty_desc with
  | Pcty_signature cs ->
      class_signature ctxt f cs;
      attributes ctxt f x.pcty_attributes
  | Pcty_constr (li, l) ->
      pp f ""%a%a%a""
        (fun f l -> match l with
           | [] -> ()
           | _  -> pp f ""[%a]@ "" (list (core_type ctxt) ~sep:"","" ) l) l
        longident_loc li
        (attributes ctxt) x.pcty_attributes
  | Pcty_arrow (l, co, cl) ->
      pp f ""@[<2>%a@;->@;%a@]"" (* FIXME remove parens later *)
        (type_with_label ctxt) (l,co)
        (class_type ctxt) cl
  | Pcty_extension e ->
      extension ctxt f e;
      attributes ctxt f x.pcty_attributes
  | Pcty_open (o, e) ->
      pp f ""@[<2>let open%s %a in@;%a@]""
        (override o.popen_override) longident_loc o.popen_expr
        (class_type ctxt) e

(* [class type a = object end] *)
and class_type_declaration_list ctxt f l =
  let class_type_declaration kwd f x =
    let { pci_params=ls; pci_name={ txt; _ }; _ } = x in
    pp f ""@[<2>%s %a%a%s@ =@ %a@]%a"" kwd
      virtual_flag x.pci_virt
      (class_params_def ctxt) ls txt
      (class_type ctxt) x.pci_expr
      (item_attributes ctxt) x.pci_attributes
  in
  match l with
  | [] -> ()
  | [x] -> class_type_declaration ""class type"" f x
  | x :: xs ->
      pp f ""@[<v>%a@,%a@]""
        (class_type_declaration ""class type"") x
        (list ~sep:""@,"" (class_type_declaration ""and"")) xs

and class_field ctxt f x =
  match x.pcf_desc with
  | Pcf_inherit (ovf, ce, so) ->
      pp f ""@[<2>inherit@ %s@ %a%a@]%a"" (override ovf)
        (class_expr ctxt) ce
        (fun f so -> match so with
           | None -> ();
           | Some (s) -> pp f ""@ as %s"" s.txt ) so
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_val (s, mf, Cfk_concrete (ovf, e)) ->
      pp f ""@[<2>val%s %a%s =@;%a@]%a"" (override ovf)
        mutable_flag mf s.txt
        (expression ctxt) e
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_method (s, pf, Cfk_virtual ct) ->
      pp f ""@[<2>method virtual %a %s :@;%a@]%a""
        private_flag pf s.txt
        (core_type ctxt) ct
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_val (s, mf, Cfk_virtual ct) ->
      pp f ""@[<2>val virtual %a%s :@ %a@]%a""
        mutable_flag mf s.txt
        (core_type ctxt) ct
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_method (s, pf, Cfk_concrete (ovf, e)) ->
      let bind e =
        binding ctxt f
          {pvb_pat=
             {ppat_desc=Ppat_var s;
              ppat_loc=Location.none;
              ppat_loc_stack=[];
              ppat_attributes=[]};
           pvb_expr=e;
           pvb_attributes=[];
           pvb_loc=Location.none;
          }
      in
      pp f ""@[<2>method%s %a%a@]%a""
        (override ovf)
        private_flag pf
        (fun f -> function
           | {pexp_desc=Pexp_poly (e, Some ct); pexp_attributes=[]; _} ->
               pp f ""%s :@;%a=@;%a""
                 s.txt (core_type ctxt) ct (expression ctxt) e
           | {pexp_desc=Pexp_poly (e, None); pexp_attributes=[]; _} ->
               bind e
           | _ -> bind e) e
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_constraint (ct1, ct2) ->
      pp f ""@[<2>constraint %a =@;%a@]%a""
        (core_type ctxt) ct1
        (core_type ctxt) ct2
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_initializer (e) ->
      pp f ""@[<2>initializer@ %a@]%a""
        (expression ctxt) e
        (item_attributes ctxt) x.pcf_attributes
  | Pcf_attribute a -> floating_attribute ctxt f a
  | Pcf_extension e ->
      item_extension ctxt f e;
      item_attributes ctxt f x.pcf_attributes

and class_structure ctxt f { pcstr_self = p; pcstr_fields =  l } =
  pp f ""@[<hv0>@[<hv2>object%a@;%a@]@;end@]""
    (fun f p -> match p.ppat_desc with
       | Ppat_any -> ()
       | Ppat_constraint _ -> pp f "" %a"" (pattern ctxt) p
       | _ -> pp f "" (%a)"" (pattern ctxt) p) p
    (list (class_field ctxt)) l

and class_expr ctxt f x =
  if x.pcl_attributes <> [] then begin
    pp f ""((%a)%a)"" (class_expr ctxt) {x with pcl_attributes=[]}
      (attributes ctxt) x.pcl_attributes
  end else
    match x.pcl_desc with
    | Pcl_structure (cs) -> class_structure ctxt f cs
    | Pcl_fun (l, eo, p, e) ->
        pp f ""fun@ %a@ ->@ %a""
          (label_exp ctxt) (l,eo,p)
          (class_expr ctxt) e
    | Pcl_let (rf, l, ce) ->
        pp f ""%a@ in@ %a""
          (bindings ctxt) (rf,l)
          (class_expr ctxt) ce
    | Pcl_apply (ce, l) ->
        pp f ""((%a)@ %a)"" (* Cf: #7200 *)
          (class_expr ctxt) ce
          (list (label_x_expression_param ctxt)) l
    | Pcl_constr (li, l) ->
        pp f ""%a%a""
          (fun f l-> if l <>[] then
              pp f ""[%a]@ ""
                (list (core_type ctxt) ~sep:"","") l) l
          longident_loc li
    | Pcl_constraint (ce, ct) ->
        pp f ""(%a@ :@ %a)""
          (class_expr ctxt) ce
          (class_type ctxt) ct
    | Pcl_extension e -> extension ctxt f e
    | Pcl_open (o, e) ->
        pp f ""@[<2>let open%s %a in@;%a@]""
          (override o.popen_override) longident_loc o.popen_expr
          (class_expr ctxt) e

and module_type ctxt f x =
  if x.pmty_attributes <> [] then begin
    pp f ""((%a)%a)"" (module_type ctxt) {x with pmty_attributes=[]}
      (attributes ctxt) x.pmty_attributes
  end else
    match x.pmty_desc with
    | Pmty_functor (Unit, mt2) ->
        pp f ""@[<hov2>functor () ->@ %a@]"" (module_type ctxt) mt2
    | Pmty_functor (Named (s, mt1), mt2) ->
        begin match s.txt with
        | None ->
            pp f ""@[<hov2>%a@ ->@ %a@]""
              (module_type1 ctxt) mt1 (module_type ctxt) mt2
        | Some name ->
            pp f ""@[<hov2>functor@ (%s@ :@ %a)@ ->@ %a@]"" name
              (module_type ctxt) mt1 (module_type ctxt) mt2
        end
    | Pmty_with (mt, []) -> module_type ctxt f mt
    | Pmty_with (mt, l) ->
        pp f ""@[<hov2>%a@ with@ %a@]""
          (module_type1 ctxt) mt
          (list (with_constraint ctxt) ~sep:""@ and@ "") l
    | _ -> module_type1 ctxt f x

and with_constraint ctxt f = function
  | Pwith_type (li, ({ptype_params= ls ;_} as td)) ->
      let ls = List.map fst ls in
      pp f ""type@ %a %a =@ %a""
        (list (core_type ctxt) ~sep:"","" ~first:""("" ~last:"")"")
        ls longident_loc li (type_declaration ctxt) td
  | Pwith_module (li, li2) ->
      pp f ""module %a =@ %a"" longident_loc li longident_loc li2;
  | Pwith_modtype (li, mty) ->
      pp f ""module type %a =@ %a"" longident_loc li (module_type ctxt) mty;
  | Pwith_typesubst (li, ({ptype_params=ls;_} as td)) ->
      let ls = List.map fst ls in
      pp f ""type@ %a %a :=@ %a""
        (list (core_type ctxt) ~sep:"","" ~first:""("" ~last:"")"")
        ls longident_loc li
        (type_declaration ctxt) td
  | Pwith_modsubst (li, li2) ->
      pp f ""module %a :=@ %a"" longident_loc li longident_loc li2
  | Pwith_modtypesubst (li, mty) ->
      pp f ""module type %a :=@ %a"" longident_loc li (module_type ctxt) mty;


and module_type1 ctxt f x =
  if x.pmty_attributes <> [] then module_type ctxt f x
  else match x.pmty_desc with
    | Pmty_ident li ->
        pp f ""%a"" longident_loc li;
    | Pmty_alias li ->
        pp f ""(module %a)"" longident_loc li;
    | Pmty_signature (s) ->
        pp f ""@[<hv0>@[<hv2>sig@ %a@]@ end@]"" (* ""@[<hov>sig@ %a@ end@]"" *)
          (list (signature_item ctxt)) s (* FIXME wrong indentation*)
    | Pmty_typeof me ->
        pp f ""@[<hov2>module@ type@ of@ %a@]"" (module_expr ctxt) me
    | Pmty_extension e -> extension ctxt f e
    | _ -> paren true (module_type ctxt) f x

and signature ctxt f x =  list ~sep:""@\n"" (signature_item ctxt) f x

and signature_item ctxt f x : unit =
  match x.psig_desc with
  | Psig_type (rf, l) ->
      type_def_list ctxt f (rf, true, l)
  | Psig_typesubst l ->
      (* Psig_typesubst is never recursive, but we specify [Recursive] here to
         avoid printing a [nonrec] flag, which would be rejected by the parser.
      *)
      type_def_list ctxt f (Recursive, false, l)
  | Psig_value vd ->
      let intro = if vd.pval_prim = [] then ""val"" else ""external"" in
      pp f ""@[<2>%s@ %a@ :@ %a@]%a"" intro
        protect_ident vd.pval_name.txt
        (value_description ctxt) vd
        (item_attributes ctxt) vd.pval_attributes
  | Psig_typext te ->
      type_extension ctxt f te
  | Psig_exception ed ->
      exception_declaration ctxt f ed
  | Psig_class l ->
      let class_description kwd f ({pci_params=ls;pci_name={txt;_};_} as x) =
        pp f ""@[<2>%s %a%a%s@;:@;%a@]%a"" kwd
          virtual_flag x.pci_virt
          (class_params_def ctxt) ls txt
          (class_type ctxt) x.pci_expr
          (item_attributes ctxt) x.pci_attributes
      in begin
        match l with
        | [] -> ()
        | [x] -> class_description ""class"" f x
        | x :: xs ->
            pp f ""@[<v>%a@,%a@]""
              (class_description ""class"") x
              (list ~sep:""@,"" (class_description ""and"")) xs
      end
  | Psig_module ({pmd_type={pmty_desc=Pmty_alias alias;
                            pmty_attributes=[]; _};_} as pmd) ->
      pp f ""@[<hov>module@ %s@ =@ %a@]%a""
        (Option.value pmd.pmd_name.txt ~default:""_"")
        longident_loc alias
        (item_attributes ctxt) pmd.pmd_attributes
  | Psig_module pmd ->
      pp f ""@[<hov>module@ %s@ :@ %a@]%a""
        (Option.value pmd.pmd_name.txt ~default:""_"")
        (module_type ctxt) pmd.pmd_type
        (item_attributes ctxt) pmd.pmd_attributes
  | Psig_modsubst pms ->
      pp f ""@[<hov>module@ %s@ :=@ %a@]%a"" pms.pms_name.txt
        longident_loc pms.pms_manifest
        (item_attributes ctxt) pms.pms_attributes
  | Psig_open od ->
      pp f ""@[<hov2>open%s@ %a@]%a""
        (override od.popen_override)
        longident_loc od.popen_expr
        (item_attributes ctxt) od.popen_attributes
  | Psig_include incl ->
      pp f ""@[<hov2>include@ %a@]%a""
        (module_type ctxt) incl.pincl_mod
        (item_attributes ctxt) incl.pincl_attributes
  | Psig_modtype {pmtd_name=s; pmtd_type=md; pmtd_attributes=attrs} ->
      pp f ""@[<hov2>module@ type@ %s%a@]%a""
        s.txt
        (fun f md -> match md with
           | None -> ()
           | Some mt ->
               pp_print_space f () ;
               pp f ""@ =@ %a"" (module_type ctxt) mt
        ) md
        (item_attributes ctxt) attrs
  | Psig_modtypesubst {pmtd_name=s; pmtd_type=md; pmtd_attributes=attrs} ->
      let md = match md with
        | None -> assert false (* ast invariant *)
        | Some mt -> mt in
      pp f ""@[<hov2>module@ type@ %s@ :=@ %a@]%a""
        s.txt (module_type ctxt) md
        (item_attributes ctxt) attrs
  | Psig_class_type (l) -> class_type_declaration_list ctxt f l
  | Psig_recmodule decls ->
      let rec  string_x_module_type_list f ?(first=true) l =
        match l with
        | [] -> () ;
        | pmd :: tl ->
            if not first then
              pp f ""@ @[<hov2>and@ %s:@ %a@]%a""
                (Option.value pmd.pmd_name.txt ~default:""_"")
                (module_type1 ctxt) pmd.pmd_type
                (item_attributes ctxt) pmd.pmd_attributes
            else
              pp f ""@[<hov2>module@ rec@ %s:@ %a@]%a""
                (Option.value pmd.pmd_name.txt ~default:""_"")
                (module_type1 ctxt) pmd.pmd_type
                (item_attributes ctxt) pmd.pmd_attributes;
            string_x_module_type_list f ~first:false tl
      in
      string_x_module_type_list f decls
  | Psig_attribute a -> floating_attribute ctxt f a
  | Psig_extension(e, a) ->
      item_extension ctxt f e;
      item_attributes ctxt f a

and module_expr ctxt f x =
  if x.pmod_attributes <> [] then
    pp f ""((%a)%a)"" (module_expr ctxt) {x with pmod_attributes=[]}
      (attributes ctxt) x.pmod_attributes
  else match x.pmod_desc with
    | Pmod_structure (s) ->
        pp f ""@[<hv2>struct@;@[<0>%a@]@;<1 -2>end@]""
          (list (structure_item ctxt) ~sep:""@\n"") s;
    | Pmod_constraint (me, mt) ->
        pp f ""@[<hov2>(%a@ :@ %a)@]""
          (module_expr ctxt) me
          (module_type ctxt) mt
    | Pmod_ident (li) ->
        pp f ""%a"" longident_loc li;
    | Pmod_functor (Unit, me) ->
        pp f ""functor ()@;->@;%a"" (module_expr ctxt) me
    | Pmod_functor (Named (s, mt), me) ->
        pp f ""functor@ (%s@ :@ %a)@;->@;%a""
          (Option.value s.txt ~default:""_"")
          (module_type ctxt) mt (module_expr ctxt) me
    | Pmod_apply (me1, me2) ->
        pp f ""(%a)(%a)"" (module_expr ctxt) me1 (module_expr ctxt) me2
        (* Cf: #7200 *)
    | Pmod_unpack e ->
        pp f ""(val@ %a)"" (expression ctxt) e
    | Pmod_extension e -> extension ctxt f e

and structure ctxt f x = list ~sep:""@\n"" (structure_item ctxt) f x

and payload ctxt f = function
  | PStr [{pstr_desc = Pstr_eval (e, attrs)}] ->
      pp f ""@[<2>%a@]%a""
        (expression ctxt) e
        (item_attributes ctxt) attrs
  | PStr x -> structure ctxt f x
  | PTyp x -> pp f "":@ ""; core_type ctxt f x
  | PSig x -> pp f "":@ ""; signature ctxt f x
  | PPat (x, None) -> pp f ""?@ ""; pattern ctxt f x
  | PPat (x, Some e) ->
      pp f ""?@ ""; pattern ctxt f x;
      pp f "" when ""; expression ctxt f e

(* transform [f = fun g h -> ..] to [f g h = ... ] could be improved *)
and binding ctxt f {pvb_pat=p; pvb_expr=x; _} =
  (* .pvb_attributes have already been printed by the caller, #bindings *)
  let rec pp_print_pexp_function f x =
    if x.pexp_attributes <> [] then pp f ""=@;%a"" (expression ctxt) x
    else match x.pexp_desc with
      | Pexp_fun (label, eo, p, e) ->
          if label=Nolabel then
            pp f ""%a@ %a"" (simple_pattern ctxt) p pp_print_pexp_function e
          else
            pp f ""%a@ %a""
              (label_exp ctxt) (label,eo,p) pp_print_pexp_function e
      | Pexp_newtype (str,e) ->
          pp f ""(type@ %s)@ %a"" str.txt pp_print_pexp_function e
      | _ -> pp f ""=@;%a"" (expression ctxt) x
  in
  let tyvars_str tyvars = List.map (fun v -> v.txt) tyvars in
  let is_desugared_gadt p e =
    let gadt_pattern =
      match p with
      | {ppat_desc=Ppat_constraint({ppat_desc=Ppat_var _} as pat,
                                   {ptyp_desc=Ptyp_poly (args_tyvars, rt)});
         ppat_attributes=[]}->
          Some (pat, args_tyvars, rt)
      | _ -> None in
    let rec gadt_exp tyvars e =
      match e with
      | {pexp_desc=Pexp_newtype (tyvar, e); pexp_attributes=[]} ->
          gadt_exp (tyvar :: tyvars) e
      | {pexp_desc=Pexp_constraint (e, ct); pexp_attributes=[]} ->
          Some (List.rev tyvars, e, ct)
      | _ -> None in
    let gadt_exp = gadt_exp [] e in
    match gadt_pattern, gadt_exp with
    | Some (p, pt_tyvars, pt_ct), Some (e_tyvars, e, e_ct)
      when tyvars_str pt_tyvars = tyvars_str e_tyvars ->
      let ety = Typ.varify_constructors e_tyvars e_ct in
      if ety = pt_ct then
      Some (p, pt_tyvars, e_ct, e) else None
    | _ -> None in
  if x.pexp_attributes <> []
  then
    match p with
    | {ppat_desc=Ppat_constraint({ppat_desc=Ppat_var _; _} as pat,
                                 ({ptyp_desc=Ptyp_poly _; _} as typ));
       ppat_attributes=[]; _} ->
        pp f ""%a@;: %a@;=@;%a""
          (simple_pattern ctxt) pat (core_type ctxt) typ (expression ctxt) x
    | _ ->
        pp f ""%a@;=@;%a"" (pattern ctxt) p (expression ctxt) x
  else
  match is_desugared_gadt p x with
  | Some (p, [], ct, e) ->
      pp f ""%a@;: %a@;=@;%a""
        (simple_pattern ctxt) p (core_type ctxt) ct (expression ctxt) e
  | Some (p, tyvars, ct, e) -> begin
    pp f ""%a@;: type@;%a.@;%a@;=@;%a""
    (simple_pattern ctxt) p (list pp_print_string ~sep:""@;"")
    (tyvars_str tyvars) (core_type ctxt) ct (expression ctxt) e
    end
  | None -> begin
      match p with
      | {ppat_desc=Ppat_constraint(p ,ty);
         ppat_attributes=[]} -> (* special case for the first*)
          begin match ty with
          | {ptyp_desc=Ptyp_poly _; ptyp_attributes=[]} ->
              pp f ""%a@;:@;%a@;=@;%a"" (simple_pattern ctxt) p
                (core_type ctxt) ty (expression ctxt) x
          | _ ->
              pp f ""(%a@;:@;%a)@;=@;%a"" (simple_pattern ctxt) p
                (core_type ctxt) ty (expression ctxt) x
          end
      | {ppat_desc=Ppat_var _; ppat_attributes=[]} ->
          pp f ""%a@ %a"" (simple_pattern ctxt) p pp_print_pexp_function x
      | _ ->
          pp f ""%a@;=@;%a"" (pattern ctxt) p (expression ctxt) x
    end

(* [in] is not printed *)
and bindings ctxt f (rf,l) =
  let binding kwd rf f x =
    pp f ""@[<2>%s %a%a@]%a"" kwd rec_flag rf
      (binding ctxt) x (item_attributes ctxt) x.pvb_attributes
  in
  match l with
  | [] -> ()
  | [x] -> binding ""let"" rf f x
  | x::xs ->
      pp f ""@[<v>%a@,%a@]""
        (binding ""let"" rf) x
        (list ~sep:""@,"" (binding ""and"" Nonrecursive)) xs

and binding_op ctxt f x =
  match x.pbop_pat, x.pbop_exp with
  | {ppat_desc = Ppat_var { txt=pvar; _ }; ppat_attributes = []; _},
    {pexp_desc = Pexp_ident { txt=Lident evar; _}; pexp_attributes = []; _}
       when pvar = evar ->
     pp f ""@[<2>%s %s@]"" x.pbop_op.txt evar
  | pat, exp ->
     pp f ""@[<2>%s %a@;=@;%a@]""
       x.pbop_op.txt (pattern ctxt) pat (expression ctxt) exp

and structure_item ctxt f x =
  match x.pstr_desc with
  | Pstr_eval (e, attrs) ->
      pp f ""@[<hov2>;;%a@]%a""
        (expression ctxt) e
        (item_attributes ctxt) attrs
  | Pstr_type (_, []) -> assert false
  | Pstr_type (rf, l)  -> type_def_list ctxt f (rf, true, l)
  | Pstr_value (rf, l) ->
      (* pp f ""@[<hov2>let %a%a@]""  rec_flag rf bindings l *)
      pp f ""@[<2>%a@]"" (bindings ctxt) (rf,l)
  | Pstr_typext te -> type_extension ctxt f te
  | Pstr_exception ed -> exception_declaration ctxt f ed
  | Pstr_module x ->
      let rec module_helper = function
        | {pmod_desc=Pmod_functor(arg_opt,me'); pmod_attributes = []} ->
            begin match arg_opt with
            | Unit -> pp f ""()""
            | Named (s, mt) ->
              pp f ""(%s:%a)"" (Option.value s.txt ~default:""_"")
                (module_type ctxt) mt
            end;
            module_helper me'
        | me -> me
      in
      pp f ""@[<hov2>module %s%a@]%a""
        (Option.value x.pmb_name.txt ~default:""_"")
        (fun f me ->
           let me = module_helper me in
           match me with
           | {pmod_desc=
                Pmod_constraint
                  (me',
                   ({pmty_desc=(Pmty_ident (_)
                               | Pmty_signature (_));_} as mt));
              pmod_attributes = []} ->
               pp f "" :@;%a@;=@;%a@;""
                 (module_type ctxt) mt (module_expr ctxt) me'
           | _ -> pp f "" =@ %a"" (module_expr ctxt) me
        ) x.pmb_expr
        (item_attributes ctxt) x.pmb_attributes
  | Pstr_open od ->
      pp f ""@[<2>open%s@;%a@]%a""
        (override od.popen_override)
        (module_expr ctxt) od.popen_expr
        (item_attributes ctxt) od.popen_attributes
  | Pstr_modtype {pmtd_name=s; pmtd_type=md; pmtd_attributes=attrs} ->
      pp f ""@[<hov2>module@ type@ %s%a@]%a""
        s.txt
        (fun f md -> match md with
           | None -> ()
           | Some mt ->
               pp_print_space f () ;
               pp f ""@ =@ %a"" (module_type ctxt) mt
        ) md
        (item_attributes ctxt) attrs
  | Pstr_class l ->
      let extract_class_args cl =
        let rec loop acc = function
          | {pcl_desc=Pcl_fun (l, eo, p, cl'); pcl_attributes = []} ->
              loop ((l,eo,p) :: acc) cl'
          | cl -> List.rev acc, cl
        in
        let args, cl = loop [] cl in
        let constr, cl =
          match cl with
          | {pcl_desc=Pcl_constraint (cl', ct); pcl_attributes = []} ->
              Some ct, cl'
          | _ -> None, cl
        in
        args, constr, cl
      in
      let class_constraint f ct = pp f "": @[%a@] "" (class_type ctxt) ct in
      let class_declaration kwd f
          ({pci_params=ls; pci_name={txt;_}; _} as x) =
        let args, constr, cl = extract_class_args x.pci_expr in
        pp f ""@[<2>%s %a%a%s %a%a=@;%a@]%a"" kwd
          virtual_flag x.pci_virt
          (class_params_def ctxt) ls txt
          (list (label_exp ctxt)) args
          (option class_constraint) constr
          (class_expr ctxt) cl
          (item_attributes ctxt) x.pci_attributes
      in begin
        match l with
        | [] -> ()
        | [x] -> class_declaration ""class"" f x
        | x :: xs ->
            pp f ""@[<v>%a@,%a@]""
              (class_declaration ""class"") x
              (list ~sep:""@,"" (class_declaration ""and"")) xs
      end
  | Pstr_class_type l -> class_type_declaration_list ctxt f l
  | Pstr_primitive vd ->
      pp f ""@[<hov2>external@ %a@ :@ %a@]%a""
        protect_ident vd.pval_name.txt
        (value_description ctxt) vd
        (item_attributes ctxt) vd.pval_attributes
  | Pstr_include incl ->
      pp f ""@[<hov2>include@ %a@]%a""
        (module_expr ctxt) incl.pincl_mod
        (item_attributes ctxt) incl.pincl_attributes
  | Pstr_recmodule decls -> (* 3.07 *)
      let aux f = function
        | ({pmb_expr={pmod_desc=Pmod_constraint (expr, typ)}} as pmb) ->
            pp f ""@[<hov2>@ and@ %s:%a@ =@ %a@]%a""
              (Option.value pmb.pmb_name.txt ~default:""_"")
              (module_type ctxt) typ
              (module_expr ctxt) expr
              (item_attributes ctxt) pmb.pmb_attributes
        | pmb ->
            pp f ""@[<hov2>@ and@ %s@ =@ %a@]%a""
              (Option.value pmb.pmb_name.txt ~default:""_"")
              (module_expr ctxt) pmb.pmb_expr
              (item_attributes ctxt) pmb.pmb_attributes
      in
      begin match decls with
      | ({pmb_expr={pmod_desc=Pmod_constraint (expr, typ)}} as pmb) :: l2 ->
          pp f ""@[<hv>@[<hov2>module@ rec@ %s:%a@ =@ %a@]%a@ %a@]""
            (Option.value pmb.pmb_name.txt ~default:""_"")
            (module_type ctxt) typ
            (module_expr ctxt) expr
            (item_attributes ctxt) pmb.pmb_attributes
            (fun f l2 -> List.iter (aux f) l2) l2
      | pmb :: l2 ->
          pp f ""@[<hv>@[<hov2>module@ rec@ %s@ =@ %a@]%a@ %a@]""
            (Option.value pmb.pmb_name.txt ~default:""_"")
            (module_expr ctxt) pmb.pmb_expr
            (item_attributes ctxt) pmb.pmb_attributes
            (fun f l2 -> List.iter (aux f) l2) l2
      | _ -> assert false
      end
  | Pstr_attribute a -> floating_attribute ctxt f a
  | Pstr_extension(e, a) ->
      item_extension ctxt f e;
      item_attributes ctxt f a

and type_param ctxt f (ct, (a,b)) =
  pp f ""%s%s%a"" (type_variance a) (type_injectivity b) (core_type ctxt) ct

and type_params ctxt f = function
  | [] -> ()
  | l -> pp f ""%a "" (list (type_param ctxt) ~first:""("" ~last:"")"" ~sep:"",@;"") l

and type_def_list ctxt f (rf, exported, l) =
  let type_decl kwd rf f x =
    let eq =
      if (x.ptype_kind = Ptype_abstract)
         && (x.ptype_manifest = None) then """"
      else if exported then "" =""
      else "" :=""
    in
    pp f ""@[<2>%s %a%a%s%s%a@]%a"" kwd
      nonrec_flag rf
      (type_params ctxt) x.ptype_params
      x.ptype_name.txt eq
      (type_declaration ctxt) x
      (item_attributes ctxt) x.ptype_attributes
  in
  match l with
  | [] -> assert false
  | [x] -> type_decl ""type"" rf f x
  | x :: xs -> pp f ""@[<v>%a@,%a@]""
                 (type_decl ""type"" rf) x
                 (list ~sep:""@,"" (type_decl ""and"" Recursive)) xs

and record_declaration ctxt f lbls =
  let type_record_field f pld =
    pp f ""@[<2>%a%s:@;%a@;%a@]""
      mutable_flag pld.pld_mutable
      pld.pld_name.txt
      (core_type ctxt) pld.pld_type
      (attributes ctxt) pld.pld_attributes
  in
  pp f ""{@\n%a}""
    (list type_record_field ~sep:"";@\n"" )  lbls

and type_declaration ctxt f x =
  (* type_declaration has an attribute field,
     but it's been printed by the caller of this method *)
  let priv f =
    match x.ptype_private with
    | Public -> ()
    | Private -> pp f ""@;private""
  in
  let manifest f =
    match x.ptype_manifest with
    | None -> ()
    | Some y ->
        if x.ptype_kind = Ptype_abstract then
          pp f ""%t@;%a"" priv (core_type ctxt) y
        else
          pp f ""@;%a"" (core_type ctxt) y
  in
  let constructor_declaration f pcd =
    pp f ""|@;"";
    constructor_declaration ctxt f
      (pcd.pcd_name.txt, pcd.pcd_vars,
       pcd.pcd_args, pcd.pcd_res, pcd.pcd_attributes)
  in
  let repr f =
    let intro f =
      if x.ptype_manifest = None then ()
      else pp f ""@;=""
    in
    match x.ptype_kind with
    | Ptype_variant xs ->
      let variants fmt xs =
        if xs = [] then pp fmt "" |"" else
          pp fmt ""@\n%a"" (list ~sep:""@\n"" constructor_declaration) xs
      in pp f ""%t%t%a"" intro priv variants xs
    | Ptype_abstract -> ()
    | Ptype_record l ->
        pp f ""%t%t@;%a"" intro priv (record_declaration ctxt) l
    | Ptype_open -> pp f ""%t%t@;.."" intro priv
  in
  let constraints f =
    List.iter
      (fun (ct1,ct2,_) ->
         pp f ""@[<hov2>@ constraint@ %a@ =@ %a@]""
           (core_type ctxt) ct1 (core_type ctxt) ct2)
      x.ptype_cstrs
  in
  pp f ""%t%t%t"" manifest repr constraints

and type_extension ctxt f x =
  let extension_constructor f x =
    pp f ""@\n|@;%a"" (extension_constructor ctxt) x
  in
  pp f ""@[<2>type %a%a += %a@ %a@]%a""
    (fun f -> function
       | [] -> ()
       | l ->
           pp f ""%a@;"" (list (type_param ctxt) ~first:""("" ~last:"")"" ~sep:"","") l)
    x.ptyext_params
    longident_loc x.ptyext_path
    private_flag x.ptyext_private (* Cf: #7200 *)
    (list ~sep:"""" extension_constructor)
    x.ptyext_constructors
    (item_attributes ctxt) x.ptyext_attributes

and constructor_declaration ctxt f (name, vars, args, res, attrs) =
  let name =
    match name with
    | ""::"" -> ""(::)""
    | s -> s in
  let pp_vars f vs =
    match vs with
    | [] -> ()
    | vs -> pp f ""%a@;.@;"" (list tyvar_loc ~sep:""@;"") vs in
  match res with
  | None ->
      pp f ""%s%a@;%a"" name
        (fun f -> function
           | Pcstr_tuple [] -> ()
           | Pcstr_tuple l ->
             pp f ""@;of@;%a"" (list (core_type1 ctxt) ~sep:""@;*@;"") l
           | Pcstr_record l -> pp f ""@;of@;%a"" (record_declaration ctxt) l
        ) args
        (attributes ctxt) attrs
  | Some r ->
      pp f ""%s:@;%a%a@;%a"" name
        pp_vars vars
        (fun f -> function
           | Pcstr_tuple [] -> core_type1 ctxt f r
           | Pcstr_tuple l -> pp f ""%a@;->@;%a""
                                (list (core_type1 ctxt) ~sep:""@;*@;"") l
                                (core_type1 ctxt) r
           | Pcstr_record l ->
               pp f ""%a@;->@;%a"" (record_declaration ctxt) l (core_type1 ctxt) r
        )
        args
        (attributes ctxt) attrs

and extension_constructor ctxt f x =
  (* Cf: #7200 *)
  match x.pext_kind with
  | Pext_decl(v, l, r) ->
      constructor_declaration ctxt f
        (x.pext_name.txt, v, l, r, x.pext_attributes)
  | Pext_rebind li ->
      pp f ""%s@;=@;%a%a"" x.pext_name.txt
        longident_loc li
        (attributes ctxt) x.pext_attributes

and case_list ctxt f l : unit =
  let aux f {pc_lhs; pc_guard; pc_rhs} =
    pp f ""@;| @[<2>%a%a@;->@;%a@]""
      (pattern ctxt) pc_lhs (option (expression ctxt) ~first:""@;when@;"")
      pc_guard (expression (under_pipe ctxt)) pc_rhs
  in
  list aux f l ~sep:""""

and label_x_expression_param ctxt f (l,e) =
  let simple_name = match e with
    | {pexp_desc=Pexp_ident {txt=Lident l;_};
       pexp_attributes=[]} -> Some l
    | _ -> None
  in match l with
  | Nolabel  -> expression2 ctxt f e (* level 2*)
  | Optional str ->
      if Some str = simple_name then
        pp f ""?%s"" str
      else
        pp f ""?%s:%a"" str (simple_expr ctxt) e
  | Labelled lbl ->
      if Some lbl = simple_name then
        pp f ""~%s"" lbl
      else
        pp f ""~%s:%a"" lbl (simple_expr ctxt) e

and directive_argument f x =
  match x.pdira_desc with
  | Pdir_string (s) -> pp f ""@ %S"" s
  | Pdir_int (n, None) -> pp f ""@ %s"" n
  | Pdir_int (n, Some m) -> pp f ""@ %s%c"" n m
  | Pdir_ident (li) -> pp f ""@ %a"" longident li
  | Pdir_bool (b) -> pp f ""@ %s"" (string_of_bool b)

let toplevel_phrase f x =
  match x with
  | Ptop_def (s) ->pp f ""@[<hov0>%a@]""  (list (structure_item reset_ctxt)) s
   (* pp_open_hvbox f 0; *)
   (* pp_print_list structure_item f s ; *)
   (* pp_close_box f (); *)
  | Ptop_dir {pdir_name; pdir_arg = None; _} ->
   pp f ""@[<hov2>#%s@]"" pdir_name.txt
  | Ptop_dir {pdir_name; pdir_arg = Some pdir_arg; _} ->
   pp f ""@[<hov2>#%s@ %a@]"" pdir_name.txt directive_argument pdir_arg

let expression f x =
  pp f ""@[%a@]"" (expression reset_ctxt) x

let string_of_expression x =
  ignore (flush_str_formatter ()) ;
  let f = str_formatter in
  expression f x;
  flush_str_formatter ()

let string_of_structure x =
  ignore (flush_str_formatter ());
  let f = str_formatter in
  structure reset_ctxt f x;
  flush_str_formatter ()

let top_phrase f x =
  pp_print_newline f ();
  toplevel_phrase f x;
  pp f "";;"";
  pp_print_newline f ()

let core_type = core_type reset_ctxt
let pattern = pattern reset_ctxt
let signature = signature reset_ctxt
let structure = structure reset_ctxt
let module_expr = module_expr reset_ctxt
let module_type = module_type reset_ctxt
let class_field = class_field reset_ctxt
let class_type_field = class_type_field reset_ctxt
let class_expr = class_expr reset_ctxt
let class_type = class_type reset_ctxt
let structure_item = structure_item reset_ctxt
let signature_item = signature_item reset_ctxt
let binding = binding reset_ctxt
let payload = payload reset_ctxt
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

type config = {
  heap_size: int;
  hash_table_pow: int;
  log_level: int;
}

type handle = Unix.file_descr

type buf = (char, Bigarray.int8_unsigned_elt, Bigarray.c_layout) Bigarray.Array1.t

(* Addresses are represented as integers, but are well-typed via a phantom
 * type parameter. The type checker will ensure that a `foo addr` is not
 * passed where a `bar addr` is expected. *)
type +'k addr [@@immediate]

exception Out_of_shared_memory

exception Hash_table_full

exception Heap_full

val connect : handle -> worker_id:int -> unit

val on_compact : (unit -> unit -> unit) ref

val collect_slice : ?force:bool -> int -> bool

val collect_full : unit -> unit

val compact : unit -> unit

type table_stats = {
  nonempty_slots: int;
  used_slots: int;
  slots: int;
}

val hash_stats : unit -> table_stats

val heap_size : unit -> int

val init : config -> num_workers:int -> (handle, unit) result

val commit_transaction : unit -> unit

val is_init_transaction : unit -> bool

module type Key = sig
  type t

  val to_string : t -> string

  val compare : t -> t -> int
end

module type Value = sig
  type t

  val description : string
end

module type AddrValue = sig
  type t
end

module type NoCache = sig
  type key

  type value

  module KeySet : Flow_set.S with type elt = key

  val add : key -> value -> unit

  val get : key -> value option

  val get_old : key -> value option

  val remove_old_batch : KeySet.t -> unit

  val remove : key -> unit

  val remove_batch : KeySet.t -> unit

  val mem : key -> bool

  val mem_old : key -> bool

  val oldify : key -> unit

  val oldify_batch : KeySet.t -> unit

  val revive_batch : KeySet.t -> unit
end

module type DebugCacheType = sig
  val get_size : unit -> int
end

module type LocalCache = sig
  type key

  type value

  module DebugL1 : DebugCacheType

  module DebugL2 : DebugCacheType

  val add : key -> value -> unit

  val get : key -> value option

  val remove : key -> unit

  val clear : unit -> unit
end

module type CacheConfig = sig
  type key

  type value

  val capacity : int
end

module type WithCache = sig
  include NoCache

  val write_around : key -> value -> unit

  val get_no_cache : key -> value option

  module DebugCache : LocalCache with type key = key and type value = value
end

module LocalCache (Config : CacheConfig) :
  LocalCache with type key = Config.key and type value = Config.value

module WithCache (Key : Key) (Value : Value) :
  WithCache with type key = Key.t and type value = Value.t and module KeySet = Flow_set.Make(Key)

module NoCache (Key : Key) (Value : Value) :
  NoCache with type key = Key.t and type value = Value.t and module KeySet = Flow_set.Make(Key)

module NoCacheAddr (Key : Key) (Value : AddrValue) : sig
  include
    NoCache
      with type key = Key.t
       and type value = Value.t addr
       and module KeySet = Flow_set.Make(Key)

  val add : Key.t -> Value.t addr -> Value.t addr
end

val debug_value_size : Obj.t -> int

module NewAPI : sig
  (* This module provides a type-safe and bounds-checked interface to shared
   * memory and specifies the exact layout of the objects which we want to
   * store.
   *
   * Heap objects are all prefixed with a header word which includes a tag and
   * the size of the object in words. The following words, depending on the tag,
   * include 0 or more fixed size fields and optionally one variable size field.
   *
   * For example, the ""checked_file"" object has several words containing addrs
   * pointing to other objects (things like exports, definitions exported from
   * the file, etc.). The ""local def"" object, which represents a definition
   * local to a checked file has a variable size string field which contains the
   * serialized signature of the definition. *)

  (* A chunk is an append-only cursor into the heap. To use a chunk, first
   * allocate the needed space, then call the appropriate write_* functions to
   * fill the chunk with data.
   *
   * The chunk API ensures that callers (1) do not write beyond the allocated
   * space and (2) consume all of the allocated space. *)
  type chunk

  (* Phantom type tag for string objects. *)
  type heap_string

  (* Phantom type tag for int64 data, like hashes *)
  type heap_int64

  (* Phantom type tag for entities, which can store both a ""committed"" and
   * ""latest"" value. *)
  type 'a entity

  (* Phantom type tag for addr map objects, which are arrays of addresses to
   * another kind of object. For example, a `heap_string addr_tbl addr` is an
   * array of addresses to string objects. *)
  type 'a addr_tbl

  (* Phantom type tag for ASTs. *)
  type ast

  (* Phantom type tag for docblock, which contains information contained in the
   * leading comment of a file. *)
  type docblock

  (* Phantom type tag for aloc table. An aloc table provides the concrete
   * location for a given keyed location in a signature. *)
  type aloc_table

  (* Phantom type tag for type sig, which contains a serialized representation
   * of the visible exports of a file. See Type_sig_bin *)
  type type_sig

  (* Phantom type tag for file sig, which contains a serialized representation
   * of the imports/requires of a file. *)
  type file_sig

  type exports

  type resolved_requires

  type +'a parse

  type haste_info

  type file

  type haste_module

  type file_module

  (* Before writing to the heap, we first calculate the required size (in words)
   * for all the heap objects we would like to write. We will pass this size
   * into the `alloc` function below, to get a chunk which we use to perform
   * writes. *)
  type size = int

  (* Allocate the requested space (in words) in the heap. All writes must be
   * done within the provided callback, and the writes must fully consume all
   * allocated space. *)
  val alloc : size -> (chunk -> 'a) -> 'a

  (* headers *)

  val header_size : size

  val with_header_size : ('a -> size) -> 'a -> size

  (* strings *)

  val string_size : string -> size

  val write_string : chunk -> string -> heap_string addr

  val read_string : heap_string addr -> string

  (* hash *)

  val int64_size : size

  val write_int64 : chunk -> int64 -> heap_int64 addr

  val read_int64 : heap_int64 addr -> int64

  (* addr tbl *)

  val addr_tbl_size : 'a array -> size

  val write_addr_tbl : (chunk -> 'a -> 'k addr) -> chunk -> 'a array -> 'k addr_tbl addr

  val read_addr_tbl_generic :
    ('k addr -> 'a) -> 'k addr_tbl addr -> (int -> (int -> 'a) -> 'b) -> 'b

  val read_addr_tbl : ('k addr -> 'a) -> 'k addr_tbl addr -> 'a array

  (* entities *)

  val entity_size : int

  val write_entity : chunk -> 'k addr option -> 'k entity addr

  val entity_advance : 'k entity addr -> 'k addr option -> unit

  val entity_read_committed : 'k entity addr -> 'k addr option

  val entity_read_latest : 'k entity addr -> 'k addr option

  val entity_rollback : _ entity addr -> unit

  val entity_changed : _ entity addr -> bool

  (* ast *)

  val prepare_write_ast : string -> size * (chunk -> ast addr)

  val read_ast : ast addr -> string

  (* file sig *)

  val prepare_write_file_sig : string -> size * (chunk -> file_sig addr)

  val read_file_sig : file_sig addr -> string

  (* exports *)

  val prepare_write_exports : string -> size * (chunk -> exports addr)

  val read_exports : exports addr -> string

  (* resolved requires *)

  val prepare_write_resolved_requires : string -> size * (chunk -> resolved_requires addr)

  val read_resolved_requires : resolved_requires addr -> string

  val iter_resolved_requires : (file addr -> resolved_requires addr -> unit) -> unit

  (* docblock *)

  val docblock_size : string -> size

  val write_docblock : chunk -> string -> docblock addr

  val read_docblock : docblock addr -> string

  (* aloc table *)

  val aloc_table_size : string -> size

  val write_aloc_table : chunk -> string -> aloc_table addr

  val read_aloc_table : aloc_table addr -> string

  (* type sig *)

  val type_sig_size : int -> size

  val write_type_sig : chunk -> int -> (buf -> unit) -> type_sig addr

  val read_type_sig : type_sig addr -> (buf -> 'a) -> 'a

  val type_sig_buf : type_sig addr -> buf

  (* parse data *)

  val untyped_parse_size : size

  val typed_parse_size : size

  val write_untyped_parse : chunk -> heap_int64 addr -> [ `untyped ] parse addr

  val write_typed_parse :
    chunk ->
    heap_int64 addr ->
    exports addr ->
    resolved_requires entity addr ->
    [ `typed ] parse addr

  val is_typed : [> ] parse addr -> bool

  val coerce_typed : [> ] parse addr -> [ `typed ] parse addr option

  val get_file_hash : [> ] parse addr -> heap_int64 addr

  val get_ast : [ `typed ] parse addr -> ast addr option

  val get_docblock : [ `typed ] parse addr -> docblock addr option

  val get_aloc_table : [ `typed ] parse addr -> aloc_table addr option

  val get_type_sig : [ `typed ] parse addr -> type_sig addr option

  val get_file_sig : [ `typed ] parse addr -> file_sig addr option

  val get_exports : [ `typed ] parse addr -> exports addr

  val get_resolved_requires : [ `typed ] parse addr -> resolved_requires entity addr

  val set_ast : [ `typed ] parse addr -> ast addr -> unit

  val set_docblock : [ `typed ] parse addr -> docblock addr -> unit

  val set_aloc_table : [ `typed ] parse addr -> aloc_table addr -> unit

  val set_type_sig : [ `typed ] parse addr -> type_sig addr -> unit

  val set_file_sig : [ `typed ] parse addr -> file_sig addr -> unit

  (* haste info *)

  val haste_info_size : size

  val write_haste_info : chunk -> haste_module addr -> haste_info addr

  val get_haste_module : haste_info addr -> haste_module addr

  val haste_info_equal : haste_info addr -> haste_info addr -> bool

  (* file data *)

  type file_kind =
    | Source_file
    | Json_file
    | Resource_file
    | Lib_file

  val file_size : size

  val write_file :
    chunk ->
    file_kind ->
    heap_string addr ->
    [ `typed | `untyped ] parse entity addr ->
    haste_info entity addr ->
    file_module addr option ->
    file addr

  val get_file_kind : file addr -> file_kind

  val get_file_name : file addr -> heap_string addr

  val get_file_module : file addr -> file_module addr option

  val get_haste_info : file addr -> haste_info entity addr

  val get_parse : file addr -> [ `typed | `untyped ] parse entity addr

  val files_equal : file addr -> file addr -> bool

  val file_changed : file addr -> bool

  (* haste module *)

  val haste_module_size : size

  val write_haste_module : chunk -> heap_string addr -> file entity addr -> haste_module addr

  val haste_modules_equal : haste_module addr -> haste_module addr -> bool

  val get_haste_name : haste_module addr -> heap_string addr

  val get_haste_provider : haste_module addr -> file entity addr

  val add_haste_provider : haste_module addr -> file addr -> haste_info addr -> unit

  val get_haste_all_providers_exclusive : haste_module addr -> file addr list

  val remove_haste_provider_exclusive : haste_module addr -> file addr -> unit

  (* file module *)

  val file_module_size : size

  val write_file_module : chunk -> file entity addr -> file_module addr

  val get_file_provider : file_module addr -> file entity addr

  val add_file_provider : file_module addr -> file addr -> unit

  val get_file_all_providers_exclusive : file_module addr -> file addr list

  val remove_file_provider_exclusive : file_module addr -> file addr -> unit
end
",ocaml
"type let_binding =
  { lb_pattern: Parsetree.pattern;
    lb_expression: Parsetree.expression;
    lb_is_pun: bool;
    lb_attributes: Parsetree.attributes;
    lb_docs: Docstrings.docs Lazy.t;
    lb_text: Docstrings.text Lazy.t;
    lb_loc: Location.t; }

type let_bindings =
  { lbs_bindings: let_binding list;
    lbs_rec: Asttypes.rec_flag;
    lbs_extension: string Asttypes.loc option }
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Utils_js
open Type
open Reason
open Loc_collections

module type S = sig
  include Env_sig.S

  val resolve_env_entry : Context.t -> Type.t -> ALoc.t -> unit

  val read_entry : for_type:bool -> Context.t -> ALoc.t -> reason -> Type.t
end

module New_env = struct
  (* The new env handles all the logic for regular variables internally, but
     internal variables still need to be handled by name, which makes them
     incompatible with the new environment as it stands. Eventually we'll need
     to figure out a different approach for them, but that different approach will
     vary per-variable (e.g. maybe_exhaustively_checked will go away entirely, returns will
     not be treated as variables, and this/super can probably be included in the new env), and
     currently they rely on quite a bit of the existing env behavior (such as initialization state,
     merging, etc) so it doesn't make sense to build a separate system for them now (it would be
     pretty big if we did).

     Instead, the new env includes the old env directly. The old env's interface for things that
     are unrelated to the new env (e.g. pushing scopes) are left intact, while things that
     can apply to either regular variables or to internals are shadowed with a function that decides
     what interface to use.*)
  module Old_env = Env.Env

  let peek_env = Old_env.peek_env

  let merge_env = Old_env.merge_env

  let update_env = Old_env.update_env

  let clone_env = Old_env.clone_env

  let copy_env = Old_env.copy_env

  let widen_env = Old_env.widen_env

  let havoc_heap_refinements_with_propname = Old_env.havoc_heap_refinements_with_propname

  let havoc_local_refinements = Old_env.havoc_local_refinements

  let havoc_heap_refinements = Old_env.havoc_heap_refinements

  let havoc_vars = Old_env.havoc_vars

  let reset_current_activation = Old_env.reset_current_activation

  let havoc_all = Old_env.havoc_all

  let refine_expr = Old_env.refine_expr

  let get_current_env_refi = Old_env.get_current_env_refi

  let save_excluded_symbols = Old_env.save_excluded_symbols

  let set_internal_var = Old_env.set_internal_var

  let get_internal_var = Old_env.get_internal_var

  let get_class_entries = Old_env.get_class_entries

  let bind_class = Old_env.bind_class

  let restore_excluded_symbols = Old_env.restore_excluded_symbols

  let trunc_env = Old_env.trunc_env

  let env_depth = Old_env.env_depth

  let in_lex_scope = Old_env.in_lex_scope

  let pop_var_scope = Old_env.pop_var_scope

  let push_var_scope = Old_env.push_var_scope

  let in_predicate_scope = Old_env.in_predicate_scope

  let in_generator_scope = Old_env.in_generator_scope

  let in_async_scope = Old_env.in_async_scope

  let var_scope_kind = Old_env.var_scope_kind

  let string_of_env = Old_env.string_of_env

  let in_global_scope = Old_env.in_global_scope

  let in_toplevel_scope = Old_env.in_toplevel_scope

  let is_provider = Old_env.is_provider

  let install_provider = Old_env.install_provider

  type t = Old_env.t

  type scope = Old_env.scope

  let this_type_params = ref ALocMap.empty

  let valid_declaration_check = Old_env.valid_declaration_check

  (************************)
  (* Helpers **************)
  (************************)

  let record_expression_type_if_needed cx loc t =
    let env = Context.environment cx in
    match Loc_env.find_write env loc with
    | None -> ()
    | Some w ->
      Debug_js.Verbose.print_if_verbose
        cx
        [spf ""recording expression at location %s"" (Reason.string_of_aloc loc)];
      Flow_js.unify cx ~use_op:unknown_use t w;
      let env' = Loc_env.update_reason env loc (TypeUtil.reason_of_t t) in
      Context.set_environment cx env'

  let find_var_opt { Env_api.env_values; _ } loc =
    match ALocMap.find_opt loc env_values with
    | Some x -> Ok x
    | None -> Error loc

  let find_refi { Env_api.refinement_of_id; _ } = refinement_of_id

  let find_providers { Env_api.providers; _ } loc =
    Env_api.Provider_api.providers_of_def providers loc
    |> Base.Option.value_map ~f:snd ~default:[]
    |> Base.List.map ~f:Reason.aloc_of_reason

  let is_def_loc_annotated { Env_api.providers; _ } loc =
    let providers = Env_api.Provider_api.providers_of_def providers loc in
    match providers with
    | Some (Find_providers.AnnotatedVar _, _) -> true
    | _ -> false

  let is_def_loc_predicate_function { Env_api.providers; _ } loc =
    let providers = Env_api.Provider_api.providers_of_def providers loc in
    match providers with
    | Some (Find_providers.AnnotatedVar { predicate }, _) -> predicate
    | _ -> false

  let provider_type_for_def_loc ?(intersect = false) env def_loc =
    let { Loc_env.var_info; _ } = env in
    let providers =
      find_providers var_info def_loc
      |> Base.List.map ~f:(Loc_env.find_write env)
      |> Base.Option.all
    in
    match providers with
    | None -> assert_false (spf ""Missing providers for %s"" (Reason.string_of_aloc def_loc))
    | Some [] -> MixedT.make (mk_reason (RCustom ""no providers"") def_loc) (Trust.bogus_trust ())
    | Some [t] -> t
    | Some (t1 :: t2 :: ts) when intersect ->
      IntersectionT (mk_reason (RCustom ""providers"") def_loc, InterRep.make t1 t2 ts)
    | Some (t1 :: t2 :: ts) ->
      UnionT (mk_reason (RCustom ""providers"") def_loc, UnionRep.make t1 t2 ts)

  (*************)
  (*  Reading  *)
  (*************)
  open Env_sig.LookupMode

  (** Computes the phi type for a node given all its lower bounds
 *  Currently, this just produces a new type variable with the types of
 *  all the incoming writes as lower bounds. In the future, however, we
 *  may want to compute a more specific least upper bound for these writes.
 *)
  let phi cx reason ts =
    match ts with
    | [t] -> t
    | _ ->
      Tvar.mk_where cx reason (fun tvar ->
          Base.List.iter ts ~f:(fun t -> Flow_js.flow_t cx (t, tvar))
      )

  let rec predicate_of_refinement cx =
    Env_api.Refi.(
      function
      | AndR (r1, r2) -> AndP (predicate_of_refinement cx r1, predicate_of_refinement cx r2)
      | OrR (r1, r2) -> OrP (predicate_of_refinement cx r1, predicate_of_refinement cx r2)
      | NotR r -> NotP (predicate_of_refinement cx r)
      | TruthyR -> ExistsP
      | NullR -> NullP
      | UndefinedR -> VoidP
      | MaybeR -> MaybeP
      | InstanceOfR (loc, _) ->
        (* Instanceof refinements store the loc they check against, which is a read in the env *)
        let reason = mk_reason (RCustom ""RHS of `instanceof` operator"") loc in
        let t = read_entry_exn ~lookup_mode:ForValue cx loc reason in
        Flow_js.flow cx (t, AssertInstanceofRHST reason);
        LeftP (InstanceofTest, t)
      | IsArrayR -> ArrP
      | BoolR loc -> BoolP loc
      | FunctionR -> FunP
      | NumberR loc -> NumP loc
      | ObjectR -> ObjP
      | StringR loc -> StrP loc
      | SymbolR loc -> SymbolP loc
      | SingletonBoolR { loc; sense = _; lit } -> SingletonBoolP (loc, lit)
      | SingletonStrR { loc; sense; lit } -> SingletonStrP (loc, sense, lit)
      | SingletonNumR { loc; sense; lit } -> SingletonNumP (loc, sense, lit)
      | SentinelR (prop, loc) ->
        let env = Context.environment cx in
        let other_t = Base.Option.value_exn (Loc_env.find_write env loc) in
        LeftP (SentinelProp prop, other_t)
      | LatentR { func = (func_loc, _); index } ->
        (* Latent refinements store the loc of the callee, which is a read in the env *)
        let reason = mk_reason (RCustom ""Function call"") func_loc in
        let t = read_entry_exn ~lookup_mode:ForValue cx func_loc reason in
        LatentP (t, index)
      | PropExistsR { propname; loc } ->
        PropExistsP (propname, mk_reason (RProperty (Some (OrdinaryName propname))) loc)
    )

  and refine cx reason loc refi t =
    Base.Option.value_map
      ~f:(fun predicate ->
        let predicate = predicate |> snd |> predicate_of_refinement cx in
        let reason = mk_reason (RRefined (desc_of_reason reason)) loc in
        Tvar.mk_no_wrap_where cx reason (fun tvar ->
            Flow_js.flow cx (t, PredicateT (predicate, tvar))
        ))
      ~default:t
      refi

  and read_entry ~lookup_mode cx loc reason =
    let ({ Loc_env.var_info; _ } as env) = Context.environment cx in
    let rec type_of_state states val_id refi =
      let t =
        lazy
          (Base.List.map
             ~f:(fun entry ->
               match (entry, lookup_mode) with
               | (Env_api.Undefined reason, _)
               | (Env_api.Uninitialized reason, _) ->
                 Type.(VoidT.make reason |> with_trust Trust.bogus_trust)
               | (Env_api.Number reason, _) ->
                 Type.(NumT.make reason |> with_trust Trust.bogus_trust)
               | (Env_api.DeclaredFunction loc, _) ->
                 provider_type_for_def_loc ~intersect:true env loc
               | (Env_api.Undeclared (_name, def_loc), (ForType | ForTypeof)) ->
                 Base.Option.value_exn (Loc_env.find_write env def_loc)
               | (Env_api.Undeclared (name, def_loc), ForValue) ->
                 Flow_js.add_output
                   cx
                   Error_message.(
                     EBindingError (EReferencedBeforeDeclaration, loc, OrdinaryName name, def_loc)
                   );
                 Type.(AnyT.make (AnyError None) reason)
               | (Env_api.UndeclaredClass { def; _ }, (ForType | ForTypeof)) ->
                 Debug_js.Verbose.print_if_verbose
                   cx
                   [
                     spf
                       ""reading %s from location %s""
                       (Reason.string_of_aloc loc)
                       (Reason.aloc_of_reason def |> Reason.string_of_aloc);
                   ];
                 Base.Option.value_exn (Reason.aloc_of_reason def |> Loc_env.find_write env)
               | (Env_api.UndeclaredClass { name; def }, _) ->
                 let def_loc = aloc_of_reason def in
                 Flow_js.add_output
                   cx
                   Error_message.(
                     EBindingError (EReferencedBeforeDeclaration, loc, OrdinaryName name, def_loc)
                   );
                 Type.(AnyT.make (AnyError None) reason)
               | (Env_api.With_ALoc.Write reason, _) ->
                 Debug_js.Verbose.print_if_verbose
                   cx
                   [
                     spf
                       ""reading %s from location %s""
                       (Reason.string_of_aloc loc)
                       (Reason.aloc_of_reason reason |> Reason.string_of_aloc);
                   ];
                 Base.Option.value_exn (Reason.aloc_of_reason reason |> Loc_env.find_write env)
               | (Env_api.With_ALoc.Refinement { refinement_id; writes; write_id }, _) ->
                 find_refi var_info refinement_id
                 |> Base.Option.some
                 |> type_of_state writes write_id
               | (Env_api.With_ALoc.Global name, _) ->
                 Flow_js.get_builtin cx (Reason.OrdinaryName name) reason
               | (Env_api.With_ALoc.This, _) ->
                 Old_env.query_var ~lookup_mode cx (Reason.InternalName ""this"") loc
               | (Env_api.With_ALoc.Super, _) ->
                 Old_env.query_var ~lookup_mode cx (Reason.InternalName ""super"") loc
               | (Env_api.With_ALoc.Arguments, _) -> Type.(AnyT.at AnnotatedAny loc)
               | (Env_api.With_ALoc.Unreachable loc, _) ->
                 let reason = mk_reason (RCustom ""unreachable value"") loc in
                 EmptyT.make reason (Trust.bogus_trust ())
               | (Env_api.With_ALoc.Projection loc, _) ->
                 Base.Option.value_exn (Loc_env.find_write env loc))
             states
          |> phi cx reason
          )
      in
      let t =
        match val_id with
        | Some id ->
          let for_value = lookup_mode = ForValue in
          (match Context.env_cache_find_opt cx ~for_value id with
          | None ->
            let t = Lazy.force t in
            Context.add_env_cache_entry cx ~for_value id t;
            t
          | Some t -> t)
        | _ -> Lazy.force t
      in
      t |> refine cx reason loc refi
    in
    match find_var_opt var_info loc with
    | Error loc -> Error loc
    | Ok { Env_api.def_loc; write_locs; val_kind; name; id } ->
      (match (val_kind, name, def_loc, lookup_mode) with
      | (Some (Env_api.Type { imported }), Some name, Some def_loc, (ForValue | ForTypeof)) ->
        Flow_js.add_output
          cx
          (Error_message.EBindingError
             (Error_message.ETypeInValuePosition { imported; name }, loc, OrdinaryName name, def_loc)
          );
        Ok (AnyT.at (AnyError None) loc)
      | _ -> Ok (type_of_state write_locs id None))

  and read_entry_exn ~lookup_mode cx loc reason =
    match read_entry ~lookup_mode cx loc reason with
    | Error loc -> failwith (Utils_js.spf ""LocEnvEntryNotFound %s"" (Reason.string_of_aloc loc))
    | Ok x -> x

  let get_this_type_param_if_necessary ~otherwise name loc =
    if name = OrdinaryName ""this"" then
      match ALocMap.find_opt loc !this_type_params with
      | Some t -> t
      | None -> otherwise ()
    else
      otherwise ()

  let get_refinement cx key loc =
    let reason = mk_reason (Key.reason_desc key) loc in
    match read_entry ~lookup_mode:ForValue cx loc reason with
    | Ok x -> Some (Flow_js.reposition cx loc x)
    | Error _ -> None

  let get_var ?(lookup_mode = ForValue) cx name loc =
    ignore lookup_mode;
    let name = OrdinaryName name in
    get_this_type_param_if_necessary name loc ~otherwise:(fun () ->
        read_entry_exn ~lookup_mode cx loc (mk_reason (RIdentifier name) loc)
    )

  let query_var ?(lookup_mode = ForValue) cx name ?desc loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.query_var ~lookup_mode cx name ?desc loc
    | _ ->
      get_this_type_param_if_necessary name loc ~otherwise:(fun () ->
          let desc =
            match desc with
            | Some desc -> desc
            | None -> RIdentifier name
          in
          read_entry_exn ~lookup_mode cx loc (mk_reason desc loc)
      )

  let query_var_non_specific cx name loc = Tvar.mk cx (mk_reason (RIdentifier name) loc)

  let var_ref ?(lookup_mode = ForValue) cx ?desc name loc =
    let t = query_var ~lookup_mode cx name ?desc loc in
    Flow_js.reposition cx loc t

  let is_global_var cx _ loc =
    let { Loc_env.var_info; _ } = Context.environment cx in
    let rec local_def_exists states =
      Base.List.exists
        ~f:(function
          | Env_api.With_ALoc.Undefined _ -> true
          | Env_api.With_ALoc.Number _ -> true
          | Env_api.With_ALoc.DeclaredFunction _ -> true
          | Env_api.With_ALoc.Uninitialized _ -> true
          | Env_api.With_ALoc.UndeclaredClass _ -> true
          | Env_api.With_ALoc.Write _ -> true
          | Env_api.With_ALoc.Unreachable _ -> true
          | Env_api.With_ALoc.Undeclared _ -> true
          | Env_api.With_ALoc.Refinement { refinement_id = _; writes; write_id = _ } ->
            local_def_exists writes
          | Env_api.With_ALoc.Projection _ -> true
          | Env_api.With_ALoc.This -> true
          | Env_api.With_ALoc.Super -> true
          | Env_api.With_ALoc.Arguments -> true
          | Env_api.With_ALoc.Global _ -> false)
        states
      |> not
    in
    match find_var_opt var_info loc with
    | Ok { Env_api.def_loc = _; write_locs; val_kind = _; name = _; id = _ } ->
      local_def_exists write_locs
    | Error _ -> false

  let local_scope_entry_exists cx loc name = not (is_global_var cx name loc)

  let get_var_annotation cx name loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.get_var_annotation cx name loc
    | OrdinaryName _ -> (* TODO *) None

  let get_var_declared_type ?(lookup_mode = ForValue) cx name loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.get_var_declared_type ~lookup_mode cx name loc
    | OrdinaryName _ ->
      let env = Context.environment cx in
      provider_type_for_def_loc env loc

  let constraining_type ~default cx name loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.constraining_type ~default cx name loc
    | OrdinaryName _ ->
      let ({ Loc_env.var_info; _ } as env) = Context.environment cx in
      let providers =
        find_providers var_info loc |> Base.List.map ~f:(Loc_env.find_write env) |> Base.Option.all
      in
      (match providers with
      | None
      | Some [] ->
        default
      | Some [t] -> t
      | Some (t1 :: t2 :: ts) -> UnionT (mk_reason (RCustom ""providers"") loc, UnionRep.make t1 t2 ts))

  (*************)
  (*  Writing  *)
  (*************)

  let set_expr cx _key loc ~refined ~original:_ =
    let env = Context.environment cx in
    Debug_js.Verbose.print_if_verbose cx [spf ""set expr at location %s"" (Reason.string_of_aloc loc)];
    match Loc_env.find_write env loc with
    | None ->
      (* As below, this entry is empty if the refinement is never read from *)
      ()
    | Some w -> Flow_js.unify cx ~use_op:unknown_use refined w

  (* Unifies `t` with the entry in the loc_env's map. This allows it to be looked up for Write
   * entries reported by the name_resolver as well as providers for the provider analysis *)
  let unify_write_entry cx ~use_op t loc =
    let ({ Loc_env.resolved; _ } as env) = Context.environment cx in
    if not (ALocSet.mem loc resolved) then begin
      Debug_js.Verbose.print_if_verbose
        cx
        [spf ""writing to location %s"" (Reason.string_of_aloc loc)];
      match Loc_env.find_write env loc with
      | None ->
        (* If we don't see a spot for this write, it's because it's never read from. *)
        ()
      | Some w -> Flow_js.unify cx ~use_op w t
    end else
      Debug_js.Verbose.print_if_verbose
        cx
        [spf ""Location %s already fully resolved"" (Reason.string_of_aloc loc)]

  (* Subtypes the given type against the providers for a def loc. Should be used on assignments to
   * non-import value bindings *)
  let subtype_against_providers cx ~use_op ?potential_global_name t loc =
    let ({ Loc_env.var_info = { Env_api.providers; scopes; _ } as var_info; _ } as env) =
      Context.environment cx
    in
    (* We only perform a subtyping check if this is an assigning write. We call
     * writes to immutable bindings non-assigning writes. For example:
     * const x: number = 3;
     * x = 'string';
     *
     * Since the x = 'string' doesn't actually assign a value to x, we should
     * not perform a subtyping check and a second error saying string is incompatible
     * with number. We should only emit an error saying that a const cannot be reassigned. *)
    match ALocMap.find_opt loc var_info.Env_api.env_entries with
    | Some Env_api.NonAssigningWrite -> ()
    | Some (Env_api.GlobalWrite _) ->
      if is_provider cx loc then
        Base.Option.iter potential_global_name ~f:(fun name ->
            let name = Reason.OrdinaryName name in
            ignore @@ Flow_js.get_builtin cx name (mk_reason (RIdentifier name) loc)
        )
    | _ ->
      if not (is_provider cx loc) then
        let general = provider_type_for_def_loc env loc in
        if is_def_loc_annotated var_info loc then
          Flow_js.flow cx (t, UseT (use_op, general))
        else
          let use_op =
            match Scope_api.With_ALoc.(def_of_use_opt scopes loc) with
            | Some { Scope_api.With_ALoc.Def.locs = (declaration, _); actual_name = name; _ } ->
              let provider_locs =
                Base.Option.value_map
                  ~f:snd
                  ~default:[]
                  (Env_api.Provider_api.providers_of_def providers loc)
              in
              Frame (ConstrainedAssignment { name; declaration; providers = provider_locs }, use_op)
            | None -> use_op
          in
          Context.add_constrained_write cx (t, UseT (use_op, general))

  let assign_env_value_entry cx ~use_op ?potential_global_name t loc =
    unify_write_entry cx ~use_op t loc;
    subtype_against_providers cx ~use_op ?potential_global_name t loc

  (* Sanity check for predicate functions: If there are multiple declare function
   * providers, make sure none of them have a predicate. *)
  let check_predicate_declare_function cx ~predicate name loc =
    let { Loc_env.var_info; _ } = Context.environment cx in
    match Env_api.Provider_api.providers_of_def var_info.Env_api.providers loc with
    (* This check is only relevant when there are multiple providers *)
    | Some (_, def_reason :: _) ->
      let def_loc = Reason.aloc_of_reason def_reason in
      let def_loc_is_pred = is_def_loc_predicate_function var_info def_loc in
      (* Raise an error for an overload (other than the first one) if:
       * - The first overload is a predicate function (`def_loc_is_pred`), or
       * - The current overload is a predicate function (`predicate`). *)
      if def_loc <> loc && (predicate || def_loc_is_pred) then
        Flow_js_utils.add_output
          cx
          (Error_message.EBindingError (Error_message.ENameAlreadyBound, loc, name, def_loc))
    | _ -> ()

  let resolve_env_entry cx t loc =
    unify_write_entry cx ~use_op:unknown_use t loc;
    let ({ Loc_env.resolved; _ } as env) = Context.environment cx in
    Context.set_environment cx { env with Loc_env.resolved = ALocSet.add loc resolved }

  let subtype_entry cx ~use_op t loc =
    let env = Context.environment cx in
    match Loc_env.find_write env loc with
    | None ->
      (* If we don't see a spot for this write it is because the annotated
       * binding being looked up here is one that caused a redeclaration
       * error *)
      assert (
        ALocMap.find_opt loc env.Loc_env.var_info.Env_api.env_entries
        = Some Env_api.NonAssigningWrite
      )
    | Some w -> Flow_js.flow cx (t, UseT (use_op, w))

  (* init_entry is called on variable declarations (not assignments), and `t`
     is the RHS type. If the variable is annotated, we just need to check t against
     its type; but if it's not annotated, the RHS t becomes the variable's type. *)
  let init_entry cx ~use_op ~has_anno:_ t loc =
    let { Loc_env.var_info; _ } = Context.environment cx in
    if is_def_loc_annotated var_info loc then
      subtype_entry cx ~use_op t loc
    else
      assign_env_value_entry cx ~use_op t loc

  let set_var cx ~use_op name t loc =
    assign_env_value_entry cx ~use_op ~potential_global_name:name t loc

  let bind cx t loc = unify_write_entry cx ~use_op:Type.unknown_use t loc

  let bind_var ?state:_ cx name t loc =
    valid_declaration_check cx (OrdinaryName name) loc;
    (* TODO: Vars can be bound multiple times and we need to make sure that the
     * annots are all compatible with each other. For that reason, we subtype
     * against providers when just binding a var *)
    assign_env_value_entry cx ~use_op:unknown_use (TypeUtil.type_t_of_annotated_or_inferred t) loc

  let bind_let ?state:_ cx name t loc =
    valid_declaration_check cx (OrdinaryName name) loc;
    bind cx (TypeUtil.type_t_of_annotated_or_inferred t) loc

  let bind_implicit_let ?state kind cx name t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.bind_implicit_let ?state kind cx name t loc
    | OrdinaryName _ ->
      valid_declaration_check cx name loc;
      bind cx (TypeUtil.type_t_of_annotated_or_inferred t) loc

  let bind_fun ?state cx name t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.bind_fun ?state cx name t loc
    | OrdinaryName _ -> bind cx t loc

  let bind_implicit_const ?state:_ _ cx _ t loc =
    bind cx (TypeUtil.type_t_of_annotated_or_inferred t) loc

  let bind_const ?state:_ cx _ t loc = bind cx (TypeUtil.type_t_of_annotated_or_inferred t) loc

  let bind_import cx _ t loc = bind cx t loc

  let bind_declare_var cx name t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.bind_declare_var cx name t loc
    | OrdinaryName _ -> bind cx t loc

  let bind_declare_fun cx ~predicate name t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.bind_declare_fun cx ~predicate name t loc
    | OrdinaryName _ ->
      check_predicate_declare_function cx ~predicate name loc;
      bind cx t loc

  let bind_type ?state:(_ = Scope.State.Declared) cx _name t loc = bind cx t loc

  let bind_import_type cx _name t loc = bind cx t loc

  let bind_this_tparam ~state:_ _cx t loc = this_type_params := ALocMap.add loc t !this_type_params

  let declare_let cx name =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.declare_let cx name
    | OrdinaryName _ -> Fn.const ()

  let declare_implicit_let kind cx name =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.declare_implicit_let kind cx name
    | OrdinaryName _ -> Fn.const ()

  let declare_const cx name =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.declare_const cx name
    | OrdinaryName _ -> Fn.const ()

  let declare_implicit_const kind cx name =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.declare_implicit_const kind cx name
    | OrdinaryName _ -> Fn.const ()

  let init_var cx ~use_op name ~has_anno t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.init_var cx ~use_op name ~has_anno t loc
    | OrdinaryName _ -> init_entry ~has_anno cx ~use_op t loc

  let init_let cx ~use_op name ~has_anno t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.init_let cx ~use_op name ~has_anno t loc
    | OrdinaryName _ -> init_entry ~has_anno cx ~use_op t loc

  let init_implicit_let kind cx ~use_op name ~has_anno t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.init_implicit_let kind cx ~use_op name ~has_anno t loc
    | OrdinaryName _ -> init_entry ~has_anno cx ~use_op t loc

  let init_fun cx ~use_op name t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.init_fun cx ~use_op name t loc
    | OrdinaryName _ -> assign_env_value_entry cx ~use_op t loc

  let init_const cx ~use_op name ~has_anno t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.init_const cx ~use_op name ~has_anno t loc
    | OrdinaryName _ -> init_entry ~has_anno cx ~use_op t loc

  let init_implicit_const kind cx ~use_op name ~has_anno t loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.init_implicit_const kind cx ~use_op name ~has_anno t loc
    | OrdinaryName _ -> init_entry ~has_anno cx ~use_op t loc

  let init_type cx _name t loc = unify_write_entry cx ~use_op:unknown_use t loc

  let pseudo_init_declared_type _ _ _ = ()

  let unify_declared_type ?(lookup_mode = ForValue) ?(is_func = false) cx name loc t =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.unify_declared_type ~lookup_mode ~is_func cx name loc t
    | OrdinaryName _ -> unify_write_entry cx ~use_op:unknown_use t loc

  let unify_declared_fun_type cx name loc t =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.unify_declared_fun_type cx name loc t
    | OrdinaryName _ -> unify_write_entry cx ~use_op:unknown_use t loc

  (************************)
  (* Variable Declaration *)
  (************************)

  let init_env ?exclude_syms cx scope =
    Old_env.init_env ?exclude_syms cx scope;
    let ({ Loc_env.var_info; _ } as env) = Context.environment cx in
    ALocMap.fold
      (fun loc env_entry env ->
        match env_entry with
        | Env_api.AssigningWrite reason
        | Env_api.GlobalWrite reason ->
          let t = Inferred (Tvar.mk cx reason) in
          (* Treat everything as inferred for now for the purposes of annotated vs inferred *)
          Loc_env.initialize env loc t
        | Env_api.NonAssigningWrite -> env)
      var_info.Env_api.env_entries
      env
    |> Context.set_environment cx

  let find_entry cx name ?desc loc =
    match name with
    | InternalName _
    | InternalModuleName _ ->
      Old_env.find_entry cx name ?desc loc
    | OrdinaryName name ->
      assert_false (spf ""Looking up an ordinary name entry %s in new environment"" name)

  (* This is mostly copied from the same function in env.ml, but with refinements of ordinary names
     being ignored, because that happens in the name_resolver. *)
  let refine_with_preds cx loc preds orig_types =
    let refine_type orig_type pred refined_type =
      Flow_js.flow cx (orig_type, PredicateT (pred, refined_type))
    in
    let mk_refi_type orig_type pred refi_reason =
      refine_type orig_type pred |> Tvar.mk_no_wrap_where cx refi_reason
    in
    let refine_with_pred key pred acc =
      let refi_reason = mk_reason (RRefined (Key.reason_desc key)) loc in
      match key with
      | (OrdinaryName _, _) ->
        (* new env doesn't need to refine ordinary names. The EnvBuilder computes
         * the refinements in advance *)
        acc
      | _ ->
        let orig_type = Key_map.find key orig_types in
        let refi_type = mk_refi_type orig_type pred refi_reason in
        let change = Old_env.refine_expr key loc refi_type orig_type in
        Changeset.add_refi change acc
    in
    Key_map.fold refine_with_pred preds Changeset.empty

  (* Directly copied from env.ml, needed because it calls refine_with_preds *)
  let in_refined_env cx loc preds orig_types f =
    let oldset = Changeset.Global.clear () in
    let orig_env = peek_env () in
    let new_env = clone_env orig_env in
    update_env loc new_env;
    let _ = refine_with_preds cx loc preds orig_types in
    let result = f () in
    let newset = Changeset.Global.merge oldset in
    merge_env cx loc (orig_env, orig_env, new_env) newset;
    update_env loc orig_env;
    result

  let new_env = true

  let discriminant_after_negated_cases cx switch_loc refinement_key_opt _discriminant =
    let reason_desc =
      match refinement_key_opt with
      | None -> RCustom ""discriminant of switch""
      | Some refinement_key -> Key.reason_desc refinement_key
    in
    match read_entry ~lookup_mode:ForValue cx switch_loc (mk_reason reason_desc switch_loc) with
    | Ok t -> Some t
    | Error _ -> None

  let init_import ~lookup_mode:_ cx _name loc t = unify_write_entry ~use_op:unknown_use cx t loc
end
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* This module listens to the socket, accepts new connections, and starts the
 * FlowServerMonitorConnections which handle those connects *)

let spf = Printf.sprintf

module Logger = FlowServerMonitorLogger
module Server = FlowServerMonitorServer

(* Just forward requests to the server *)
let handle_ephemeral_request ~msg ~connection =
  Lwt.return (Server.send_request ~client:connection ~request:msg)

(* Just forward requests to the server *)
let handle_persistent_message ~client_id ~msg ~connection:_ =
  Logger.debug ""Persistent connection #%d received a message!"" client_id;
  Lwt.return (Server.send_persistent_request ~client_id ~request:msg)

module type STATUS_WRITER = sig
  type t

  val write : ServerStatus.status * FileWatcherStatus.status -> t -> bool
end

(* A loop that sends the Server's busy status to a waiting connection every 0.5 seconds *)
module StatusLoop (Writer : STATUS_WRITER) = LwtLoop.Make (struct
  exception Break

  type acc = Writer.t

  let main conn =
    let%lwt status = StatusStream.wait_for_signficant_status ~timeout:0.5 in
    if not (Writer.write status conn) then
      (* The connection closed its write stream, likely it is closed or closing *)
      raise Break;
    Lwt.return conn

  let catch _ exn =
    begin
      match Exception.unwrap exn with
      | Break -> ()
      | _ -> Logger.error ~exn:(Exception.to_exn exn) ""StatusLoop threw an exception""
    end;
    Lwt.return_unit
end)

module EphemeralStatusLoop = StatusLoop (struct
  type t = EphemeralConnection.t

  let write status conn = EphemeralConnection.write ~msg:(MonitorProt.Please_hold status) conn
end)

module PersistentStatusLoop = StatusLoop (struct
  type t = PersistentConnection.t

  let write status conn =
    PersistentConnection.write ~msg:LspProt.(NotificationFromServer (Please_hold status)) conn
end)

let create_ephemeral_connection ~client_fd ~close =
  Logger.debug ""Creating a new ephemeral connection"";

  let%lwt (start, conn) =
    EphemeralConnection.create
      ~name:""some ephemeral connection""
      ~in_fd:client_fd
      ~out_fd:client_fd
      ~close
      ~on_read:handle_ephemeral_request
  in
  (* On exit, do our best to send all pending messages to the waiting client *)
  let close_on_exit =
    let%lwt _ = Lwt_condition.wait ExitSignal.signal in
    EphemeralConnection.try_flush_and_close conn
  in
  (* Lwt.pick returns the first thread to finish and cancels the rest. *)
  Lwt.async (fun () -> Lwt.pick [close_on_exit; EphemeralConnection.wait_for_closed conn]);

  (* Start the ephemeral connection *)
  start ();

  (* Send the current server state immediate *)
  let msg = MonitorProt.Please_hold (StatusStream.get_status ()) in
  ignore (EphemeralConnection.write ~msg conn);

  (* Start sending the status to the ephemeral connection *)
  Lwt.async (fun () -> EphemeralStatusLoop.run ~cancel_condition:ExitSignal.signal conn);

  Lwt.return_unit

(* No lock needed, since the socket acceptor runs serially *)
let create_persistent_id =
  let last_persistent_id = ref 0 in
  fun () ->
    incr last_persistent_id;
    !last_persistent_id

let create_persistent_connection ~client_fd ~close ~lsp_init_params =
  let client_id = create_persistent_id () in
  Logger.debug ""Creating a persistent connection #%d"" client_id;

  Server.notify_new_persistent_connection ~client_id ~lsp_init_params;

  let close () =
    Server.notify_dead_persistent_connection ~client_id;
    close ()
  in
  let%lwt (start, conn) =
    PersistentConnection.create
      ~name:(spf ""persistent connection #%d"" client_id)
      ~in_fd:client_fd
      ~out_fd:client_fd
      ~close
      ~on_read:(handle_persistent_message ~client_id)
  in
  (* On exit, do our best to send all pending messages to the waiting client *)
  let close_on_exit =
    let%lwt (exit_status, _) = Lwt_condition.wait ExitSignal.signal in
    (* Notifies the client why the connection is closing. This can be useful to
       the persistent client to decide if it should autostart a new monitor. *)
    ignore
      (PersistentConnection.write
         ~msg:LspProt.(NotificationFromServer (ServerExit exit_status))
         conn
      );
    (* TODO: we don't need this anymore, just use ServerExit *)
    ignore (PersistentConnection.write ~msg:LspProt.(NotificationFromServer EOF) conn);
    PersistentConnection.try_flush_and_close conn
  in
  (* Lwt.pick returns the first thread to finish and cancels the rest. *)
  Lwt.async (fun () -> Lwt.pick [close_on_exit; PersistentConnection.wait_for_closed conn]);

  (* Don't start the connection until we add it to the persistent connection map *)
  Lwt.async (fun () ->
      PersistentConnectionMap.add ~client_id ~client:conn;
      start ();
      let msg = LspProt.(NotificationFromServer (Please_hold (StatusStream.get_status ()))) in
      ignore (PersistentConnection.write ~msg conn);
      let%lwt () = PersistentStatusLoop.run ~cancel_condition:ExitSignal.signal conn in
      Lwt.return_unit
  );

  Lwt.return ()

let close client_fd () =
  (* Close the client_fd, regardless of whether or not we were able to shutdown the connection.
   * This prevents fd leaks *)
  Logger.debug ""Shutting down and closing a socket client fd"";
  (* To be perfectly honest, it's not clear whether the SHUTDOWN_ALL is really needed. I mean,
   * shutdown is useful to shutdown one direction of the socket, but if you're about to close
   * it, does shutting down first actually make any difference? *)
  begin
    try Lwt_unix.(shutdown client_fd SHUTDOWN_ALL) with
    | Unix.(Unix_error ((EBADF | ENOTCONN | ECONNRESET | ECONNABORTED), _, _)) ->
      (* These errors happen when the connection is already closed, so we can
         ignore them. Note that POSIX and Windows have different errors:
         see https://man7.org/linux/man-pages/man2/shutdown.2.html
         and https://docs.microsoft.com/en-us/windows/win32/api/winsock/nf-winsock-shutdown *)
      ()
    | exn -> Logger.error ~exn ""Failed to shutdown socket client""
  end;
  try%lwt Lwt_unix.close client_fd with
  (* Already closed *)
  | Unix.Unix_error (Unix.EBADF, _, _) -> Lwt.return_unit
  | exn -> Lwt.return (Logger.error ~exn ""Failed to close socket client fd"")

(* Well...I mean this is a pretty descriptive function name. It performs the handshake and then
 * returns the client's side of the handshake *)
let perform_handshake_and_get_client_handshake ~client_fd =
  SocketHandshake.(
    let server_build_id = build_revision in
    let server_bin = Sys.executable_name in
    (* handshake step 1: client sends handshake *)
    let%lwt (wire : client_handshake_wire) = Marshal_tools_lwt.from_fd_with_preamble client_fd in
    let client_handshake =
      try fst wire |> Hh_json.json_of_string |> json_to__client_to_monitor_1 with
      | exn ->
        Logger.error ~exn ""Failed to parse JSON section of handshake: %s"" (fst wire);
        default_client_to_monitor_1
    in
    let client =
      if client_handshake.client_build_id <> server_build_id then
        None
      else
        Some (Marshal.from_string (snd wire) 0 : client_to_monitor_2)
    in
    (* handshake step 2: server sends back handshake *)
    let respond server_intent server2 =
      assert (server2 = None || client_handshake.client_build_id = server_build_id);

      (* the client will trust our invariant that server2=Some means the client *)
      (* can certainly deserialize server2. *)
      let server_version = Flow_version.version in
      let server1 = { server_build_id; server_bin; server_intent; server_version } in
      let wire : server_handshake_wire =
        ( server1 |> monitor_to_client_1__to_json |> Hh_json.json_to_string,
          Base.Option.map server2 ~f:(fun server2 -> Marshal.to_string server2 [])
        )
      in
      let%lwt _ = Marshal_tools_lwt.to_fd_with_preamble client_fd wire in
      Lwt.return_unit
    in
    let error_client () =
      let%lwt () = respond Server_will_hangup None in
      Logger.error ""Build mismatch, so rejecting attempted connection"";
      Lwt.return None
    in
    let stop_server () =
      let%lwt () = respond Server_will_exit None in
      let msg = ""Client and server are different builds. Flow server is out of date. Exiting"" in
      FlowEventLogger.out_of_date ();
      Logger.fatal ""%s"" msg;
      Exit.exit ~msg Exit.Build_id_mismatch
    in
    let fd_as_int = client_fd |> Lwt_unix.unix_file_descr |> Obj.magic in
    if client_handshake.is_stop_request then
      (* Stop request *)
      let%lwt () = respond Server_will_exit None in
      let%lwt () = close client_fd () in
      Server.stop Server.Stopped
    else if client_handshake.client_build_id <> build_revision then
      (* Binary version mismatch *)
      match client_handshake.version_mismatch_strategy with
      | Always_stop_server -> stop_server ()
      | Stop_server_if_older ->
        if Semver.compare Flow_version.version client_handshake.client_version < 0 then
          stop_server ()
        (* server < client *)
        else
          error_client ()
      | Error_client -> error_client ()
    else if Sys.unix && fd_as_int > 500 then (
      (* Too many clients *)
      (* We currently rely on using Unix.select, which doesn't work for fds >= FD_SETSIZE (1024).
       * So we can't have an unlimited number of clients. So if the new fd is too large, let's
       * reject it.
       * TODO(glevi): Figure out whether this check is needed for Windows *)
      let%lwt () = respond Server_will_hangup (Some Server_has_too_many_clients) in
      Logger.error ""Too many clients, so rejecting new connection (%d)"" fd_as_int;
      Lwt.return None
    ) else if not (StatusStream.ever_been_free ()) then
      (* Server still initializing *)
      let client = Base.Option.value_exn client in
      let status = StatusStream.get_status () in
      if client_handshake.server_should_hangup_if_still_initializing then (
        let%lwt () = respond Server_will_hangup (Some (Server_still_initializing status)) in
        (* In the case of Persistent, lspCommand will retry a second later. *)
        (* The message we log here solely goes to the logs, not the user. *)
        let (server_status, watchman_status) = status in
        Logger.info
          ""Server still initializing -> hangup. server_status=%s watchman_status=%s""
          (ServerStatus.string_of_status server_status)
          (FileWatcherStatus.string_of_status watchman_status);
        Lwt.return None
      ) else
        let%lwt () = respond Server_will_continue (Some (Server_still_initializing status)) in
        Lwt.return (Some client)
    (* Success *)
    else
      let client = Base.Option.value_exn client in
      let%lwt () = respond Server_will_continue (Some Server_ready) in
      Lwt.return (Some client)
  )

let catch close exn =
  (* We catch all exceptions, since one bad connection shouldn't kill the whole monitor *)
  begin
    match Exception.unwrap exn with
    (* Monitor is dying *)
    | Lwt.Canceled -> ()
    | Marshal_tools.Malformed_Preamble_Exception ->
      Logger.error
        ~exn:(Exception.to_exn exn)
        ""Someone tried to connect to the socket, but spoke a different protocol. Ignoring them""
    | _ ->
      Logger.error
        ~exn:(Exception.to_exn exn)
        ""Exception while trying to establish new connection over the socket. Closing connection""
  end;
  close ()

module type Handler = sig
  val create_socket_connection :
    autostop:bool -> Lwt_unix.file_descr * Lwt_unix.sockaddr -> unit Lwt.t

  val name : string
end

module SocketAcceptorLoop (Handler : Handler) = LwtLoop.Make (struct
  type acc = bool * Lwt_unix.file_descr

  let main (autostop, socket_fd) =
    Logger.debug ""Waiting for a new %s"" Handler.name;
    let%lwt conn = Lwt_unix.accept socket_fd in
    let%lwt () = Handler.create_socket_connection ~autostop conn in
    Lwt.return (autostop, socket_fd)

  let catch _ exn =
    Logger.fatal ~exn:(Exception.to_exn exn) ""Uncaught exception in the socket acceptor"";
    Exception.reraise exn
end)

module Autostop : sig
  val cancel_countdown : unit -> unit

  val start_countdown : unit -> unit
end = struct
  let current_countdown = ref Lwt.return_unit

  let cancel_countdown () = Lwt.cancel !current_countdown

  let start_countdown () =
    current_countdown :=
      let%lwt () = Lwt_unix.sleep 60. in
      Server.stop Server.Autostopped
end

module MonitorSocketAcceptorLoop = SocketAcceptorLoop (struct
  let name = ""socket connection""

  let create_socket_connection ~autostop (client_fd, _) =
    (* Autostop is meant to be ""edge-triggered"", i.e. when we transition
       from 1 connections to 0 connections then it might stop the server.
       But when an attempt to connect has failed, we need to close without
       triggering an autostop. *)
    let close_without_autostop = close client_fd in
    let close () =
      let%lwt () = close_without_autostop () in
      let num_persistent = PersistentConnectionMap.cardinal () in
      let num_ephemeral = RequestMap.cardinal () in
      if autostop && num_persistent = 0 && num_ephemeral = 0 then
        Lwt.return (Autostop.start_countdown ())
      else
        Lwt.return_unit
    in
    try%lwt
      match%lwt perform_handshake_and_get_client_handshake ~client_fd with
      | Some client ->
        let open SocketHandshake in
        Autostop.cancel_countdown ();
        (match client with
        | { client_type = Ephemeral; _ } -> create_ephemeral_connection ~client_fd ~close
        | { client_type = Persistent { lsp_init_params }; _ } ->
          create_persistent_connection ~client_fd ~close ~lsp_init_params)
      | None -> close_without_autostop ()
    with
    | exn ->
      let exn = Exception.wrap exn in
      catch close_without_autostop exn
end)

let run monitor_socket_fd ~autostop =
  MonitorSocketAcceptorLoop.run ~cancel_condition:ExitSignal.signal (autostop, monitor_socket_fd)

module LegacySocketAcceptorLoop = SocketAcceptorLoop (struct
  let name = ""legacy socket connection""

  let create_socket_connection ~autostop:_ (client_fd, _) =
    let close = close client_fd in
    try%lwt
      let%lwt () = close () in
      FlowEventLogger.out_of_date ();
      let msg = ""Client and server are different builds. Flow server is out of date. Exiting"" in
      Logger.fatal ""%s"" msg;
      Server.stop Server.Legacy_client
    with
    | exn ->
      let exn = Exception.wrap exn in
      catch close exn
end)

let run_legacy legacy_socket_fd =
  LegacySocketAcceptorLoop.run ~cancel_condition:ExitSignal.signal (false, legacy_socket_fd)
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*              Damien Doligez, projet Para, INRIA Rocquencourt           *)
(*                                                                        *)
(*   Copyright 1999 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(** Raw printer for {!Parsetree}

  {b Warning:} this module is unstable and part of
  {{!Compiler_libs}compiler-libs}.

*)

open Parsetree
open Format

val interface : formatter -> signature_item list -> unit
val implementation : formatter -> structure_item list -> unit
val top_phrase : formatter -> toplevel_phrase -> unit

val expression: int -> formatter -> expression -> unit
val structure: int -> formatter -> structure -> unit
val payload: int -> formatter -> payload -> unit
val core_type: int -> formatter -> core_type -> unit
val module_type: int -> formatter -> module_type -> unit
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Reason
open Type
open TypeUtil
open Utils_js
open Loc_collections

let string_of_polarity = function
  | Polarity.Negative -> ""Negative""
  | Polarity.Neutral -> ""Neutral""
  | Polarity.Positive -> ""Positive""

let string_of_union_enum = function
  | UnionEnum.Str x -> spf ""string %s"" (display_string_of_name x)
  | UnionEnum.Num (_, x) -> spf ""number %s"" x
  | UnionEnum.Bool x -> spf ""boolean %b"" x
  | UnionEnum.Null -> ""null""
  | UnionEnum.Void -> ""void""

let string_of_sentinel = function
  | UnionEnum.One enum -> string_of_union_enum enum
  | UnionEnum.Many enums ->
    ListUtils.to_string "" | "" string_of_union_enum @@ UnionEnumSet.elements enums

let string_of_selector = function
  | Elem _ -> ""Elem _"" (* TODO print info about the key *)
  | Prop (x, _) -> spf ""Prop %s"" x
  | ArrRest i -> spf ""ArrRest %i"" i
  | ObjRest xs -> spf ""ObjRest [%s]"" (String.concat ""; "" xs)
  | Default -> ""Default""

let string_of_destructor = function
  | NonMaybeType -> ""NonMaybeType""
  | PropertyType { name; _ } -> spf ""PropertyType %s"" (display_string_of_name name)
  | ElementType _ -> ""ElementType""
  | OptionalIndexedAccessNonMaybeType _ -> ""OptionalIndexedAccessNonMaybeType""
  | OptionalIndexedAccessResultType _ -> ""OptionalIndexedAccessResultType""
  | ReadOnlyType -> ""ReadOnly""
  | PartialType -> ""PartialType""
  | SpreadType _ -> ""Spread""
  | RestType _ -> ""Rest""
  | ValuesType -> ""Values""
  | CallType _ -> ""CallType""
  | TypeMap (TupleMap _) -> ""TupleMap""
  | TypeMap (ObjectMap _) -> ""ObjectMap""
  | TypeMap (ObjectMapi _) -> ""ObjectMapi""
  | TypeMap ObjectKeyMirror -> ""ObjectKeyMirror""
  | TypeMap (ObjectMapConst _) -> ""ObjectMapConst""
  | ReactElementPropsType -> ""ReactElementProps""
  | ReactElementConfigType -> ""ReactElementConfig""
  | ReactElementRefType -> ""ReactElementRef""
  | ReactConfigType _ -> ""ReactConfig""

let string_of_destruct_kind = function
  | DestructAnnot -> ""Annot""
  | DestructInfer -> ""Infer""

let bool_of_sealtype = function
  | Object.Spread.Sealed -> true
  | _ -> false

(*****************************************************************)

(* debug printer *)

let lookup_trust cx id =
  Trust_constraint.(
    match Context.find_trust_graph cx id with
    | TrustResolved trust -> trust
    | TrustUnresolved b -> get_trust b
  )

let dump_reason cx reason =
  let strip_root =
    if Context.should_strip_root cx then
      Some (Context.root cx)
    else
      None
  in
  Reason.dump_reason ~strip_root reason

let rec dump_t_ (depth, tvars) cx t =
  let p ?(reason = true) ?(extra = """") ?(trust = None) t =
    spf
      ""%s %s(%s%s%s)""
      (string_of_ctor t)
      ( if not (Context.trust_tracking cx) then
        """"
      else
        Base.Option.value_map ~default:"""" ~f:(lookup_trust cx |> string_of_trust_rep) trust
      )
      ( if reason then
        spf ""%S"" (dump_reason cx (reason_of_t t))
      else
        """"
      )
      ( if reason && extra <> """" then
        "", ""
      else
        """"
      )
      extra
  in
  let kid = dump_t_ (depth - 1, tvars) cx in
  let tvar id = dump_tvar_ (depth - 1, tvars) cx id in
  let defer_use expr t =
    match expr with
    | LatentPredT (_, p) -> spf ""LatentPred %s on %s"" (string_of_predicate p) t
    | TypeDestructorT (use_op, _, destructor) ->
      spf ""%s, TypeDestruct %s on %s"" (string_of_use_op use_op) (string_of_destructor destructor) t
  in
  let string_of_mixed_flavor = function
    | Mixed_everything -> ""Mixed_everything""
    | Mixed_function -> ""Mixed_function""
    | Mixed_truthy -> ""Mixed_truthy""
    | Mixed_non_maybe -> ""Mixed_non_maybe""
    | Mixed_non_null -> ""Mixed_non_null""
    | Mixed_non_void -> ""Mixed_non_void""
  in
  let string_of_any_source = function
    | AnnotatedAny -> ""AnnotatedAny""
    | CatchAny -> ""CatchAny""
    | AnyError _ -> ""Error""
    | Unsound _ -> ""Unsound""
    | Untyped -> ""Untyped""
  in
  let custom_fun =
    let react_prop_type =
      React.PropType.(
        let complex = function
          | ArrayOf -> ""ArrayOf""
          | InstanceOf -> ""InstanceOf""
          | ObjectOf -> ""ObjectOf""
          | OneOf -> ""OneOf""
          | OneOfType -> ""OneOfType""
          | Shape -> ""Shape""
        in
        function
        | Primitive (is_required, t) -> spf ""Primitive (%b, %s)"" is_required (kid t)
        | Complex kind -> complex kind
      )
    in
    function
    | ObjectAssign -> ""ObjectAssign""
    | ObjectGetPrototypeOf -> ""ObjectGetPrototypeOf""
    | ObjectSetPrototypeOf -> ""ObjectSetPrototypeOf""
    | Compose false -> ""Compose""
    | Compose true -> ""ComposeReverse""
    | ReactPropType p -> spf ""ReactPropType (%s)"" (react_prop_type p)
    | ReactCreateElement -> ""ReactCreateElement""
    | ReactCloneElement -> ""ReactCloneElement""
    | ReactElementFactory _ -> ""ReactElementFactory""
    | Idx -> ""Idx""
    | TypeAssertIs -> ""TypeAssert.is""
    | TypeAssertThrows -> ""TypeAssert.throws""
    | TypeAssertWraps -> ""TypeAssert.wraps""
    | DebugPrint -> ""DebugPrint""
    | DebugThrow -> ""DebugThrow""
    | DebugSleep -> ""DebugSleep""
  in
  if depth = 0 then
    string_of_ctor t
  else
    match t with
    | OpenT (_, id) -> p ~extra:(tvar id) t
    | DefT (_, trust, NumT lit) ->
      p
        ~trust:(Some trust)
        ~extra:
          (match lit with
          | Literal (_, (_, raw)) -> raw
          | Truthy -> ""truthy""
          | AnyLiteral -> """")
        t
    | DefT (_, trust, StrT c) ->
      p
        ~trust:(Some trust)
        ~extra:
          (match c with
          | Literal (_, s) -> spf ""%S"" (display_string_of_name s)
          | Truthy -> ""truthy""
          | AnyLiteral -> """")
        t
    | DefT (_, trust, BoolT c) ->
      p
        ~trust:(Some trust)
        ~extra:
          (match c with
          | Some b -> spf ""%B"" b
          | None -> """")
        t
    | DefT (_, trust, FunT (_, { params; return_t; this_t; _ })) ->
      p
        ~trust:(Some trust)
        ~extra:
          (spf
             ""<this: %s>(%s) => %s""
             (kid (fst this_t))
             (String.concat ""; "" (Base.List.map ~f:(fun (_, t) -> kid t) params))
             (kid return_t)
          )
        t
    | AnyT (_, src) -> p ~extra:(string_of_any_source src) t
    | DefT (_, trust, MixedT flavor) ->
      p ~trust:(Some trust) ~extra:(string_of_mixed_flavor flavor) t
    | DefT (_, trust, EmptyT)
    | DefT (_, trust, SymbolT)
    | DefT (_, trust, NullT)
    | DefT (_, trust, VoidT) ->
      p ~trust:(Some trust) t
    | NullProtoT _
    | ObjProtoT _
    | FunProtoT _
    | FunProtoApplyT _
    | FunProtoBindT _
    | FunProtoCallT _ ->
      p t
    | DefT (_, trust, PolyT { tparams = tps; t_out = c; id; _ }) ->
      p
        ~trust:(Some trust)
        ~extra:
          (spf
             ""%s [%s] #%s""
             (kid c)
             (String.concat
                ""; ""
                (Base.List.map
                   ~f:(fun tp -> Subst_name.string_of_subst_name tp.name)
                   (Nel.to_list tps)
                )
             )
             (Poly.string_of_id id)
          )
        t
    | ThisClassT (_, inst, _, _) -> p ~extra:(kid inst) t
    | GenericT { name; bound; _ } ->
      p ~extra:(spf ""%s: %s"" (Subst_name.string_of_subst_name name) (kid bound)) t
    | DefT (_, trust, ObjT { props_tmap; flags; _ }) ->
      let obj_kind =
        match flags.obj_kind with
        | Exact -> ""Exact""
        | Inexact -> ""Inexact""
        | Indexed { key; value; _ } ->
          spf ""Indexed {[%s]: %s}"" (p ~reason:false key) (p ~reason:false value)
        | UnsealedInFile _ -> ""UnsealedInFile""
      in
      p ~trust:(Some trust) t ~extra:(spf ""%s, %s"" (Properties.string_of_id props_tmap) obj_kind)
    | DefT (_, trust, ArrT (ArrayAT (elemt, None))) ->
      p ~trust:(Some trust) ~extra:(spf ""Array %s"" (kid elemt)) t
    | DefT (_, trust, ArrT (ArrayAT (elemt, Some tup))) ->
      p
        ~trust:(Some trust)
        ~extra:
          (spf
             ""Array %s, %s""
             (kid elemt)
             (spf ""[%s]"" (String.concat ""; "" (Base.List.map ~f:kid tup)))
          )
        t
    | DefT (_, trust, ArrT (TupleAT (_, tup))) ->
      p
        ~trust:(Some trust)
        ~extra:(spf ""Tuple [%s]"" (String.concat "", "" (Base.List.map ~f:kid tup)))
        t
    | DefT (_, trust, ArrT (ROArrayAT elemt)) ->
      p ~trust:(Some trust) ~extra:(spf ""ReadOnlyArray %s"" (kid elemt)) t
    | DefT (_, trust, CharSetT chars) ->
      p ~trust:(Some trust) ~extra:(spf ""<%S>"" (String_utils.CharSet.to_string chars)) t
    | DefT (_, trust, ClassT inst) -> p ~trust:(Some trust) ~extra:(kid inst) t
    | DefT (_, trust, InstanceT (_, _, _, { class_id; _ })) ->
      p ~trust:(Some trust) ~extra:(spf ""#%s"" (ALoc.debug_to_string (class_id :> ALoc.t))) t
    | DefT (_, trust, TypeT (kind, arg)) ->
      p ~trust:(Some trust) ~extra:(spf ""%s, %s"" (string_of_type_t_kind kind) (kid arg)) t
    | DefT (_, trust, EnumT { enum_id; members = _; representation_t = _; has_unknown_members = _ })
    | DefT
        ( _,
          trust,
          EnumObjectT { enum_id; members = _; representation_t = _; has_unknown_members = _ }
        ) ->
      p ~trust:(Some trust) ~extra:(spf ""enum #%s"" (ALoc.debug_to_string (enum_id :> ALoc.t))) t
    | AnnotT (_, arg, use_desc) -> p ~extra:(spf ""use_desc=%b, %s"" use_desc (kid arg)) t
    | OpaqueT (_, { underlying_t = Some arg; _ }) -> p ~extra:(spf ""%s"" (kid arg)) t
    | OpaqueT _ -> p t
    | OptionalT { reason = _; type_ = arg; use_desc = _ } -> p ~extra:(kid arg) t
    | EvalT (arg, expr, id) ->
      p ~extra:(spf ""%s, %s"" (defer_use expr (kid arg)) (Eval.string_of_id id)) t
    | TypeAppT (_, _, base, args) ->
      p ~extra:(spf ""%s, [%s]"" (kid base) (String.concat ""; "" (Base.List.map ~f:kid args))) t
    | ThisTypeAppT (_, base, this, args_opt) ->
      p
        ~reason:false
        ~extra:
          begin
            match args_opt with
            | Some args ->
              spf
                ""%s, %s, [%s]""
                (kid base)
                (kid this)
                (String.concat ""; "" (Base.List.map ~f:kid args))
            | None -> spf ""%s, %s"" (kid base) (kid this)
          end
        t
    | ExactT (_, arg) -> p ~extra:(kid arg) t
    | MaybeT (_, arg) -> p ~extra:(kid arg) t
    | IntersectionT (_, rep) ->
      p ~extra:(spf ""[%s]"" (String.concat ""; "" (Base.List.map ~f:kid (InterRep.members rep)))) t
    | UnionT (_, rep) ->
      p
        ~extra:
          (spf
             ""[%s]%s""
             (String.concat ""; "" (Base.List.map ~f:kid (UnionRep.members rep)))
             (UnionRep.string_of_specialization rep)
          )
        t
    | DefT (_, trust, IdxWrapper inner_obj) -> p ~trust:(Some trust) ~extra:(kid inner_obj) t
    | DefT (_, trust, ReactAbstractComponentT _) -> p ~trust:(Some trust) t
    | ShapeT (_, arg) -> p ~extra:(kid arg) t
    | MatchingPropT (_, _, arg) -> p ~extra:(kid arg) t
    | KeysT (_, arg) -> p ~extra:(kid arg) t
    | DefT (_, trust, SingletonStrT s) ->
      p ~trust:(Some trust) ~extra:(spf ""%S"" (display_string_of_name s)) t
    | DefT (_, trust, SingletonNumT (_, s)) -> p ~trust:(Some trust) ~extra:s t
    | DefT (_, trust, SingletonBoolT b) -> p ~trust:(Some trust) ~extra:(spf ""%B"" b) t
    | ModuleT (_, { exports_tmap; _ }, _) ->
      p
        t
        ~extra:
          (Context.find_exports cx exports_tmap
          |> NameUtils.Map.bindings
          |> Base.List.map ~f:(fun (name, (_, t)) ->
                 kid t |> spf ""%s: %s"" (display_string_of_name name)
             )
          |> String.concat "", ""
          |> spf ""[%s]""
          )
    | InternalT (ExtendsT (_, l, u)) -> p ~extra:(spf ""%s, %s"" (kid l) (kid u)) t
    | CustomFunT (_, kind) -> p ~extra:(custom_fun kind) t
    | InternalT (ChoiceKitT _) -> p t
    | TypeDestructorTriggerT (_, _, _, s, (r, x)) ->
      p
        ~extra:(spf ""%s on upper, (%s, %s)"" (string_of_destructor s) (string_of_reason r) (tvar x))
        t
    | OpenPredT { base_t = arg; m_pos = p_pos; m_neg = p_neg; reason = _ } ->
      p
        t
        ~extra:
          (spf
             ""%s, {%s}, {%s}""
             (kid arg)
             (String.concat
                ""; ""
                (Base.List.map
                   ~f:(fun (k, p) -> spf ""%s: %s"" (Key.string_of_key k) (string_of_predicate p))
                   (Key_map.elements p_pos)
                )
             )
             (String.concat
                ""; ""
                (Base.List.map
                   ~f:(fun (k, p) -> spf ""%s: %s"" (Key.string_of_key k) (string_of_predicate p))
                   (Key_map.elements p_neg)
                )
             )
          )

and dump_use_t_ (depth, tvars) cx t =
  let p ?(reason = true) ?(extra = """") use_t =
    spf
      ""%s (%s%s%s)""
      (string_of_use_ctor use_t)
      ( if reason then
        spf ""%S"" (dump_reason cx (reason_of_use_t use_t))
      else
        """"
      )
      ( if reason && extra <> """" then
        "", ""
      else
        """"
      )
      extra
  in
  let kid t = dump_t_ (depth - 1, tvars) cx t in
  let use_kid use_t = dump_use_t_ (depth - 1, tvars) cx use_t in
  let tvar id = dump_tvar_ (depth - 1, tvars) cx id in
  let tout (reason, id) = spf ""(%s, %s)"" (string_of_reason reason) (tvar id) in
  let prop p = dump_prop_ (depth - 1, tvars) cx p in
  let string_of_use_op = string_of_use_op_rec in
  let call_arg_kid = function
    | Arg t -> kid t
    | SpreadArg t -> spf ""...%s"" (kid t)
  in
  let tlist ts = spf ""[%s]"" (String.concat ""; "" (Base.List.map ~f:kid ts)) in
  let props map =
    spf
      ""{%s}""
      (String.concat
         ""; ""
         (NameUtils.Map.fold
            (fun k p acc -> spf ""%s = %s"" (display_string_of_name k) (prop p) :: acc)
            map
            []
         )
      )
  in
  let propref = function
    | Named (r, x) -> spf ""%S %s"" (dump_reason cx r) (display_string_of_name x)
    | Computed t -> kid t
  in
  let lookup_kind = function
    | NonstrictReturning (default_opt, testid_opt) ->
      spf
        ""Nonstrict%s%s""
        (Base.Option.value_map default_opt ~default:"""" ~f:(fun (t, _) -> spf "" returning %s"" (kid t))
        )
        (Base.Option.value_map testid_opt ~default:"""" ~f:(fun (id, _) -> spf "" for test id %d"" id))
    | Strict r -> spf ""Strict %S"" (dump_reason cx r)
    | ShadowRead (_, ids) ->
      spf
        ""ShadowRead [%s]""
        (String.concat ""; "" (Nel.to_list ids |> Base.List.map ~f:Properties.string_of_id))
    | ShadowWrite ids ->
      spf
        ""ShadowWrite [%s]""
        (String.concat ""; "" (Nel.to_list ids |> Base.List.map ~f:Properties.string_of_id))
  in
  let lookup_action = function
    | ReadProp { tout = (reason, tout); _ } ->
      spf ""Read (%s, %s)"" (string_of_reason reason) (tvar tout)
    | WriteProp { tin; _ } -> spf ""Write %s"" (kid tin)
    | LookupProp (op, p) -> spf ""Lookup (%s, %s)"" (string_of_use_op op) (prop p)
    | SuperProp (_, p) -> spf ""Super %s"" (prop p)
    | MatchProp { prop_t = tin; _ } -> spf ""Match %s"" (kid tin)
  in
  let specialize_cache = function
    | None -> ""None""
    | Some rs -> spf ""Some [%s]"" (String.concat ""; "" @@ Base.List.map ~f:(dump_reason cx) rs)
  in
  let try_flow = function
    | UnionCases (use_op, t, _rep, ts) ->
      spf
        ""(%s, %s, [%s])""
        (string_of_use_op use_op)
        (kid t)
        (String.concat ""; "" (Base.List.map ~f:kid ts))
    | IntersectionCases (ts, use_t) ->
      spf ""([%s], %s)"" (String.concat ""; "" (Base.List.map ~f:kid ts)) (use_kid use_t)
  in
  let react_kit =
    React.(
      let resolved_object (_, pmap, _) = props pmap in
      let resolve_array = function
        | ResolveArray -> ""ResolveArray""
        | ResolveElem (todo, done_rev) -> spf ""ResolveElem (%s, %s)"" (tlist todo) (tlist done_rev)
      in
      let resolve_object = function
        | ResolveObject -> ""ResolveObject""
        | ResolveDict (_, todo, acc) -> spf ""ResolveDict (%s, %s)"" (props todo) (resolved_object acc)
        | ResolveProp (k, todo, acc) ->
          spf
            ""ResolveProp (%s, %s, %s)""
            (display_string_of_name k)
            (props todo)
            (resolved_object acc)
      in
      let simplify_prop_type =
        SimplifyPropType.(
          function
          | ArrayOf -> ""ArrayOf""
          | InstanceOf -> ""InstanceOf""
          | ObjectOf -> ""ObjectOf""
          | OneOf tool -> spf ""OneOf (%s)"" (resolve_array tool)
          | OneOfType tool -> spf ""OneOfType (%s)"" (resolve_array tool)
          | Shape tool -> spf ""Shape (%s)"" (resolve_object tool)
        )
      in
      function
      | CreateElement0 (_, config, (children, children_spread), tout)
      | CreateElement (_, _, config, (children, children_spread), tout) ->
        p
          ~extra:
            (spf
               ""CreateElement (%s; %s%s) => %s""
               (kid config)
               (String.concat ""; "" (Base.List.map ~f:kid children))
               (match children_spread with
               | Some children_spread -> spf ""; ...%s"" (kid children_spread)
               | None -> """")
               (kid tout)
            )
          t
      | ConfigCheck config -> spf ""ConfigCheck (%s)"" (kid config)
      | GetProps tout -> spf ""GetProps (%s)"" (kid tout)
      | GetConfig tout -> spf ""GetConfig (%s)"" (kid tout)
      | GetConfigType (default_props, tout) ->
        spf ""GetConfigType (%s, %s)"" (kid default_props) (kid tout)
      | GetRef tout -> spf ""GetRef (%s)"" (kid tout)
      | SimplifyPropType (tool, tout) ->
        spf ""SimplifyPropType (%s, %s)"" (simplify_prop_type tool) (kid tout)
    )
  in
  let slice { Object.reason = _; props; flags = { obj_kind; _ }; generics = _; interface = _ } =
    let xs =
      match obj_kind with
      | Indexed { dict_polarity = p; _ } -> [Polarity.sigil p ^ ""[]""]
      | Exact
      | Inexact
      | UnsealedInFile _ ->
        []
    in
    let xs =
      NameUtils.Map.fold
        (fun k (t, _, _) xs ->
          let opt =
            match t with
            | OptionalT _ -> ""?""
            | _ -> """"
          in
          (display_string_of_name k ^ opt) :: xs)
        props
        xs
    in
    let xs = String.concat ""; "" xs in
    match obj_kind with
    | Exact -> spf ""{|%s|}"" xs
    | _ -> spf ""{%s}"" xs
  in
  let operand_slice reason prop_map dict =
    let props =
      NameUtils.Map.fold
        (fun k p acc ->
          match (Type.Property.read_t p, Type.Property.write_t p) with
          | (Some t, _)
          | (_, Some t) ->
            NameUtils.Map.add k (t, true, false) acc
          | _ -> acc)
        prop_map
        NameUtils.Map.empty
    in
    let obj_kind =
      match dict with
      | None -> Exact
      | Some d -> Indexed d
    in
    let flags = { obj_kind; frozen = false } in
    slice { Object.reason; props; flags; generics = Generic.spread_empty; interface = None }
  in
  let object_kit =
    Object.(
      let join (_loc, op) =
        match op with
        | And -> ""And""
        | Or -> ""Or""
      in
      let resolved xs = spf ""[%s]"" (String.concat ""; "" (Base.List.map ~f:slice (Nel.to_list xs))) in
      let resolve = function
        | Next -> ""Next""
        | List0 (todo, j) ->
          spf
            ""List0 ([%s], %s)""
            (String.concat ""; "" (Base.List.map ~f:kid (Nel.to_list todo)))
            (join j)
        | List (todo, done_rev, j) ->
          spf
            ""List ([%s], [%s], %s)""
            (String.concat ""; "" (Base.List.map ~f:kid todo))
            (String.concat ""; "" (Base.List.map ~f:resolved (Nel.to_list done_rev)))
            (join j)
      in
      let resolve_tool = function
        | Resolve tool -> spf ""Resolve %s"" (resolve tool)
        | Super (s, tool) -> spf ""Super (%s, %s)"" (slice s) (resolve tool)
      in
      let acc_element = function
        | Spread.InlineSlice { Spread.reason; prop_map; dict; generics = _ } ->
          operand_slice reason prop_map dict
        | Spread.ResolvedSlice xs -> resolved xs
      in
      let spread target state =
        Object.Spread.(
          let target =
            match target with
            | Annot { make_exact } -> spf ""Annot { make_exact=%b }"" make_exact
            | Value { make_seal } -> spf ""Value {make_seal=%b"" (bool_of_sealtype make_seal)
          in
          let spread_operand = function
            | Slice { Spread.reason; prop_map; dict; generics = _ } ->
              operand_slice reason prop_map dict
            | Type t -> kid t
          in
          let state =
            let { todo_rev; acc; spread_id; union_reason; curr_resolve_idx } = state in
            spf
              ""{todo_rev=[%s]; acc=[%s]; spread_id=%s; curr_resolve_idx=%s; union_reason=%s}""
              (String.concat ""; "" (Base.List.map ~f:spread_operand todo_rev))
              (String.concat ""; "" (Base.List.map ~f:acc_element acc))
              (string_of_int spread_id)
              (string_of_int curr_resolve_idx)
              (Base.Option.value_map union_reason ~default:""None"" ~f:(dump_reason cx))
          in
          spf ""Spread (%s, %s)"" target state
        )
      in
      let rest merge_mode state =
        Object.Rest.(
          spf
            ""Rest ({merge_mode=%s}, %s)""
            (match merge_mode with
            | Sound -> ""Sound""
            | IgnoreExactAndOwn -> ""IgnoreExactAndOwn""
            | ReactConfigMerge _ -> ""ReactConfigMerge"")
            (match state with
            | One t -> spf ""One (%s)"" (kid t)
            | Done o -> spf ""Done (%s)"" (resolved o))
        )
      in
      let react_props state =
        Object.ReactConfig.(
          spf
            ""(%s)""
            (match state with
            | Config _ -> ""Config""
            | Defaults _ -> ""Defaults"")
        )
      in
      let tool = function
        | ReadOnly -> ""ReadOnly""
        | Partial -> ""Partial""
        | ObjectRep -> ""ObjectRep""
        | ObjectWiden id -> spf ""ObjectWiden (%s)"" (string_of_int id)
        | Spread (options, state) -> spread options state
        | Rest (options, state) -> rest options state
        | ReactConfig state -> react_props state
      in
      (fun a b -> spf ""(%s, %s)"" (resolve_tool a) (tool b))
    )
  in
  let method_action = function
    | CallM { meth_args_tlist; meth_tout = (call_r, call_tvar); meth_generic_this; _ }
    | ChainM (_, _, _, { meth_args_tlist; meth_tout = (call_r, call_tvar); meth_generic_this; _ }, _)
      ->
      spf
        ""<this: %s>(%s) => (%s, %s)""
        (Base.Option.value_map ~f:kid ~default:""None"" meth_generic_this)
        (String.concat ""; "" (Base.List.map ~f:call_arg_kid meth_args_tlist))
        (string_of_reason call_r)
        (tvar call_tvar)
  in
  if depth = 0 then
    string_of_use_ctor t
  else
    match t with
    | UseT (use_op, OpenT (r, id)) ->
      spf ""UseT (%s, OpenT (%S, %d))"" (string_of_use_op use_op) (dump_reason cx r) id
    | UseT (use_op, (DefT (_, trust, _) as t)) ->
      spf
        ""UseT (%s, %s%s)""
        (string_of_use_op use_op)
        ( if Context.trust_tracking cx then
          string_of_trust_rep (lookup_trust cx) trust
        else
          """"
        )
        (kid t)
    | UseT (use_op, t) -> spf ""UseT (%s, %s)"" (string_of_use_op use_op) (kid t)
    | AdderT (use_op, _, _, x, y) ->
      p ~extra:(spf ""%s, %s, %s"" (string_of_use_op use_op) (kid x) (kid y)) t
    | AndT (_, x, y) -> p ~extra:(spf ""%s, %s"" (kid x) (tout y)) t
    | ArrRestT (use_op, _, _, _) -> p ~extra:(string_of_use_op use_op) t
    | AssertArithmeticOperandT _ -> p t
    | AssertBinaryInLHST _ -> p t
    | AssertBinaryInRHST _ -> p t
    | AssertForInRHST _ -> p t
    | AssertImportIsValueT _ -> p t
    | AssertInstanceofRHST _ -> p t
    | AssertIterableT _ -> p t
    | BecomeT { reason = _; t = arg; empty_success = _ } -> p ~extra:(kid arg) t
    | BindT (use_op, _, _) -> p t ~extra:(string_of_use_op use_op)
    | CallElemT (_, _, _, _) -> p t
    | CallT (use_op, _, { call_args_tlist; call_tout = (call_r, call_tvar); call_this_t; _ }) ->
      p
        ~extra:
          (spf
             ""%s, <this: %s>(%s) => (%s, %s)""
             (string_of_use_op use_op)
             (kid call_this_t)
             (String.concat ""; "" (Base.List.map ~f:call_arg_kid call_args_tlist))
             (string_of_reason call_r)
             (tvar call_tvar)
          )
        t
    | CallLatentPredT _ -> p t
    | CallOpenPredT _ -> p t
    | ChoiceKitUseT (_, TryFlow (_, spec)) -> p ~extra:(try_flow spec) t
    | ChoiceKitUseT (_, FullyResolveType id) -> p ~extra:(tvar id) t
    | CJSExtractNamedExportsT _ -> p t
    | CJSRequireT _ -> p t
    | ComparatorT { arg; _ } -> p ~extra:(kid arg) t
    | ConstructorT _ -> p t
    | CopyNamedExportsT _ -> p t
    | CopyTypeExportsT _ -> p t
    | CheckUntypedImportT _ -> p t
    | DebugPrintT _ -> p t
    | DebugSleepT _ -> p t
    | ElemT _ -> p t
    | ExportNamedT (_, tmap, _export_kind, arg) ->
      p
        t
        ~extra:
          (spf
             ""%s, {%s}""
             (kid arg)
             (String.concat
                ""; ""
                (Base.List.map
                   ~f:(fun (x, _) -> display_string_of_name x)
                   (NameUtils.Map.bindings tmap)
                )
             )
          )
    | ExportTypeT _ -> p t
    | FunImplicitVoidReturnT _ -> p t
    | AssertExportIsTypeT _ -> p t
    | GetElemT (_, _, ix, (preason, ptvar)) ->
      p ~extra:(spf ""%s, (%s, %s)"" (kid ix) (string_of_reason preason) (tvar ptvar)) t
    | GetKeysT _ -> p t
    | GetValuesT _ -> p t
    | MatchPropT (use_op, _, prop, (preason, ptvar))
    | GetPropT (use_op, _, _, prop, (preason, ptvar)) ->
      p
        ~extra:
          (spf
             ""%s, (%s), (%s, %s)""
             (string_of_use_op use_op)
             (propref prop)
             (string_of_reason preason)
             (tvar ptvar)
          )
        t
    | GetPrivatePropT (_, _, prop, _, _, (preason, ptvar)) ->
      p ~extra:(spf ""(%s), (%s, %s)"" prop (string_of_reason preason) (tvar ptvar)) t
    | GetProtoT (_, (_, arg)) -> p ~extra:(tvar arg) t
    | GetStaticsT (_, arg) -> p ~extra:(tvar arg) t
    | GuardT (pred, result, sink) ->
      p
        ~reason:false
        ~extra:(spf ""%s, %s, %s"" (string_of_predicate pred) (kid result) (tout sink))
        t
    | HasOwnPropT _ -> p t
    | IdxUnMaybeifyT _ -> p t
    | IdxUnwrap _ -> p t
    | ImportDefaultT _ -> p t
    | ImportModuleNsT _ -> p t
    | ImportNamedT _ -> p t
    | ImportTypeofT _ -> p t
    | ImportTypeT _ -> p t
    | IntersectionPreprocessKitT _ -> p t
    | InvariantT _ -> p t
    | LookupT { lookup_kind = kind; propref = prop; lookup_action = action; ids; _ } ->
      p
        ~extra:
          (spf
             ""%S, %s, %s, [%s]""
             (propref prop)
             (lookup_kind kind)
             (lookup_action action)
             (match ids with
             | None -> ""None""
             | Some ids ->
               spf
                 ""Some %s""
                 (String.concat
                    ""; ""
                    (Properties.Set.elements ids |> Base.List.map ~f:Properties.string_of_id)
                 ))
          )
        t
    | MakeExactT _ -> p t
    | MapTypeT _ -> p t
    | MethodT (_, _, _, prop, action, _) ->
      p ~extra:(spf ""(%s, %s)"" (propref prop) (method_action action)) t
    | PrivateMethodT (_, _, _, prop, _, _, action, _) ->
      p ~extra:(spf ""(%s), (%s)"" prop (method_action action)) t
    | MixinT (_, arg) -> p ~extra:(kid arg) t
    | NotT (_, arg) -> p ~extra:(tout arg) t
    | NullishCoalesceT (_, x, y) -> p ~extra:(spf ""%s, %s"" (kid x) (tout y)) t
    | ObjAssignToT (_, _, arg1, arg2, _) -> p t ~extra:(spf ""%s, %s"" (kid arg1) (kid arg2))
    | ObjAssignFromT (_, _, arg1, arg2, _) -> p t ~extra:(spf ""%s, %s"" (kid arg1) (kid arg2))
    | ObjRestT (_, xs, arg, _) -> p t ~extra:(spf ""[%s], %s"" (String.concat ""; "" xs) (kid arg))
    | ObjSealT _ -> p t
    | ObjTestProtoT _ -> p t
    | ObjTestT _ -> p t
    | OptionalChainT { t_out; voided_out; _ } ->
      p ~extra:(spf ""%s, %s"" (use_kid t_out) (kid voided_out)) t
    | OptionalIndexedAccessT { index = OptionalIndexedAccessTypeIndex index_type; _ } ->
      p ~extra:(kid index_type) t
    | OptionalIndexedAccessT { index = OptionalIndexedAccessStrLitIndex name; _ } ->
      p ~extra:(display_string_of_name name) t
    | OrT (_, x, y) -> p ~extra:(spf ""%s, %s"" (kid x) (tout y)) t
    | PredicateT (pred, arg) ->
      p ~reason:false ~extra:(spf ""%s, %s"" (string_of_predicate pred) (tout arg)) t
    | ReactKitT (use_op, _, tool) ->
      p t ~extra:(spf ""%s, %s"" (string_of_use_op use_op) (react_kit tool))
    | RefineT _ -> p t
    | ReactPropsToOut (_, props)
    | ReactInToProps (_, props) ->
      p ~extra:(kid props |> spf ""%s"") t
    | ReposLowerT (_, use_desc, arg) -> p t ~extra:(spf ""use_desc=%b, %s"" use_desc (use_kid arg))
    | ReposUseT (_, use_desc, use_op, arg) ->
      p t ~extra:(spf ""use_desc=%b, %s"" use_desc (use_kid (UseT (use_op, arg))))
    | ResolveSpreadT (use_op, _, { rrt_resolve_to; _ }) ->
      (match rrt_resolve_to with
      | ResolveSpreadsToArrayLiteral (_, elem_t, tout)
      | ResolveSpreadsToArray (elem_t, tout) ->
        p ~extra:(spf ""%s, %s, %s"" (string_of_use_op use_op) (kid elem_t) (kid tout)) t
      | ResolveSpreadsToMultiflowPartial (_, _, _, tout) ->
        p ~extra:(spf ""%s, %s"" (string_of_use_op use_op) (kid tout)) t
      | ResolveSpreadsToCallT (_, tin) ->
        p ~extra:(spf ""%s, %s"" (string_of_use_op use_op) (kid tin)) t
      | ResolveSpreadsToMultiflowCallFull _
      | ResolveSpreadsToMultiflowSubtypeFull _
      | ResolveSpreadsToCustomFunCall _ ->
        p ~extra:(string_of_use_op use_op) t)
    | SentinelPropTestT (_, l, _key, sense, sentinel, result) ->
      p
        ~reason:false
        ~extra:(spf ""%s, %b, %s, %s"" (kid l) sense (string_of_sentinel sentinel) (tout result))
        t
    | SubstOnPredT (_, _, subst, arg) ->
      let subst =
        SMap.bindings subst
        |> List.map (fun (k, v) -> spf ""%s -> %s"" k (Key.string_of_key v))
        |> String.concat "", ""
      in
      p t ~extra:(spf ""[subst: {%s}] %s"" subst (kid arg))
    | SuperT _ -> p t
    | ImplementsT (_, arg) -> p ~reason:false ~extra:(kid arg) t
    | SetElemT (_, _, ix, _, etype, _) -> p ~extra:(spf ""%s, %s"" (kid ix) (kid etype)) t
    | SetPropT (use_op, _, prop, _, _, ptype, _) ->
      p ~extra:(spf ""%s, (%s), %s"" (string_of_use_op use_op) (propref prop) (kid ptype)) t
    | SetPrivatePropT (_, _, prop, _, _, _, ptype, _) ->
      p ~extra:(spf ""(%s), %s"" prop (kid ptype)) t
    | SetProtoT (_, arg) -> p ~extra:(kid arg) t
    | SpecializeT (_, _, _, cache, args_opt, ret) ->
      p
        ~extra:
          begin
            match args_opt with
            | Some args ->
              spf
                ""%s, [%s], %s""
                (specialize_cache cache)
                (String.concat ""; "" (Base.List.map ~f:kid args))
                (kid ret)
            | None -> spf ""%s, %s"" (specialize_cache cache) (kid ret)
          end
        t
    | StrictEqT { arg; _ }
    | EqT { arg; _ } ->
      p ~extra:(kid arg) t
    | ObjKitT (use_op, _, resolve_tool, tool, tout) ->
      p
        ~extra:(spf ""%s, %s, %s"" (string_of_use_op use_op) (object_kit resolve_tool tool) (kid tout))
        t
    | TestPropT (use_op, _, _, prop, (preason, ptvar)) ->
      p
        ~extra:
          (spf
             ""%s, (%s), (%s, %s)""
             (string_of_use_op use_op)
             (propref prop)
             (string_of_reason preason)
             (tvar ptvar)
          )
        t
    | ThisSpecializeT (_, this, _) -> p ~extra:(spf ""%s"" (kid this)) t
    | ToStringT (_, arg) -> p ~extra:(use_kid arg) t
    | UnaryMinusT _ -> p t
    | UnifyT (x, y) -> p ~reason:false ~extra:(spf ""%s, %s"" (kid x) (kid y)) t
    | VarianceCheckT (_, _, args, pol) ->
      p
        ~extra:
          (spf ""[%s], %s"" (String.concat ""; "" (Base.List.map ~f:kid args)) (Polarity.string pol))
        t
    | ConcretizeTypeAppsT _ -> p t
    | TypeAppVarianceCheckT _ -> p t
    | TypeCastT (_, arg) -> p ~reason:false ~extra:(kid arg) t
    | EnumCastT { use_op = _; enum = (reason, trust, enum) } ->
      p ~reason:false ~extra:(kid (DefT (reason, trust, EnumT enum))) t
    | EnumExhaustiveCheckT { check; _ } ->
      let check_str =
        match check with
        | EnumExhaustiveCheckPossiblyValid _ -> ""EnumExhaustiveCheckPossiblyValid""
        | EnumExhaustiveCheckInvalid _ -> ""EnumExhaustiveCheckInvalid""
      in
      p ~extra:check_str t
    | FilterOptionalT (_, arg) -> p ~reason:false ~extra:(kid arg) t
    | FilterMaybeT (_, arg) -> p ~reason:false ~extra:(kid arg) t
    | SealGenericT { name; cont = Lower (_, l); _ } ->
      p ~extra:(spf ""%s <~ %s"" (Subst_name.string_of_subst_name name) (kid l)) t
    | SealGenericT { name; cont = Upper u; _ } ->
      p ~extra:(spf ""%s ~> %s"" (Subst_name.string_of_subst_name name) (use_kid u)) t
    | CondT (_, then_t, else_t, tout) ->
      p
        t
        ~extra:
          (spf
             ""%s, %s, %s""
             (match then_t with
             | None -> ""None""
             | Some t -> spf ""Some (%s)"" (kid t))
             (kid else_t)
             (kid tout)
          )
    | ExtendsUseT (_, _, nexts, l, u) ->
      p
        ~extra:(spf ""[%s], %s, %s"" (String.concat ""; "" (Base.List.map ~f:kid nexts)) (kid l) (kid u))
        t
    | DestructuringT (_, k, s, (r, tout), _) ->
      p
        t
        ~extra:
          (spf
             ""%s, %s, (%s, %s)""
             (string_of_destruct_kind k)
             (string_of_selector s)
             (string_of_reason r)
             (tvar tout)
          )
    | CreateObjWithComputedPropT { reason = _; value; tout_tvar } ->
      p t ~extra:(spf ""%s %s"" (kid value) (kid (OpenT tout_tvar)))
    | ResolveUnionT { resolved; unresolved; upper; id; _ } ->
      p
        t
        ~extra:
          (spf
             ""%d [%s], [%s], %s""
             id
             (String.concat ""; "" (Base.List.map ~f:kid resolved))
             (String.concat ""; "" (Base.List.map ~f:kid unresolved))
             (use_kid upper)
          )

and dump_tvar_ (depth, tvars) cx id =
  if ISet.mem id tvars then
    spf ""%d, ^"" id
  else
    let stack = ISet.add id tvars in
    Constraint.(
      try
        match Context.find_tvar cx id with
        | Goto g -> spf ""%d, Goto %d"" id g
        | Root { constraints = Resolved (_, t); _ } ->
          spf ""%d, Resolved %s"" id (dump_t_ (depth - 1, stack) cx t)
        | Root { constraints = FullyResolved (_, (lazy t)); _ } ->
          spf ""%d, FullyResolved %s"" id (dump_t_ (depth - 1, stack) cx t)
        | Root { constraints = Unresolved { lower; upper; _ }; _ } ->
          if lower = TypeMap.empty && upper = UseTypeMap.empty then
            spf ""%d"" id
          else
            spf
              ""%d, [%s], [%s]""
              id
              (String.concat
                 ""; ""
                 (List.rev
                    (TypeMap.fold (fun t _ acc -> dump_t_ (depth - 1, stack) cx t :: acc) lower [])
                 )
              )
              (String.concat
                 ""; ""
                 (List.rev
                    (UseTypeMap.fold
                       (fun (use_t, _) _ acc -> dump_use_t_ (depth - 1, stack) cx use_t :: acc)
                       upper
                       []
                    )
                 )
              )
      with
      | Union_find.Tvar_not_found _ -> spf ""Not Found: %d"" id
    )

and dump_prop_ (depth, tvars) cx p =
  let kid t = dump_t_ (depth, tvars) cx t in
  match p with
  | Field (_loc, t, polarity) -> spf ""Field (%s) %s"" (string_of_polarity polarity) (kid t)
  | Get (_loc, t) -> spf ""Get %s"" (kid t)
  | Set (_loc, t) -> spf ""Set %s"" (kid t)
  | GetSet (_loc1, t1, _loc2, t2) -> spf ""Get %s Set %s"" (kid t1) (kid t2)
  | Method (_loc, t) -> spf ""Method %s"" (kid t)

(* This is the type-dump debugging API.
   We should make sure these are not called recursively to avoid circumventing
   one of the termination mechanisms: depth or tvar-set.
*)
let dump_t ?(depth = 3) cx t = dump_t_ (depth, ISet.empty) cx t

let dump_use_t ?(depth = 3) cx t = dump_use_t_ (depth, ISet.empty) cx t

let dump_prop ?(depth = 3) cx p = dump_prop_ (depth, ISet.empty) cx p

let dump_tvar ?(depth = 3) cx id = dump_tvar_ (depth, ISet.empty) cx id

let dump_flow ?(depth = 3) cx (l, u) =
  spf ""Lower: %s ~>\n Upper: %s"" (dump_t ~depth cx l) (dump_use_t ~depth cx u)

(*****************************************************)

(* scopes and types *)

let string_of_scope_entry =
  Scope.(
    let string_of_value_binding
        cx
        {
          Entry.kind;
          value_state;
          value_declare_loc;
          value_assign_loc;
          specific;
          general;
          closure_writes;
          provider;
        } =
      let general_str =
        match general with
        | Annotated t -> spf ""Annotated %s"" (dump_t cx t)
        | Inferred t -> spf ""Inferred %s"" (dump_t cx t)
      in
      spf
        ""{ kind: %s; value_state: %s; value_declare_loc: %S; value_assign_loc: %s; specific: %s; general: %s; provider:%s;%s }""
        (Entry.string_of_value_kind kind)
        (State.to_string value_state)
        (string_of_aloc value_declare_loc)
        (string_of_aloc value_assign_loc)
        (dump_t cx specific)
        general_str
        (dump_t cx provider)
        (Base.Option.value_map closure_writes ~default:"""" ~f:(fun (locs, t, _) ->
             spf
               ""; closure_writes: { locs: { %s }; t: %s }""
               (ListUtils.to_string "", "" string_of_aloc @@ ALocSet.elements locs)
               (dump_t cx t)
         )
        )
    in
    let string_of_type_binding cx { Entry.type_state; type_loc; type_; type_binding_kind = _ } =
      spf
        ""{ type_state: %s; type_loc: %S; type_: %s }""
        (State.to_string type_state)
        (string_of_aloc type_loc)
        (dump_t cx type_)
    in
    fun cx ->
      Entry.(
        function
        | Value r -> spf ""Value %s"" (string_of_value_binding cx r)
        | Type r -> spf ""Type %s"" (string_of_type_binding cx r)
        | Class r -> spf ""Class %s"" (ALoc.debug_to_string (r.class_binding_id :> ALoc.t))
      )
  )

let string_of_scope_entries cx entries =
  let strings =
    NameUtils.Map.fold
      (fun name entry acc ->
        spf ""%s: %s"" (Reason.display_string_of_name name) (string_of_scope_entry cx entry) :: acc)
      entries
      []
    |> String.concat ""; \n""
  in
  spf ""[ %s ]"" strings

let string_of_scope_refi cx { Scope.refi_loc; refined; original } =
  spf
    ""{ refi_loc: %S; refined: %s; original: %s }""
    (string_of_aloc refi_loc)
    (dump_t cx refined)
    (dump_t cx original)

let string_of_scope_refis cx refis =
  let strings =
    Key_map.fold
      (fun key refi acc ->
        spf ""%s: %s"" (Key.string_of_key key) (string_of_scope_refi cx refi) :: acc)
      refis
      []
    |> String.concat "";\n""
  in
  spf ""[ %s ]"" strings

let string_of_scope cx scope =
  Scope.(
    spf
      ""{ kind: %s;\nentries:\n%s\nrefis:\n%s\n}""
      (string_of_kind scope.kind)
      (string_of_scope_entries cx scope.entries)
      (string_of_scope_refis cx scope.refis)
  )

let string_of_reason cx reason =
  let strip_root =
    if Context.should_strip_root cx then
      Some (Context.root cx)
    else
      None
  in
  Reason.string_of_reason ~strip_root reason

let string_of_file cx =
  let filename = File_key.to_string (Context.file cx) in
  match Context.is_verbose cx with
  | false -> filename
  | true ->
    let root_str = Path.to_string (Context.root cx) ^ Filename.dir_sep in
    if String_utils.string_starts_with filename root_str then
      Files.relative_path root_str filename
    else
      filename

let string_of_default =
  Default.fold
    ~expr:(fun (loc, _) -> spf ""Expr %s"" (string_of_loc loc))
    ~selector:(fun _ str sel -> spf ""Selector (%s) (%s)"" str (string_of_selector sel))
    ~cons:(fun str default -> spf ""Cons (%s) (%s)"" str default)

let string_of_signature_error pp_loc err =
  let open Signature_error in
  match err with
  | ExpectedAnnotation (loc, sort) ->
    spf ""Expected annotation at %s @ %s"" (Expected_annotation_sort.to_string sort) (pp_loc loc)
  | UnexpectedObjectKey (_loc, key_loc) -> spf ""Expected simple object key @ %s"" (pp_loc key_loc)
  | UnexpectedArraySpread (_loc, spread_loc) ->
    spf ""Unexpected array spread @ %s"" (pp_loc spread_loc)
  | UnexpectedArrayHole loc -> spf ""Unexpected array hole @ %s"" (pp_loc loc)
  | EmptyArray loc -> spf ""Cannot determine the element type of an empty array @ %s"" (pp_loc loc)
  | EmptyObject loc ->
    spf ""Cannot determine types of initialized properties of an empty object @ %s"" (pp_loc loc)
  | UnexpectedExpression (loc, esort) ->
    spf
      ""Cannot determine the type of this %s @ %s""
      (Flow_ast_utils.ExpressionSort.to_string esort)
      (pp_loc loc)

let dump_error_message =
  let open Error_message in
  let string_of_use_op = string_of_use_op_rec in
  let dump_internal_error = function
    | AbnormalControlFlow -> ""AbnormalControlFlow""
    | MethodNotAFunction -> ""MethodNotAFunction""
    | OptionalMethod -> ""OptionalMethod""
    | PredFunWithoutParamNames -> ""PredFunWithoutParamNames""
    | UnsupportedGuardPredicate _ -> ""UnsupportedGuardPredicate""
    | BreakEnvMissingForCase -> ""BreakEnvMissingForCase""
    | PropertyDescriptorPropertyCannotBeRead -> ""PropertyDescriptorPropertyCannotBeRead""
    | ForInLHS -> ""ForInLHS""
    | ForOfLHS -> ""ForOfLHS""
    | InstanceLookupComputed -> ""InstanceLookupComputed""
    | PropRefComputedOpen -> ""PropRefComputedOpen""
    | PropRefComputedLiteral -> ""PropRefComputedLiteral""
    | ShadowReadComputed -> ""ShadowReadComputed""
    | ShadowWriteComputed -> ""ShadowWriteComputed""
    | RestParameterNotIdentifierPattern -> ""RestParameterNotIdentifierPattern""
    | InterfaceTypeSpread -> ""InterfaceTypeSpread""
    | Error_message.DebugThrow -> ""DebugThrow""
    | ParseJobException _ -> ""ParseJobException""
    | MergeTimeout _ -> ""MergeTimeout""
    | MergeJobException _ -> ""MergeJobException""
    | CheckTimeout _ -> ""CheckTimeout""
    | CheckJobException _ -> ""CheckJobException""
    | UnexpectedTypeapp _ -> ""UnexpectedTypeapp""
    | UnexpectedAnnotationInference _ -> ""UnexpectedAnnotationInference""
  in
  let dump_upper_kind = function
    | IncompatibleGetPropT _ -> ""IncompatibleGetPropT""
    | IncompatibleSetPropT _ -> ""IncompatibleSetPropT""
    | IncompatibleMatchPropT _ -> ""IncompatibleSetPropT""
    | IncompatibleGetPrivatePropT -> ""IncompatibleGetPrivatePropT""
    | IncompatibleSetPrivatePropT -> ""IncompatibleSetPrivatePropT""
    | IncompatibleMethodT _ -> ""IncompatibleMethodT""
    | IncompatibleCallT -> ""IncompatibleCallT""
    | IncompatibleMixedCallT -> ""IncompatibleMixedCallT""
    | IncompatibleGetElemT _ -> ""IncompatibleGetElemT""
    | IncompatibleSetElemT _ -> ""IncompatibleSetElemT""
    | IncompatibleCallElemT _ -> ""IncompatibleCallElemT""
    | IncompatibleElemTOfArrT -> ""IncompatibleElemTOfArrT""
    | IncompatibleObjAssignFromTSpread -> ""IncompatibleObjAssignFromTSpread""
    | IncompatibleObjAssignFromT -> ""IncompatibleObjAssignFromT""
    | IncompatibleObjRestT -> ""IncompatibleObjRestT""
    | IncompatibleObjSealT -> ""IncompatibleObjSealT""
    | IncompatibleArrRestT -> ""IncompatibleArrRestT""
    | IncompatibleSuperT -> ""IncompatibleSuperT""
    | IncompatibleMixinT -> ""IncompatibleMixinT""
    | IncompatibleSpecializeT -> ""IncompatibleSpecializeT""
    | IncompatibleThisSpecializeT -> ""IncompatibleThisSpecializeT""
    | IncompatibleVarianceCheckT -> ""IncompatibleVarianceCheckT""
    | IncompatibleGetKeysT -> ""IncompatibleGetKeysT""
    | IncompatibleHasOwnPropT _ -> ""IncompatibleHasOwnPropT""
    | IncompatibleGetValuesT -> ""IncompatibleGetValuesT""
    | IncompatibleUnaryMinusT -> ""IncompatibleUnaryMinusT""
    | IncompatibleMapTypeTObject -> ""IncompatibleMapTypeTObject""
    | IncompatibleTypeAppVarianceCheckT -> ""IncompatibleTypeAppVarianceCheckT""
    | IncompatibleGetStaticsT -> ""IncompatibleGetStaticsT""
    | IncompatibleBindT -> ""IncompatibleBindT""
    | IncompatibleUnclassified ctor -> spf ""IncompatibleUnclassified %S"" ctor
  in
  fun cx err ->
    match err with
    | EIncompatible
        {
          lower = (reason_lower, _lower_kind);
          upper = (reason_upper, upper_kind);
          use_op;
          branches = _;
        } ->
      spf
        ""EIncompatible { lower = (%s, _); upper = (%s, %s); use_op = %s; branches = _ }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (dump_upper_kind upper_kind)
        (match use_op with
        | None -> ""None""
        | Some use_op -> spf ""Some(%s)"" (string_of_use_op use_op))
    | EIncompatibleDefs { use_op; reason_lower; reason_upper; branches = _ } ->
      spf
        ""EIncompatibleDefs { reason_lower = %s; reason_upper = %s; use_op = %s; branches = _ }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (string_of_use_op use_op)
    | EIncompatibleProp { reason_prop; reason_obj; special = _; prop = _; use_op = _ } ->
      spf
        ""EIncompatibleProp { reason_prop = %s; reason_obj = %s; special = _; prop = _; use_op = _ }""
        (dump_reason cx reason_prop)
        (dump_reason cx reason_obj)
    | EDebugPrint (reason, _) -> spf ""EDebugPrint (%s, _)"" (dump_reason cx reason)
    | EExportValueAsType (reason, name) ->
      spf ""EExportValueAsType (%s, %s)"" (dump_reason cx reason) (display_string_of_name name)
    | EImportValueAsType (reason, str) ->
      spf ""EImportValueAsType (%s, %s)"" (dump_reason cx reason) str
    | EImportTypeAsTypeof (reason, str) ->
      spf ""EImportTypeAsTypeof (%s, %s)"" (dump_reason cx reason) str
    | EImportTypeAsValue (reason, str) ->
      spf ""EImportTypeAsValue (%s, %s)"" (dump_reason cx reason) str
    | ERefineAsValue (reason, name) ->
      spf ""ERefineAsValue (%s, %s)"" (dump_reason cx reason) (display_string_of_name name)
    | ENoDefaultExport (reason, module_name, _) ->
      spf ""ENoDefaultExport (%s, %s)"" (dump_reason cx reason) module_name
    | EOnlyDefaultExport (reason, module_name, export_name) ->
      spf ""EOnlyDefaultExport (%s, %s, %s)"" (dump_reason cx reason) module_name export_name
    | ENoNamedExport (reason, module_name, export_name, _) ->
      spf ""ENoNamedExport (%s, %s, %s)"" (dump_reason cx reason) module_name export_name
    | EMissingTypeArgs { reason_op; reason_tapp; reason_arity; min_arity; max_arity } ->
      spf
        ""EMissingTypeArgs { reason_op=%s; reason_tapp=%s; reason_arity=%s; min_arity=%d; max_arity=%d }""
        (dump_reason cx reason_op)
        (dump_reason cx reason_tapp)
        (dump_reason cx reason_arity)
        min_arity
        max_arity
    | EAnyValueUsedAsType { reason_use } ->
      spf ""EAnyValueUsedAsType { use = %s }"" (dump_reason cx reason_use)
    | EValueUsedAsType { reason_use } ->
      spf ""EValueUsedAsType { use = %s }"" (dump_reason cx reason_use)
    | EExpectedStringLit { reason_lower; reason_upper; use_op } ->
      spf
        ""EExpectedStringLit { reason_lower = %s; reason_upper = %s; use_op = %s }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (string_of_use_op use_op)
    | EExpectedNumberLit { reason_lower; reason_upper; use_op } ->
      spf
        ""EExpectedNumberLit { reason_lower = %s; reason_upper = %s; use_op = %s }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (string_of_use_op use_op)
    | EExpectedBooleanLit { reason_lower; reason_upper; use_op } ->
      spf
        ""EExpectedBooleanLit { reason_lower = %s; reason_upper = %s; use_op = %s }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (string_of_use_op use_op)
    | EPropNotFound { prop_name = prop; reason_prop; reason_obj; use_op; suggestion } ->
      spf
        ""EPropNotFound (%s, %s, %s, %s, %s)""
        (match prop with
        | Some prop -> spf ""Some %s"" (display_string_of_name prop)
        | None -> ""None"")
        (dump_reason cx reason_prop)
        (dump_reason cx reason_obj)
        (string_of_use_op use_op)
        (match suggestion with
        | Some prop -> spf ""Some %s"" prop
        | None -> ""None"")
    | EPropNotReadable { reason_prop; prop_name; use_op } ->
      spf
        ""EPropNotReadable { reason_prop = %s; prop_name = %s; use_op = %s }""
        (dump_reason cx reason_prop)
        (match prop_name with
        | Some x -> spf ""%S"" (display_string_of_name x)
        | None -> ""(computed)"")
        (string_of_use_op use_op)
    | EPropNotWritable { reason_prop; prop_name; use_op } ->
      spf
        ""EPropNotWritable { reason_prop = %s; prop_name = %s; use_op = %s }""
        (dump_reason cx reason_prop)
        (match prop_name with
        | Some x -> spf ""%S"" (display_string_of_name x)
        | None -> ""(computed)"")
        (string_of_use_op use_op)
    | EPropPolarityMismatch ((reason1, reason2), x, _, _) ->
      spf
        ""EPropPolarityMismatch ((%s, %s), %s, _, _)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (match x with
        | Some x -> spf ""%S"" (display_string_of_name x)
        | None -> ""(computed)"")
    | EPolarityMismatch { reason; name; expected_polarity; actual_polarity } ->
      spf
        ""EPolarityMismatch { reason=%s; name=%S; expected_polarity=%s; actual_polarity=%s }""
        (dump_reason cx reason)
        name
        (Polarity.string expected_polarity)
        (Polarity.string actual_polarity)
    | EBuiltinLookupFailed { reason; name; potential_generator } ->
      spf
        ""EBuiltinLookupFailed { reason = %s; name = %S; potential_generator = %s }""
        (dump_reason cx reason)
        (match name with
        | Some x -> spf ""Some(%S)"" (Reason.display_string_of_name x)
        | None -> ""None"")
        (match potential_generator with
        | Some generator -> spf ""Some(%s)"" generator
        | None -> ""None"")
    | EStrictLookupFailed { reason_prop; reason_obj; name; suggestion; use_op } ->
      spf
        ""EStrictLookupFailed { reason_prop = %s; reason_obj = %s; name = %S; suggestion = %S; use_op = %s }""
        (dump_reason cx reason_prop)
        (dump_reason cx reason_obj)
        (match name with
        | Some x -> spf ""Some(%S)"" (display_string_of_name x)
        | None -> ""None"")
        (match suggestion with
        | Some x -> spf ""Some(%S)"" x
        | None -> ""None"")
        (match use_op with
        | Some use_op -> spf ""Some(%s)"" (string_of_use_op use_op)
        | None -> ""None"")
    | EPrivateLookupFailed ((reason1, reason2), x, use_op) ->
      spf
        ""EPrivateLookupFailed ((%s, %s), %s, %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (display_string_of_name x)
        (string_of_use_op use_op)
    | EAdditionMixed (reason, use_op) ->
      spf ""EAdditionMixed (%s, %s)"" (dump_reason cx reason) (string_of_use_op use_op)
    | EComparison (reason1, reason2) ->
      spf ""EComparison (%s, %s)"" (dump_reason cx reason1) (dump_reason cx reason2)
    | ENonStrictEqualityComparison (reason1, reason2) ->
      spf ""ENonStrictEqualityComparison (%s, %s)"" (dump_reason cx reason1) (dump_reason cx reason2)
    | ETupleArityMismatch ((reason1, reason2), arity1, arity2, use_op) ->
      spf
        ""ETupleArityMismatch (%s, %s, %d, %d, %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        arity1
        arity2
        (string_of_use_op use_op)
    | ENonLitArrayToTuple ((reason1, reason2), use_op) ->
      spf
        ""ENonLitArrayToTuple ((%s, %s), %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (string_of_use_op use_op)
    | ETupleOutOfBounds { use_op; reason; reason_op; length; index } ->
      spf
        ""ETupleOutOfBounds { use_op = %s; reason = %s; reason_op = %s; length = %d; index = %s }""
        (string_of_use_op use_op)
        (dump_reason cx reason)
        (dump_reason cx reason_op)
        length
        index
    | ETupleNonIntegerIndex { use_op; reason; index } ->
      spf
        ""ETupleNonIntegerIndex { use_op = %s; reason = %s; index = %s }""
        (string_of_use_op use_op)
        (dump_reason cx reason)
        index
    | ETupleUnsafeWrite { reason; use_op } ->
      spf
        ""ETupleUnsafeWrite { reason = %s; use_op = %s }""
        (dump_reason cx reason)
        (string_of_use_op use_op)
    | EROArrayWrite ((reason1, reason2), use_op) ->
      spf
        ""EROArrayWrite (%s, %s, %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (string_of_use_op use_op)
    | EUnionSpeculationFailed { use_op; reason; reason_op; branches = _ } ->
      spf
        ""EUnionSpeculationFailed { use_op = %s; reason = %s; reason_op = %s; branches = _ }""
        (string_of_use_op use_op)
        (dump_reason cx reason)
        (dump_reason cx reason_op)
    | ESpeculationAmbiguous { reason; _ } ->
      spf ""ESpeculationAmbiguous { reason = %s; _ }"" (dump_reason cx reason)
    | EIncompatibleWithExact ((reason1, reason2), use_op, _) ->
      spf
        ""EIncompatibleWithExact ((%s, %s), %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (string_of_use_op use_op)
    | EFunctionIncompatibleWithIndexer ((reason1, reason2), use_op) ->
      spf
        ""EFunctionIncompatibleWithIndexer((%s, %s), %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (string_of_use_op use_op)
    | EUnsupportedExact (reason1, reason2) ->
      spf ""EUnsupportedExact (%s, %s)"" (dump_reason cx reason1) (dump_reason cx reason2)
    | EIdxArity reason -> spf ""EIdxArity (%s)"" (dump_reason cx reason)
    | EIdxUse1 reason -> spf ""EIdxUse1 (%s)"" (dump_reason cx reason)
    | EIdxUse2 reason -> spf ""EIdxUse2 (%s)"" (dump_reason cx reason)
    | EUnexpectedThisType loc -> spf ""EUnexpectedThisType (%s)"" (string_of_aloc loc)
    | ETypeParamArity (loc, expected) ->
      spf ""ETypeParamArity (%s, %d)"" (string_of_aloc loc) expected
    | ETypeParamMinArity (loc, expected) ->
      spf ""ETypeParamMinArity (%s, %d)"" (string_of_aloc loc) expected
    | ECallTypeArity { call_loc; is_new; reason_arity; expected_arity } ->
      spf
        ""ECallTypeArity { call_loc=%s; is_new=%b; reason_arity=%s; expected_arity=%d; }""
        (string_of_aloc call_loc)
        is_new
        (dump_reason cx reason_arity)
        expected_arity
    | ETooManyTypeArgs (reason_tapp, reason_arity, maximum_arity) ->
      spf
        ""ETooManyTypeArgs (%s, %s, %d)""
        (dump_reason cx reason_tapp)
        (dump_reason cx reason_arity)
        maximum_arity
    | ETooFewTypeArgs (reason_tapp, reason_arity, minimum_arity) ->
      spf
        ""ETooFewTypeArgs (%s, %s, %d)""
        (dump_reason cx reason_tapp)
        (dump_reason cx reason_arity)
        minimum_arity
    | EInvalidTypeArgs (reason_tapp, reason_arity) ->
      spf ""EInvalidTypeArgs (%s, %s)"" (dump_reason cx reason_tapp) (dump_reason cx reason_arity)
    | EPropertyTypeAnnot loc -> spf ""EPropertyTypeAnnot (%s)"" (string_of_aloc loc)
    | EExportsAnnot loc -> spf ""EExportsAnnot (%s)"" (string_of_aloc loc)
    | ECharSetAnnot loc -> spf ""ECharSetAnnot (%s)"" (string_of_aloc loc)
    | EInvalidCharSet { invalid = (reason, _); valid; use_op } ->
      spf
        ""EInvalidCharSet { invalid = (%s, _); valid = %s; use_op = %s }""
        (dump_reason cx reason)
        (dump_reason cx valid)
        (string_of_use_op use_op)
    | EUnsupportedKeyInObjectType loc -> spf ""EUnsupportedKeyInObjectType (%s)"" (string_of_aloc loc)
    | EPredAnnot loc -> spf ""EPredAnnot (%s)"" (string_of_aloc loc)
    | ERefineAnnot loc -> spf ""ERefineAnnot (%s)"" (string_of_aloc loc)
    | ETrustedAnnot loc -> spf ""ETrustedAnnot (%s)"" (string_of_aloc loc)
    | EPrivateAnnot loc -> spf ""EPrivateAnnot (%s)"" (string_of_aloc loc)
    | EFunPredCustom ((reason1, reason2), msg) ->
      spf ""EFunPredCustom (%s, %s, %S)"" (dump_reason cx reason1) (dump_reason cx reason2) msg
    | EIncompatibleWithShape (lower, upper, use_op) ->
      spf
        ""EIncompatibleWithShape (%s, %s, %s)""
        (dump_reason cx lower)
        (dump_reason cx upper)
        (string_of_use_op use_op)
    | EInternal (loc, err) -> spf ""EInternal (%s, %s)"" (string_of_aloc loc) (dump_internal_error err)
    | EUnsupportedSyntax (loc, _) -> spf ""EUnsupportedSyntax (%s, _)"" (string_of_aloc loc)
    | EUseArrayLiteral loc -> spf ""EUseArrayLiteral (%s)"" (string_of_aloc loc)
    | EMissingAnnotation (reason, _) -> spf ""EMissingAnnotation (%s)"" (dump_reason cx reason)
    | EMissingLocalAnnotation reason -> spf ""EMissingLocalAnnotation (%s)"" (dump_reason cx reason)
    | EBindingError (_binding_error, loc, x, entry_loc) ->
      spf
        ""EBindingError (_, %s, %s, %s)""
        (string_of_aloc loc)
        (Reason.display_string_of_name x)
        (string_of_aloc entry_loc)
    | ERecursionLimit (reason1, reason2) ->
      spf ""ERecursionLimit (%s, %s)"" (dump_reason cx reason1) (dump_reason cx reason2)
    | EUnsafeGetSet loc -> spf ""EUnsafeGetSet (%s)"" (string_of_aloc loc)
    | EUninitializedInstanceProperty (loc, err) ->
      spf
        ""EUninitializedInstanceProperty (%s, %s)""
        (string_of_aloc loc)
        Lints.(
          match err with
          | PropertyNotDefinitelyInitialized -> ""PropertyNotDefinitelyInitialized""
          | ReadFromUninitializedProperty -> ""ReadFromUninitializedProperty""
          | MethodCallBeforeEverythingInitialized -> ""MethodCallBeforeEverythingInitialized""
          | PropertyFunctionCallBeforeEverythingInitialized ->
            ""PropertyFunctionCallBeforeEverythingInitialized""
          | ThisBeforeEverythingInitialized -> ""ThisBeforeEverythingInitialized""
        )
    | EEnumsNotEnabled loc -> spf ""EEnumsNotEnabled (%s)"" (string_of_aloc loc)
    | EIndeterminateModuleType loc -> spf ""EIndeterminateModuleType (%s)"" (string_of_aloc loc)
    | EBadExportPosition loc -> spf ""EBadExportPosition (%s)"" (string_of_aloc loc)
    | EBadExportContext (name, loc) -> spf ""EBadExportContext (%s, %s)"" name (string_of_aloc loc)
    | EBadDefaultImportAccess (loc, reason) ->
      spf ""EBadDefaultImportAccess (%s, %s)"" (string_of_aloc loc) (dump_reason cx reason)
    | EBadDefaultImportDestructuring loc ->
      spf ""EBadDefaultImportDestructuring (%s)"" (string_of_aloc loc)
    | EInvalidImportStarUse (loc, reason) ->
      spf ""EInvalidImportStarUse (%s, %s)"" (string_of_aloc loc) (dump_reason cx reason)
    | ENonConstVarExport (loc, reason) ->
      spf
        ""ENonConstVarExport (%s, %s)""
        (string_of_aloc loc)
        (Base.Option.value_map ~f:(dump_reason cx) ~default:""None"" reason)
    | EThisInExportedFunction loc -> spf ""EThisInExportedFunction (%s)"" (string_of_aloc loc)
    | EMixedImportAndRequire (loc, reason) ->
      spf ""EMixedImportAndRequire (%s, %s)"" (string_of_aloc loc) (dump_reason cx reason)
    | EToplevelLibraryImport loc -> spf ""EToplevelLibraryImport (%s)"" (string_of_aloc loc)
    | EExportRenamedDefault { loc; name; is_reexport } ->
      spf
        ""EExportRenamedDefault { loc = %s; name = %s; is_reexport = %B }""
        (string_of_aloc loc)
        (Base.Option.value ~default:""None"" name)
        is_reexport
    | EUnreachable loc -> spf ""EUnreachable (%s)"" (string_of_aloc loc)
    | EInvalidObjectKit { reason; reason_op; use_op } ->
      spf
        ""EInvalidObjectKit { reason = %s; reason_op = %s; use_op = %s }""
        (dump_reason cx reason)
        (dump_reason cx reason_op)
        (string_of_use_op use_op)
    | EInvalidTypeof (loc, name) -> spf ""EInvalidTypeof (%s, %S)"" (string_of_aloc loc) name
    | EBinaryInLHS reason -> spf ""EBinaryInLHS (%s)"" (dump_reason cx reason)
    | EBinaryInRHS reason -> spf ""EBinaryInRHS (%s)"" (dump_reason cx reason)
    | EArithmeticOperand reason -> spf ""EArithmeticOperand (%s)"" (dump_reason cx reason)
    | EForInRHS reason -> spf ""EForInRHS (%s)"" (dump_reason cx reason)
    | EInstanceofRHS reason -> spf ""EInstanceofRHS (%s)"" (dump_reason cx reason)
    | EObjectComputedPropertyAccess (reason1, reason2) ->
      spf ""EObjectComputedPropertyAccess (%s, %s)"" (dump_reason cx reason1) (dump_reason cx reason2)
    | EObjectComputedPropertyAssign (reason1, reason2) ->
      spf ""EObjectComputedPropertyAssign (%s, %s)"" (dump_reason cx reason1) (dump_reason cx reason2)
    | EInvalidLHSInAssignment loc -> spf ""EInvalidLHSInAssignment (%s)"" (string_of_aloc loc)
    | EIncompatibleWithUseOp { reason_lower; reason_upper; use_op } ->
      spf
        ""EIncompatibleWithUseOp { reason_lower = %s; reason_upper = %s; use_op = %s }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (string_of_use_op use_op)
    | ETrustIncompatibleWithUseOp (reason1, reason2, use_op) ->
      spf
        ""ETrustIncompatibleWithUseOp (%s, %s, %s)""
        (dump_reason cx reason1)
        (dump_reason cx reason2)
        (string_of_use_op use_op)
    | EUnsupportedImplements reason -> spf ""EUnsupportedImplements (%s)"" (dump_reason cx reason)
    | ENotAReactComponent { reason; use_op } ->
      spf
        ""ENotAReactComponent { reason = %s; use_op = %s }""
        (dump_reason cx reason)
        (string_of_use_op use_op)
    | EInvalidReactConfigType { reason; use_op } ->
      spf
        ""EInvalidReactConfigType { reason = %s; use_op = %s }""
        (dump_reason cx reason)
        (string_of_use_op use_op)
    | EInvalidReactPropType { reason; use_op; tool = _ } ->
      spf
        ""EInvalidReactPropType { reason = %s; use_op = %s; _ }""
        (dump_reason cx reason)
        (string_of_use_op use_op)
    | EReactElementFunArity (reason, _, _) ->
      spf ""EReactElementFunArity (%s)"" (dump_reason cx reason)
    | EFunctionCallExtraArg (unused_reason, def_reason, param_count, use_op) ->
      spf
        ""EFunctionCallExtraArg (%s, %s, %d, %s)""
        (dump_reason cx unused_reason)
        (dump_reason cx def_reason)
        param_count
        (string_of_use_op use_op)
    | EUnsupportedSetProto reason -> spf ""EUnsupportedSetProto (%s)"" (dump_reason cx reason)
    | EEscapedGeneric { reason; use_op; bound_name; _ } ->
      spf
        ""EEscapedGeneric { reason = %s; use_op = %s; bound_name = %s; _ }""
        (dump_reason cx reason)
        (string_of_use_op use_op)
        bound_name
    | EDuplicateModuleProvider { module_name; provider; conflict } ->
      spf
        ""EDuplicateModuleProvider (%S, %s, %s)""
        module_name
        (string_of_aloc provider)
        (string_of_aloc conflict)
    | EParseError (loc, _parse_error) -> spf ""EParseError (%s, _)"" (string_of_aloc loc)
    (* TODO: string of parse error constructor *)
    | EDocblockError (loc, err) ->
      spf
        ""EDocblockError (%s, %s)""
        (string_of_aloc loc)
        (match err with
        | MultipleFlowAttributes -> ""MultipleFlowAttributes""
        | InvalidFlowMode _ -> ""InvalidFlowMode""
        | MultipleProvidesModuleAttributes -> ""MultipleProvidesModuleAttributes""
        | MultipleJSXAttributes -> ""MultipleJSXAttributes""
        | InvalidJSXAttribute _ -> ""InvalidJSXAttribute"")
    | EImplicitInexactObject loc -> spf ""EImplicitInexactObject (%s)"" (string_of_aloc loc)
    | EAmbiguousObjectType loc -> spf ""EAmbiguousObjectType (%s)"" (string_of_aloc loc)
    | EUntypedTypeImport (loc, module_name) ->
      spf ""EUntypedTypeImport (%s, %s)"" (string_of_aloc loc) module_name
    | EUntypedImport (loc, module_name) ->
      spf ""EUntypedImport (%s, %s)"" (string_of_aloc loc) module_name
    | ENonstrictImport loc -> spf ""ENonstrictImport (%s)"" (string_of_aloc loc)
    | EUnclearType loc -> spf ""EUnclearType (%s)"" (string_of_aloc loc)
    | EDeprecatedUtility (loc, name) -> spf ""EDeprecatedUtility (%s, %s)"" (string_of_aloc loc) name
    | EDeprecatedType loc -> spf ""EDeprecatedType (%s)"" (string_of_aloc loc)
    | EUnsafeGettersSetters loc -> spf ""EUnclearGettersSetters (%s)"" (string_of_aloc loc)
    | EUnusedSuppression loc -> spf ""EUnusedSuppression (%s)"" (string_of_aloc loc)
    | ECodelessSuppression (loc, c) -> spf ""ECodelessSuppression (%s, %s)"" (string_of_aloc loc) c
    | ELintSetting (loc, kind) ->
      LintSettings.(
        let kind_str =
          match kind with
          | Invalid_setting -> ""Invalid_setting""
          | Malformed_argument -> ""Malformed_argument""
          | Naked_comment -> ""Naked_comment""
          | Nonexistent_rule -> ""Nonexistent_rule""
          | Overwritten_argument -> ""Overwritten_argument""
          | Redundant_argument -> ""Redundant_argument""
        in
        spf ""ELintSetting (%s, %s)"" (string_of_aloc loc) kind_str
      )
    | ESketchyNullLint { kind; loc; null_loc; falsy_loc } ->
      Lints.(
        let kind_str =
          match kind with
          | SketchyNullBool -> ""SketchyNullBool""
          | SketchyNullString -> ""SketchyNullString""
          | SketchyNullNumber -> ""SketchyNullNumber""
          | SketchyNullMixed -> ""SketchyNullMixed""
          | SketchyNullEnumBool -> ""SketchyNullEnumBool""
          | SketchyNullEnumString -> ""SketchyNullEnumString""
          | SketchyNullEnumNumber -> ""SketchyNullEnumNumber""
        in
        spf
          ""ESketchyNullLint {kind=%s; loc=%s; null_loc=%s; falsy_loc=%s}""
          kind_str
          (string_of_aloc loc)
          (string_of_aloc null_loc)
          (string_of_aloc falsy_loc)
      )
    | ESketchyNumberLint (kind, reason) ->
      Lints.(
        let kind_str =
          match kind with
          | SketchyNumberAnd -> ""SketchyNumberAnd""
        in
        spf ""ESketchyNumberLint (%s) (%s)"" kind_str (dump_reason cx reason)
      )
    | EInvalidConstructor reason -> spf ""EInvalidConstructor (%s)"" (dump_reason cx reason)
    | EInvalidPrototype (loc, reason) ->
      spf ""EInvalidPrototype (%s) (%s)"" (string_of_aloc loc) (dump_reason cx reason)
    | EUnnecessaryOptionalChain (loc, _) -> spf ""EUnnecessaryOptionalChain (%s)"" (string_of_aloc loc)
    | EUnnecessaryInvariant (loc, _) -> spf ""EUnnecessaryInvariant (%s)"" (string_of_aloc loc)
    | EUnexpectedTemporaryBaseType loc ->
      spf ""EUnexpectedTemporaryBaseType (%s)"" (string_of_aloc loc)
    | ECannotDelete (l1, r1) -> spf ""ECannotDelete (%s, %s)"" (string_of_aloc l1) (dump_reason cx r1)
    | ESignatureVerification sve ->
      let msg = string_of_signature_error ALoc.debug_to_string sve in
      spf ""ESignatureVerification (%s)"" msg
    | EBigIntNotYetSupported reason -> spf ""EBigIntNotYetSupported (%s)"" (dump_reason cx reason)
    | ECannotSpreadInterface { spread_reason; interface_reason; use_op } ->
      spf
        ""ECannotSpreadInterface (%s) (%s) (%s)""
        (dump_reason cx spread_reason)
        (dump_reason cx interface_reason)
        (string_of_use_op use_op)
    | ECannotSpreadIndexerOnRight { spread_reason; object_reason; key_reason; use_op } ->
      spf
        ""ECannotSpreadIndexerOnRight (%s) (%s) (%s) (%s)""
        (dump_reason cx spread_reason)
        (dump_reason cx object_reason)
        (dump_reason cx key_reason)
        (string_of_use_op use_op)
    | EUnableToSpread
        { spread_reason; object1_reason; object2_reason; propname; error_kind = _; use_op } ->
      spf
        ""EUnableToSpread (%s) (%s) (%s) (%s) (%s)""
        (dump_reason cx spread_reason)
        (dump_reason cx object1_reason)
        (dump_reason cx object2_reason)
        (display_string_of_name propname)
        (string_of_use_op use_op)
    | EInexactMayOverwriteIndexer
        { spread_reason; key_reason; value_reason; object2_reason; use_op } ->
      spf
        ""EInexactMayOverwriteIndexer (%s) (%s) (%s) (%s) (%s)""
        (dump_reason cx spread_reason)
        (dump_reason cx key_reason)
        (dump_reason cx value_reason)
        (dump_reason cx object2_reason)
        (string_of_use_op use_op)
    | EExponentialSpread { reason; reasons_for_operand1; reasons_for_operand2 } ->
      let format_reason_group { first_reason; second_reason } =
        spf
          ""[%s; %s]""
          (dump_reason cx first_reason)
          (Base.Option.value_map ~default:""None"" ~f:(dump_reason cx) second_reason)
      in
      spf
        ""EExponentialSpread %s ([%s]) ([%s])""
        (dump_reason cx reason)
        (format_reason_group reasons_for_operand1)
        (format_reason_group reasons_for_operand2)
    | EComputedPropertyWithMultipleLowerBounds
        { computed_property_reason; new_lower_bound_reason; existing_lower_bound_reason } ->
      spf
        ""EComputedPropertyWithMultipleLowerBounds (%s) (%s) (%s)""
        (dump_reason cx computed_property_reason)
        (dump_reason cx new_lower_bound_reason)
        (dump_reason cx existing_lower_bound_reason)
    | EComputedPropertyWithUnion { computed_property_reason; union_reason } ->
      spf
        ""EComputedPropertyWithUnion (%s) (%s)""
        (dump_reason cx computed_property_reason)
        (dump_reason cx union_reason)
    | EEnumInvalidMemberAccess { member_name; suggestion; reason; enum_reason } ->
      spf
        ""EEnumInvalidMemberAccess (%s) (%s) (%s) (%s)""
        (Base.Option.value_map ~default:""<None>"" ~f:display_string_of_name member_name)
        (Base.Option.value ~default:""<None>"" suggestion)
        (dump_reason cx reason)
        (dump_reason cx enum_reason)
    | EEnumModification { loc; enum_reason } ->
      spf ""EEnumModification (%s) (%s)"" (string_of_aloc loc) (dump_reason cx enum_reason)
    | EEnumMemberDuplicateValue { loc; prev_use_loc; enum_reason } ->
      spf
        ""EEnumMemberDuplicateValue (%s) (%s) (%s)""
        (string_of_aloc loc)
        (string_of_aloc prev_use_loc)
        (dump_reason cx enum_reason)
    | EEnumInvalidObjectUtil { reason; enum_reason } ->
      spf ""EEnumInvalidObjectUtil (%s) (%s)"" (dump_reason cx reason) (dump_reason cx enum_reason)
    | EEnumNotIterable { reason; for_in } ->
      spf ""EEnumNotIterable (%s) (%s)"" (dump_reason cx reason) (spf ""for_in = %B"" for_in)
    | EEnumMemberAlreadyChecked { reason; prev_check_reason; enum_reason; member_name } ->
      spf
        ""EEnumMemberAlreadyChecked (%s) (%s) (%s) (%s)""
        (dump_reason cx reason)
        (dump_reason cx prev_check_reason)
        (dump_reason cx enum_reason)
        member_name
    | EEnumAllMembersAlreadyChecked { reason; enum_reason } ->
      spf
        ""EEnumAllMembersAlreadyChecked (%s) (%s)""
        (dump_reason cx reason)
        (dump_reason cx enum_reason)
    | EEnumNotAllChecked { reason; enum_reason; left_to_check; default_case } ->
      spf
        ""EEnumNotAllChecked (%s) (%s) (%s) (%s)""
        (dump_reason cx reason)
        (dump_reason cx enum_reason)
        (String.concat "", "" left_to_check)
        (Base.Option.value_map ~default:""<None>"" ~f:(dump_reason cx) default_case)
    | EEnumUnknownNotChecked { reason; enum_reason } ->
      spf ""EEnumUnknownNotChecked (%s) (%s)"" (dump_reason cx reason) (dump_reason cx enum_reason)
    | EEnumInvalidCheck { reason; enum_reason; example_member } ->
      spf
        ""EEnumInvalidCheck (%s) (%s) (%s)""
        (dump_reason cx reason)
        (dump_reason cx enum_reason)
        (Base.Option.value ~default:""<None>"" example_member)
    | EEnumMemberUsedAsType { reason; enum_reason } ->
      spf ""EEnumMemberUsedAsType (%s) (%s)"" (dump_reason cx reason) (dump_reason cx enum_reason)
    | EEnumIncompatible { reason_lower; reason_upper; use_op; representation_type } ->
      spf
        ""EEnumIncompatible { reason_lower = %s; reason_upper = %s; use_op = %s; representation_type = %s }""
        (dump_reason cx reason_lower)
        (dump_reason cx reason_upper)
        (string_of_use_op use_op)
        (Base.Option.value ~default:""<None>"" representation_type)
    | EAssignConstLikeBinding { loc; definition; binding_kind } ->
      spf
        ""EAssignConstLikeBinding (%s) (%s) (%s)""
        (string_of_aloc loc)
        (dump_reason cx definition)
        (Scope.Entry.string_of_let_binding_kind binding_kind)
    | ECannotResolveOpenTvar { use_op; reason; blame_reasons } ->
      spf
        ""ECannotResolveOpenTvar (%s) (%s) (%s)""
        (string_of_use_op use_op)
        (dump_reason cx reason)
        (ListUtils.to_string "", "" (dump_reason cx) blame_reasons)
    | EMalformedCode loc -> spf ""EMalformedCode (%s)"" (string_of_aloc loc)
    | EObjectThisReference (loc, r) ->
      spf ""EObjectThisReference (%s, %s)"" (string_of_aloc loc) (dump_reason cx r)
    | EInvalidDeclaration { declaration = r; _ } -> spf ""EInvalidDeclaration %s"" (dump_reason cx r)
    | EImplicitInstantiationTemporaryError _ -> ""EImplicitInstantiationTemporaryError""
    | EImportInternalReactServerModule loc ->
      spf ""EImportInternalReactServerModule (%s)"" (string_of_aloc loc)
    | EImplicitInstantiationUnderconstrainedError _ -> ""EImplicitInstantiationUnderconstrainedError""
    | EClassToObject _ -> ""EClassToObject""
    | EMethodUnbinding { use_op; reason_prop; reason_op } ->
      spf
        ""EMethodUnbinding (%s) (%s) (%s)""
        (string_of_use_op use_op)
        (dump_reason cx reason_op)
        (dump_reason cx reason_prop)
    | EInvalidGraphQL (loc, err) ->
      let err_str =
        match err with
        | Graphql.InvalidTaggedTemplate -> ""invalid tagged template""
        | Graphql.InvalidGraphQL -> ""invalid graphql""
      in
      spf ""EInvalidGraphQL (%s) (%s)"" (string_of_aloc loc) err_str
    | EAnnotationInference (loc, reason_op, reason, _) ->
      spf
        ""EAnnotationInference (%s) (%s) (%s)""
        (string_of_aloc loc)
        (dump_reason cx reason_op)
        (dump_reason cx reason)
    | EAnnotationInferenceRecursive (loc, reason) ->
      spf ""EAnnotationInferenceRecursive (%s) (%s)"" (string_of_aloc loc) (dump_reason cx reason)
    | EDefinitionCycle _ -> ""EDefinitionCycle""
    | ERecursiveDefinition _ -> ""ERecursiveDefinition""
    | EDuplicateClassMember { loc; name; _ } ->
      spf ""EDuplicateClassMember (%s) (%s)"" (string_of_aloc loc) name

module Verbose = struct
  let verbose_in_file cx verbose =
    match verbose with
    | { Verbose.focused_files = Some filenames; _ } ->
      Base.List.mem filenames (Context.file cx |> File_key.to_string) ~equal:String.equal
    | { Verbose.focused_files = None; _ } -> true

  let print_if_verbose_lazy
      cx ?(trace = Trace.dummy_trace) ?(delim = """") ?(indent = 0) (lines : string list Lazy.t) =
    match Context.verbose cx with
    | Some ({ Verbose.indent = num_spaces; _ } as verbose) when verbose_in_file cx verbose ->
      let indent = max (indent + Trace.trace_depth trace - 1) 0 in
      let prefix = String.make (indent * num_spaces) ' ' in
      let pid = Context.pid_prefix cx in
      let add_prefix line = spf ""\n%s%s%s"" prefix pid line in
      let lines = Base.List.map ~f:add_prefix (Lazy.force lines) in
      prerr_endline (String.concat delim lines)
    | _ -> ()

  let print_if_verbose
      cx ?(trace = Trace.dummy_trace) ?(delim = """") ?(indent = 0) (lines : string list) =
    match Context.verbose cx with
    | Some verbose when verbose_in_file cx verbose ->
      print_if_verbose_lazy cx ~trace ~delim ~indent (lazy lines)
    | _ -> ()

  let print_types_if_verbose cx trace ?(note : string option) ((l : Type.t), (u : Type.use_t)) =
    match Context.verbose cx with
    | Some ({ Verbose.depth; _ } as verbose) when verbose_in_file cx verbose ->
      let delim =
        match note with
        | Some x -> spf "" ~> %s"" x
        | None -> "" ~>""
      in
      print_if_verbose cx ~trace ~delim [dump_t ~depth cx l; dump_use_t ~depth cx u]
    | _ -> ()
end
",ocaml
"class c = (object end :
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* This module is responsible for building a mapping from variable reads to the
 * writes and refinements that reach those reads. It is based on the implementation of the
 * ssa_builder, but with enough divergent behavior that the ssa_builder and name_resolver don't
 * actually share much code. If you're here to add support for a new syntax feature, you'll likely
 * need to modify the ssa_builder as well, but not necessarily with identical changes.*)

let statement_error = ()

open Reason
open Hoister

let is_call_to_invariant callee =
  match callee with
  | (_, Flow_ast.Expression.Identifier (_, { Flow_ast.Identifier.name = ""invariant""; _ })) -> true
  | _ -> false

let is_number_literal node =
  let open Flow_ast in
  match node with
  | Expression.Literal { Literal.value = Literal.Number _; _ }
  | Expression.Unary
      {
        Expression.Unary.operator = Expression.Unary.Minus;
        argument = (_, Expression.Literal { Literal.value = Literal.Number _; _ });
        comments = _;
      } ->
    true
  | _ -> false

let extract_number_literal node =
  let open Flow_ast in
  match node with
  | Expression.Literal { Literal.value = Literal.Number lit; raw; comments = _ } -> (lit, raw)
  | Expression.Unary
      {
        Expression.Unary.operator = Expression.Unary.Minus;
        argument = (_, Expression.Literal { Literal.value = Literal.Number lit; raw; _ });
        comments = _;
      } ->
    (-.lit, ""-"" ^ raw)
  | _ -> Utils_js.assert_false ""not a number literal""

let error_todo = ()

module type C = sig
  type t

  val enable_enums : t -> bool

  val jsx : t -> Options.jsx_mode

  val react_runtime : t -> Options.react_runtime

  val enable_const_params : t -> bool

  val env_mode : t -> Options.env_mode

  val add_new_env_literal_subtypes : t -> ALoc.t * Env_api.new_env_literal_check -> unit

  val add_new_env_matching_props : t -> string * ALoc.t * ALoc.t -> unit
end

module type F = sig
  type cx

  val add_output : cx -> ?trace:Type.trace -> ALoc.t Error_message.t' -> unit
end

module type S = sig
  module Env_api : Env_api.S with module L = Loc_sig.ALocS

  type cx

  type abrupt_kind

  exception AbruptCompletionExn of abrupt_kind

  val program_with_scope :
    cx -> (ALoc.t, ALoc.t) Flow_ast.Program.t -> abrupt_kind option * Env_api.env_info

  val program :
    cx -> (ALoc.t, ALoc.t) Flow_ast.Program.t -> Env_api.values * (int -> Env_api.refinement)
end

module PostInferenceCheck = Env_api

module Make
    (Scope_api : Scope_api_sig.S with module L = Loc_sig.ALocS)
    (Ssa_api : Ssa_api.S with module L = Loc_sig.ALocS)
    (Env_api : Env_api.S
                 with module L = Loc_sig.ALocS
                  and module Scope_api = Scope_api
                  and module Ssa_api = Ssa_api)
    (Context : C)
    (FlowAPIUtils : F with type cx = Context.t) :
  S with module Env_api = Env_api and type cx = Context.t = struct
  let _f = FlowAPIUtils.add_output
  (* To make ocaml not complain, will be removed when FlowAPIUtils module is used *)

  module Scope_builder :
    Scope_builder_sig.S with module L = Loc_sig.ALocS and module Api = Scope_api =
    Scope_builder.Make (Loc_sig.ALocS) (Scope_api)

  module Provider_api :
    Provider_api.S with type info = Env_api.Provider_api.info and module L = Loc_sig.ALocS =
    Env_api.Provider_api

  module Ssa_builder = Ssa_builder.Make (Loc_sig.ALocS) (Ssa_api) (Scope_builder)
  module Invalidation_api =
    Invalidation_api.Make (Loc_sig.ALocS) (Scope_api) (Ssa_api) (Provider_api)
  module Env_api = Env_api
  open Scope_builder
  open Env_api.Refi

  type cx = Context.t

  type refinement_chain =
    | BASE of refinement
    | AND of int * int
    | OR of int * int
    | NOT of int

  type cond_context =
    | SwitchTest
    | OtherTest

  (* For every read of a variable x, we are interested in tracking writes to x
     that can reach that read. Ultimately the writes are going to be represented
     as a list of locations, where each location corresponds to a ""single static
     assignment"" of the variable in the code. But for the purposes of analysis, it
     is useful to represent these writes with a data type that contains either a
     single write, or a ""join"" of writes (in compiler terminology, a PHI node), or
     a reference to something that is unknown at a particular point in the AST
     during traversal, but will be known by the time traversal is complete. *)
  module Val : sig
    type t = {
      id: int;
      write_state: write_state;
    }

    and write_state

    module WriteSet : Flow_set.S with type elt = write_state

    val empty : unit -> t

    val uninitialized : ALoc.t -> t

    val undefined : L.t virtual_reason -> t

    val number : L.t virtual_reason -> t

    val undeclared_class : L.t virtual_reason -> string -> t

    val merge : t -> t -> t

    val this : t

    val super : t

    val arguments : t

    val global : string -> t

    val one : ALoc.t virtual_reason -> t

    val all : ALoc.t virtual_reason list -> t

    val of_write : write_state -> t

    val simplify : ALoc.t option -> Bindings.kind option -> string option -> t -> Env_api.read

    val id_of_val : t -> int

    val base_id_of_val : t -> int

    val refinement : int -> t -> t

    val projection : ALoc.t -> t

    val undeclared : string -> ALoc.t -> t

    val declared_but_skipped : string -> ALoc.t -> t

    val declared_function : ALoc.t -> t

    (* unwraps a RefinementWrite into just the underlying write *)
    val unrefine : int -> t -> t

    val unrefine_deeply : int -> t -> t

    (* Replace the base write of the refinement with the new base.
       If the write is not a refinement, replace the entire write with the base.

       This is useful for attaching a refinement that is known to be associated with a write, but
       is not attached due to syntactic difference.
       e.g. refinements on obj.x should be attached to x in const {x} = obj *)
    val replace_refinement_base_write : base:t -> t -> t

    val normalize_through_refinements : write_state -> WriteSet.t

    val writes_of_uninitialized : (int -> bool) -> t -> write_state list

    val is_global_undefined : t -> bool

    val is_global : t -> bool

    val is_undeclared : t -> bool

    val is_undeclared_or_skipped : t -> bool

    val is_declared_function : t -> bool
  end = struct
    let curr_id = ref 0

    type write_state =
      | Uninitialized of ALoc.t
      | Undeclared of string * ALoc.t
      | DeclaredButSkipped of string * ALoc.t
      | UndeclaredClass of {
          def: ALoc.t virtual_reason;
          name: string;
        }
      | Projection of ALoc.t
      | This
      | Super
      | Arguments
      | Global of string
      | Loc of ALoc.t virtual_reason
      | PHI of write_state list
      | Refinement of {
          refinement_id: int;
          val_t: t;
        }
      | Undefined of ALoc.t virtual_reason
      | Number of ALoc.t virtual_reason
      | DeclaredFunction of ALoc.t

    and t = {
      id: int;
      write_state: write_state;
    }

    let is_global_undefined t =
      match t.write_state with
      | Global ""undefined"" -> true
      | _ -> false

    let is_global t =
      match t.write_state with
      | Global _ -> true
      | _ -> false

    let is_undeclared t =
      match t.write_state with
      | Undeclared _ -> true
      | UndeclaredClass _ -> true
      | _ -> false

    let is_undeclared_or_skipped t =
      match t.write_state with
      | Undeclared _ -> true
      | DeclaredButSkipped _ -> true
      | UndeclaredClass _ -> true
      | _ -> false

    let is_declared_function t =
      match t.write_state with
      | DeclaredFunction _ -> true
      | _ -> false

    let new_id () =
      let id = !curr_id in
      curr_id := !curr_id + 1;
      id

    let mk_with_write_state write_state =
      let id = new_id () in
      { id; write_state }

    let of_write = mk_with_write_state

    let empty () = mk_with_write_state @@ PHI []

    let uninitialized r = mk_with_write_state (Uninitialized r)

    let undefined r = mk_with_write_state (Undefined r)

    let number r = mk_with_write_state (Number r)

    let undeclared_class def name = mk_with_write_state (UndeclaredClass { def; name })

    let projection loc = mk_with_write_state @@ Projection loc

    let declared_function loc = mk_with_write_state @@ DeclaredFunction loc

    let refinement refinement_id val_t = mk_with_write_state @@ Refinement { refinement_id; val_t }

    let undeclared name def_loc = mk_with_write_state @@ Undeclared (name, def_loc)

    let declared_but_skipped name def_loc = mk_with_write_state @@ DeclaredButSkipped (name, def_loc)

    let rec unrefine_deeply_write_state id write_state =
      match write_state with
      | Refinement { refinement_id; val_t } when refinement_id = id ->
        unrefine_deeply_write_state id val_t.write_state
      | Refinement { refinement_id; val_t } ->
        let val_t' = mk_with_write_state @@ unrefine_deeply_write_state id val_t.write_state in
        Refinement { refinement_id; val_t = val_t' }
      | PHI ts ->
        let ts' = ListUtils.ident_map (unrefine_deeply_write_state id) ts in
        if ts' == ts then
          write_state
        else
          PHI ts'
      | _ -> write_state

    let rec base_id_of_val { id; write_state } =
      match write_state with
      | Refinement { refinement_id = _; val_t } -> base_id_of_val val_t
      | _ -> id

    let unrefine_deeply id t = mk_with_write_state @@ unrefine_deeply_write_state id t.write_state

    let unrefine id t =
      match t.write_state with
      | Refinement { refinement_id; val_t } when refinement_id = id -> val_t
      | _ -> t

    let replace_refinement_base_write ~base t =
      match t.write_state with
      | Refinement { refinement_id; val_t = _ } -> refinement refinement_id base
      | _ -> base

    let join = function
      | [] -> PHI []
      | [t] -> t
      | ts -> PHI ts

    module WriteSet = Flow_set.Make (struct
      type t = write_state

      let compare = Stdlib.compare
    end)

    let rec normalize (t : write_state) : WriteSet.t =
      match t with
      | Uninitialized _
      | Undefined _
      | Number _
      | DeclaredFunction _
      | Undeclared _
      | DeclaredButSkipped _
      | UndeclaredClass _
      | Projection _
      | This
      | Super
      | Arguments
      | Global _
      | Loc _
      | Refinement _ ->
        WriteSet.singleton t
      | PHI ts ->
        List.fold_left
          (fun vals' t ->
            let vals = normalize t in
            WriteSet.union vals' vals)
          WriteSet.empty
          ts

    let merge t1 t2 =
      if t1.id = t2.id then
        t1
      else
        (* Merging can easily lead to exponential blowup in size of terms if we're not careful. We
           amortize costs by computing normal forms as sets of ""atomic"" terms, so that merging would
           correspond to set union. (Atomic terms include Uninitialized, Loc _, and REF { contents =
           Unresolved _ }.) Note that normal forms might change over time, as unresolved refs become
           resolved; thus, we do not shortcut normalization of previously normalized terms. Still, we
           expect (and have experimentally validated that) the cost of computing normal forms becomes
           smaller over time as terms remain close to their final normal forms. *)
        let vals = WriteSet.union (normalize t1.write_state) (normalize t2.write_state) in
        mk_with_write_state @@ join (WriteSet.elements vals)

    let rec normalize_through_refinements (t : write_state) : WriteSet.t =
      match t with
      | Uninitialized _
      | Undefined _
      | Number _
      | DeclaredFunction _
      | Undeclared _
      | DeclaredButSkipped _
      | UndeclaredClass _
      | Projection _
      | Global _
      | This
      | Super
      | Arguments
      | Loc _ ->
        WriteSet.singleton t
      | PHI ts ->
        List.fold_left
          (fun vals' t ->
            let vals = normalize t in
            WriteSet.union vals' vals)
          WriteSet.empty
          ts
      | Refinement { val_t; _ } -> normalize_through_refinements val_t.write_state

    let this = mk_with_write_state This

    let super = mk_with_write_state Super

    let arguments = mk_with_write_state Arguments

    let global name = mk_with_write_state @@ Global name

    let one reason = mk_with_write_state @@ Loc reason

    let all locs = mk_with_write_state @@ join (Base.List.map ~f:(fun reason -> Loc reason) locs)

    let rec simplify_val t =
      let vals = normalize t.write_state in
      Base.List.map
        ~f:(function
          | Uninitialized l when WriteSet.cardinal vals <= 1 ->
            Env_api.Uninitialized (mk_reason RUninitialized l)
          | Undefined r -> Env_api.Undefined r
          | Number r -> Env_api.Number r
          | DeclaredFunction l -> Env_api.DeclaredFunction l
          | Undeclared (name, loc)
          | DeclaredButSkipped (name, loc) ->
            Env_api.Undeclared (name, loc)
          | UndeclaredClass { def; name } -> Env_api.UndeclaredClass { def; name }
          | Uninitialized l -> Env_api.Uninitialized (mk_reason RPossiblyUninitialized l)
          | Projection loc -> Env_api.Projection loc
          | Loc r -> Env_api.Write r
          | Refinement { refinement_id; val_t } ->
            Env_api.Refinement
              {
                writes = simplify_val val_t;
                refinement_id;
                (* We delegate to the old env for this and super,
                   so we shouldn't cache results about them. *)
                write_id =
                  (match val_t with
                  | { id = _; write_state = This | Super } -> None
                  | { id; write_state = _ } -> Some id);
              }
          | This -> Env_api.This
          | Super -> Env_api.Super
          | Arguments -> Env_api.Arguments
          | Global name -> Env_api.Global name
          | PHI _ -> failwith ""A normalized value cannot be a PHI"")
        (WriteSet.elements vals)

    (* Simplification converts a Val.t to a list of locations. *)
    let simplify def_loc binding_kind_opt name value =
      let write_locs = simplify_val value in
      let val_kind =
        match binding_kind_opt with
        | Some (Bindings.Type { imported }) -> Some (Env_api.Type { imported })
        | Some _ -> Some Env_api.Value
        | None -> None
      in
      let id =
        match value with
        | { id = _; write_state = This | Super } -> None
        | { id; write_state = _ } -> Some id
      in
      { Env_api.def_loc; write_locs; val_kind; name; id }

    let id_of_val { id; write_state = _ } = id

    let writes_of_uninitialized refine_to_undefined { write_state; _ } =
      let rec state_is_uninitialized v =
        match v with
        | Undeclared _ -> []
        | DeclaredButSkipped _ -> []
        | Undefined _ -> []
        | Number _ -> []
        | DeclaredFunction _ -> []
        | Uninitialized _ -> [v]
        | UndeclaredClass _ -> [v]
        | PHI states -> Base.List.concat_map ~f:state_is_uninitialized states
        | Refinement { refinement_id; val_t = { write_state; _ } } ->
          let states = state_is_uninitialized write_state in
          if List.length states = 0 || (not @@ refine_to_undefined refinement_id) then
            []
          else
            states
        | Loc _ -> []
        | This -> []
        | Super -> []
        | Arguments -> []
        | Global _ -> []
        | Projection _ -> []
      in
      state_is_uninitialized write_state
  end

  module RefinementKey = Refinement_key.Make (L)

  module HeapRefinementMap = WrappedMap.Make (struct
    type t = RefinementKey.proj list

    let compare = Stdlib.compare
  end)

  module LookupMap = WrappedMap.Make (struct
    type t = RefinementKey.lookup

    let compare = Stdlib.compare
  end)

  type heap_refinement_map = Val.t HeapRefinementMap.t

  (* An environment is a map from variables to values. *)
  module Env = struct
    type entry = {
      env_val: Val.t;
      heap_refinements: heap_refinement_map;
      def_loc: ALoc.t option;
    }

    type t = entry SMap.t
  end

  (* Abrupt completions induce control flows, so modeling them accurately is
     necessary for soundness. *)
  module AbruptCompletion = struct
    type label = string

    type t =
      | Break of label option
      | Continue of label option
      | Return
      | Throw

    let label_opt = Base.Option.map ~f:Flow_ast_utils.name_of_ident

    let break x = Break (label_opt x)

    let continue x = Continue (label_opt x)

    let return = Return

    let throw = Throw

    (* match particular abrupt completions *)
    let mem list : t -> bool = (fun t -> List.mem t list)

    (* match all abrupt completions *)
    let all : t -> bool = (fun _t -> true)

    (* Model an abrupt completion as an OCaml exception. *)
    exception Exn of t

    (* An abrupt completion carries an environment, which is the current
       environment at the point where the abrupt completion is ""raised."" This
       environment is merged wherever the abrupt completion is ""handled."" *)
    type env = t * Env.t
  end

  let rec list_iter3 f l1 l2 l3 =
    match (l1, l2, l3) with
    | ([], [], []) -> ()
    | (x1 :: l1, x2 :: l2, x3 :: l3) ->
      f x1 x2 x3;
      list_iter3 f l1 l2 l3
    | _ -> assert false

  type abrupt_kind = AbruptCompletion.t

  exception AbruptCompletionExn = AbruptCompletion.Exn

  type env_val = {
    val_ref: Val.t ref;
    havoc: Val.t;
    def_loc: ALoc.t option;
    heap_refinements: heap_refinement_map ref;
    kind: Bindings.kind;
  }

  type read_entry = {
    def_loc: ALoc.t option;
    binding_kind_opt: Bindings.kind option;
    value: Val.t;
    name: string option;
  }

  type refinement_id = int

  (* Describes a set of vals that arise from refinements and which should be removed from
     the environment after the refinement scope, e.g. `if (x.y) {}` *)
  type changeset = Val.t LookupMap.t

  type refinement_prop =
    | Refinements of (RefinementKey.lookup * refinement_id) IMap.t * changeset
    | Not of refinement_prop
    | And of refinement_prop * refinement_prop
    | Or of refinement_prop * refinement_prop

  (* The `applied` and `changeset` elements of this record describe the refinements and
     values that have presently been applied to the environment, when this is on the
     latest_refinement stack (see below). The `total` describes the same changeset and
     refinements, but in a propositional form that can be negated. We must maintain the invariant
     that normalizing the `total` (using the normalize_total_refinements method below) produces the
     applied and the changeset. *)
  type refinement_maps = {
    applied: (RefinementKey.lookup * refinement_id) IMap.t;
    changeset: changeset;
    total: refinement_prop option;
  }

  type name_resolver_state = {
    (* We maintain a map of read locations to raw Val.t and their def locs terms, which are
       simplified to lists of write locations once the analysis is done. *)
    values: read_entry L.LMap.t;
    (* We also maintain a list of all write locations, for use in populating the env with
       types. *)
    write_entries: Env_api.env_entry Loc_sig.ALocS.LMap.t;
    curr_id: int;
    (* Maps refinement ids to refinements. This mapping contains _all_ the refinements reachable at
     * any point in the code. The latest_refinement maps keep track of which entries to read. *)
    refinement_heap: refinement_chain IMap.t;
    latest_refinements: refinement_maps list;
    env: env_val SMap.t;
    (* When an abrupt completion is raised, it falls through any subsequent
       straight-line code, until it reaches a merge point in the control-flow
       graph. At that point, it can be re-raised if and only if all other reaching
       control-flow paths also raise the same abrupt completion.

       When re-raising is not possible, we have to save the abrupt completion and
       the current environment in a list, so that we can merge such environments
       later (when that abrupt completion and others like it are handled).

       Even when raising is possible, we still have to save the current
       environment, since the current environment will have to be cleared to model
       that the current values of all variables are unreachable.

       NOTE that raising is purely an optimization: we can have more precise
       results with raising, but even if we never raised we'd still be sound. *)
    abrupt_completion_envs: AbruptCompletion.env list;
    (* Track the list of labels that might describe a loop. Used to detect which
       labeled continues need to be handled by the loop.

       The idea is that a labeled statement adds its label to the list before
       entering its child, and if the child is not a loop or another labeled
       statement, the list will be cleared. A loop will consume the list, so we
       also clear the list on our way out of any labeled statement. *)
    possible_labeled_continues: AbruptCompletion.t list;
    visiting_hoisted_type: bool;
    jsx_base_name: string option;
  }

  let error_for_assignment_kind
      cx name assignment_loc def_loc_opt stored_binding_kind pattern_binding_kind v =
    match def_loc_opt with
    (* Identifiers with no binding can never reintroduce ""cannot reassign binding"" errors *)
    | None -> None
    | Some def_loc ->
      (* Pattern kind is None or Some (Var | Const | Let). It is set to None when we hit a regular
       * assignment, like x = 4, but set to Some x when we are in a declaration, like let x = 3, or
       * class A {}. We use the pattern_binding_kind to decide if we should emit an error saying
       * ""you cannot re-declare X"" vs. ""you cannot reassign const X"" *)
      (match (stored_binding_kind, pattern_binding_kind) with
      | (Bindings.Const, None) ->
        Some
          Error_message.(
            EBindingError (EConstReassigned, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Parameter, None) when Context.enable_const_params cx ->
        Some
          Error_message.(
            EBindingError (EConstParamReassigned, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Class, None) ->
        let def_reason = mk_reason (RIdentifier (OrdinaryName name)) def_loc in
        Some
          Error_message.(
            EAssignConstLikeBinding
              {
                loc = assignment_loc;
                definition = def_reason;
                binding_kind = Scope.Entry.ClassNameBinding;
              }
          )
      | (Bindings.Function, None) ->
        let def_reason = mk_reason (RIdentifier (OrdinaryName name)) def_loc in
        Some
          Error_message.(
            EAssignConstLikeBinding
              {
                loc = assignment_loc;
                definition = def_reason;
                binding_kind = Scope.Entry.FunctionBinding;
              }
          )
      | (Bindings.DeclaredFunction _, None) ->
        let def_reason = mk_reason (RIdentifier (OrdinaryName name)) def_loc in
        Some
          Error_message.(
            EAssignConstLikeBinding
              {
                loc = assignment_loc;
                definition = def_reason;
                (* The error message is unaffected by the predicate flag *)
                binding_kind = Scope.Entry.(DeclaredFunctionBinding { predicate = false });
              }
          )
      | (Bindings.Var, Some Flow_ast.Statement.VariableDeclaration.(Let | Const)) ->
        Some
          Error_message.(
            EBindingError (ENameAlreadyBound, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Const, Some _)
      | (Bindings.Let, Some _)
      | (Bindings.Class, Some _)
      | (Bindings.Function, Some _)
      | (Bindings.Type _, Some _)
        when not (Val.is_undeclared v) ->
        Some
          Error_message.(
            EBindingError (ENameAlreadyBound, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Enum, None) ->
        Some
          Error_message.(
            EBindingError (EEnumReassigned, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Type { imported }, None) ->
        Some
          Error_message.(
            EBindingError
              (ETypeInValuePosition { imported; name }, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Parameter, Some _) when Context.enable_const_params cx && not (Val.is_undeclared v)
        ->
        Some
          Error_message.(
            EBindingError (ENameAlreadyBound, assignment_loc, OrdinaryName name, def_loc)
          )
      | (Bindings.Parameter, Some Flow_ast.Statement.VariableDeclaration.(Let | Const))
        when not (Val.is_undeclared v) ->
        Some
          Error_message.(
            EBindingError (ENameAlreadyBound, assignment_loc, OrdinaryName name, def_loc)
          )
      | _ -> None)

  let initialize_globals unbound_names =
    SMap.empty
    |> SSet.fold
         (fun name acc ->
           let entry =
             {
               val_ref = ref (Val.global name);
               havoc = Val.global name;
               def_loc = None;
               heap_refinements = ref HeapRefinementMap.empty;
               kind = Bindings.Var;
             }
           in
           SMap.add name entry acc)
         unbound_names
    (* this has to come later, since this can be thought to be unbound names in SSA builder when it's used as a type. *)
    |> SMap.add
         ""this""
         {
           val_ref = ref Val.this;
           havoc = Val.this;
           def_loc = None;
           heap_refinements = ref HeapRefinementMap.empty;
           kind = Bindings.Var;
         }
    |> SMap.add
         ""super""
         {
           val_ref = ref Val.super;
           havoc = Val.super;
           def_loc = None;
           heap_refinements = ref HeapRefinementMap.empty;
           kind = Bindings.Var;
         }
    |> SMap.add
         ""arguments""
         {
           val_ref = ref Val.arguments;
           havoc = Val.arguments;
           def_loc = None;
           heap_refinements = ref HeapRefinementMap.empty;
           kind = Bindings.Var;
         }

  (* Statement.ml tries to extract the name and traverse at the location of the
   * jsx element if it's an identifier, otherwise it just traverses the
   * jsx_pragma expression *)
  let extract_jsx_basename =
    let open Flow_ast.Expression in
    function
    | (_, Identifier (_, { Flow_ast.Identifier.name; _ })) -> Some name
    | _ -> None

  let initial_env cx unbound_names =
    let globals = initialize_globals unbound_names in
    (* We need to make sure that the base name for jsx is always in scope.
     * statement.ml is going to read these identifiers at jsx calls, even if
     * they haven't been declared locally. *)
    let jsx_base_name =
      match Context.jsx cx with
      | Options.Jsx_react -> Some ""React""
      | Options.Jsx_pragma (_, ast) -> extract_jsx_basename ast
    in
    match jsx_base_name with
    | None -> (globals, None)
    | Some jsx_base_name ->
      (* We use a global here so that if the base name is never created locally
       * we first check the globals before emitting an error *)
      let entry =
        {
          val_ref = ref (Val.global jsx_base_name);
          havoc = Val.global jsx_base_name;
          def_loc = None;
          heap_refinements = ref HeapRefinementMap.empty;
          kind = Bindings.Var;
        }
      in
      (SMap.add jsx_base_name entry globals, Some jsx_base_name)

  let conj_total t1 t2 =
    match (t1, t2) with
    | (Some t1, Some t2) -> Some (And (t1, t2))
    | (Some t, _)
    | (_, Some t) ->
      Some t
    | (None, None) -> None

  let empty_refinements = { applied = IMap.empty; changeset = LookupMap.empty; total = None }

  class name_resolver cx (prepass_info, prepass_values, unbound_names) provider_info =
    let add_output =
      match Context.env_mode cx with
      | Options.SSAEnv _ -> FlowAPIUtils.add_output cx
      | _ -> (fun ?trace:_ _ -> ())
    in

    let add_literal_subtype_test =
      let rec f refinee_loc literal =
        match literal with
        | SingletonNumR { loc; lit = (num, raw); sense } ->
          Context.add_new_env_literal_subtypes
            cx
            (refinee_loc, PostInferenceCheck.SingletonNum (loc, sense, num, raw))
        | SingletonBoolR { loc; lit; sense } ->
          Context.add_new_env_literal_subtypes
            cx
            (refinee_loc, PostInferenceCheck.SingletonBool (loc, lit = sense))
        | SingletonStrR { loc; lit; sense } ->
          Context.add_new_env_literal_subtypes
            cx
            (refinee_loc, PostInferenceCheck.SingletonStr (loc, sense, lit))
        | NotR r -> f refinee_loc r
        | AndR (r1, r2)
        | OrR (r1, r2) ->
          f refinee_loc r1;
          f refinee_loc r2
        | _ -> ()
      in
      match Context.env_mode cx with
      | Options.SSAEnv _ -> f
      | _ -> (fun _ _ -> ())
    in

    let enable_enums = Context.enable_enums cx in
    object (this)
      inherit
        Scope_builder.scope_builder ~flowmin_compatibility:false ~enable_enums ~with_types:true as super

      val invalidation_caches = Invalidation_api.mk_caches ()

      val mutable env_state : name_resolver_state =
        let (env, jsx_base_name) = initial_env cx unbound_names in
        {
          values = L.LMap.empty;
          write_entries = L.LMap.empty;
          curr_id = 0;
          refinement_heap = IMap.empty;
          latest_refinements = [];
          env;
          abrupt_completion_envs = [];
          possible_labeled_continues = [];
          visiting_hoisted_type = false;
          jsx_base_name;
        }

      method values : Env_api.values =
        L.LMap.map
          (fun { def_loc; value; binding_kind_opt; name } ->
            Val.simplify def_loc binding_kind_opt name value)
          env_state.values

      method write_entries : Env_api.env_entry L.LMap.t = env_state.write_entries

      method private new_id () =
        let new_id = env_state.curr_id in
        let curr_id = new_id + 1 in
        env_state <- { env_state with curr_id };
        new_id

      method env : Env.t =
        SMap.map
          (fun { val_ref; heap_refinements; def_loc; _ } ->
            { Env.env_val = !val_ref; heap_refinements = !heap_refinements; def_loc })
          env_state.env

      (* We often want to merge the refinement scopes and writes of two environments with
       * different strategies, especially in logical refinement scopes. In order to do that, we
       * need to be able to get the writes in our env without the refinement writes. Then we
       * can merge the refinements from two environments using either AND or OR, and then we can
       * merge the writes and reapply the merged refinement if the ssa_id in unchanged.
       *
       * An alternative implementation here might have just used PHI nodes to model disjunctions
       * and successive refinement writes to model conjunctions, but it's not clear that that
       * approach is simpler than this one. *)
      method env_without_latest_refinements : Env.t =
        let refinements_by_key { applied; _ } =
          IMap.fold
            (fun _ (lookup_key, refinement_id) ->
              LookupMap.update lookup_key (function
                  | Some map -> Some (ISet.add refinement_id map)
                  | None -> Some (ISet.singleton refinement_id)
                  ))
            applied
            LookupMap.empty
        in
        let unrefine refinements_by_key lookup_key v =
          LookupMap.find_opt lookup_key refinements_by_key
          |> Base.Option.value_map
               ~f:(fun refinement_ids -> ISet.fold Val.unrefine refinement_ids v)
               ~default:v
        in
        SMap.mapi
          (fun name { val_ref; heap_refinements; def_loc; _ } ->
            let head = List.hd env_state.latest_refinements in
            let refinements_by_key = refinements_by_key head in
            let lookup_key = RefinementKey.lookup_of_name name in
            let env_val = unrefine refinements_by_key lookup_key !val_ref in
            let unrefined_heap_refinements =
              HeapRefinementMap.mapi
                (fun projections v ->
                  let lookup_key = RefinementKey.lookup_of_name_with_projections name projections in
                  unrefine refinements_by_key lookup_key v)
                !heap_refinements
            in
            { Env.env_val; heap_refinements = unrefined_heap_refinements; def_loc })
          env_state.env

      method merge_heap_refinements =
        (* When we merge the heap refinements from two branches we cannot include
         * keys that did not appear on both sides. Take this example:
         * let obj = {};
         * if (true) {
         *   obj.foo = 3;
         * } else {
         *   obj.bar = 4;
         * }
         * (obj.foo: 3); // Should fail because the else branch does not add this refinement
         *)
        HeapRefinementMap.merge (fun _ refinement1 refinement2 ->
            match (refinement1, refinement2) with
            | (Some v1, Some v2) -> Some (Val.merge v1 v2)
            | _ -> None
        )

      (*
       * See merge_heap_refinements for an explanation of our general strategy.
       *
       * The exception to that rule is when we're merging heap refinements after a loop.
       *
       * See the comment at env_loop for an explanation of how we havoc changed
       * values in a loop before reading on.
       *
       * If we refine over a heap value x.foo in the loop guard then we have 2
       * possible scenarios that affect the post-loop refinement:
       * 1. x.foo changes in the loop
       * 2. x.foo does not change in the loop
       *
       * If x.foo does not change in the loop then there will be an
       * entry for x.foo in both the end-of-loop environment and the never-entered-loop
       * environment. We merge those two states and then apply the negated loop guard
       * in this case.
       *
       * while (x.foo === 3) {
       * }
       * x.foo; // x.foo did not change throughout the lifetime of the loop,
       *        // so we can safely merge the pre-state and post-state and add the negated
       *        // refinement. Both the pre- and post-states will have an entry for
       *        // x.foo because both traverse the refinement
       *
       * If x.foo _does_ change then we're in a more interesting situation. In this
       * case, it is possible for the end-of-loop environment to not contain a heap
       * entry for x.foo, so merging it with the never-entered-loop environment would
       * not add an entry for the heap refinement, and applying the negated refinement
       * would have no effect. To fix this, we take advantage of the fact that if
       * x.foo is changed then we havoc before analyzing the loop guard. That means
       * that the access in the loop guard is a fine location to use for the projection
       * at the base of the refinement. If we did not havoc, then we could end
       * up in a situation where x.foo was already refined at the loop guard and we
       * unsoundly carry that refinement into the post-loop state even though that refinement
       * was invalidated by the loop body.
       *
       * while (x.foo === 3) {
       *  f();
       * } // The post state of the loop has no entry for x.foo because
       *   // the call of f havocs the heap refinement.
       * x.foo; // Since x.foo (and x) is havoced before looking at the guard,
       *        // the x.foo projection in the guard is a ""general"" type for
       *        // the x.foo projection, so we can use that location to grab
       *        // the type we need to refine with the negation of the loop guard.
       *)
      method merge_loop_guard_env_after_loop env_after_guard_no_refinements =
        let env_after_loop = env_state.env in
        let merge_heap_refinements ~heap_entries_after_loop ~heap_entries_after_guard =
          HeapRefinementMap.merge
            (fun _ refinement1 refinement2 ->
              match (refinement1, refinement2) with
              | (Some v1, Some v2) -> Some (Val.merge v1 v2)
              | (Some v, None) -> Some v (* Keep the projection from the guard! *)
              | _ -> None)
            heap_entries_after_guard
            heap_entries_after_loop
        in
        List.iter2
          (fun {
                 Env.env_val = after_guard;
                 heap_refinements = heap_entries_after_guard;
                 def_loc = _;
               }
               { val_ref = after_loop; heap_refinements = heap_entries_after_loop; _ } ->
            after_loop := Val.merge after_guard !after_loop;
            heap_entries_after_loop :=
              merge_heap_refinements
                ~heap_entries_after_loop:!heap_entries_after_loop
                ~heap_entries_after_guard)
          (SMap.values env_after_guard_no_refinements)
          (SMap.values env_after_loop)

      method merge_remote_env (env : Env.t) : unit =
        (* NOTE: env might have more keys than env_state.env, since the environment it
           describes might be nested inside the current environment *)
        SMap.iter
          (fun x { val_ref; heap_refinements = heap_refinements1; def_loc = def_loc_1; _ } ->
            let { Env.env_val; heap_refinements = heap_refinements2; def_loc = def_loc_2 } =
              SMap.find x env
            in
            if def_loc_1 = def_loc_2 then (
              val_ref := Val.merge !val_ref env_val;
              heap_refinements1 := this#merge_heap_refinements !heap_refinements1 heap_refinements2
            ))
          env_state.env

      method merge_env (env1 : Env.t) (env2 : Env.t) : unit =
        let env1 = SMap.values env1 in
        let env2 = SMap.values env2 in
        let env = SMap.values env_state.env in
        list_iter3
          (fun { val_ref; heap_refinements; _ }
               { Env.env_val = value1; heap_refinements = heap_refinements1; def_loc = _ }
               { Env.env_val = value2; heap_refinements = heap_refinements2; def_loc = _ } ->
            val_ref := Val.merge value1 value2;
            heap_refinements := this#merge_heap_refinements heap_refinements1 heap_refinements2)
          env
          env1
          env2

      method merge_self_env (other_env : Env.t) : unit =
        let other_env = SMap.values other_env in
        let env = SMap.values env_state.env in
        List.iter2
          (fun { val_ref; heap_refinements; _ }
               { Env.env_val = value; heap_refinements = new_heap_refinements; def_loc = _ } ->
            val_ref := Val.merge !val_ref value;
            heap_refinements := this#merge_heap_refinements !heap_refinements new_heap_refinements)
          env
          other_env

      method reset_env (env0 : Env.t) : unit =
        let env0 = SMap.values env0 in
        let env = SMap.values env_state.env in
        List.iter2
          (fun { val_ref; heap_refinements; _ }
               { Env.env_val; heap_refinements = old_heap_refinements; def_loc = _ } ->
            val_ref := env_val;
            heap_refinements := old_heap_refinements)
          env
          env0

      method empty_env : Env.t =
        SMap.map
          (fun _ ->
            {
              Env.env_val = Val.empty ();
              heap_refinements = HeapRefinementMap.empty;
              (* The empty env is always used as a reset value,
                 and the reset_env method (see above) does not mutate def_loc at all.
                 Therefore, the value of def_loc here does not matter. *)
              def_loc = None;
            })
          env_state.env

      (* This method applies a function over the value stored with a refinement key. It is
       * mostly just a convenient helper so that the process of deconstructing the
       * key and finding the appropriate Val.t does not have to be repeated in
       * every method that needs to update an entry. The create_val_for_heap argument can
       * be used to specify what value to apply the function to if the heap entry
       * does not yet exist.

       * In addition to updating the Val.t, if the callback Val.t updating function
       * is called (i.e. if we find a value to update), we'll return any additional
       * data that the function itself returns (as the first element of its return
       * type tuple). In addition, if we end up creating a new val.t as part of a heap
       * refinement, we'll return that val.t as well. In cases where this information
       * isn't necessary, callers can call `map_val_with_lookup` below instead.
       *)
      method map_val_with_lookup_result
          : 'r.
            RefinementKey.lookup ->
            ?create_val_for_heap:Val.t Lazy.t ->
            (Val.t -> 'r * Val.t) ->
            ('r * Val.t option) option =
        fun lookup ?create_val_for_heap f ->
          let { RefinementKey.base; projections } = lookup in
          match SMap.find_opt base env_state.env with
          | None -> None
          | Some { val_ref; heap_refinements; havoc = _; def_loc = _; kind = _ } ->
            (match projections with
            | [] ->
              let (res, val_) = f !val_ref in
              val_ref := val_;
              Some (res, None)
            | _ ->
              let (res, new_heap_refinements) =
                match
                  (HeapRefinementMap.find_opt projections !heap_refinements, create_val_for_heap)
                with
                | (Some heap_val, _) ->
                  let (res, val_) = f heap_val in
                  (Some (res, None), HeapRefinementMap.add projections val_ !heap_refinements)
                | (None, Some (lazy default)) ->
                  let (res, val_) = f default in
                  ( Some (res, Some default),
                    HeapRefinementMap.add projections val_ !heap_refinements
                  )
                | (None, None) -> (None, !heap_refinements)
              in
              heap_refinements := new_heap_refinements;
              res)

      method map_val_with_lookup lookup ?create_val_for_heap f =
        let (_ : (unit * Val.t option) option) =
          this#map_val_with_lookup_result lookup ?create_val_for_heap (fun v -> ((), f v))
        in
        ()

      method get_val_of_expression expr =
        match RefinementKey.of_expression expr with
        | None -> None
        | Some { RefinementKey.loc = _; lookup = { RefinementKey.base; projections } } ->
          (match SMap.find_opt base this#env with
          | None -> None
          | Some { Env.env_val; heap_refinements; def_loc = _ } ->
            (match projections with
            | [] -> Some env_val
            | _ -> HeapRefinementMap.find_opt projections heap_refinements))

      (* Function calls may introduce refinements if the function called is a
       * predicate function. The EnvBuilder has no idea if a function is a
       * predicate function or not. To handle that, we encode that a variable
       * _might_ be havoced by a function call if that variable is passed
       * as an argument. Variables not passed into the function are havoced if
       * the invalidation api says they can be invalidated.
       *)
      method apply_latent_refinements ((callee_loc, _) as callee) refinement_keys_by_arg =
        List.iteri
          (fun index -> function
            | None -> ()
            | Some key ->
              this#add_single_refinement
                key
                (L.LSet.singleton callee_loc, LatentR { func = callee; index = index + 1 }))
          refinement_keys_by_arg

      method havoc_heap_refinements heap_refinements = heap_refinements := HeapRefinementMap.empty

      method havoc_all_heap_refinements () =
        SMap.iter
          (fun _ { heap_refinements; _ } -> this#havoc_heap_refinements heap_refinements)
          env_state.env

      method havoc_env ~force_initialization ~all =
        SMap.iter
          (fun _x { val_ref; havoc; def_loc; heap_refinements; kind = _ } ->
            this#havoc_heap_refinements heap_refinements;
            let uninitialized_writes =
              lazy (Val.writes_of_uninitialized this#refinement_may_be_undefined !val_ref)
            in
            let val_is_undeclared_or_skipped = Val.is_undeclared_or_skipped !val_ref in
            let havoc_ref =
              if force_initialization then
                havoc
              else if val_is_undeclared_or_skipped then
                !val_ref
              else
                Base.List.fold
                  ~init:havoc
                  ~f:(fun acc write -> Val.merge acc (Val.of_write write))
                  (Lazy.force uninitialized_writes)
            in
            if
              Base.Option.is_none def_loc
              || Invalidation_api.should_invalidate
                   ~all
                   invalidation_caches
                   prepass_info
                   prepass_values
                   (Base.Option.value_exn def_loc (* checked against none above *))
              || force_initialization
                 && (List.length (Lazy.force uninitialized_writes) > 0
                    || val_is_undeclared_or_skipped
                    )
            then
              val_ref := havoc_ref)
          env_state.env

      method havoc_current_env ~all = this#havoc_env ~all ~force_initialization:false

      method havoc_uninitialized_env = this#havoc_env ~force_initialization:true ~all:true

      method refinement_may_be_undefined id =
        let rec refine_undefined = function
          | UndefinedR
          | MaybeR ->
            true
          | NotR r -> not @@ refine_undefined r
          | OrR (r1, r2) -> refine_undefined r1 || refine_undefined r2
          | AndR (r1, r2) -> refine_undefined r1 && refine_undefined r2
          | _ -> false
        in
        let (_, id) = this#refinement_of_id id in
        refine_undefined id

      method private providers_of_def_loc def_loc =
        let providers =
          Base.Option.value_map
            ~default:[]
            ~f:snd
            (Provider_api.providers_of_def provider_info def_loc)
        in
        ( ( if Base.List.is_empty providers then
            Val.uninitialized def_loc
          else
            Val.all providers
          ),
          providers
        )

      method private mk_env =
        SMap.mapi (fun name (kind, (loc, _)) ->
            match kind with
            | Bindings.Type _ ->
              let reason = mk_reason (RType (OrdinaryName name)) loc in
              let write_entries =
                L.LMap.add loc (Env_api.AssigningWrite reason) env_state.write_entries
              in
              env_state <- { env_state with write_entries };
              {
                val_ref = ref (Val.one reason);
                havoc = Val.one reason;
                def_loc = Some loc;
                heap_refinements = ref HeapRefinementMap.empty;
                kind;
              }
            | Bindings.DeclaredClass ->
              let reason = mk_reason (RIdentifier (OrdinaryName name)) loc in
              let write_entries =
                L.LMap.add loc (Env_api.AssigningWrite reason) env_state.write_entries
              in
              env_state <- { env_state with write_entries };
              {
                val_ref = ref (Val.one reason);
                havoc = Val.one reason;
                def_loc = Some loc;
                heap_refinements = ref HeapRefinementMap.empty;
                kind;
              }
            | Bindings.Class ->
              let (havoc, providers) = this#providers_of_def_loc loc in
              let write_entries =
                Base.List.fold
                  ~f:(fun acc r -> L.LMap.add (poly_loc_of_reason r) (Env_api.AssigningWrite r) acc)
                  ~init:env_state.write_entries
                  providers
              in
              let reason = mk_reason (RIdentifier (OrdinaryName name)) loc in
              env_state <- { env_state with write_entries };
              {
                val_ref = ref (Val.undeclared_class reason name);
                havoc;
                def_loc = Some loc;
                heap_refinements = ref HeapRefinementMap.empty;
                kind;
              }
            | Bindings.DeclaredFunction _ ->
              let (_, providers) = this#providers_of_def_loc loc in
              let write_entries =
                Base.List.fold
                  ~f:(fun acc r -> L.LMap.add (poly_loc_of_reason r) (Env_api.AssigningWrite r) acc)
                  ~init:env_state.write_entries
                  providers
              in
              env_state <- { env_state with write_entries };
              let declared_function = Val.declared_function loc in
              {
                val_ref = ref declared_function;
                havoc = declared_function;
                def_loc = Some loc;
                heap_refinements = ref HeapRefinementMap.empty;
                kind;
              }
            | Bindings.Import ->
              let reason = mk_reason (RIdentifier (OrdinaryName name)) loc in
              let havoc = Val.one reason in
              {
                val_ref = ref havoc;
                havoc;
                def_loc = Some loc;
                heap_refinements = ref HeapRefinementMap.empty;
                kind;
              }
            | _ ->
              let initial_val =
                match kind with
                (* let/const/enum all introduce errors if you try to access or assign them
                 * before syntactically encountering the declaration. All other bindings
                 * do not, so we don't set them to be undeclared *)
                | Bindings.Let
                | Bindings.Const
                | Bindings.Enum
                | Bindings.Parameter
                | Bindings.Function ->
                  Val.undeclared name loc
                | _ -> Val.uninitialized loc
              in
              let (havoc, providers) = this#providers_of_def_loc loc in
              let write_entries =
                Base.List.fold
                  ~f:(fun acc r -> L.LMap.add (poly_loc_of_reason r) (Env_api.AssigningWrite r) acc)
                  ~init:env_state.write_entries
                  providers
              in
              env_state <- { env_state with write_entries };
              {
                val_ref = ref initial_val;
                havoc;
                def_loc = Some loc;
                heap_refinements = ref HeapRefinementMap.empty;
                kind;
              }
        )

      method private push_env bindings =
        let old_env = env_state.env in
        let bindings = Bindings.to_map bindings in
        let env = SMap.fold SMap.add (this#mk_env bindings) old_env in
        env_state <- { env_state with env };
        (bindings, old_env)

      method private pop_env (_, old_env) = env_state <- { env_state with env = old_env }

      method! with_bindings
          : 'a. ?lexical:bool -> ALoc.t -> ALoc.t Bindings.t -> ('a -> 'a) -> 'a -> 'a =
        fun ?lexical loc bindings visit node ->
          let saved_state = this#push_env bindings in
          this#run
            (fun () -> ignore @@ super#with_bindings ?lexical loc bindings visit node)
            ~finally:(fun () -> this#pop_env saved_state);
          node

      (* Run some computation, catching any abrupt completions; do some final work,
         and then re-raise any abrupt completions that were caught. *)
      method run f ~finally =
        let completion_state = this#run_to_completion f in
        finally ();
        this#from_completion completion_state

      method run_to_completion f =
        try
          f ();
          None
        with
        | AbruptCompletion.Exn abrupt_completion -> Some abrupt_completion

      method from_completion =
        function
        | None -> ()
        | Some abrupt_completion -> raise (AbruptCompletion.Exn abrupt_completion)

      method raise_abrupt_completion : 'a. AbruptCompletion.t -> 'a =
        fun abrupt_completion ->
          let env = this#env in
          this#reset_env this#empty_env;
          let abrupt_completion_envs =
            (abrupt_completion, env) :: env_state.abrupt_completion_envs
          in
          env_state <- { env_state with abrupt_completion_envs };
          raise (AbruptCompletion.Exn abrupt_completion)

      method expecting_abrupt_completions f =
        let saved = env_state.abrupt_completion_envs in
        let saved_latest_refinements = env_state.latest_refinements in
        env_state <- { env_state with abrupt_completion_envs = [] };
        this#run f ~finally:(fun () ->
            let abrupt_completion_envs = List.rev_append saved env_state.abrupt_completion_envs in
            env_state <-
              {
                env_state with
                abrupt_completion_envs;
                latest_refinements = saved_latest_refinements;
              }
        )

      (* Given multiple completion states, (re)raise if all of them are the same
         abrupt completion. This function is called at merge points. *)
      method merge_completion_states (hd_completion_state, tl_completion_states) =
        match hd_completion_state with
        | None -> ()
        | Some abrupt_completion ->
          if
            List.for_all
              (function
                | None -> false
                | Some abrupt_completion' -> abrupt_completion = abrupt_completion')
              tl_completion_states
          then
            raise (AbruptCompletion.Exn abrupt_completion)

      (* Given a filter for particular abrupt completions to expect, find the saved
         environments corresponding to them, and merge those environments with the
         current environment. This function is called when exiting ASTs that
         introduce (and therefore expect) particular abrupt completions. *)
      method commit_abrupt_completion_matching filter completion_state =
        let (matching, non_matching) =
          List.partition
            (fun (abrupt_completion, _env) -> filter abrupt_completion)
            env_state.abrupt_completion_envs
        in
        if matching <> [] then (
          List.iter (fun (_abrupt_completion, env) -> this#merge_remote_env env) matching;
          env_state <- { env_state with abrupt_completion_envs = non_matching }
        ) else
          match completion_state with
          | Some abrupt_completion when not (filter abrupt_completion) ->
            raise (AbruptCompletion.Exn abrupt_completion)
          | _ -> ()

      method! binding_type_identifier ident =
        let (loc, { Flow_ast.Identifier.name; comments = _ }) = ident in
        let { kind; def_loc; _ } = SMap.find name env_state.env in
        (match def_loc with
        (* Identifiers with no binding can never reintroduce ""cannot reassign binding"" errors *)
        | None -> ()
        | Some def_loc ->
          (match kind with
          | Bindings.Type _ when not (ALoc.equal loc def_loc) ->
            (* Types are already bind in hoister,
               so we only check for rebind in different locations. *)
            add_output
              Error_message.(EBindingError (ENameAlreadyBound, loc, OrdinaryName name, def_loc))
          | Bindings.Type _ -> ()
          | Bindings.Var
          | Bindings.Const
          | Bindings.Let
          | Bindings.Class
          | Bindings.Function
          | Bindings.Parameter ->
            add_output
              Error_message.(EBindingError (ENameAlreadyBound, loc, OrdinaryName name, def_loc))
          | _ -> ()));
        super#identifier ident

      method! function_identifier ident =
        (* The parent flow_ast_mapper treats functions as Vars, but in Flow
         * (not JS, Flow) they behave more like hoisted lets. For the purpose of
         * reassignment errors, we should consider them to be lets *)
        this#pattern_identifier ~kind:Flow_ast.Statement.VariableDeclaration.Let ident

      (* We want to translate object pattern destructing {a:{b:{c}}} = o into o.a.b.c,
         so the use of refinement can be recorded as a write.
         We use acc to keep track of the current parent expr *)
      method private binding_pattern_track_object_destructuring ?kind ~acc expr =
        let open Ast.Pattern in
        let (_, patt) = expr in
        (match patt with
        | Object { Object.properties; annot; comments = _ } ->
          Base.List.iter properties ~f:(fun prop ->
              let open Ast.Pattern.Object in
              match prop with
              | RestElement prop -> ignore @@ this#pattern_object_rest_property ?kind prop
              | Property ((_, { Property.key; pattern; default; shorthand = _ }) as prop) ->
                (match key with
                | Property.Identifier (loc, { Ast.Identifier.name = x; comments = _ })
                | Property.Literal (loc, { Ast.Literal.value = Ast.Literal.String x; _ }) ->
                  Base.Option.iter default ~f:(fun default -> ignore @@ this#expression default);
                  let acc =
                    let open Ast.Expression in
                    let property =
                      Member.PropertyIdentifier (loc, { Ast.Identifier.name = x; comments = None })
                    in
                    (loc, Member { Member._object = acc; property; comments = None })
                  in
                  (match pattern with
                  | ( _,
                      Identifier
                        {
                          Identifier.name = (loc, { Ast.Identifier.name = x; comments = _ });
                          annot;
                          optional = _;
                        }
                    ) ->
                    ignore @@ this#expression acc;
                    (* Leaf of the object pattern *)
                    (match this#get_val_of_expression acc with
                    | None -> ignore @@ this#pattern ?kind pattern
                    | Some refined_v ->
                      ignore @@ this#type_annotation_hint annot;
                      this#bind_pattern_identifier_customized
                        ?kind
                        ~get_assigned_val:(fun base ->
                          Val.replace_refinement_base_write ~base refined_v)
                        loc
                        x)
                  | _ ->
                    ignore @@ this#binding_pattern_track_object_destructuring ?kind ~acc pattern)
                | _ -> ignore @@ this#pattern_object_property ?kind prop)
          );
          ignore @@ this#type_annotation_hint annot
        | Array _
        | Identifier _
        | Expression _ ->
          ignore @@ this#pattern ?kind expr);
        expr

      method! pattern_identifier ?kind ident =
        let (loc, { Flow_ast.Identifier.name = x; comments = _ }) = ident in
        this#bind_pattern_identifier_customized ?kind loc x;
        super#identifier ident

      method private bind_pattern_identifier_customized ?kind ?(get_assigned_val = Base.Fn.id) loc x
          =
        let reason = Reason.(mk_reason (RIdentifier (OrdinaryName x))) loc in
        let { val_ref; heap_refinements; kind = stored_binding_kind; def_loc; havoc = _ } =
          SMap.find x env_state.env
        in
        match kind with
        (* Assignments to undeclared bindings that aren't part of declarations do not
         * initialize those bindings. *)
        | None when Val.is_undeclared_or_skipped !val_ref ->
          (match def_loc with
          | None -> failwith ""Cannot have an undeclared or skipped binding without a def loc""
          | Some def_loc ->
            add_output
              Error_message.(
                EBindingError (EReferencedBeforeDeclaration, loc, OrdinaryName x, def_loc)
              ))
        | _ ->
          (match error_for_assignment_kind cx x loc def_loc stored_binding_kind kind !val_ref with
          | Some err ->
            add_output err;
            let write_entries = L.LMap.add loc Env_api.NonAssigningWrite env_state.write_entries in
            env_state <- { env_state with write_entries }
          | _ ->
            this#havoc_heap_refinements heap_refinements;
            let write_entries =
              if not (Val.is_declared_function !val_ref) then (
                let write_entry =
                  if Val.is_global !val_ref then
                    Env_api.GlobalWrite reason
                  else
                    Env_api.AssigningWrite reason
                in
                val_ref := get_assigned_val (Val.one reason);
                L.LMap.add loc write_entry env_state.write_entries
              ) else
                (* All of the providers are aleady in the map. We don't want to overwrite them with
                 * a non-assigning write. We _do_ want to enter regular function declarations as
                 * non-assigning writes so that they are not checked against the providers in
                * New_env.set_env_entry *)
                L.LMap.update
                  loc
                  (fun x ->
                    match x with
                    | None -> Some Env_api.NonAssigningWrite
                    | _ -> x)
                  env_state.write_entries
            in
            env_state <- { env_state with write_entries })

      (* This method is called during every read of an identifier. We need to ensure that
       * if the identifier is refined that we record the refiner as the write that reaches
       * this read
       *
       * Note that we don't emit EBinding errors for referenced-before-declaration errors here.
       * That is because we may read an UndeclaredClass from a type position and the
       * name_resolver doesn't keep track of whether we are in a type context or not.
       *
       * Instead of augmenting the name_resolver with those capabilities, we emit these errors
       * in the new_env, which does know if it's querying a value or a type.
       * *)
      method any_identifier loc name =
        let { val_ref; havoc; def_loc; kind; _ } = SMap.find name env_state.env in
        let v =
          if env_state.visiting_hoisted_type then
            havoc
          else
            !val_ref
        in
        let values =
          L.LMap.add
            loc
            { def_loc; value = v; binding_kind_opt = Some kind; name = Some name }
            env_state.values
        in
        env_state <- { env_state with values }

      method! this_expression loc this_ =
        this#any_identifier loc ""this"";
        this_

      method! super_expression loc super_ =
        this#any_identifier loc ""super"";
        super_

      method! identifier (ident : (ALoc.t, ALoc.t) Ast.Identifier.t) =
        let (loc, { Ast.Identifier.name = x; comments = _ }) = ident in
        this#any_identifier loc x;
        super#identifier ident

      method! generic_identifier_type (git : ('loc, 'loc) Ast.Type.Generic.Identifier.t) =
        let open Ast.Type.Generic.Identifier in
        let rec loop git =
          match git with
          | Unqualified i -> ignore @@ this#type_identifier i
          | Qualified (_, { qualification; _ }) -> loop qualification
        in
        loop git;
        git

      method! jsx_element_name_identifier (ident : (ALoc.t, ALoc.t) Ast.JSX.Identifier.t) =
        let (loc, { Ast.JSX.Identifier.name; comments = _ }) = ident in
        this#any_identifier loc name;
        super#jsx_identifier ident

      method! jsx_element_name_namespaced ns =
        (* TODO: what identifiers does `<foo:bar />` read? *)
        super#jsx_element_name_namespaced ns

      method havoc_heap_refinements_using_name ~private_ name =
        SMap.iter
          (fun _ { heap_refinements; _ } ->
            heap_refinements :=
              HeapRefinementMap.filter
                (fun projections _ ->
                  not (RefinementKey.proj_uses_propname ~private_ name projections))
                !heap_refinements)
          env_state.env

      (* This function should be called _after_ a member expression is assigned a value.
       * It havocs other heap refinements depending on the name of the member and then adds
       * a write to the heap refinement entry for that member expression *)
      method assign_expression ~update_entry lhs rhs =
        ignore @@ this#pattern_expression lhs;
        ignore @@ this#expression rhs;
        match lhs with
        | (loc, Flow_ast.Expression.Member member) ->
          let reason = mk_reason RSomeProperty loc in
          let assigned_val = Val.one reason in
          this#assign_member ~update_entry member loc assigned_val reason
        | _ -> ()

      method assign_member ~update_entry lhs_member lhs_loc assigned_val val_reason =
        this#post_assignment_heap_refinement_havoc lhs_member;
        (* We pass allow_optional:false, but optional chains can't be in the LHS anyway. *)
        let lookup = RefinementKey.lookup_of_member lhs_member ~allow_optional:false in
        let open Flow_ast.Expression in
        match (lhs_member, lookup) with
        | ( { Member.property = Member.PropertyIdentifier _ | Member.PropertyPrivateName _; _ },
            Some lookup
          )
          when update_entry ->
          this#map_val_with_lookup
            lookup
            (fun _ -> assigned_val)
            ~create_val_for_heap:(lazy assigned_val);
          let write_entries =
            L.LMap.add lhs_loc (Env_api.AssigningWrite val_reason) env_state.write_entries
          in
          env_state <- { env_state with write_entries }
        | _ -> ()

      (* This method is called after assigning a member expression but _before_ the refinement for
       * that assignment is recorded. *)
      method post_assignment_heap_refinement_havoc
          (lhs : (ALoc.t, ALoc.t) Flow_ast.Expression.Member.t) =
        let open Flow_ast.Expression in
        match lhs with
        | {
         Member._object;
         property = Member.PropertyPrivateName (_, { Flow_ast.PrivateName.name; _ });
         _;
        } ->
          (* Yes, we want to havoc using the PROPERTY name here. This is because we
           * do not do any alias tracking, so we want to have the following behavior:
           * let x = {};
           * let y = x;
           * x.foo = 3;
           * y.foo = 4;
           * (x.foo: 3) // MUST error!
           *)
          this#havoc_heap_refinements_using_name name ~private_:true
        | {
         Member._object;
         property = Member.PropertyIdentifier (_, { Flow_ast.Identifier.name; _ });
         _;
        } ->
          (* As in the previous case, we can't know if this object is aliased nor what property
           * is being written. We are forced to conservatively havoc ALL heap refinements in this
           * situation. *)
          this#havoc_heap_refinements_using_name name ~private_:false
        | { Member._object; property = Member.PropertyExpression _; _ } ->
          this#havoc_all_heap_refinements ()

      (* Order of evaluation matters *)
      method! assignment _loc (expr : (ALoc.t, ALoc.t) Ast.Expression.Assignment.t) =
        let open Ast.Expression.Assignment in
        let { operator; left = (left_loc, _) as left; right; comments = _ } = expr in
        begin
          match operator with
          | None ->
            let open Ast.Pattern in
            begin
              match left with
              | (_, (Identifier _ | Object _ | Array _)) ->
                (* given `x = e`, read e then write x *)
                ignore @@ this#expression right;
                ignore @@ this#assignment_pattern left
              | (_, Expression e) ->
                (* given `o.x = e`, read o then read e *)
                this#assign_expression ~update_entry:true e right
            end
          | Some
              ( PlusAssign | MinusAssign | MultAssign | ExpAssign | DivAssign | ModAssign
              | LShiftAssign | RShiftAssign | RShift3Assign | BitOrAssign | BitXorAssign
              | BitAndAssign ) ->
            let open Ast.Pattern in
            begin
              match left with
              | (_, Identifier { Identifier.name; _ }) ->
                (* given `x += e`, read x then read e then write x *)
                ignore @@ this#identifier name;
                ignore @@ this#expression right;
                ignore @@ this#assignment_pattern left
              | (_, Expression e) ->
                (* given `o.x += e`, read o then read e *)
                this#assign_expression ~update_entry:true e right
              | (_, (Object _ | Array _)) -> statement_error
            end
          | Some ((OrAssign | AndAssign | NullishAssign) as operator) ->
            let left_expr =
              match left with
              | (lhs_loc, Ast.Pattern.Identifier { Ast.Pattern.Identifier.name; _ }) ->
                Some (lhs_loc, Ast.Expression.Identifier name)
              | (lhs_loc, Ast.Pattern.Expression (_, Ast.Expression.Member mem)) ->
                Some (lhs_loc, Ast.Expression.Member mem)
              | _ -> None
            in
            this#push_refinement_scope empty_refinements;
            (match left_expr with
            | None -> statement_error
            | Some left_expr ->
              begin
                match RefinementKey.of_expression left_expr with
                | None -> ()
                | Some refinement_key ->
                  (* If we don't already have a projection val in the environment for this key, we need to create one and commit it. We can't create it
                     via a refinement, because then it would be popped off as part of a changeset at the end of the refinement scope. *)
                  this#add_projection refinement_key
              end;
              (* THe LHS is unconditionally evaluated, so we don't run-to-completion and catch the
               * error here *)
              (match operator with
              | OrAssign
              | AndAssign ->
                ignore (this#expression_refinement left_expr)
              | NullishAssign ->
                ignore (this#expression left_expr);
                this#add_refinement_to_expr left_expr (L.LSet.singleton left_loc, NotR MaybeR)
              | _ -> ()));
            let env1 = this#env_without_latest_refinements in
            let env1_with_refinements = this#env in
            (match operator with
            | NullishAssign
            | OrAssign ->
              this#negate_new_refinements ()
            | _ -> ());
            (* The RHS is _only_ evaluated if the LHS fails its check. That means that patterns like
               * x || invariant(false) should propagate the truthy refinement to the next line. We keep track
               * of the completion state on the rhs to do that. If the LHS throws then the entire expression
               * throws, so there's no need to catch the exception from the LHS *)
            let rhs_completion_state =
              this#run_to_completion (fun () -> ignore @@ this#expression right)
            in
            (match rhs_completion_state with
            | Some AbruptCompletion.Throw ->
              this#reset_env env1_with_refinements;
              this#pop_refinement_scope_without_unrefining ()
            | _ ->
              this#pop_refinement_scope ();
              this#merge_self_env env1);
            ignore @@ this#assignment_pattern left
        end;
        expr

      (* Order of evaluation matters *)
      method! variable_declarator
          ~kind (decl : (ALoc.t, ALoc.t) Ast.Statement.VariableDeclaration.Declarator.t) =
        let open Ast.Statement.VariableDeclaration.Declarator in
        let (_loc, { id; init }) = decl in
        let open Ast.Pattern in
        begin
          match id with
          | ( _,
              ( Identifier { Ast.Pattern.Identifier.annot; _ }
              | Object { Ast.Pattern.Object.annot; _ }
              | Array { Ast.Pattern.Array.annot; _ } )
            ) ->
            begin
              match init with
              | Some init ->
                (* given `var x = e`, read e then write x *)
                ignore @@ this#expression init;
                ignore @@ this#binding_pattern_track_object_destructuring ~kind ~acc:init id
              | None ->
                (* No rhs means no write occurs, but the variable moves from undeclared to
                 * uninitialized. *)
                Flow_ast_utils.fold_bindings_of_pattern
                  (fun () (loc, { Flow_ast.Identifier.name; _ }) ->
                    let { val_ref; kind = stored_binding_kind; def_loc; _ } =
                      SMap.find name env_state.env
                    in
                    let () =
                      error_for_assignment_kind
                        cx
                        name
                        loc
                        def_loc
                        stored_binding_kind
                        (Some kind)
                        !val_ref
                      |> Base.Option.iter ~f:add_output
                    in
                    if Val.is_undeclared !val_ref then val_ref := Val.uninitialized loc)
                  ()
                  id;
                ignore @@ this#type_annotation_hint annot
            end
          | (_, Expression _) -> statement_error
        end;
        decl

      (* read and write (when the argument is an identifier) *)
      method! update_expression _loc (expr : (ALoc.t, ALoc.t) Ast.Expression.Update.t) =
        let open Ast.Expression.Update in
        let { argument; operator = _; prefix = _; comments = _ } = expr in
        begin
          match argument with
          | (_, Ast.Expression.Identifier x) ->
            (* given `x++`, read x then write x *)
            ignore @@ this#identifier x;
            ignore @@ this#pattern_identifier x
          | (loc, Ast.Expression.Member member) ->
            (* given `o.x++`, read o.x then write o.x *)
            ignore @@ this#expression argument;
            ignore @@ this#pattern_expression argument;
            let val_reason = mk_reason RSomeProperty loc in
            let assigned_val = Val.number val_reason in
            (* We explicitly write a number instead of using the location of the write to avoid
             * location clashes between the read of the member and the write of the member. If
             * we don't do this then expressions like o.x++ will attempt to unify the read of o.x
             * with the write of o.x that happens in that update expression *)
            (match RefinementKey.lookup_of_member member ~allow_optional:false with
            | Some lookup ->
              this#map_val_with_lookup
                lookup
                (fun _ -> assigned_val)
                ~create_val_for_heap:(lazy assigned_val)
            | _ -> ())
          | _ -> (* given 'o()++`, read o *) ignore @@ this#expression argument
        end;
        expr

      (* things that cause abrupt completions *)
      method! break _loc (stmt : ALoc.t Ast.Statement.Break.t) =
        let open Ast.Statement.Break in
        let { label; comments = _ } = stmt in
        this#raise_abrupt_completion (AbruptCompletion.break label)

      method! continue _loc (stmt : ALoc.t Ast.Statement.Continue.t) =
        let open Ast.Statement.Continue in
        let { label; comments = _ } = stmt in
        this#raise_abrupt_completion (AbruptCompletion.continue label)

      method! return _loc (stmt : (ALoc.t, ALoc.t) Ast.Statement.Return.t) =
        let open Ast.Statement.Return in
        let { argument; comments = _ } = stmt in
        ignore @@ Flow_ast_mapper.map_opt this#expression argument;
        this#raise_abrupt_completion AbruptCompletion.return

      method! throw _loc (stmt : (ALoc.t, ALoc.t) Ast.Statement.Throw.t) =
        let open Ast.Statement.Throw in
        let { argument; comments = _ } = stmt in
        ignore @@ this#expression argument;
        this#raise_abrupt_completion AbruptCompletion.throw

      (** Control flow **)
      method! if_statement _loc stmt =
        let open Flow_ast.Statement.If in
        let { test; consequent; alternate; _ } = stmt in
        this#push_refinement_scope empty_refinements;
        ignore @@ this#expression_refinement test;
        let test_refinements = this#peek_new_refinements () in
        let env0 = this#env_without_latest_refinements in
        (* collect completions and environments of every branch *)
        let then_completion_state =
          this#run_to_completion (fun () ->
              ignore @@ this#if_consequent_statement ~has_else:(alternate <> None) consequent
          )
        in
        let then_env_no_refinements = this#env_without_latest_refinements in
        let then_env_with_refinements = this#env in
        this#pop_refinement_scope ();
        this#reset_env env0;
        this#push_refinement_scope test_refinements;
        this#negate_new_refinements ();
        let else_completion_state =
          this#run_to_completion (fun () ->
              ignore
              @@ Flow_ast_mapper.map_opt
                   (fun (loc, { Alternate.body; comments }) ->
                     (loc, { Alternate.body = this#statement body; comments }))
                   alternate
          )
        in
        (* merge environments *)
        let else_env_no_refinements = this#env_without_latest_refinements in
        let else_env_with_refinements = this#env in
        this#pop_refinement_scope ();
        this#reset_env env0;
        this#merge_conditional_branches_with_refinements
          (then_env_no_refinements, then_env_with_refinements, then_completion_state)
          (else_env_no_refinements, else_env_with_refinements, else_completion_state);

        (* merge completions *)
        let if_completion_states = (then_completion_state, [else_completion_state]) in
        this#merge_completion_states if_completion_states;
        stmt

      method! conditional _loc (expr : (ALoc.t, ALoc.t) Flow_ast.Expression.Conditional.t) =
        let open Flow_ast.Expression.Conditional in
        let { test; consequent; alternate; comments = _ } = expr in
        this#push_refinement_scope empty_refinements;
        ignore @@ this#expression_refinement test;
        let test_refinements = this#peek_new_refinements () in
        let env0 = this#env_without_latest_refinements in
        let consequent_completion_state =
          this#run_to_completion (fun () -> ignore @@ this#expression consequent)
        in
        let consequent_env_no_refinements = this#env_without_latest_refinements in
        let consequent_env_with_refinements = this#env in
        this#pop_refinement_scope ();
        this#reset_env env0;
        this#push_refinement_scope test_refinements;
        this#negate_new_refinements ();
        let alternate_completion_state =
          this#run_to_completion (fun () -> ignore @@ this#expression alternate)
        in
        let alternate_env_no_refinements = this#env_without_latest_refinements in
        let alternate_env_with_refinements = this#env in
        this#pop_refinement_scope ();
        this#reset_env env0;
        this#merge_conditional_branches_with_refinements
          ( consequent_env_no_refinements,
            consequent_env_with_refinements,
            consequent_completion_state
          )
          (alternate_env_no_refinements, alternate_env_with_refinements, alternate_completion_state);

        (* merge completions *)
        let conditional_completion_states =
          (consequent_completion_state, [alternate_completion_state])
        in
        this#merge_completion_states conditional_completion_states;
        expr

      method merge_conditional_branches_with_refinements
          (env1, refined_env1, completion_state1) (env2, refined_env2, completion_state2) : unit =
        (* We only want to merge the refined environments from the two branches of an if-statement
         * if there was an assignment in one of the branches. Otherwise, merging the positive and
         * negative branches of the refinement into a union would be unnecessary work to
         * reconstruct the original type.
         *
         * If one of the branches abnormally completes then we can just take the refinements
         * from the other branch. *)
        match (completion_state1, completion_state2) with
        | (None, Some _) -> this#reset_env refined_env1
        | (Some _, None) -> this#reset_env refined_env2
        | _ ->
          SMap.iter
            (fun name { val_ref; heap_refinements; _ } ->
              let { Env.env_val = value1; heap_refinements = _; def_loc = _ } =
                SMap.find name env1
              in
              let { Env.env_val = value2; heap_refinements = _; def_loc = _ } =
                SMap.find name env2
              in
              let {
                Env.env_val = refined_value1;
                heap_refinements = heap_refinements1;
                def_loc = _;
              } =
                SMap.find name refined_env1
              in
              let {
                Env.env_val = refined_value2;
                heap_refinements = heap_refinements2;
                def_loc = _;
              } =
                SMap.find name refined_env2
              in
              (* If the same key exists on both versions of the object then we can
               * merge the two heap refinements, even though the underlying value
               * has changed. This is because the final object does indeed have
               * one of the two refinements at the merge *)
              heap_refinements := this#merge_heap_refinements heap_refinements1 heap_refinements2;
              if Val.id_of_val value1 = Val.id_of_val value2 then
                val_ref := value1
              else
                val_ref := Val.merge refined_value1 refined_value2)
            env_state.env

      method with_env_state f =
        let pre_state = env_state in
        let pre_env = this#env in
        let result = f () in
        env_state <- pre_state;
        (* It's not enough to just restore the old env_state, since the env itself contains
         * refs. We need to call reset_env to _fully_ reset the env_state *)
        this#reset_env pre_env;
        result

      (* Functions called inside scout_changed_vars are responsible for popping any refinement
       * scopes they may introduce
       *)
      method scout_changed_vars ~scout =
        (* Calling scout may have side effects, like adding new abrupt completions. We
         * need to be sure to restore the old abrupt completion envs after scouting,
         * because a scout should be followed-up by a run that revisits everything visited by
         * the scout. with_env_state will ensure that all mutable state is restored. *)
        this#with_env_state (fun () ->
            let pre_env = this#env in
            scout ();
            let post_env = this#env in
            SMap.fold
              (fun name { Env.env_val = env_val1; heap_refinements = _; def_loc = _ } acc ->
                let { Env.env_val = env_val2; heap_refinements = _; def_loc = _ } =
                  SMap.find name pre_env
                in
                let normalized_val1 = Val.normalize_through_refinements env_val1.Val.write_state in
                let normalized_val2 = Val.normalize_through_refinements env_val2.Val.write_state in
                if Val.WriteSet.equal normalized_val1 normalized_val2 then
                  acc
                else
                  RefinementKey.lookup_of_name name :: acc)
              post_env
              []
        )

      method havoc_changed_vars changed_vars =
        List.iter
          (fun lookup ->
            let { RefinementKey.base; projections } = lookup in
            let { val_ref; havoc; heap_refinements; def_loc = _; kind } =
              SMap.find base env_state.env
            in
            (* If a var is changed then all the heap refinements on that var should
             * also be havoced. If only heap refinements are havoced then there's no
             * need to havoc the subject of the projection *)
            match projections with
            | [] ->
              this#havoc_heap_refinements heap_refinements;
              if kind <> Bindings.Const && not (Val.is_undeclared_or_skipped !val_ref) then
                val_ref :=
                  Base.List.fold
                    ~init:havoc
                    ~f:(fun acc write -> Val.merge acc (Val.of_write write))
                    (Val.writes_of_uninitialized this#refinement_may_be_undefined !val_ref)
            | _ -> heap_refinements := HeapRefinementMap.remove projections !heap_refinements)
          changed_vars

      method handle_continues loop_completion_state continues =
        this#run_to_completion (fun () ->
            this#commit_abrupt_completion_matching
              (AbruptCompletion.mem continues)
              loop_completion_state
        )

      (* After a loop we need to negate the loop guard and apply the refinement. The
       * targets of those refinements may have been changed by the loop, but that
       * doesn't matter. The only way to get out of the loop is for the negation of
       * the refinement to hold, so we apply that negation even though the ssa_id might
       * not match.
       *
       * The exception here is, of course, if we break out of the loop. If we break
       * inside the loop then we should not negate the refinements because it is
       * possible that we just exited the loop by breaking.
       *
       * We don't need to check for continues because they are handled before this point.
       * We don't check for throw/return because then we wouldn't proceed to the line
       * after the loop anyway. *)
      method post_loop_refinements { total; _ } =
        if not AbruptCompletion.(mem (List.map fst env_state.abrupt_completion_envs) (break None))
        then
          match total with
          | None -> ()
          | Some total ->
            let (applied, _) = this#normalize_total_refinements (Not total) in
            applied
            |> IMap.iter (fun _ (lookup, refinement_id) ->
                   let refine_val x = Val.refinement refinement_id x in
                   this#map_val_with_lookup lookup refine_val
               )

      (*
       * Unlike the ssa_builder, the name_resolver does not create REF unresolved
       * Val.ts to model the write states of variables in loops. This approach
       * would cause a lot of cycles in the ordering algorithm, which means
       * we'd need to ask for a lot of annotations. Moreover, it's not clear where
       * those annotations should go.
       *
       * Instead, we scout the body of the loop to find which variables are
       * written to. If a variable is written, then we havoc that variable
       * before entering the loop. This does not apply to variables that are
       * only refined.
       *
       * After visiting the body, we reset the state in the ssa environment,
       * havoc any vars that need to be havoced, and then visit the body again.
       * After that we negate the refinements on the loop guard.
       *
       * Here's how each param should be used:
       * scout: Visit the guard and any updaters if applicable, then visit the body
       * visit_guard_and_body: Visit the guard with a refinement scope, any updaters
       *   if applicable, and then visit the body. Return a tuple of the guard
       *   refinement scope, the env after the guard with no refinements, and the loop
       *   completion state.
       * make_completion_states: given the loop completion state, give the list of
       *   possible completion states for the loop. For do while loops this is different
       *   than regular while loops, so those two implementations may be instructive.
       * auto_handle_continues: Every loop needs to filter out continue completion states.
       *   The default behavior is to do that filtering at the end of the body.
       *   If you need to handle continues before that, like in a do/while loop, then
       *   set this to false. Ensure that you handle continues in both the scouting and
       *   main passes.
       *)
      method env_loop
          ~scout ~visit_guard_and_body ~make_completion_states ~auto_handle_continues ~continues =
        this#expecting_abrupt_completions (fun () ->
            (* Scout the body for changed vars *)
            let changed_vars = this#scout_changed_vars ~scout in

            (* We havoc the changed vars in order to prevent loops in the EnvBuilder writes-graph,
             * which would require a fix-point analysis that would not be compatible with
             * local type inference *)
            this#havoc_changed_vars changed_vars;

            (* Now we push a refinement scope and visit the guard/body. At the end, we completely
             * get rid of refinements introduced by the guard, even if they occur in a PHI node, to
             * ensure that the refinement does not escape the loop via something like
             * control flow. For example:
             * while (x != null) {
             *   if (x == 3) {
             *     x = 4;
             *   }
             * }
             * x; // Don't want x to be a PHI of x != null and x = 4.
             *)
            this#push_refinement_scope empty_refinements;
            let (guard_refinements, env_after_test_no_refinements, loop_completion_state) =
              visit_guard_and_body ()
            in
            let loop_completion_state =
              if auto_handle_continues then
                this#handle_continues loop_completion_state continues
              else
                loop_completion_state
            in
            this#pop_refinement_scope_after_loop ();

            (* We either enter the loop body or we don't *)
            (match env_after_test_no_refinements with
            | None -> ()
            | Some env -> this#merge_loop_guard_env_after_loop env);
            this#post_loop_refinements guard_refinements;

            let completion_states = make_completion_states loop_completion_state in
            let completion_state =
              this#run_to_completion (fun () -> this#merge_completion_states completion_states)
            in
            this#commit_abrupt_completion_matching
              AbruptCompletion.(mem [break None])
              completion_state
        )

      method! while_ _loc (stmt : (ALoc.t, ALoc.t) Flow_ast.Statement.While.t) =
        let open Flow_ast.Statement.While in
        let { test; body; comments = _ } = stmt in
        let scout () =
          ignore @@ this#expression test;
          ignore @@ this#run_to_completion (fun () -> ignore @@ this#statement body)
        in
        let visit_guard_and_body () =
          ignore @@ this#expression_refinement test;
          let guard_refinements = this#peek_new_refinements () in
          let post_guard_no_refinements_env = this#env_without_latest_refinements in
          let loop_completion_state =
            this#run_to_completion (fun () -> ignore @@ this#statement body)
          in
          (guard_refinements, Some post_guard_no_refinements_env, loop_completion_state)
        in
        let make_completion_states loop_completion_state = (None, [loop_completion_state]) in
        let continues = AbruptCompletion.continue None :: env_state.possible_labeled_continues in
        this#env_loop
          ~scout
          ~visit_guard_and_body
          ~make_completion_states
          ~auto_handle_continues:true
          ~continues;
        stmt

      method! do_while _loc stmt =
        let open Flow_ast.Statement.DoWhile in
        let { test; body; comments = _ } = stmt in
        let continues = AbruptCompletion.continue None :: env_state.possible_labeled_continues in
        let scout () =
          let loop_completion_state =
            this#run_to_completion (fun () -> ignore @@ this#statement body)
          in
          ignore @@ this#handle_continues loop_completion_state continues;
          match loop_completion_state with
          | None -> ignore @@ this#expression test
          | Some _ -> ()
        in
        let visit_guard_and_body () =
          let loop_completion_state =
            this#run_to_completion (fun () -> ignore @@ this#statement body)
          in
          let loop_completion_state = this#handle_continues loop_completion_state continues in
          (match loop_completion_state with
          | None -> ignore @@ this#expression_refinement test
          | Some _ -> ());
          (this#peek_new_refinements (), None, loop_completion_state)
        in
        let make_completion_states loop_completion_state = (loop_completion_state, []) in
        this#env_loop
          ~scout
          ~visit_guard_and_body
          ~make_completion_states
          ~auto_handle_continues:false
          ~continues;
        stmt

      method! scoped_for_statement _loc stmt =
        let open Flow_ast.Statement.For in
        let { init; test; update; body; comments = _ } = stmt in
        let continues = AbruptCompletion.continue None :: env_state.possible_labeled_continues in
        let scout () =
          ignore @@ Flow_ast_mapper.map_opt this#for_statement_init init;
          ignore @@ Flow_ast_mapper.map_opt this#expression test;
          let loop_completion_state =
            this#run_to_completion (fun () -> ignore @@ this#statement body)
          in
          let loop_completion_state = this#handle_continues loop_completion_state continues in
          match loop_completion_state with
          | None -> ignore @@ Flow_ast_mapper.map_opt this#expression update
          | Some _ -> ()
        in
        let visit_guard_and_body () =
          ignore @@ Flow_ast_mapper.map_opt this#for_statement_init init;
          ignore @@ Flow_ast_mapper.map_opt this#expression_refinement test;
          let guard_refinements = this#peek_new_refinements () in
          let post_guard_no_refinements_env = this#env_without_latest_refinements in
          let loop_completion_state =
            this#run_to_completion (fun () -> ignore @@ this#statement body)
          in
          let loop_completion_state = this#handle_continues loop_completion_state continues in
          (match loop_completion_state with
          | None -> ignore @@ Flow_ast_mapper.map_opt this#expression update
          | Some _ -> ());
          (guard_refinements, Some post_guard_no_refinements_env, loop_completion_state)
        in
        let make_completion_states loop_completion_state = (None, [loop_completion_state]) in
        this#env_loop
          ~scout
          ~visit_guard_and_body
          ~make_completion_states
          ~auto_handle_continues:false
          ~continues;
        stmt

      method for_in_or_of_left_declaration left =
        let (_, decl) = left in
        let { Flow_ast.Statement.VariableDeclaration.declarations; kind; comments = _ } = decl in
        match declarations with
        | [(_, { Flow_ast.Statement.VariableDeclaration.Declarator.id; init = _ })] ->
          let open Flow_ast.Pattern in
          (match id with
          | (_, (Identifier _ | Object _ | Array _)) ->
            ignore @@ this#variable_declarator_pattern ~kind id
          | _ -> failwith ""unexpected AST node"")
        | _ -> failwith ""Syntactically valid for-in loops must have exactly one left declaration""

      method! for_in_left_declaration left =
        this#for_in_or_of_left_declaration left;
        left

      method! for_of_left_declaration left =
        this#for_in_or_of_left_declaration left;
        left

      method scoped_for_in_or_of_statement traverse_left body =
        (* You might be wondering why the lhs has to be scouted-- the LHS can be a pattern that
         * includes a default write with a variable that is written to inside the loop. It's
         * critical that we catch loops in the dependency graph with such variables, since the
         * ordering algorithm will not have a good place to ask for an annotation in that case.
         *)
        let scout () =
          traverse_left ();
          ignore @@ this#run_to_completion (fun () -> ignore @@ this#statement body)
        in
        let visit_guard_and_body () =
          let env = this#env in
          traverse_left ();
          let loop_completion_state =
            this#run_to_completion (fun () -> ignore @@ this#statement body)
          in
          (this#peek_new_refinements (), Some env, loop_completion_state)
        in
        let make_completion_states loop_completion_state = (None, [loop_completion_state]) in
        let continues = AbruptCompletion.continue None :: env_state.possible_labeled_continues in
        this#env_loop
          ~scout
          ~visit_guard_and_body
          ~make_completion_states
          ~auto_handle_continues:true
          ~continues

      method! scoped_for_in_statement _loc stmt =
        let open Flow_ast.Statement.ForIn in
        let { left; right; body; each = _; comments = _ } = stmt in
        let traverse_left () = ignore (this#for_in_statement_lhs left) in
        this#push_refinement_scope empty_refinements;
        ignore @@ this#expression_refinement right;
        this#scoped_for_in_or_of_statement traverse_left body;
        this#pop_refinement_scope ();
        stmt

      method! scoped_for_of_statement _loc stmt =
        let open Flow_ast.Statement.ForOf in
        let { left; right; body; await = _; comments = _ } = stmt in
        (* This is only evaluated once and so does not need to be scouted *)
        ignore @@ this#expression right;
        let traverse_left () = ignore (this#for_of_statement_lhs left) in
        this#scoped_for_in_or_of_statement traverse_left body;
        stmt

      method! switch loc switch =
        let open Flow_ast.Statement.Switch in
        let incoming_env = this#env in
        let { discriminant; cases; comments = _ } = switch in
        let _ = this#expression discriminant in
        let lexical_hoist = new lexical_hoister ~flowmin_compatibility:false ~enable_enums in
        let cases_with_lexical_bindings =
          Base.List.map cases ~f:(fun ((_, { Case.consequent; _ }) as case) ->
              let bindings = lexical_hoist#acc |> Bindings.to_map in
              let _ = lexical_hoist#statement_list consequent in
              (case, bindings)
          )
        in
        this#run
          (fun () ->
            ignore
            @@ this#with_bindings
                 ~lexical:true
                 loc
                 lexical_hoist#acc
                 (this#switch_cases_with_lexical_bindings loc discriminant)
                 cases_with_lexical_bindings)
          ~finally:(fun () ->
            let post_env = this#env in
            (* After all refinements and potential shadowing inside switch,
               we need to re-read the discriminant to restore it. *)
            this#reset_env incoming_env;
            ignore @@ this#expression switch.discriminant;
            this#reset_env post_env);
        switch

      (***********************************************************)
      (* [PRE] switch (e) { case e1: s1 ... case eN: sN } [POST] *)
      (***********************************************************)
      (*     |                                                   *)
      (*     e                                                   *)
      (*    /                                                    *)
      (*   e1                                                    *)
      (*   | \                                                   *)
      (*   .  s1                                                 *)
      (*   |   |                                                 *)
      (*   ei  .                                                 *)
      (*   | \ |                                                 *)
      (*   .  si                                                 *)
      (*   |   |                                                 *)
      (*   eN  .                                                 *)
      (*   | \ |                                                 *)
      (*   |  sN                                                 *)
      (*    \  |                                                 *)
      (*      \|                                                 *)
      (*       |                                                 *)
      (***********************************************************)
      (* [PRE] e [ENV0]                                          *)
      (* ENV0' = empty                                           *)
      (* \forall i = 0..N-1:                                     *)
      (*   [ENVi] ei+1 [ENVi+1]                                  *)
      (*   [ENVi+1 | ENVi'] si+1 [ENVi+1']                       *)
      (* POST = ENVN | ENVN'                                     *)
      (***********************************************************)
      method private switch_cases_with_lexical_bindings
          switch_loc discriminant cases_with_lexical_bindings =
        let incoming_env = this#env in
        this#expecting_abrupt_completions (fun () ->
            let (case_starting_env, case_completion_states, fallthrough_env, has_default) =
              List.fold_left
                (fun acc ((loc, case), bindings) ->
                  this#env_switch_case discriminant acc (loc, case, bindings))
                (incoming_env, [], None, false)
                cases_with_lexical_bindings
            in
            this#reset_env case_starting_env;
            ( if not has_default then
              let discriminant_after_all_negated_refinements =
                this#get_val_of_expression discriminant
              in
              match discriminant_after_all_negated_refinements with
              | Some discriminant ->
                env_state <-
                  {
                    env_state with
                    values =
                      L.LMap.add
                        switch_loc
                        {
                          def_loc = None;
                          value = discriminant;
                          binding_kind_opt = None;
                          name = None;
                        }
                        env_state.values;
                  }
              | None -> ()
            );

            (match fallthrough_env with
            (* If the switch has a default then it is exhaustive. Thus, the post-env can be
             * determined by joining all of the breaks with the last fallthrough env. If there
             * was no fallthrough env, then the we can use empty as the base. *)
            | Some env when has_default -> this#reset_env env
            | None when has_default -> this#reset_env this#empty_env
            (* If the switch wasn't exhaustive then merge with the case_starting_env as a base. If
             * the last case fell out then merge that in too. *)
            | Some fallthrough -> this#merge_remote_env fallthrough
            | _ -> ());

            (* In general, cases are non-exhaustive, but if it has a default case then it is! *)
            let completion_state =
              if has_default then
                (* Since there is a default we know there is at least one element in this
                 * list, which means calling List.hd or tail will not fail *)
                let first_state = List.hd case_completion_states in
                let remaining_states = List.tl case_completion_states in
                this#run_to_completion (fun () ->
                    this#merge_completion_states (first_state, remaining_states)
                )
              else
                None
            in

            this#commit_abrupt_completion_matching
              AbruptCompletion.(mem [break None])
              completion_state
        );
        cases_with_lexical_bindings

      method private env_switch_case
          discriminant
          (case_starting_env, case_completion_states, fallthrough_env, has_default)
          (case_loc, case, lexical_bindings) =
        let open Ast.Statement.Switch.Case in
        let { test; consequent; comments = _ } = case in
        this#reset_env case_starting_env;
        (* Reset discriminant *)
        this#push_refinement_scope empty_refinements;
        let (has_default, latest_refinements, case_starting_env) =
          match test with
          | None -> (true, empty_refinements, this#env)
          | Some test ->
            (* As a convention, locate refined versions of the discriminant on
               case locations, in order to read them from the environment for
               filtered TestProp checks. *)
            begin
              match discriminant with
              | (_, Ast.Expression.Member { Ast.Expression.Member._object; _ }) ->
                begin
                  match this#get_val_of_expression _object with
                  | None ->
                    let values = L.LMap.remove case_loc env_state.values in
                    env_state <- { env_state with values }
                  | Some refined_v ->
                    let values =
                      L.LMap.add
                        case_loc
                        { def_loc = None; value = refined_v; binding_kind_opt = None; name = None }
                        env_state.values
                    in
                    env_state <- { env_state with values }
                end
              | _ -> ()
            end;
            ignore @@ this#expression test;
            let (loc, _) = test in
            this#eq_test ~strict:true ~sense:true ~cond_context:SwitchTest loc discriminant test;
            (has_default, this#peek_new_refinements (), this#env_without_latest_refinements)
        in
        (match fallthrough_env with
        | None -> ()
        | Some fallthrough -> this#merge_self_env fallthrough);
        let () =
          lexical_bindings
          |> SMap.iter (fun name (kind, (loc, _)) ->
                 match kind with
                 | Bindings.Let
                 | Bindings.Const ->
                   let { val_ref; heap_refinements; _ } = SMap.find name env_state.env in
                   this#havoc_heap_refinements heap_refinements;
                   val_ref := Val.declared_but_skipped name loc
                 | _ -> ()
             )
        in
        let case_completion_state =
          this#run_to_completion (fun () -> ignore @@ this#statement_list consequent)
        in
        let fallthrough_env =
          match case_completion_state with
          | None -> Some this#env
          | Some _ -> None
        in
        this#pop_refinement_scope ();
        this#reset_env case_starting_env;
        let negated_refinements = this#negate_refinements latest_refinements in
        this#push_refinement_scope negated_refinements;
        let case_starting_env = this#env in
        this#pop_refinement_scope ();
        ( case_starting_env,
          case_completion_state :: case_completion_states,
          fallthrough_env,
          has_default
        )

      (****************************************)
      (* [PRE] try { s1 } catch { s2 } [POST] *)
      (****************************************)
      (*    |                                 *)
      (*    s1 ..~                            *)
      (*    |    |                            *)
      (*    |   s2                            *)
      (*     \./                              *)
      (*      |                               *)
      (****************************************)
      (* [PRE] s1 [ENV1]                      *)
      (* [HAVOC] s2 [ENV2 ]                   *)
      (* POST = ENV1 | ENV2                   *)
      (****************************************)
      (*******************************************************)
      (* [PRE] try { s1 } catch { s2 } finally { s3 } [POST] *)
      (*******************************************************)
      (*    |                                                *)
      (*    s1 ..~                                           *)
      (*    |    |                                           *)
      (*    |   s2 ..~                                       *)
      (*     \./     |                                       *)
      (*      |______|                                       *)
      (*             |                                       *)
      (*            s3                                       *)
      (*             |                                       *)
      (*******************************************************)
      (* [PRE] s1 [ENV1]                                     *)
      (* [HAVOC] s2 [ENV2 ]                                  *)
      (* [HAVOC] s3 [ENV3 ]                                  *)
      (* POST = ENV3                                         *)
      (*******************************************************)
      method! try_catch _loc (stmt : (ALoc.t, ALoc.t) Ast.Statement.Try.t) =
        this#expecting_abrupt_completions (fun () ->
            let open Ast.Statement.Try in
            let { block = (loc, block); handler; finalizer; comments = _ } = stmt in
            let try_entry_env = this#env in
            let try_completion_state =
              this#run_to_completion (fun () -> ignore @@ this#block loc block)
            in
            let try_exit_env = this#env in
            this#merge_env try_entry_env try_exit_env;
            let catch_entry_env = this#env in
            let catch_completion_state_opt =
              match handler with
              | Some (loc, clause) ->
                this#run_to_completion (fun () -> ignore @@ this#catch_clause loc clause)
              | None ->
                (* No catch is like having a catch that always re-throws the error from the
                 * try block.*)
                Some AbruptCompletion.Throw
            in
            let catch_exit_env = this#env in
            this#merge_env try_exit_env catch_exit_env;
            let try_catch_completion_states =
              (try_completion_state, [catch_completion_state_opt])
            in
            let completion_state =
              this#run_to_completion (fun () ->
                  this#merge_completion_states try_catch_completion_states
              )
            in
            this#commit_abrupt_completion_matching AbruptCompletion.all completion_state;
            begin
              match finalizer with
              | Some (_loc, block) ->
                this#merge_env catch_entry_env catch_exit_env;
                ignore @@ this#block loc block
              | None ->
                (match catch_completion_state_opt with
                | None -> this#merge_env try_exit_env catch_exit_env
                | Some _ -> this#reset_env try_exit_env)
            end;
            this#from_completion completion_state
        );
        stmt

      (* We also havoc state when entering functions and exiting calls. *)
      method! lambda params predicate body =
        this#expecting_abrupt_completions (fun () ->
            let env = this#env in
            this#run
              (fun () ->
                this#havoc_uninitialized_env;
                let completion_state =
                  this#run_to_completion (fun () -> super#lambda params predicate body)
                in
                this#commit_abrupt_completion_matching
                  AbruptCompletion.(mem [return; throw])
                  completion_state)
              ~finally:(fun () -> this#reset_env env)
        )

      method! class_property loc prop =
        let open Ast.Class.Property in
        let { static; _ } = prop in
        if static then
          super#class_property loc prop
        else
          let env = this#env in
          this#run
            (fun () ->
              this#havoc_uninitialized_env;
              ignore @@ super#class_property loc prop)
            ~finally:(fun () -> this#reset_env env);
          prop

      method! class_private_field loc field =
        let open Ast.Class.PrivateField in
        let { static; _ } = field in
        if static then
          super#class_private_field loc field
        else
          let env = this#env in
          this#run
            (fun () ->
              this#havoc_uninitialized_env;
              ignore @@ super#class_private_field loc field)
            ~finally:(fun () -> this#reset_env env);
          field

      method! declare_function loc expr =
        match Declare_function_utils.declare_function_to_function_declaration_simple loc expr with
        | Some stmt ->
          let _ = this#statement (loc, stmt) in
          expr
        | None -> super#declare_function loc expr

      method! call loc (expr : (ALoc.t, ALoc.t) Ast.Expression.Call.t) =
        (* Traverse everything up front. Now we don't need to worry about missing any reads
         * of identifiers in sub-expressions *)
        ignore @@ super#call loc expr;

        let open Ast.Expression.Call in
        let { callee; targs; arguments; _ } = expr in
        if is_call_to_invariant callee then
          match (targs, arguments) with
          (* invariant() and invariant(false, ...) are treated like throw *)
          | (None, (_, { Ast.Expression.ArgList.arguments = []; comments = _ })) ->
            this#raise_abrupt_completion AbruptCompletion.throw
          | ( None,
              ( _,
                {
                  Ast.Expression.ArgList.arguments =
                    Ast.Expression.Expression
                      ( _,
                        Ast.Expression.Literal { Ast.Literal.value = Ast.Literal.Boolean false; _ }
                      )
                    :: other_args;
                  comments = _;
                }
              )
            ) ->
            let _ = List.map this#expression_or_spread other_args in
            this#raise_abrupt_completion AbruptCompletion.throw
          | ( None,
              ( _,
                {
                  Ast.Expression.ArgList.arguments = Ast.Expression.Expression cond :: other_args;
                  comments = _;
                }
              )
            ) ->
            this#push_refinement_scope empty_refinements;
            ignore @@ this#expression_refinement cond;
            let _ = List.map this#expression_or_spread other_args in
            this#pop_refinement_scope_without_unrefining ()
          | ( _,
              (_, { Ast.Expression.ArgList.arguments = Ast.Expression.Spread _ :: _; comments = _ })
            ) ->
            error_todo
          | (Some _, _) -> error_todo
        else
          this#havoc_current_env ~all:false;
        expr

      method! new_ loc (expr : (ALoc.t, ALoc.t) Ast.Expression.New.t) =
        ignore @@ super#new_ loc expr;
        this#havoc_current_env ~all:false;
        expr

      method private delete loc argument =
        let undefined_reason = mk_reason RVoid loc in
        let undefined = Val.undefined undefined_reason in
        let update_write_entries ~assigning =
          let write =
            if assigning then
              Env_api.AssigningWrite undefined_reason
            else
              Env_api.NonAssigningWrite
          in
          let write_entries = L.LMap.add (fst argument) write env_state.write_entries in
          env_state <- { env_state with write_entries }
        in
        match argument with
        | (_, Flow_ast.Expression.Identifier (id_loc, { Flow_ast.Identifier.name; _ })) ->
          let { kind; def_loc; val_ref; _ } = SMap.find name env_state.env in
          (match error_for_assignment_kind cx name id_loc def_loc kind None !val_ref with
          | None ->
            val_ref := undefined;
            update_write_entries ~assigning:true
          | Some err ->
            update_write_entries ~assigning:false;
            add_output err)
        | (_, Flow_ast.Expression.Member member) ->
          this#assign_member ~update_entry:true member loc undefined undefined_reason
        | _ -> ()

      method! unary_expression loc (expr : (ALoc.t, ALoc.t) Ast.Expression.Unary.t) =
        Ast.Expression.Unary.(
          let { argument; operator; comments = _ } = expr in
          ignore @@ this#expression argument;
          match operator with
          | Await -> this#havoc_current_env ~all:false
          | Delete -> this#delete loc argument
          | _ -> ()
        );
        expr

      method! yield loc (expr : ('loc, 'loc) Ast.Expression.Yield.t) =
        ignore @@ super#yield loc expr;
        this#havoc_current_env ~all:true;
        expr

      (* Labeled statements handle labeled breaks, but also push labeled continues
         that are expected to be handled by immediately nested loops. *)
      method! labeled_statement _loc (stmt : (ALoc.t, ALoc.t) Ast.Statement.Labeled.t) =
        this#expecting_abrupt_completions (fun () ->
            let open Ast.Statement.Labeled in
            let { label; body; comments = _ } = stmt in
            env_state <-
              {
                env_state with
                possible_labeled_continues =
                  AbruptCompletion.continue (Some label) :: env_state.possible_labeled_continues;
              };
            let completion_state =
              this#run_to_completion (fun () -> ignore @@ this#statement body)
            in
            env_state <- { env_state with possible_labeled_continues = [] };
            this#commit_abrupt_completion_matching
              AbruptCompletion.(mem [break (Some label)])
              completion_state
        );
        stmt

      method! statement (stmt : (ALoc.t, ALoc.t) Ast.Statement.t) =
        let open Ast.Statement in
        begin
          match stmt with
          | (_, While _)
          | (_, DoWhile _)
          | (_, For _)
          | (_, ForIn _)
          | (_, ForOf _)
          | (_, Labeled _) ->
            ()
          | _ -> env_state <- { env_state with possible_labeled_continues = [] }
        end;
        super#statement stmt

      (* Function declarations are hoisted to the top of a block, so that they may be considered
         initialized before they are read. *)
      method! statement_list (stmts : (ALoc.t, ALoc.t) Ast.Statement.t list) =
        let open Ast.Statement in
        let (function_decls, other_stmts) =
          List.partition
            (function
              | (_, FunctionDeclaration _) -> true
              | (_, DeclareFunction _) -> true
              | ( _,
                  ExportDefaultDeclaration
                    ExportDefaultDeclaration.
                      { declaration = Declaration (_, FunctionDeclaration _); _ }
                ) ->
                true
              | ( _,
                  ExportNamedDeclaration
                    ExportNamedDeclaration.{ declaration = Some (_, FunctionDeclaration _); _ }
                ) ->
                true
              | ( _,
                  DeclareExportDeclaration
                    DeclareExportDeclaration.{ declaration = Some (Function _); _ }
                ) ->
                true
              | _ -> false)
            stmts
        in
        ignore @@ super#statement_list (function_decls @ other_stmts);
        stmts

      (* WHen the refinement scope we push is non-empty we want to make sure that the variables
       * that scope refines are given their new refinement writes in the environment *)
      method private push_refinement_scope
          ({ applied; changeset; total = _ } as new_latest_refinements) =
        env_state <-
          {
            env_state with
            latest_refinements = new_latest_refinements :: env_state.latest_refinements;
          };
        IMap.iter
          (fun ssa_id (lookup, refinement_id) ->
            let refine_val v =
              if Val.base_id_of_val v = ssa_id then
                Val.refinement refinement_id v
              else
                v
            in
            let create_val_for_heap =
              LookupMap.find_opt lookup changeset |> Base.Option.map ~f:Lazy.from_val
            in
            this#map_val_with_lookup lookup ?create_val_for_heap refine_val)
          applied

      (* See pop_refinement_scope. The only difference here is that we unrefine values deeply
       * instead of just at the top level. The reason for this is that intermediate control-flow
       * can introduce refinement writes into phi nodes, and we don't want those refinements to
       * escape the scope of the loop. You may find it instructive to change the calls to
       * just pop_refinement_scope to see the behavioral differences *)
      method private pop_refinement_scope_after_loop () =
        let { applied; _ } = List.hd env_state.latest_refinements in
        env_state <- { env_state with latest_refinements = List.tl env_state.latest_refinements };
        applied
        |> IMap.iter (fun _ (lookup, refinement_id) ->
               let unrefine_deeply x = Val.unrefine_deeply refinement_id x in
               this#map_val_with_lookup lookup unrefine_deeply
           )

      (* Invariant refinement scopes can be popped, but the refinement should continue living on.
       * To model that, we pop the refinement scope but do not unrefine the refinements. The
       * refinements live on in the Refinement writes in the env. *)
      method private pop_refinement_scope_without_unrefining () =
        env_state <- { env_state with latest_refinements = List.tl env_state.latest_refinements }

      (* When a refinement scope ends, we need to undo the refinement applied to the
       * variables mentioned in the latest_refinements head. Some of these values may no
       * longer be the refined value, in which case Val.unrefine will be a no-op. Otherwise,
       * the Refinement Val.t is replaced with the original Val.t that was being refined, with
       * the same original ssa_id. That means that if for some reason you needed to push the refinement
       * scope again that you would re-refine the unrefined variables, which is desirable in cases
       * where we juggle refinement scopes like we do for nullish coalescing *)
      method private pop_refinement_scope () =
        let { applied; changeset; _ } = List.hd env_state.latest_refinements in
        env_state <- { env_state with latest_refinements = List.tl env_state.latest_refinements };
        changeset
        |> LookupMap.iter (fun { RefinementKey.base; projections } v ->
               match (projections, SMap.find_opt base env_state.env) with
               | (_ :: _, Some { heap_refinements; _ })
                 when Base.Option.value_map
                        (HeapRefinementMap.find_opt projections !heap_refinements)
                        ~f:(fun v' -> Val.base_id_of_val v' = Val.base_id_of_val v)
                        ~default:false ->
                 heap_refinements := HeapRefinementMap.remove projections !heap_refinements
               | _ -> ()
           );
        applied
        |> IMap.iter (fun _ (lookup, refinement_id) ->
               let unrefine x = Val.unrefine refinement_id x in
               this#map_val_with_lookup lookup unrefine
           )

      method private peek_new_refinements () = List.hd env_state.latest_refinements

      method private negate_refinements { applied = _; changeset = _; total } =
        match total with
        | None -> empty_refinements
        | Some total ->
          let negated = Not total in
          let (applied, changeset) = this#normalize_total_refinements negated in
          { applied; changeset; total = Some negated }

      method private conjunct_all_refinements refinement_scopes =
        match refinement_scopes with
        | [] -> empty_refinements
        | [x] -> x
        | _ -> List.fold_left (this#merge ~conjunction:true) empty_refinements refinement_scopes

      method private negate_new_refinements () =
        let head = List.hd env_state.latest_refinements in
        let new_latest_refinements = this#negate_refinements head in
        this#pop_refinement_scope ();
        this#push_refinement_scope new_latest_refinements

      method private merge_self_refinement_scope { applied = _; changeset = _; total } =
        let { applied = _; changeset = _; total = head_total } =
          List.hd env_state.latest_refinements
        in
        let merged = conj_total head_total total in
        let (applied, changeset) =
          Base.Option.value_map
            ~f:this#normalize_total_refinements
            ~default:(IMap.empty, LookupMap.empty)
            merged
        in
        let refis = { applied; changeset; total = merged } in
        this#pop_refinement_scope ();
        this#push_refinement_scope refis

      method private normalize_total_refinements total =
        let rec nnf total =
          match total with
          | Not (And (t1, t2)) -> Or (nnf (Not t1), nnf (Not t2))
          | Not (Or (t1, t2)) -> And (nnf (Not t1), nnf (Not t2))
          | Not (Not t) -> nnf t
          | And (t1, t2) -> And (nnf t1, nnf t2)
          | Or (t1, t2) -> Or (nnf t1, nnf t2)
          | Refinements _
          | Not (Refinements _) ->
            total
        in
        let rec recur total =
          match total with
          | Refinements (r, c) -> (r, c)
          | Not (Refinements (r, c)) ->
            ( IMap.map
                (fun (lookup, refinement_id) ->
                  let new_refinement_id = this#new_id () in
                  env_state <-
                    {
                      env_state with
                      refinement_heap =
                        IMap.add new_refinement_id (NOT refinement_id) env_state.refinement_heap;
                    };
                  (lookup, new_refinement_id))
                r,
              c
            )
          | Not _ -> failwith ""Negations not resolved""
          | And (t1, t2) ->
            let (r1, c1) = recur t1 in
            let (r2, c2) = recur t2 in
            let r =
              IMap.union
                ~combine:(fun _ (lookup1, rid1) (lookup2, rid2) ->
                  if lookup1 = lookup2 then begin
                    let new_refinement_id = this#new_id () in
                    env_state <-
                      {
                        env_state with
                        refinement_heap =
                          IMap.add new_refinement_id (AND (rid1, rid2)) env_state.refinement_heap;
                      };
                    Some (lookup1, new_refinement_id)
                  end else
                    None)
                r1
                r2
            in
            let c = LookupMap.union c1 c2 in
            (r, c)
          | Or (t1, t2) ->
            let (r1, c1) = recur t1 in
            let (r2, c2) = recur t2 in
            let r =
              IMap.merge
                (fun _ r1 r2 ->
                  match (r1, r2) with
                  | (None, _)
                  | (_, None) ->
                    None
                  | (Some (lookup1, rid1), Some (lookup2, rid2)) ->
                    if lookup1 = lookup2 then begin
                      let new_refinement_id = this#new_id () in
                      env_state <-
                        {
                          env_state with
                          refinement_heap =
                            IMap.add new_refinement_id (OR (rid1, rid2)) env_state.refinement_heap;
                        };
                      Some (lookup1, new_refinement_id)
                    end else
                      None)
                r1
                r2
            in
            let c =
              LookupMap.merge
                (fun _ c1 c2 ->
                  match (c1, c2) with
                  | (None, _)
                  | (_, None) ->
                    None
                  | (Some v1, Some v2) -> Some (Val.merge v1 v2))
                c1
                c2
            in
            (r, c)
        in
        let nnf = nnf total in
        recur nnf

      method private add_projection ({ RefinementKey.lookup; loc } as key) =
        let create_val_for_heap =
          lazy
            (let reason = mk_reason (RefinementKey.reason_desc key) loc in
             let write_entries =
               L.LMap.add loc (Env_api.AssigningWrite reason) env_state.write_entries
             in
             env_state <- { env_state with write_entries };
             Val.projection loc
            )
        in
        this#map_val_with_lookup lookup ~create_val_for_heap (fun x -> x)

      (* Commit a set of refinements, all of which are linked biconditionally. If these refinements are negated,
         then the negation of each refinement should hold; separate calls to this function in the same
         refinement scope produce separate maps that are connected with an AND--and if they are negated, will produce
         an OR of negations of the maps.

         To see how this works, consider two cases:

          First,
            if (x && y) { } else { }
          In this case, we will call commit_refinement twice, each time with a Truthy refinement on either x or y.
          Inside the then case, x and y are both Truthy, but within the else case, we'll end up with a proposition
          like Or (x Falsey, y Falsey). This means that within the else case we don't actually know anything concrete
          about x or y.

          Compare that to
            if {x.y} { } else { }
          For this case, we will call commit_refinement only once, with a map that contains both the refinement x HasProp(y) and
          x.y Truthy. When we negate this, because we only called commit_refinement once and therefore our refinement propositon
          contains just a single set of refinements (not multiple ones conjuncted together), we'll end up with
          x NotHasProp(y) and x.y Falsey--which is what we want.
      *)
      method private commit_refinement (refinements : (ALoc.t * refinement) LookupMap.t) =
        let { applied; changeset = old_changeset; total } = List.hd env_state.latest_refinements in

        let (applied, changeset, map) =
          LookupMap.fold
            (fun key (loc, refinement) (applied, changeset, map) ->
              (* Prevent refinement on undeclared const/let.
                 We should only error if the undeclared const/let is in the same activation scope
                 as the current one. Although we have no information about the current scope, this
                 is not a problem. We will force initialization for all bindings before we visit a
                 lambda. *)
              let should_not_refine =
                let { RefinementKey.base; projections } = key in
                if projections = [] then
                  match SMap.find base env_state.env with
                  | { val_ref; kind = Bindings.Const | Bindings.Let; def_loc = Some def_loc; _ }
                    when Val.is_undeclared_or_skipped !val_ref ->
                    refinement
                    |> fst
                    |> L.LSet.iter (fun loc ->
                           add_output
                             Error_message.(
                               EBindingError
                                 (EReferencedBeforeDeclaration, loc, OrdinaryName base, def_loc)
                             )
                       );
                    true
                  | _ -> false
                else
                  false
              in
              if should_not_refine then
                (applied, changeset, map)
              else
                let add_refinements v =
                  let ssa_id = Val.base_id_of_val v in
                  let refinement_id = this#new_id () in
                  env_state <-
                    {
                      env_state with
                      refinement_heap =
                        IMap.add refinement_id (BASE refinement) env_state.refinement_heap;
                    };
                  let latest_refinement_opt = IMap.find_opt ssa_id applied in
                  let (final_refinement_id, unrefined_v) =
                    match latest_refinement_opt with
                    | Some (_, existing_refinement_id) ->
                      let unrefined_v = Val.unrefine existing_refinement_id v in
                      let new_refinement_id = this#new_id () in
                      let new_chain = AND (existing_refinement_id, refinement_id) in
                      env_state <-
                        {
                          env_state with
                          refinement_heap =
                            IMap.add new_refinement_id new_chain env_state.refinement_heap;
                        };

                      (new_refinement_id, unrefined_v)
                    | None -> (refinement_id, v)
                  in
                  ( (ssa_id, refinement_id, final_refinement_id),
                    Val.refinement final_refinement_id unrefined_v
                  )
                in
                match
                  this#map_val_with_lookup_result
                    key
                    ~create_val_for_heap:
                      ( lazy
                        (let reason =
                           mk_reason
                             (RefinementKey.reason_desc { RefinementKey.lookup = key; loc })
                             loc
                         in
                         let write_entries =
                           L.LMap.add loc (Env_api.AssigningWrite reason) env_state.write_entries
                         in
                         env_state <- { env_state with write_entries };
                         Val.projection loc
                        )
                        )
                    add_refinements
                with
                | Some ((ssa_id, base_refinement_id, final_refinement_id), change) ->
                  ( IMap.add ssa_id (key, final_refinement_id) applied,
                    Base.Option.value_map
                      ~f:(fun change -> LookupMap.add key change changeset)
                      ~default:changeset
                      change,
                    IMap.add ssa_id (key, base_refinement_id) map
                  )
                | None -> (applied, changeset, map))
            refinements
            (applied, LookupMap.empty, IMap.empty)
        in

        env_state <-
          {
            env_state with
            latest_refinements =
              {
                applied;
                changeset = LookupMap.union changeset old_changeset;
                total = conj_total total (Some (Refinements (map, changeset)));
              }
              :: List.tl env_state.latest_refinements;
          }

      method add_single_refinement key refi = this#commit_refinement (this#start_refinement key refi)

      method start_refinement { RefinementKey.loc; lookup } refi =
        LookupMap.singleton lookup (loc, refi)

      method extend_refinement { RefinementKey.loc; lookup } refi refis =
        LookupMap.union
          ~combine:(fun _ (loc1, (locs1, refi1)) (loc2, (locs2, refi2)) ->
            if loc1 <> loc2 then failwith ""Loc mismatch"";
            Some (loc1, (L.LSet.union locs1 locs2, AndR (refi1, refi2))))
          refis
          (LookupMap.singleton lookup (loc, refi))

      method identifier_refinement ((loc, ident) as identifier) =
        ignore @@ this#identifier identifier;
        let { Flow_ast.Identifier.name; _ } = ident in
        let { val_ref; _ } = SMap.find name env_state.env in
        if not (Val.is_undeclared_or_skipped !val_ref) then
          this#add_single_refinement (RefinementKey.of_name name loc) (L.LSet.singleton loc, TruthyR)

      method assignment_refinement loc assignment =
        ignore @@ this#assignment loc assignment;
        let open Flow_ast.Expression.Assignment in
        match assignment.left with
        | ( id_loc,
            Flow_ast.Pattern.Identifier
              { Flow_ast.Pattern.Identifier.name = (_, { Flow_ast.Identifier.name; _ }); _ }
          ) ->
          this#add_single_refinement
            (RefinementKey.of_name name id_loc)
            (L.LSet.singleton loc, TruthyR)
        | _ -> ()

      method private merge
          ~conjunction
          { applied = _; changeset = _; total = total1 }
          { applied = _; changeset = _; total = total2 } =
        let total =
          if conjunction then
            conj_total total1 total2
          else
            match (total1, total2) with
            | (Some total1, Some total2) -> Some (Or (total1, total2))
            | (Some total, _)
            | (_, Some total) ->
              Some total
            | (None, None) -> None
        in
        let (applied, changeset) =
          Base.Option.value_map
            ~f:this#normalize_total_refinements
            ~default:(IMap.empty, LookupMap.empty)
            total
        in
        { applied; changeset; total }

      method private merge_refinement_scopes
          ~conjunction lhs_latest_refinements rhs_latest_refinements =
        let new_latest_refinements =
          this#merge ~conjunction lhs_latest_refinements rhs_latest_refinements
        in
        this#merge_self_refinement_scope new_latest_refinements

      (* Refines an expr if that expr has a refinement key, othewise does nothing *)
      method add_refinement_to_expr expr refinement =
        match RefinementKey.of_expression expr with
        | None -> ()
        | Some refinement_key -> this#add_single_refinement refinement_key refinement

      method logical_refinement expr =
        let { Flow_ast.Expression.Logical.operator; left = (loc, _) as left; right; comments = _ } =
          expr
        in
        this#push_refinement_scope empty_refinements;
        (* The RHS is _only_ evaluated if the LHS fails its check. That means that patterns like
         * x || invariant(false) should propagate the truthy refinement to the next line. We keep track
         * of the completion state on the rhs to do that. If the LHS throws then the entire expression
         * throws, so there's no need to catch the exception from the LHS *)
        let (lhs_latest_refinements, rhs_latest_refinements, env1, rhs_completion_state) =
          match operator with
          | Flow_ast.Expression.Logical.Or
          | Flow_ast.Expression.Logical.And ->
            ignore @@ this#expression_refinement left;
            let lhs_latest_refinements = this#peek_new_refinements () in
            let env1 = this#env_without_latest_refinements in
            (match operator with
            | Flow_ast.Expression.Logical.Or -> this#negate_new_refinements ()
            | _ -> ());
            this#push_refinement_scope empty_refinements;
            let rhs_completion_state =
              this#run_to_completion (fun () -> ignore @@ this#expression_refinement right)
            in
            let rhs_latest_refinements = this#peek_new_refinements () in
            (* Pop LHS refinement scope *)
            this#pop_refinement_scope ();
            (* Pop RHS refinement scope *)
            this#pop_refinement_scope ();
            (lhs_latest_refinements, rhs_latest_refinements, env1, rhs_completion_state)
          | Flow_ast.Expression.Logical.NullishCoalesce ->
            (* If this overall expression is truthy, then either the LHS or the RHS has to be truthy.
               If it's because the LHS is truthy, then the LHS also has to be non-maybe (this is of course
               true by definition, but it's also true because of the nature of ??).
               But if we're evaluating the RHS, the LHS doesn't have to be truthy, it just has to be
               non-maybe. As a result, we do this weird dance of refinements so that when we traverse the
               RHS we have done the null-test but the overall result of this expression includes both the
               truthy and non-maybe qualities.

               We can't use null_test here because null_test requires some actual null for the
               sentinel refinement it can create. We can add some complexity here to introduce a
               synthetic null Val.t and get sentinel refinements against null here, but that seems
               like an unlikely way for nullish coalescing to be used. Instead, we simply add a
               NotR MaybeR refinement to the left *)
            ignore (this#expression left);
            this#add_refinement_to_expr left (L.LSet.singleton loc, NotR MaybeR);
            let nullish = this#peek_new_refinements () in
            let env1 = this#env_without_latest_refinements in
            this#negate_new_refinements ();
            this#push_refinement_scope empty_refinements;
            let rhs_completion_state =
              this#run_to_completion (fun () -> ignore (this#expression_refinement right))
            in
            let rhs_latest_refinements = this#peek_new_refinements () in
            this#pop_refinement_scope ();
            this#pop_refinement_scope ();
            this#push_refinement_scope empty_refinements;
            this#add_refinement_to_expr left (L.LSet.singleton loc, TruthyR);
            let truthy_refinements = this#peek_new_refinements () in
            this#pop_refinement_scope ();
            this#push_refinement_scope empty_refinements;
            this#merge_refinement_scopes ~conjunction:true nullish truthy_refinements;
            let lhs_latest_refinements = this#peek_new_refinements () in
            this#pop_refinement_scope ();
            (lhs_latest_refinements, rhs_latest_refinements, env1, rhs_completion_state)
        in
        let conjunction =
          match operator with
          | Flow_ast.Expression.Logical.Or
          | Flow_ast.Expression.Logical.NullishCoalesce ->
            false
          | Flow_ast.Expression.Logical.And -> true
        in
        match rhs_completion_state with
        | Some AbruptCompletion.Throw ->
          let env2 = this#env in
          this#reset_env env1;
          this#push_refinement_scope lhs_latest_refinements;
          this#pop_refinement_scope_without_unrefining ();
          this#merge_self_env env2
        | _ ->
          this#merge_self_env env1;
          this#merge_refinement_scopes ~conjunction lhs_latest_refinements rhs_latest_refinements

      method null_test ~strict ~sense loc expr other =
        (* Negating if sense is false is handled by negate_new_refinements. *)
        let refis = this#maybe_sentinel ~sense:true ~strict loc expr other in
        let refis =
          match RefinementKey.of_expression expr with
          | None -> refis
          | Some key ->
            let refinement =
              if strict then
                NullR
              else
                NotR MaybeR
            in
            this#extend_refinement key (L.LSet.singleton loc, refinement) refis
        in
        ignore @@ this#optional_chain expr;
        this#commit_refinement refis;
        if strict <> sense then this#negate_new_refinements ()

      method void_test ~sense ~strict ~check_for_bound_undefined loc expr other =
        (* Negating if sense is true is handled by negate_new_refinements. *)
        let refis = this#maybe_sentinel ~sense:false ~strict loc expr other in
        let is_global_undefined () =
          match SMap.find_opt ""undefined"" env_state.env with
          | None -> false
          | Some { val_ref = v; _ } -> Val.is_global_undefined !v
        in
        if (not check_for_bound_undefined) || is_global_undefined () then begin
          let refis =
            match RefinementKey.of_expression expr with
            | None -> refis
            | Some key ->
              let refinement =
                if strict then
                  NotR UndefinedR
                else
                  NotR MaybeR
              in
              this#extend_refinement key (L.LSet.singleton loc, refinement) refis
          in
          ignore @@ this#optional_chain expr;
          this#commit_refinement refis;
          if sense then this#negate_new_refinements ()
        end else begin
          ignore @@ this#optional_chain expr;
          this#commit_refinement refis
        end

      method typeof_test loc arg typename sense =
        let (refinement, undef) =
          match typename with
          | ""boolean"" -> (Some (BoolR loc), false)
          | ""function"" -> (Some FunctionR, false)
          | ""number"" -> (Some (NumberR loc), false)
          | ""object"" -> (Some ObjectR, false)
          | ""string"" -> (Some (StringR loc), false)
          | ""symbol"" -> (Some (SymbolR loc), false)
          | ""undefined"" -> (Some UndefinedR, true)
          | _ -> (None, false)
        in
        match (refinement, RefinementKey.of_expression arg) with
        | (Some ref, Some refinement_key) ->
          ignore @@ this#optional_chain arg;
          let refinement =
            if sense && not undef then
              ref
            else
              NotR ref
          in
          this#add_single_refinement refinement_key (L.LSet.singleton loc, refinement);
          if sense && undef then this#negate_new_refinements ()
        | _ -> ignore @@ this#optional_chain arg

      method literal_test ~strict ~sense loc expr refinement other =
        (* Negating if sense is false is handled by negate_new_refinements. *)
        let refis = this#maybe_sentinel ~sense:true ~strict loc expr other in
        let refis =
          match RefinementKey.of_expression expr with
          | Some ({ RefinementKey.lookup; loc = _ } as key) when strict ->
            (match lookup with
            | { RefinementKey.base; projections = [] } ->
              let { val_ref = _; def_loc; _ } = SMap.find base env_state.env in
              (match def_loc with
              | None -> ()
              | Some def_loc -> add_literal_subtype_test def_loc refinement)
            | _ -> ());
            this#extend_refinement key (L.LSet.singleton loc, refinement) refis
          | _ -> refis
        in
        ignore @@ this#optional_chain expr;
        this#commit_refinement refis;
        if not sense then this#negate_new_refinements ()

      method maybe_sentinel ~sense ~strict loc expr (other_loc, _) =
        let open Flow_ast in
        let expr' =
          match expr with
          | (loc, Expression.OptionalMember { Expression.OptionalMember.member; _ }) ->
            (loc, Expression.Member member)
          | _ -> expr
        in
        let refis =
          match (strict, expr') with
          | ( true,
              ( _,
                Expression.Member
                  {
                    Expression.Member._object = (obj_loc, _) as _object;
                    property =
                      ( Expression.Member.PropertyIdentifier
                          (ploc, { Identifier.name = prop_name; _ })
                      | Expression.Member.PropertyExpression
                          (ploc, Expression.Literal { Literal.value = Literal.String prop_name; _ })
                        );
                    _;
                  }
              )
            ) ->
            (match RefinementKey.of_expression _object with
            | Some refinement_key ->
              let reason = mk_reason (RProperty (Some (OrdinaryName prop_name))) ploc in
              ( if RefinementKey.(refinement_key.lookup.projections) = [] then
                let { val_ref = _; def_loc; _ } =
                  SMap.find RefinementKey.(refinement_key.lookup.base) env_state.env
                in
                Base.Option.iter def_loc ~f:(fun def_loc ->
                    Context.add_new_env_matching_props cx (prop_name, other_loc, def_loc)
                )
              );
              let obj_reason = mk_reason (RefinementKey.reason_desc refinement_key) obj_loc in
              let write_entries =
                L.LMap.add
                  obj_loc
                  (Env_api.AssigningWrite obj_reason)
                  (L.LMap.add other_loc (Env_api.AssigningWrite reason) env_state.write_entries)
              in
              env_state <- { env_state with write_entries };
              let refinement =
                if sense then
                  SentinelR (prop_name, other_loc)
                else
                  NotR (SentinelR (prop_name, other_loc))
              in
              this#start_refinement refinement_key (L.LSet.singleton loc, refinement)
            | None -> LookupMap.empty)
          | _ -> LookupMap.empty
        in
        refis

      method eq_test ~strict ~sense ~cond_context loc left right =
        let open Flow_ast in
        match (left, right) with
        (* typeof expr ==/=== string *)
        | ( ( _,
              Expression.Unary
                { Expression.Unary.operator = Expression.Unary.Typeof; argument; comments = _ }
            ),
            (_, Expression.Literal { Literal.value = Literal.String s; _ })
          )
        | ( (_, Expression.Literal { Literal.value = Literal.String s; _ }),
            ( _,
              Expression.Unary
                { Expression.Unary.operator = Expression.Unary.Typeof; argument; comments = _ }
            )
          )
        | ( ( _,
              Expression.Unary
                { Expression.Unary.operator = Expression.Unary.Typeof; argument; comments = _ }
            ),
            ( _,
              Expression.TemplateLiteral
                {
                  Expression.TemplateLiteral.quasis =
                    [
                      ( _,
                        {
                          Expression.TemplateLiteral.Element.value =
                            { Expression.TemplateLiteral.Element.cooked = s; _ };
                          _;
                        }
                      );
                    ];
                  expressions = [];
                  comments = _;
                }
            )
          )
        | ( ( _,
              Expression.TemplateLiteral
                {
                  Expression.TemplateLiteral.quasis =
                    [
                      ( _,
                        {
                          Expression.TemplateLiteral.Element.value =
                            { Expression.TemplateLiteral.Element.cooked = s; _ };
                          _;
                        }
                      );
                    ];
                  expressions = [];
                  comments = _;
                }
            ),
            ( _,
              Expression.Unary
                { Expression.Unary.operator = Expression.Unary.Typeof; argument; comments = _ }
            )
          ) ->
          this#typeof_test loc argument s sense
        (* bool equality *)
        | (((lit_loc, Expression.Literal { Literal.value = Literal.Boolean lit; _ }) as other), expr)
        | (expr, ((lit_loc, Expression.Literal { Literal.value = Literal.Boolean lit; _ }) as other))
          ->
          this#literal_test
            ~strict
            ~sense
            loc
            expr
            (SingletonBoolR { loc = lit_loc; sense; lit })
            other
        (* string equality *)
        | (((lit_loc, Expression.Literal { Literal.value = Literal.String lit; _ }) as other), expr)
        | (expr, ((lit_loc, Expression.Literal { Literal.value = Literal.String lit; _ }) as other))
        | ( expr,
            ( ( lit_loc,
                Expression.TemplateLiteral
                  {
                    Expression.TemplateLiteral.quasis =
                      [
                        ( _,
                          {
                            Expression.TemplateLiteral.Element.value =
                              { Expression.TemplateLiteral.Element.cooked = lit; _ };
                            _;
                          }
                        );
                      ];
                    _;
                  }
              ) as other
            )
          )
        | ( ( ( lit_loc,
                Expression.TemplateLiteral
                  {
                    Expression.TemplateLiteral.quasis =
                      [
                        ( _,
                          {
                            Expression.TemplateLiteral.Element.value =
                              { Expression.TemplateLiteral.Element.cooked = lit; _ };
                            _;
                          }
                        );
                      ];
                    _;
                  }
              ) as other
            ),
            expr
          ) ->
          this#literal_test
            ~strict
            ~sense
            loc
            expr
            (SingletonStrR { loc = lit_loc; sense; lit })
            other
        (* number equality *)
        | (((lit_loc, number_literal) as other), expr) when is_number_literal number_literal ->
          let raw = extract_number_literal number_literal in
          this#literal_test
            ~strict
            ~sense
            loc
            expr
            (SingletonNumR { loc = lit_loc; sense; lit = raw })
            other
        | (expr, ((lit_loc, number_literal) as other)) when is_number_literal number_literal ->
          let raw = extract_number_literal number_literal in
          this#literal_test
            ~strict
            ~sense
            loc
            expr
            (SingletonNumR { loc = lit_loc; sense; lit = raw })
            other
        (* expr op null *)
        | (((_, Expression.Literal { Literal.value = Literal.Null; _ }) as other), expr)
        | (expr, ((_, Expression.Literal { Literal.value = Literal.Null; _ }) as other)) ->
          this#null_test ~sense ~strict loc expr other
        (* expr op undefined *)
        | ( ( ( _,
                Expression.Identifier (_, { Flow_ast.Identifier.name = ""undefined""; comments = _ })
              ) as undefined
            ),
            expr
          )
        | ( expr,
            ( ( _,
                Expression.Identifier (_, { Flow_ast.Identifier.name = ""undefined""; comments = _ })
              ) as undefined
            )
          ) ->
          ignore @@ this#expression undefined;
          this#void_test ~sense ~strict ~check_for_bound_undefined:true loc expr undefined
        (* expr op void(...) *)
        | ( ((_, Expression.Unary { Expression.Unary.operator = Expression.Unary.Void; _ }) as other),
            expr
          )
        | ( expr,
            ((_, Expression.Unary { Expression.Unary.operator = Expression.Unary.Void; _ }) as other)
          ) ->
          this#void_test ~sense ~strict ~check_for_bound_undefined:false loc expr other
        (* Member expressions compared against non-literals that include
         * an optional chain cannot refine like we do in literal cases. The
         * non-literal value we are comparing against may be null or undefined,
         * in which case we'd need to use the special case behavior. Since we can't
         * know at this point, we conservatively do not refine at all based on optional
         * chains by ignoring the output of maybe_sentinel.
         *
         * NOTE: Switch statements do not introduce sentinel refinements *)
        | (((_, Expression.Member _) as expr), other) ->
          ignore @@ this#expression expr;
          let refis = this#maybe_sentinel ~sense ~strict loc expr other in
          this#commit_refinement refis;
          ignore @@ this#expression other
        | (other, ((_, Expression.Member _) as expr)) when not (cond_context = SwitchTest) ->
          ignore @@ this#expression other;
          ignore @@ this#expression expr;
          let refis = this#maybe_sentinel ~sense ~strict loc expr other in
          this#commit_refinement refis
        | _ ->
          ignore @@ this#expression left;
          ignore @@ this#expression right

      method instance_test loc expr instance =
        ignore @@ this#optional_chain expr;
        ignore @@ this#expression instance;
        match RefinementKey.of_expression expr with
        | None -> ()
        | Some refinement_key ->
          let (instance_loc, _) = instance in
          ( if not (L.LMap.mem instance_loc env_state.values) then
            (* instance is not something the name_resolver can reason about.
               However, we still need to has a read and write entry, so we can
               record it in statement.ml and use it in new-env. *)
            let reason = mk_reason (RefinementKey.reason_desc refinement_key) instance_loc in
            let values =
              L.LMap.add
                instance_loc
                {
                  def_loc = None;
                  value = Val.one reason;
                  binding_kind_opt = Some Bindings.Const;
                  name = None;
                }
                env_state.values
            in
            let write_entries =
              L.LMap.add instance_loc (Env_api.AssigningWrite reason) env_state.write_entries
            in
            env_state <- { env_state with values; write_entries }
          );
          this#add_single_refinement refinement_key (L.LSet.singleton loc, InstanceOfR instance)

      method binary_refinement loc expr =
        let open Flow_ast.Expression.Binary in
        let { operator; left; right; comments = _ } = expr in
        let eq_test = this#eq_test ~cond_context:OtherTest in
        match operator with
        (* == and != refine if lhs or rhs is an ident and other side is null *)
        | Equal -> eq_test ~strict:false ~sense:true loc left right
        | NotEqual -> eq_test ~strict:false ~sense:false loc left right
        | StrictEqual -> eq_test ~strict:true ~sense:true loc left right
        | StrictNotEqual -> eq_test ~strict:true ~sense:false loc left right
        | Instanceof -> this#instance_test loc left right
        | LessThan
        | LessThanEqual
        | GreaterThan
        | GreaterThanEqual
        | In
        | LShift
        | RShift
        | RShift3
        | Plus
        | Minus
        | Mult
        | Exp
        | Div
        | Mod
        | BitOr
        | Xor
        | BitAnd ->
          ignore @@ this#binary loc expr

      method call_refinement loc call =
        match call with
        | {
         Flow_ast.Expression.Call.callee =
           ( _,
             Flow_ast.Expression.Member
               {
                 Flow_ast.Expression.Member._object =
                   ( _,
                     Flow_ast.Expression.Identifier
                       (_, { Flow_ast.Identifier.name = ""Array""; comments = _ })
                   );
                 property =
                   Flow_ast.Expression.Member.PropertyIdentifier
                     (_, { Flow_ast.Identifier.name = ""isArray""; comments = _ });
                 comments = _;
               }
           ) as callee;
         targs = _;
         arguments =
           ( _,
             {
               Flow_ast.Expression.ArgList.arguments = [Flow_ast.Expression.Expression arg];
               comments = _;
             }
           );
         comments = _;
        } ->
          let refi =
            match RefinementKey.of_expression arg with
            | None -> LookupMap.empty
            | Some refinement_key ->
              this#start_refinement refinement_key (L.LSet.singleton loc, IsArrayR)
          in

          ignore @@ this#expression callee;
          ignore @@ this#optional_chain arg;
          this#commit_refinement refi
        (* Latent refinements are only applied on function calls where the function call is an identifier *)
        | {
         Flow_ast.Expression.Call.callee = (_, Flow_ast.Expression.Identifier _) as callee;
         arguments;
         _;
        }
          when not (is_call_to_invariant callee) ->
          (* This case handles predicate functions. We ensure that this
           * is not a call to invariant and that the callee is an identifier.
           * The only other criterion that must be met for this call to produce
           * a refinement is that the arguments cannot contain a spread.
           *
           * Assuming there are no spreads we create a mapping from each argument
           * index to the refinement key at that index.
           *
           * The semantics for passing the same argument multiple times to predicate
           * function are sketchy. Pre-LTI Flow allows you to do this but it is buggy. See
           * https://fburl.com/vf52s7rb on v0.155.0
           *
           * We should strongly consider disallowing the same refinement key to
           * appear multiple times in the arguments. *)
          let { Flow_ast.Expression.ArgList.arguments = arglist; _ } = snd arguments in
          let is_spread = function
            | Flow_ast.Expression.Spread _ -> true
            | _ -> false
          in
          let refinement_keys =
            if List.exists is_spread arglist then
              []
            else
              List.map (fun arg -> RefinementKey.of_argument arg) arglist
          in
          ignore @@ this#expression callee;
          ignore @@ this#call_arguments arguments;
          this#havoc_current_env ~all:false;
          this#apply_latent_refinements callee refinement_keys
        | _ -> ignore @@ this#call loc call

      method unary_refinement
          loc ({ Flow_ast.Expression.Unary.operator; argument; comments = _ } as unary) =
        match operator with
        | Flow_ast.Expression.Unary.Not ->
          this#push_refinement_scope empty_refinements;
          ignore @@ this#expression_refinement argument;
          this#negate_new_refinements ();
          let negated_refinements = this#peek_new_refinements () in
          this#pop_refinement_scope ();
          this#merge_self_refinement_scope negated_refinements
        | _ -> ignore @@ this#unary_expression loc unary

      method private record_member_read (loc, expr) =
        let open Ast.Expression in
        match expr with
        | OptionalMember _
        | Member _ ->
          (match this#get_val_of_expression (loc, expr) with
          | None ->
            (* In some cases, we may re-visit the same expression multiple times via different
               environments--for example, visiting the discriminant of a switch statement. In
               these cases, it's possible that there was a val for an expression in a previous
               environment which is no longer available when seen through a subsequent. In order
               to prevent old environment values from ""leaking"" through, we need to actively remove
               values that may have previously existed but no longer do. *)
            let values = L.LMap.remove loc env_state.values in
            env_state <- { env_state with values }
          | Some refined_v ->
            (* We model a heap refinement as a separate const binding. We prefer this over using
             * None so that we can report errors when using this value in a type position *)
            let values =
              L.LMap.add
                loc
                {
                  def_loc = None;
                  value = refined_v;
                  binding_kind_opt = Some Bindings.Const;
                  name = None;
                }
                env_state.values
            in
            env_state <- { env_state with values })
        | _ -> ()

      method optional_chain (loc, expr) =
        let open Ast.Expression in
        this#record_member_read (loc, expr);
        let () =
          match expr with
          | OptionalMember _ -> this#member_expression_refinement loc expr LookupMap.empty
          | OptionalCall
              { OptionalCall.call = { Call.callee; targs; arguments; comments = _ }; optional } ->
            let refi =
              match RefinementKey.of_expression callee with
              | Some refinement_key_obj when optional ->
                this#start_refinement refinement_key_obj (L.LSet.singleton loc, NotR MaybeR)
              | _ -> LookupMap.empty
            in

            ignore @@ this#optional_chain callee;
            this#commit_refinement refi;
            let _targs' = Base.Option.map ~f:this#call_type_args targs in
            let _arguments' = this#call_arguments arguments in
            this#havoc_current_env ~all:false
          | Member mem -> ignore @@ this#member loc mem
          | Call call -> ignore @@ this#call loc call
          | _ -> ignore @@ this#expression (loc, expr)
        in
        (loc, expr)

      method member_expression_refinement loc expr refis =
        let open Flow_ast.Expression in
        let open Flow_ast.Expression.Member in
        let optional =
          match expr with
          | OptionalMember { Ast.Expression.OptionalMember.optional; _ } -> optional
          | _ -> false
        in
        match expr with
        | OptionalMember OptionalMember.{ member = { Member._object; property; _ }; _ }
        | Member Member.{ _object; property; _ } ->
          ignore @@ this#optional_chain _object;
          let propname =
            match property with
            | PropertyIdentifier (_, { Flow_ast.Identifier.name; _ })
            | PropertyExpression (_, Literal { Flow_ast.Literal.value = Ast.Literal.String name; _ })
            | PropertyExpression
                (_, Literal { Flow_ast.Literal.value = Ast.Literal.Number _; raw = name; _ }) ->
              Some name
            | _ -> None
          in
          (match RefinementKey.of_expression _object with
          | None -> ignore @@ this#member_property property
          | Some refinement_key_obj ->
            if optional then
              this#add_single_refinement refinement_key_obj (L.LSet.singleton loc, NotR MaybeR);
            ignore @@ this#member_property property;
            let refis =
              Base.Option.value_map
                ~f:(fun propname ->
                  this#extend_refinement
                    refinement_key_obj
                    (L.LSet.singleton loc, PropExistsR { propname; loc })
                    refis)
                ~default:refis
                propname
            in

            this#commit_refinement refis)
        | _ ->
          failwith ""member_expression_refinement can only be called on OptionalMember or Member""

      method expression_refinement ((loc, expr) as expression) =
        let open Flow_ast.Expression in
        match expr with
        | Identifier ident ->
          this#identifier_refinement ident;
          expression
        | Logical logical ->
          this#logical_refinement logical;
          expression
        | Assignment assignment ->
          this#assignment_refinement loc assignment;
          expression
        | Binary binary ->
          this#binary_refinement loc binary;
          expression
        | Call call ->
          this#call_refinement loc call;
          expression
        | Unary unary ->
          this#unary_refinement loc unary;
          expression
        | Member _
        | OptionalMember _ ->
          (* Add a PropExists refinement to the object and a
           * Truthy heap refinement to the access *)
          let refis =
            match RefinementKey.of_expression (loc, expr) with
            | None -> LookupMap.empty
            | Some key -> this#start_refinement key (L.LSet.singleton loc, TruthyR)
          in
          ignore @@ this#record_member_read expression;
          this#member_expression_refinement loc expr refis;
          expression
        | Array _
        | ArrowFunction _
        | Class _
        | Comprehension _
        | Conditional _
        | Function _
        | Generator _
        | Import _
        | JSXElement _
        | JSXFragment _
        | Literal _
        | MetaProperty _
        | New _
        | Object _
        | OptionalCall _
        | Sequence _
        | Super _
        | TaggedTemplate _
        | TemplateLiteral _
        | TypeCast _
        | This _
        | Update _
        | Yield _ ->
          this#expression expression

      method! logical _loc (expr : (ALoc.t, ALoc.t) Flow_ast.Expression.Logical.t) =
        let open Flow_ast.Expression.Logical in
        let { operator; left = (loc, _) as left; right; comments = _ } = expr in
        this#push_refinement_scope empty_refinements;
        (* THe LHS is unconditionally evaluated, so we don't run-to-completion and catch the
         * error here *)
        (match operator with
        | Flow_ast.Expression.Logical.Or
        | Flow_ast.Expression.Logical.And ->
          ignore (this#expression_refinement left)
        | Flow_ast.Expression.Logical.NullishCoalesce ->
          ignore (this#expression left);
          this#add_refinement_to_expr left (L.LSet.singleton loc, NotR MaybeR));
        let env1 = this#env_without_latest_refinements in
        let env1_with_refinements = this#env in
        (match operator with
        | Flow_ast.Expression.Logical.NullishCoalesce
        | Flow_ast.Expression.Logical.Or ->
          this#negate_new_refinements ()
        | Flow_ast.Expression.Logical.And -> ());
        (* The RHS is _only_ evaluated if the LHS fails its check. That means that patterns like
         * x || invariant(false) should propagate the truthy refinement to the next line. We keep track
         * of the completion state on the rhs to do that. If the LHS throws then the entire expression
         * throws, so there's no need to catch the exception from the LHS *)
        let rhs_completion_state =
          this#run_to_completion (fun () -> ignore @@ this#expression right)
        in
        (match rhs_completion_state with
        | Some AbruptCompletion.Throw ->
          let env2 = this#env in
          this#reset_env env1_with_refinements;
          this#pop_refinement_scope_without_unrefining ();
          this#merge_self_env env2
        | _ ->
          this#pop_refinement_scope ();
          this#merge_self_env env1);
        expr

      method private chain_to_refinement =
        function
        | BASE refinement -> refinement
        | AND (id1, id2) ->
          let (locs1, ref1) = this#chain_to_refinement (IMap.find id1 env_state.refinement_heap) in
          let (locs2, ref2) = this#chain_to_refinement (IMap.find id2 env_state.refinement_heap) in
          (L.LSet.union locs1 locs2, AndR (ref1, ref2))
        | OR (id1, id2) ->
          let (locs1, ref1) = this#chain_to_refinement (IMap.find id1 env_state.refinement_heap) in
          let (locs2, ref2) = this#chain_to_refinement (IMap.find id2 env_state.refinement_heap) in
          (L.LSet.union locs1 locs2, OrR (ref1, ref2))
        | NOT id ->
          let (locs, ref) = this#chain_to_refinement (IMap.find id env_state.refinement_heap) in
          (locs, NotR ref)

      method refinement_of_id id =
        let chain = IMap.find id env_state.refinement_heap in
        this#chain_to_refinement chain

      method! expression expr =
        match expr with
        | (_, Flow_ast.Expression.Call _)
        | (_, Flow_ast.Expression.OptionalCall _)
        | (_, Flow_ast.Expression.Member _)
        | (_, Flow_ast.Expression.OptionalMember _) ->
          this#push_refinement_scope empty_refinements;
          let res = this#optional_chain expr in
          this#pop_refinement_scope ();
          res
        | _ -> super#expression expr

      method! private hoist_annotations f =
        let visiting_hoisted_type = env_state.visiting_hoisted_type in
        env_state <- { env_state with visiting_hoisted_type = true };
        f ();
        env_state <- { env_state with visiting_hoisted_type }

      method jsx_function_call loc =
        match (Context.react_runtime cx, env_state.jsx_base_name, Context.jsx cx) with
        | (Options.ReactRuntimeClassic, Some name, _) -> this#any_identifier loc name
        | (Options.ReactRuntimeClassic, None, Options.Jsx_pragma (_, ast)) ->
          ignore @@ this#expression ast
        | _ -> ()

      method! jsx_element loc expr =
        this#jsx_function_call loc;
        super#jsx_element loc expr

      method! jsx_fragment loc expr =
        this#jsx_function_call loc;
        super#jsx_fragment loc expr
    end

  (* The EnvBuilder does not traverse dead code, but statement.ml does. Dead code
   * is an error in Flow, so type checking after that point is not very meaningful.
   * In order to support statement.ml's queries, we must ensure that the value map we
   * send to it has the dead code reads filled in. An alternative approach to this visitor
   * would be to assume that if the entry does not exist in the map then it is unreachable,
   * but that assumes that the EnvBuilder is 100% correct. This approach lets us discriminate
   * between real dead code and issues with the EnvBuilder, which seems far better than
   * the alternative *)
  class dead_code_marker cx env_values =
    object (this)
      inherit
        Scope_builder.scope_builder
          ~flowmin_compatibility:false
          ~enable_enums:(Context.enable_enums cx)
          ~with_types:true as super

      val mutable values = env_values

      method values = values

      method any_identifier loc name =
        values <-
          L.LMap.update
            loc
            (function
              | None ->
                Some
                  {
                    Env_api.def_loc = None;
                    write_locs = [Env_api.Unreachable loc];
                    val_kind = None;
                    name = Some name;
                    id = None;
                  }
              | x -> x)
            values

      method! binding_type_identifier ident = super#identifier ident

      method! identifier (ident : (ALoc.t, ALoc.t) Ast.Identifier.t) =
        let (loc, { Flow_ast.Identifier.name; _ }) = ident in
        this#any_identifier loc name;
        super#identifier ident

      method private jsx_function_call loc =
        match Context.react_runtime cx with
        | Options.ReactRuntimeClassic -> this#any_identifier loc ""React""
        | _ -> ()

      method! jsx_element loc expr =
        this#jsx_function_call loc;
        super#jsx_element loc expr

      method! jsx_fragment loc expr =
        this#jsx_function_call loc;
        super#jsx_fragment loc expr

      method! pattern_identifier ?kind e =
        ignore kind;
        e
    end

  let program_with_scope cx program =
    let open Hoister in
    let (loc, _) = program in
    let jsx_ast =
      match Context.jsx cx with
      | Options.Jsx_react -> None
      | Options.Jsx_pragma (_, ast) -> Some ast
    in
    let enable_enums = Context.enable_enums cx in
    let (_ssa_completion_state, ((scopes, ssa_values, _) as prepass)) =
      Ssa_builder.program_with_scope_and_jsx_pragma
        ~flowmin_compatibility:false
        ~enable_enums
        ~jsx_ast
        program
    in
    let providers = Provider_api.find_providers program in
    let env_walk = new name_resolver cx prepass providers in
    let bindings =
      let hoist = new hoister ~flowmin_compatibility:false ~enable_enums ~with_types:true in
      hoist#eval hoist#program program
    in
    let completion_state =
      env_walk#run_to_completion (fun () ->
          ignore @@ env_walk#with_bindings loc bindings env_walk#program program
      )
    in
    (* Fill in dead code reads *)
    let dead_code_marker = new dead_code_marker cx env_walk#values in
    let _ = dead_code_marker#program program in
    ( completion_state,
      {
        Env_api.scopes;
        ssa_values;
        env_values = dead_code_marker#values;
        env_entries = env_walk#write_entries;
        providers;
        refinement_of_id = env_walk#refinement_of_id;
      }
    )

  let program cx program =
    let (_, { Env_api.env_values; refinement_of_id; _ }) = program_with_scope cx program in
    (env_values, refinement_of_id)
end

module DummyFlow (Context : C) = struct
  type cx = Context.t

  let add_output _ ?trace _ = ignore trace
end

module Make_Test_With_Cx (Context : C) =
  Make (Scope_api.With_ALoc) (Ssa_api.With_ALoc) (Env_api.With_ALoc) (Context) (DummyFlow (Context))
module Make_of_flow = Make (Scope_api.With_ALoc) (Ssa_api.With_ALoc) (Env_api.With_ALoc)
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                                 OCaml                                  *)
(*                                                                        *)
(*                         Alain Frisch, LexiFi                           *)
(*                                                                        *)
(*   Copyright 2012 Institut National de Recherche en Informatique et     *)
(*     en Automatique.                                                    *)
(*                                                                        *)
(*   All rights reserved.  This file is distributed under the terms of    *)
(*   the GNU Lesser General Public License version 2.1, with the          *)
(*   special exception on linking described in the file LICENSE.          *)
(*                                                                        *)
(**************************************************************************)

(* A generic Parsetree mapping class *)

(*
[@@@ocaml.warning ""+9""]
  (* Ensure that record patterns don't miss any field. *)
*)

open Parsetree
open Ast_helper
open Location

module String = Misc.Stdlib.String

type mapper = {
  attribute: mapper -> attribute -> attribute;
  attributes: mapper -> attribute list -> attribute list;
  binding_op: mapper -> binding_op -> binding_op;
  case: mapper -> case -> case;
  cases: mapper -> case list -> case list;
  class_declaration: mapper -> class_declaration -> class_declaration;
  class_description: mapper -> class_description -> class_description;
  class_expr: mapper -> class_expr -> class_expr;
  class_field: mapper -> class_field -> class_field;
  class_signature: mapper -> class_signature -> class_signature;
  class_structure: mapper -> class_structure -> class_structure;
  class_type: mapper -> class_type -> class_type;
  class_type_declaration: mapper -> class_type_declaration
                          -> class_type_declaration;
  class_type_field: mapper -> class_type_field -> class_type_field;
  constant: mapper -> constant -> constant;
  constructor_declaration: mapper -> constructor_declaration
                           -> constructor_declaration;
  expr: mapper -> expression -> expression;
  extension: mapper -> extension -> extension;
  extension_constructor: mapper -> extension_constructor
                         -> extension_constructor;
  include_declaration: mapper -> include_declaration -> include_declaration;
  include_description: mapper -> include_description -> include_description;
  label_declaration: mapper -> label_declaration -> label_declaration;
  location: mapper -> Location.t -> Location.t;
  module_binding: mapper -> module_binding -> module_binding;
  module_declaration: mapper -> module_declaration -> module_declaration;
  module_substitution: mapper -> module_substitution -> module_substitution;
  module_expr: mapper -> module_expr -> module_expr;
  module_type: mapper -> module_type -> module_type;
  module_type_declaration: mapper -> module_type_declaration
                           -> module_type_declaration;
  open_declaration: mapper -> open_declaration -> open_declaration;
  open_description: mapper -> open_description -> open_description;
  pat: mapper -> pattern -> pattern;
  payload: mapper -> payload -> payload;
  signature: mapper -> signature -> signature;
  signature_item: mapper -> signature_item -> signature_item;
  structure: mapper -> structure -> structure;
  structure_item: mapper -> structure_item -> structure_item;
  typ: mapper -> core_type -> core_type;
  type_declaration: mapper -> type_declaration -> type_declaration;
  type_extension: mapper -> type_extension -> type_extension;
  type_exception: mapper -> type_exception -> type_exception;
  type_kind: mapper -> type_kind -> type_kind;
  value_binding: mapper -> value_binding -> value_binding;
  value_description: mapper -> value_description -> value_description;
  with_constraint: mapper -> with_constraint -> with_constraint;
}

let map_fst f (x, y) = (f x, y)
let map_snd f (x, y) = (x, f y)
let map_tuple f1 f2 (x, y) = (f1 x, f2 y)
let map_tuple3 f1 f2 f3 (x, y, z) = (f1 x, f2 y, f3 z)
let map_opt f = function None -> None | Some x -> Some (f x)

let map_loc sub {loc; txt} = {loc = sub.location sub loc; txt}

module C = struct
  (* Constants *)

  let map sub c = match c with
    | Pconst_integer _
    | Pconst_char _
    | Pconst_float _
      -> c
    | Pconst_string (s, loc, quotation_delimiter) ->
        let loc = sub.location sub loc in
        Const.string ~loc ?quotation_delimiter s
end

module T = struct
  (* Type expressions for the core language *)

  let row_field sub {
      prf_desc;
      prf_loc;
      prf_attributes;
    } =
    let loc = sub.location sub prf_loc in
    let attrs = sub.attributes sub prf_attributes in
    let desc = match prf_desc with
      | Rtag (l, b, tl) -> Rtag (map_loc sub l, b, List.map (sub.typ sub) tl)
      | Rinherit t -> Rinherit (sub.typ sub t)
    in
    Rf.mk ~loc ~attrs desc

  let object_field sub {
      pof_desc;
      pof_loc;
      pof_attributes;
    } =
    let loc = sub.location sub pof_loc in
    let attrs = sub.attributes sub pof_attributes in
    let desc = match pof_desc with
      | Otag (l, t) -> Otag (map_loc sub l, sub.typ sub t)
      | Oinherit t -> Oinherit (sub.typ sub t)
    in
    Of.mk ~loc ~attrs desc

  let map sub {ptyp_desc = desc; ptyp_loc = loc; ptyp_attributes = attrs} =
    let open Typ in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Ptyp_any -> any ~loc ~attrs ()
    | Ptyp_var s -> var ~loc ~attrs s
    | Ptyp_arrow (lab, t1, t2) ->
        arrow ~loc ~attrs lab (sub.typ sub t1) (sub.typ sub t2)
    | Ptyp_tuple tyl -> tuple ~loc ~attrs (List.map (sub.typ sub) tyl)
    | Ptyp_constr (lid, tl) ->
        constr ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tl)
    | Ptyp_object (l, o) ->
        object_ ~loc ~attrs (List.map (object_field sub) l) o
    | Ptyp_class (lid, tl) ->
        class_ ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tl)
    | Ptyp_alias (t, s) -> alias ~loc ~attrs (sub.typ sub t) s
    | Ptyp_variant (rl, b, ll) ->
        variant ~loc ~attrs (List.map (row_field sub) rl) b ll
    | Ptyp_poly (sl, t) -> poly ~loc ~attrs
                             (List.map (map_loc sub) sl) (sub.typ sub t)
    | Ptyp_package (lid, l) ->
        package ~loc ~attrs (map_loc sub lid)
          (List.map (map_tuple (map_loc sub) (sub.typ sub)) l)
    | Ptyp_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_type_declaration sub
      {ptype_name; ptype_params; ptype_cstrs;
       ptype_kind;
       ptype_private;
       ptype_manifest;
       ptype_attributes;
       ptype_loc} =
    let loc = sub.location sub ptype_loc in
    let attrs = sub.attributes sub ptype_attributes in
    Type.mk ~loc ~attrs (map_loc sub ptype_name)
      ~params:(List.map (map_fst (sub.typ sub)) ptype_params)
      ~priv:ptype_private
      ~cstrs:(List.map
                (map_tuple3 (sub.typ sub) (sub.typ sub) (sub.location sub))
                ptype_cstrs)
      ~kind:(sub.type_kind sub ptype_kind)
      ?manifest:(map_opt (sub.typ sub) ptype_manifest)

  let map_type_kind sub = function
    | Ptype_abstract -> Ptype_abstract
    | Ptype_variant l ->
        Ptype_variant (List.map (sub.constructor_declaration sub) l)
    | Ptype_record l -> Ptype_record (List.map (sub.label_declaration sub) l)
    | Ptype_open -> Ptype_open

  let map_constructor_arguments sub = function
    | Pcstr_tuple l -> Pcstr_tuple (List.map (sub.typ sub) l)
    | Pcstr_record l ->
        Pcstr_record (List.map (sub.label_declaration sub) l)

  let map_type_extension sub
      {ptyext_path; ptyext_params;
       ptyext_constructors;
       ptyext_private;
       ptyext_loc;
       ptyext_attributes} =
    let loc = sub.location sub ptyext_loc in
    let attrs = sub.attributes sub ptyext_attributes in
    Te.mk ~loc ~attrs
      (map_loc sub ptyext_path)
      (List.map (sub.extension_constructor sub) ptyext_constructors)
      ~params:(List.map (map_fst (sub.typ sub)) ptyext_params)
      ~priv:ptyext_private

  let map_type_exception sub
      {ptyexn_constructor; ptyexn_loc; ptyexn_attributes} =
    let loc = sub.location sub ptyexn_loc in
    let attrs = sub.attributes sub ptyexn_attributes in
    Te.mk_exception ~loc ~attrs
      (sub.extension_constructor sub ptyexn_constructor)

  let map_extension_constructor_kind sub = function
      Pext_decl(vars, ctl, cto) ->
        Pext_decl(List.map (map_loc sub) vars,
                  map_constructor_arguments sub ctl,
                  map_opt (sub.typ sub) cto)
    | Pext_rebind li ->
        Pext_rebind (map_loc sub li)

  let map_extension_constructor sub
      {pext_name;
       pext_kind;
       pext_loc;
       pext_attributes} =
    let loc = sub.location sub pext_loc in
    let attrs = sub.attributes sub pext_attributes in
    Te.constructor ~loc ~attrs
      (map_loc sub pext_name)
      (map_extension_constructor_kind sub pext_kind)

end

module CT = struct
  (* Type expressions for the class language *)

  let map sub {pcty_loc = loc; pcty_desc = desc; pcty_attributes = attrs} =
    let open Cty in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pcty_constr (lid, tys) ->
        constr ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tys)
    | Pcty_signature x -> signature ~loc ~attrs (sub.class_signature sub x)
    | Pcty_arrow (lab, t, ct) ->
        arrow ~loc ~attrs lab (sub.typ sub t) (sub.class_type sub ct)
    | Pcty_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pcty_open (o, ct) ->
        open_ ~loc ~attrs (sub.open_description sub o) (sub.class_type sub ct)

  let map_field sub {pctf_desc = desc; pctf_loc = loc; pctf_attributes = attrs}
    =
    let open Ctf in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pctf_inherit ct -> inherit_ ~loc ~attrs (sub.class_type sub ct)
    | Pctf_val (s, m, v, t) ->
        val_ ~loc ~attrs (map_loc sub s) m v (sub.typ sub t)
    | Pctf_method (s, p, v, t) ->
        method_ ~loc ~attrs (map_loc sub s) p v (sub.typ sub t)
    | Pctf_constraint (t1, t2) ->
        constraint_ ~loc ~attrs (sub.typ sub t1) (sub.typ sub t2)
    | Pctf_attribute x -> attribute ~loc (sub.attribute sub x)
    | Pctf_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_signature sub {pcsig_self; pcsig_fields} =
    Csig.mk
      (sub.typ sub pcsig_self)
      (List.map (sub.class_type_field sub) pcsig_fields)
end

let map_functor_param sub = function
  | Unit -> Unit
  | Named (s, mt) -> Named (map_loc sub s, sub.module_type sub mt)

module MT = struct
  (* Type expressions for the module language *)

  let map sub {pmty_desc = desc; pmty_loc = loc; pmty_attributes = attrs} =
    let open Mty in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pmty_ident s -> ident ~loc ~attrs (map_loc sub s)
    | Pmty_alias s -> alias ~loc ~attrs (map_loc sub s)
    | Pmty_signature sg -> signature ~loc ~attrs (sub.signature sub sg)
    | Pmty_functor (param, mt) ->
        functor_ ~loc ~attrs
          (map_functor_param sub param)
          (sub.module_type sub mt)
    | Pmty_with (mt, l) ->
        with_ ~loc ~attrs (sub.module_type sub mt)
          (List.map (sub.with_constraint sub) l)
    | Pmty_typeof me -> typeof_ ~loc ~attrs (sub.module_expr sub me)
    | Pmty_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_with_constraint sub = function
    | Pwith_type (lid, d) ->
        Pwith_type (map_loc sub lid, sub.type_declaration sub d)
    | Pwith_module (lid, lid2) ->
        Pwith_module (map_loc sub lid, map_loc sub lid2)
    | Pwith_modtype (lid, mty) ->
        Pwith_modtype (map_loc sub lid, sub.module_type sub mty)
    | Pwith_typesubst (lid, d) ->
        Pwith_typesubst (map_loc sub lid, sub.type_declaration sub d)
    | Pwith_modsubst (s, lid) ->
        Pwith_modsubst (map_loc sub s, map_loc sub lid)
    | Pwith_modtypesubst (lid, mty) ->
        Pwith_modtypesubst (map_loc sub lid, sub.module_type sub mty)

  let map_signature_item sub {psig_desc = desc; psig_loc = loc} =
    let open Sig in
    let loc = sub.location sub loc in
    match desc with
    | Psig_value vd -> value ~loc (sub.value_description sub vd)
    | Psig_type (rf, l) ->
        type_ ~loc rf (List.map (sub.type_declaration sub) l)
    | Psig_typesubst l ->
        type_subst ~loc (List.map (sub.type_declaration sub) l)
    | Psig_typext te -> type_extension ~loc (sub.type_extension sub te)
    | Psig_exception ed -> exception_ ~loc (sub.type_exception sub ed)
    | Psig_module x -> module_ ~loc (sub.module_declaration sub x)
    | Psig_modsubst x -> mod_subst ~loc (sub.module_substitution sub x)
    | Psig_recmodule l ->
        rec_module ~loc (List.map (sub.module_declaration sub) l)
    | Psig_modtype x -> modtype ~loc (sub.module_type_declaration sub x)
    | Psig_modtypesubst x ->
        modtype_subst ~loc (sub.module_type_declaration sub x)
    | Psig_open x -> open_ ~loc (sub.open_description sub x)
    | Psig_include x -> include_ ~loc (sub.include_description sub x)
    | Psig_class l -> class_ ~loc (List.map (sub.class_description sub) l)
    | Psig_class_type l ->
        class_type ~loc (List.map (sub.class_type_declaration sub) l)
    | Psig_extension (x, attrs) ->
        let attrs = sub.attributes sub attrs in
        extension ~loc ~attrs (sub.extension sub x)
    | Psig_attribute x -> attribute ~loc (sub.attribute sub x)
end


module M = struct
  (* Value expressions for the module language *)

  let map sub {pmod_loc = loc; pmod_desc = desc; pmod_attributes = attrs} =
    let open Mod in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pmod_ident x -> ident ~loc ~attrs (map_loc sub x)
    | Pmod_structure str -> structure ~loc ~attrs (sub.structure sub str)
    | Pmod_functor (param, body) ->
        functor_ ~loc ~attrs
          (map_functor_param sub param)
          (sub.module_expr sub body)
    | Pmod_apply (m1, m2) ->
        apply ~loc ~attrs (sub.module_expr sub m1) (sub.module_expr sub m2)
    | Pmod_constraint (m, mty) ->
        constraint_ ~loc ~attrs (sub.module_expr sub m)
                    (sub.module_type sub mty)
    | Pmod_unpack e -> unpack ~loc ~attrs (sub.expr sub e)
    | Pmod_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_structure_item sub {pstr_loc = loc; pstr_desc = desc} =
    let open Str in
    let loc = sub.location sub loc in
    match desc with
    | Pstr_eval (x, attrs) ->
        let attrs = sub.attributes sub attrs in
        eval ~loc ~attrs (sub.expr sub x)
    | Pstr_value (r, vbs) -> value ~loc r (List.map (sub.value_binding sub) vbs)
    | Pstr_primitive vd -> primitive ~loc (sub.value_description sub vd)
    | Pstr_type (rf, l) -> type_ ~loc rf (List.map (sub.type_declaration sub) l)
    | Pstr_typext te -> type_extension ~loc (sub.type_extension sub te)
    | Pstr_exception ed -> exception_ ~loc (sub.type_exception sub ed)
    | Pstr_module x -> module_ ~loc (sub.module_binding sub x)
    | Pstr_recmodule l -> rec_module ~loc (List.map (sub.module_binding sub) l)
    | Pstr_modtype x -> modtype ~loc (sub.module_type_declaration sub x)
    | Pstr_open x -> open_ ~loc (sub.open_declaration sub x)
    | Pstr_class l -> class_ ~loc (List.map (sub.class_declaration sub) l)
    | Pstr_class_type l ->
        class_type ~loc (List.map (sub.class_type_declaration sub) l)
    | Pstr_include x -> include_ ~loc (sub.include_declaration sub x)
    | Pstr_extension (x, attrs) ->
        let attrs = sub.attributes sub attrs in
        extension ~loc ~attrs (sub.extension sub x)
    | Pstr_attribute x -> attribute ~loc (sub.attribute sub x)
end

module E = struct
  (* Value expressions for the core language *)

  let map sub {pexp_loc = loc; pexp_desc = desc; pexp_attributes = attrs} =
    let open Exp in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pexp_ident x -> ident ~loc ~attrs (map_loc sub x)
    | Pexp_constant x -> constant ~loc ~attrs (sub.constant sub x)
    | Pexp_let (r, vbs, e) ->
        let_ ~loc ~attrs r (List.map (sub.value_binding sub) vbs)
          (sub.expr sub e)
    | Pexp_fun (lab, def, p, e) ->
        fun_ ~loc ~attrs lab (map_opt (sub.expr sub) def) (sub.pat sub p)
          (sub.expr sub e)
    | Pexp_function pel -> function_ ~loc ~attrs (sub.cases sub pel)
    | Pexp_apply (e, l) ->
        apply ~loc ~attrs (sub.expr sub e) (List.map (map_snd (sub.expr sub)) l)
    | Pexp_match (e, pel) ->
        match_ ~loc ~attrs (sub.expr sub e) (sub.cases sub pel)
    | Pexp_try (e, pel) -> try_ ~loc ~attrs (sub.expr sub e) (sub.cases sub pel)
    | Pexp_tuple el -> tuple ~loc ~attrs (List.map (sub.expr sub) el)
    | Pexp_construct (lid, arg) ->
        construct ~loc ~attrs (map_loc sub lid) (map_opt (sub.expr sub) arg)
    | Pexp_variant (lab, eo) ->
        variant ~loc ~attrs lab (map_opt (sub.expr sub) eo)
    | Pexp_record (l, eo) ->
        record ~loc ~attrs (List.map (map_tuple (map_loc sub) (sub.expr sub)) l)
          (map_opt (sub.expr sub) eo)
    | Pexp_field (e, lid) ->
        field ~loc ~attrs (sub.expr sub e) (map_loc sub lid)
    | Pexp_setfield (e1, lid, e2) ->
        setfield ~loc ~attrs (sub.expr sub e1) (map_loc sub lid)
          (sub.expr sub e2)
    | Pexp_array el -> array ~loc ~attrs (List.map (sub.expr sub) el)
    | Pexp_ifthenelse (e1, e2, e3) ->
        ifthenelse ~loc ~attrs (sub.expr sub e1) (sub.expr sub e2)
          (map_opt (sub.expr sub) e3)
    | Pexp_sequence (e1, e2) ->
        sequence ~loc ~attrs (sub.expr sub e1) (sub.expr sub e2)
    | Pexp_while (e1, e2) ->
        while_ ~loc ~attrs (sub.expr sub e1) (sub.expr sub e2)
    | Pexp_for (p, e1, e2, d, e3) ->
        for_ ~loc ~attrs (sub.pat sub p) (sub.expr sub e1) (sub.expr sub e2) d
          (sub.expr sub e3)
    | Pexp_coerce (e, t1, t2) ->
        coerce ~loc ~attrs (sub.expr sub e) (map_opt (sub.typ sub) t1)
          (sub.typ sub t2)
    | Pexp_constraint (e, t) ->
        constraint_ ~loc ~attrs (sub.expr sub e) (sub.typ sub t)
    | Pexp_send (e, s) ->
        send ~loc ~attrs (sub.expr sub e) (map_loc sub s)
    | Pexp_new lid -> new_ ~loc ~attrs (map_loc sub lid)
    | Pexp_setinstvar (s, e) ->
        setinstvar ~loc ~attrs (map_loc sub s) (sub.expr sub e)
    | Pexp_override sel ->
        override ~loc ~attrs
          (List.map (map_tuple (map_loc sub) (sub.expr sub)) sel)
    | Pexp_letmodule (s, me, e) ->
        letmodule ~loc ~attrs (map_loc sub s) (sub.module_expr sub me)
          (sub.expr sub e)
    | Pexp_letexception (cd, e) ->
        letexception ~loc ~attrs
          (sub.extension_constructor sub cd)
          (sub.expr sub e)
    | Pexp_assert e -> assert_ ~loc ~attrs (sub.expr sub e)
    | Pexp_lazy e -> lazy_ ~loc ~attrs (sub.expr sub e)
    | Pexp_poly (e, t) ->
        poly ~loc ~attrs (sub.expr sub e) (map_opt (sub.typ sub) t)
    | Pexp_object cls -> object_ ~loc ~attrs (sub.class_structure sub cls)
    | Pexp_newtype (s, e) ->
        newtype ~loc ~attrs (map_loc sub s) (sub.expr sub e)
    | Pexp_pack me -> pack ~loc ~attrs (sub.module_expr sub me)
    | Pexp_open (o, e) ->
        open_ ~loc ~attrs (sub.open_declaration sub o) (sub.expr sub e)
    | Pexp_letop {let_; ands; body} ->
        letop ~loc ~attrs (sub.binding_op sub let_)
          (List.map (sub.binding_op sub) ands) (sub.expr sub body)
    | Pexp_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pexp_unreachable -> unreachable ~loc ~attrs ()

  let map_binding_op sub {pbop_op; pbop_pat; pbop_exp; pbop_loc} =
    let open Exp in
    let op = map_loc sub pbop_op in
    let pat = sub.pat sub pbop_pat in
    let exp = sub.expr sub pbop_exp in
    let loc = sub.location sub pbop_loc in
    binding_op op pat exp loc

end

module P = struct
  (* Patterns *)

  let map sub {ppat_desc = desc; ppat_loc = loc; ppat_attributes = attrs} =
    let open Pat in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Ppat_any -> any ~loc ~attrs ()
    | Ppat_var s -> var ~loc ~attrs (map_loc sub s)
    | Ppat_alias (p, s) -> alias ~loc ~attrs (sub.pat sub p) (map_loc sub s)
    | Ppat_constant c -> constant ~loc ~attrs (sub.constant sub c)
    | Ppat_interval (c1, c2) ->
        interval ~loc ~attrs (sub.constant sub c1) (sub.constant sub c2)
    | Ppat_tuple pl -> tuple ~loc ~attrs (List.map (sub.pat sub) pl)
    | Ppat_construct (l, p) ->
        construct ~loc ~attrs (map_loc sub l)
          (map_opt
             (fun (vl, p) -> List.map (map_loc sub) vl, sub.pat sub p)
             p)
    | Ppat_variant (l, p) -> variant ~loc ~attrs l (map_opt (sub.pat sub) p)
    | Ppat_record (lpl, cf) ->
        record ~loc ~attrs
               (List.map (map_tuple (map_loc sub) (sub.pat sub)) lpl) cf
    | Ppat_array pl -> array ~loc ~attrs (List.map (sub.pat sub) pl)
    | Ppat_or (p1, p2) -> or_ ~loc ~attrs (sub.pat sub p1) (sub.pat sub p2)
    | Ppat_constraint (p, t) ->
        constraint_ ~loc ~attrs (sub.pat sub p) (sub.typ sub t)
    | Ppat_type s -> type_ ~loc ~attrs (map_loc sub s)
    | Ppat_lazy p -> lazy_ ~loc ~attrs (sub.pat sub p)
    | Ppat_unpack s -> unpack ~loc ~attrs (map_loc sub s)
    | Ppat_open (lid,p) -> open_ ~loc ~attrs (map_loc sub lid) (sub.pat sub p)
    | Ppat_exception p -> exception_ ~loc ~attrs (sub.pat sub p)
    | Ppat_extension x -> extension ~loc ~attrs (sub.extension sub x)
end

module CE = struct
  (* Value expressions for the class language *)

  let map sub {pcl_loc = loc; pcl_desc = desc; pcl_attributes = attrs} =
    let open Cl in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pcl_constr (lid, tys) ->
        constr ~loc ~attrs (map_loc sub lid) (List.map (sub.typ sub) tys)
    | Pcl_structure s ->
        structure ~loc ~attrs (sub.class_structure sub s)
    | Pcl_fun (lab, e, p, ce) ->
        fun_ ~loc ~attrs lab
          (map_opt (sub.expr sub) e)
          (sub.pat sub p)
          (sub.class_expr sub ce)
    | Pcl_apply (ce, l) ->
        apply ~loc ~attrs (sub.class_expr sub ce)
          (List.map (map_snd (sub.expr sub)) l)
    | Pcl_let (r, vbs, ce) ->
        let_ ~loc ~attrs r (List.map (sub.value_binding sub) vbs)
          (sub.class_expr sub ce)
    | Pcl_constraint (ce, ct) ->
        constraint_ ~loc ~attrs (sub.class_expr sub ce) (sub.class_type sub ct)
    | Pcl_extension x -> extension ~loc ~attrs (sub.extension sub x)
    | Pcl_open (o, ce) ->
        open_ ~loc ~attrs (sub.open_description sub o) (sub.class_expr sub ce)

  let map_kind sub = function
    | Cfk_concrete (o, e) -> Cfk_concrete (o, sub.expr sub e)
    | Cfk_virtual t -> Cfk_virtual (sub.typ sub t)

  let map_field sub {pcf_desc = desc; pcf_loc = loc; pcf_attributes = attrs} =
    let open Cf in
    let loc = sub.location sub loc in
    let attrs = sub.attributes sub attrs in
    match desc with
    | Pcf_inherit (o, ce, s) ->
        inherit_ ~loc ~attrs o (sub.class_expr sub ce)
          (map_opt (map_loc sub) s)
    | Pcf_val (s, m, k) -> val_ ~loc ~attrs (map_loc sub s) m (map_kind sub k)
    | Pcf_method (s, p, k) ->
        method_ ~loc ~attrs (map_loc sub s) p (map_kind sub k)
    | Pcf_constraint (t1, t2) ->
        constraint_ ~loc ~attrs (sub.typ sub t1) (sub.typ sub t2)
    | Pcf_initializer e -> initializer_ ~loc ~attrs (sub.expr sub e)
    | Pcf_attribute x -> attribute ~loc (sub.attribute sub x)
    | Pcf_extension x -> extension ~loc ~attrs (sub.extension sub x)

  let map_structure sub {pcstr_self; pcstr_fields} =
    {
      pcstr_self = sub.pat sub pcstr_self;
      pcstr_fields = List.map (sub.class_field sub) pcstr_fields;
    }

  let class_infos sub f {pci_virt; pci_params = pl; pci_name; pci_expr;
                         pci_loc; pci_attributes} =
    let loc = sub.location sub pci_loc in
    let attrs = sub.attributes sub pci_attributes in
    Ci.mk ~loc ~attrs
     ~virt:pci_virt
     ~params:(List.map (map_fst (sub.typ sub)) pl)
      (map_loc sub pci_name)
      (f pci_expr)
end

(* Now, a generic AST mapper, to be extended to cover all kinds and
   cases of the OCaml grammar.  The default behavior of the mapper is
   the identity. *)

let default_mapper =
  {
    constant = C.map;
    structure = (fun this l -> List.map (this.structure_item this) l);
    structure_item = M.map_structure_item;
    module_expr = M.map;
    signature = (fun this l -> List.map (this.signature_item this) l);
    signature_item = MT.map_signature_item;
    module_type = MT.map;
    with_constraint = MT.map_with_constraint;
    class_declaration =
      (fun this -> CE.class_infos this (this.class_expr this));
    class_expr = CE.map;
    class_field = CE.map_field;
    class_structure = CE.map_structure;
    class_type = CT.map;
    class_type_field = CT.map_field;
    class_signature = CT.map_signature;
    class_type_declaration =
      (fun this -> CE.class_infos this (this.class_type this));
    class_description =
      (fun this -> CE.class_infos this (this.class_type this));
    type_declaration = T.map_type_declaration;
    type_kind = T.map_type_kind;
    typ = T.map;
    type_extension = T.map_type_extension;
    type_exception = T.map_type_exception;
    extension_constructor = T.map_extension_constructor;
    value_description =
      (fun this {pval_name; pval_type; pval_prim; pval_loc;
                 pval_attributes} ->
        Val.mk
          (map_loc this pval_name)
          (this.typ this pval_type)
          ~attrs:(this.attributes this pval_attributes)
          ~loc:(this.location this pval_loc)
          ~prim:pval_prim
      );

    pat = P.map;
    expr = E.map;
    binding_op = E.map_binding_op;

    module_declaration =
      (fun this {pmd_name; pmd_type; pmd_attributes; pmd_loc} ->
         Md.mk
           (map_loc this pmd_name)
           (this.module_type this pmd_type)
           ~attrs:(this.attributes this pmd_attributes)
           ~loc:(this.location this pmd_loc)
      );

    module_substitution =
      (fun this {pms_name; pms_manifest; pms_attributes; pms_loc} ->
         Ms.mk
           (map_loc this pms_name)
           (map_loc this pms_manifest)
           ~attrs:(this.attributes this pms_attributes)
           ~loc:(this.location this pms_loc)
      );

    module_type_declaration =
      (fun this {pmtd_name; pmtd_type; pmtd_attributes; pmtd_loc} ->
         Mtd.mk
           (map_loc this pmtd_name)
           ?typ:(map_opt (this.module_type this) pmtd_type)
           ~attrs:(this.attributes this pmtd_attributes)
           ~loc:(this.location this pmtd_loc)
      );

    module_binding =
      (fun this {pmb_name; pmb_expr; pmb_attributes; pmb_loc} ->
         Mb.mk (map_loc this pmb_name) (this.module_expr this pmb_expr)
           ~attrs:(this.attributes this pmb_attributes)
           ~loc:(this.location this pmb_loc)
      );


    open_declaration =
      (fun this {popen_expr; popen_override; popen_attributes; popen_loc} ->
         Opn.mk (this.module_expr this popen_expr)
           ~override:popen_override
           ~loc:(this.location this popen_loc)
           ~attrs:(this.attributes this popen_attributes)
      );

    open_description =
      (fun this {popen_expr; popen_override; popen_attributes; popen_loc} ->
         Opn.mk (map_loc this popen_expr)
           ~override:popen_override
           ~loc:(this.location this popen_loc)
           ~attrs:(this.attributes this popen_attributes)
      );

    include_description =
      (fun this {pincl_mod; pincl_attributes; pincl_loc} ->
         Incl.mk (this.module_type this pincl_mod)
           ~loc:(this.location this pincl_loc)
           ~attrs:(this.attributes this pincl_attributes)
      );

    include_declaration =
      (fun this {pincl_mod; pincl_attributes; pincl_loc} ->
         Incl.mk (this.module_expr this pincl_mod)
           ~loc:(this.location this pincl_loc)
           ~attrs:(this.attributes this pincl_attributes)
      );


    value_binding =
      (fun this {pvb_pat; pvb_expr; pvb_attributes; pvb_loc} ->
         Vb.mk
           (this.pat this pvb_pat)
           (this.expr this pvb_expr)
           ~loc:(this.location this pvb_loc)
           ~attrs:(this.attributes this pvb_attributes)
      );


    constructor_declaration =
      (fun this {pcd_name; pcd_vars; pcd_args;
                 pcd_res; pcd_loc; pcd_attributes} ->
        Type.constructor
          (map_loc this pcd_name)
          ~vars:(List.map (map_loc this) pcd_vars)
          ~args:(T.map_constructor_arguments this pcd_args)
          ?res:(map_opt (this.typ this) pcd_res)
          ~loc:(this.location this pcd_loc)
          ~attrs:(this.attributes this pcd_attributes)
      );

    label_declaration =
      (fun this {pld_name; pld_type; pld_loc; pld_mutable; pld_attributes} ->
         Type.field
           (map_loc this pld_name)
           (this.typ this pld_type)
           ~mut:pld_mutable
           ~loc:(this.location this pld_loc)
           ~attrs:(this.attributes this pld_attributes)
      );

    cases = (fun this l -> List.map (this.case this) l);
    case =
      (fun this {pc_lhs; pc_guard; pc_rhs} ->
         {
           pc_lhs = this.pat this pc_lhs;
           pc_guard = map_opt (this.expr this) pc_guard;
           pc_rhs = this.expr this pc_rhs;
         }
      );



    location = (fun _this l -> l);

    extension = (fun this (s, e) -> (map_loc this s, this.payload this e));
    attribute = (fun this a ->
      {
        attr_name = map_loc this a.attr_name;
        attr_payload = this.payload this a.attr_payload;
        attr_loc = this.location this a.attr_loc
      }
    );
    attributes = (fun this l -> List.map (this.attribute this) l);
    payload =
      (fun this -> function
         | PStr x -> PStr (this.structure this x)
         | PSig x -> PSig (this.signature this x)
         | PTyp x -> PTyp (this.typ this x)
         | PPat (x, g) -> PPat (this.pat this x, map_opt (this.expr this) g)
      );
  }

let extension_of_error {kind; main; sub} =
  if kind <> Location.Report_error then
    raise (Invalid_argument ""extension_of_error: expected kind Report_error"");
  let str_of_pp pp_msg = Format.asprintf ""%t"" pp_msg in
  let extension_of_sub sub =
    { loc = sub.loc; txt = ""ocaml.error"" },
    PStr ([Str.eval (Exp.constant
                       (Pconst_string (str_of_pp sub.txt, sub.loc, None)))])
  in
  { loc = main.loc; txt = ""ocaml.error"" },
  PStr (Str.eval (Exp.constant
                    (Pconst_string (str_of_pp main.txt, main.loc, None))) ::
        List.map (fun msg -> Str.extension (extension_of_sub msg)) sub)

let attribute_of_warning loc s =
  Attr.mk
    {loc; txt = ""ocaml.ppwarning"" }
    (PStr ([Str.eval ~loc (Exp.constant (Pconst_string (s, loc, None)))]))

let cookies = ref String.Map.empty

let get_cookie k =
  try Some (String.Map.find k !cookies)
  with Not_found -> None

let set_cookie k v =
  cookies := String.Map.add k v !cookies

let tool_name_ref = ref ""_none_""

let tool_name () = !tool_name_ref


module PpxContext = struct
  open Longident
  open Asttypes
  open Ast_helper

  let lid name = { txt = Lident name; loc = Location.none }

  let make_string s = Exp.constant (Const.string s)

  let make_bool x =
    if x
    then Exp.construct (lid ""true"") None
    else Exp.construct (lid ""false"") None

  let rec make_list f lst =
    match lst with
    | x :: rest ->
      Exp.construct (lid ""::"") (Some (Exp.tuple [f x; make_list f rest]))
    | [] ->
      Exp.construct (lid ""[]"") None

  let make_pair f1 f2 (x1, x2) =
    Exp.tuple [f1 x1; f2 x2]

  let make_option f opt =
    match opt with
    | Some x -> Exp.construct (lid ""Some"") (Some (f x))
    | None   -> Exp.construct (lid ""None"") None

  let get_cookies () =
    lid ""cookies"",
    make_list (make_pair make_string (fun x -> x))
      (String.Map.bindings !cookies)

  let mk fields =
    {
      attr_name = { txt = ""ocaml.ppx.context""; loc = Location.none };
      attr_payload = Parsetree.PStr [Str.eval (Exp.record fields None)];
      attr_loc = Location.none
    }

  let make ~tool_name () =
    let fields =
      [
        lid ""tool_name"",    make_string tool_name;
        lid ""include_dirs"", make_list make_string !Clflags.include_dirs;
        lid ""load_path"",    make_list make_string (Load_path.get_paths ());
        lid ""open_modules"", make_list make_string !Clflags.open_modules;
        lid ""for_package"",  make_option make_string !Clflags.for_package;
        lid ""debug"",        make_bool !Clflags.debug;
        lid ""use_threads"",  make_bool !Clflags.use_threads;
        lid ""use_vmthreads"", make_bool false;
        lid ""recursive_types"", make_bool !Clflags.recursive_types;
        lid ""principal"", make_bool !Clflags.principal;
        lid ""transparent_modules"", make_bool !Clflags.transparent_modules;
        lid ""unboxed_types"", make_bool !Clflags.unboxed_types;
        lid ""unsafe_string"", make_bool false; (* kept for compatibility *)
        get_cookies ()
      ]
    in
    mk fields

  let get_fields = function
    | PStr [{pstr_desc = Pstr_eval
                 ({ pexp_desc = Pexp_record (fields, None) }, [])}] ->
        fields
    | _ ->
        raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context] syntax""

  let restore fields =
    let field name payload =
      let rec get_string = function
        | { pexp_desc = Pexp_constant (Pconst_string (str, _, None)) } -> str
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] string syntax"" name
      and get_bool pexp =
        match pexp with
        | {pexp_desc = Pexp_construct ({txt = Longident.Lident ""true""},
                                       None)} ->
            true
        | {pexp_desc = Pexp_construct ({txt = Longident.Lident ""false""},
                                       None)} ->
            false
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] bool syntax"" name
      and get_list elem = function
        | {pexp_desc =
             Pexp_construct ({txt = Longident.Lident ""::""},
                             Some {pexp_desc = Pexp_tuple [exp; rest]}) } ->
            elem exp :: get_list elem rest
        | {pexp_desc =
             Pexp_construct ({txt = Longident.Lident ""[]""}, None)} ->
            []
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] list syntax"" name
      and get_pair f1 f2 = function
        | {pexp_desc = Pexp_tuple [e1; e2]} ->
            (f1 e1, f2 e2)
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] pair syntax"" name
      and get_option elem = function
        | { pexp_desc =
              Pexp_construct ({ txt = Longident.Lident ""Some"" }, Some exp) } ->
            Some (elem exp)
        | { pexp_desc =
              Pexp_construct ({ txt = Longident.Lident ""None"" }, None) } ->
            None
        | _ -> raise_errorf ""Internal error: invalid [@@@ocaml.ppx.context \
                             { %s }] option syntax"" name
      in
      match name with
      | ""tool_name"" ->
          tool_name_ref := get_string payload
      | ""include_dirs"" ->
          Clflags.include_dirs := get_list get_string payload
      | ""load_path"" ->
          Load_path.init (get_list get_string payload)
      | ""open_modules"" ->
          Clflags.open_modules := get_list get_string payload
      | ""for_package"" ->
          Clflags.for_package := get_option get_string payload
      | ""debug"" ->
          Clflags.debug := get_bool payload
      | ""use_threads"" ->
          Clflags.use_threads := get_bool payload
      | ""use_vmthreads"" ->
          if get_bool payload then
            raise_errorf ""Internal error: vmthreads not supported after 4.09.0""
      | ""recursive_types"" ->
          Clflags.recursive_types := get_bool payload
      | ""principal"" ->
          Clflags.principal := get_bool payload
      | ""transparent_modules"" ->
          Clflags.transparent_modules := get_bool payload
      | ""unboxed_types"" ->
          Clflags.unboxed_types := get_bool payload
      | ""cookies"" ->
          let l = get_list (get_pair get_string (fun x -> x)) payload in
          cookies :=
            List.fold_left
              (fun s (k, v) -> String.Map.add k v s) String.Map.empty
              l
      | _ ->
          ()
    in
    List.iter (function ({txt=Lident name}, x) -> field name x | _ -> ()) fields

  let update_cookies fields =
    let fields =
      List.filter
        (function ({txt=Lident ""cookies""}, _) -> false | _ -> true)
        fields
    in
    fields @ [get_cookies ()]
end

let ppx_context = PpxContext.make

let extension_of_exn exn =
  match error_of_exn exn with
  | Some (`Ok error) -> extension_of_error error
  | Some `Already_displayed ->
      { loc = Location.none; txt = ""ocaml.error"" }, PStr []
  | None -> raise exn


let apply_lazy ~source ~target mapper =
  let implem ast =
    let fields, ast =
      match ast with
      | {pstr_desc = Pstr_attribute ({attr_name = {txt = ""ocaml.ppx.context""};
                                      attr_payload = x})} :: l ->
          PpxContext.get_fields x, l
      | _ -> [], ast
    in
    PpxContext.restore fields;
    let ast =
      try
        let mapper = mapper () in
        mapper.structure mapper ast
      with exn ->
        [{pstr_desc = Pstr_extension (extension_of_exn exn, []);
          pstr_loc  = Location.none}]
    in
    let fields = PpxContext.update_cookies fields in
    Str.attribute (PpxContext.mk fields) :: ast
  in
  let iface ast =
    let fields, ast =
      match ast with
      | {psig_desc = Psig_attribute ({attr_name = {txt = ""ocaml.ppx.context""};
                                      attr_payload = x;
                                      attr_loc = _})} :: l ->
          PpxContext.get_fields x, l
      | _ -> [], ast
    in
    PpxContext.restore fields;
    let ast =
      try
        let mapper = mapper () in
        mapper.signature mapper ast
      with exn ->
        [{psig_desc = Psig_extension (extension_of_exn exn, []);
          psig_loc  = Location.none}]
    in
    let fields = PpxContext.update_cookies fields in
    Sig.attribute (PpxContext.mk fields) :: ast
  in

  let ic = open_in_bin source in
  let magic =
    really_input_string ic (String.length Config.ast_impl_magic_number)
  in

  let rewrite transform =
    Location.input_name := input_value ic;
    let ast = input_value ic in
    close_in ic;
    let ast = transform ast in
    let oc = open_out_bin target in
    output_string oc magic;
    output_value oc !Location.input_name;
    output_value oc ast;
    close_out oc
  and fail () =
    close_in ic;
    failwith ""Ast_mapper: OCaml version mismatch or malformed input"";
  in

  if magic = Config.ast_impl_magic_number then
    rewrite (implem : structure -> structure)
  else if magic = Config.ast_intf_magic_number then
    rewrite (iface : signature -> signature)
  else fail ()

let drop_ppx_context_str ~restore = function
  | {pstr_desc = Pstr_attribute
                   {attr_name = {Location.txt = ""ocaml.ppx.context""};
                    attr_payload = a;
                    attr_loc = _}}
    :: items ->
      if restore then
        PpxContext.restore (PpxContext.get_fields a);
      items
  | items -> items

let drop_ppx_context_sig ~restore = function
  | {psig_desc = Psig_attribute
                   {attr_name = {Location.txt = ""ocaml.ppx.context""};
                    attr_payload = a;
                    attr_loc = _}}
    :: items ->
      if restore then
        PpxContext.restore (PpxContext.get_fields a);
      items
  | items -> items

let add_ppx_context_str ~tool_name ast =
  Ast_helper.Str.attribute (ppx_context ~tool_name ()) :: ast

let add_ppx_context_sig ~tool_name ast =
  Ast_helper.Sig.attribute (ppx_context ~tool_name ()) :: ast


let apply ~source ~target mapper =
  apply_lazy ~source ~target (fun () -> mapper)

let run_main mapper =
  try
    let a = Sys.argv in
    let n = Array.length a in
    if n > 2 then
      let mapper () =
        try mapper (Array.to_list (Array.sub a 1 (n - 3)))
        with exn ->
          (* PR#6463 *)
          let f _ _ = raise exn in
          {default_mapper with structure = f; signature = f}
      in
      apply_lazy ~source:a.(n - 2) ~target:a.(n - 1) mapper
    else begin
      Printf.eprintf ""Usage: %s [extra_args] <infile> <outfile>\n%!""
                     Sys.executable_name;
      exit 2
    end
  with exn ->
    prerr_endline (Printexc.to_string exn);
    exit 2

let register_function = ref (fun _name f -> run_main f)
let register name f = !register_function name f
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Loc_collections

exception Props_not_found of Type.Properties.id

exception Exports_not_found of Type.Exports.id

exception Require_not_found of string

exception Module_not_found of string

(* The Context module defines types for data which is passed around during type
 * checking, providing access to commonly needed state. The data is layered
 * according to their lifetimes and falls into three categories: *)

(* 1. Per-file information is needed during the AST traversal, to answer
 * questions like ""what options are enabled"" where options can be set on a
 * perf-file bases, like the ability to munge underscores. *)
type t

(* 2. Per-component information is needed during constraint solving, which
 * happens outside the context of any specific file -- specifically when dealing
 * with constraints between files in a cycle. *)
type component_t

(* 3. Inter-component information, i.e., stuff that we might want to know about
 * dependencies, like what modules they export and what types correspond to what
 * resolved tvars. *)
type sig_t = Type.TypeContext.t

type master_context = {
  master_sig_cx: sig_t;
  builtins: Builtins.t;
}

type metadata = {
  (* local *)
  checked: bool;
  include_suppressions: bool;
  jsx: Options.jsx_mode;
  munge_underscores: bool;
  strict: bool;
  strict_local: bool;
  verbose: Verbose.t option;
  (* global *)
  any_propagation: bool;
  automatic_require_default: bool;
  babel_loose_array_spread: bool;
  cycle_errors: bool;
  enable_const_params: bool;
  enable_enums: bool;
  enable_relay_integration: bool;
  enforce_local_inference_annotations: bool;
  enforce_strict_call_arity: bool;
  enforce_this_annotations: bool;
  env_mode: Options.env_mode;
  env_mode_constrain_write_dirs: string list;
  exact_by_default: bool;
  exact_empty_objects: bool;
  experimental_infer_indexers: bool;
  facebook_fbs: string option;
  facebook_fbt: string option;
  facebook_module_interop: bool;
  haste_module_ref_prefix: string option;
  ignore_non_literal_requires: bool;
  local_inference_annotation_dirs: string list;
  max_literal_length: int;
  max_trace_depth: int;
  max_workers: int;
  missing_module_generators: (Str.regexp * string) list;
  react_runtime: Options.react_runtime;
  react_server_component_exts: SSet.t;
  recursion_limit: int;
  relay_integration_excludes: Str.regexp list;
  relay_integration_module_prefix: string option;
  relay_integration_module_prefix_includes: Str.regexp list;
  root: Path.t;
  run_post_inference_implicit_instantiation: bool;
  statement_reorder_checking: Options.statement_order_mode;
  strict_es6_import_export: bool;
  strict_es6_import_export_excludes: string list;
  strip_root: bool;
  suppress_types: SSet.t;
  trust_mode: Options.trust_mode;
  type_asserts: bool;
}

type phase =
  | InitLib
  | Checking
  | Merging
  | PostInference

val string_of_phase : phase -> string

type type_assert_kind =
  | Is
  | Throws
  | Wraps

type voidable_check = {
  public_property_map: Type.Properties.id;
  private_property_map: Type.Properties.id;
  errors: ALoc.t Property_assignment.errors;
}

module Implicit_instantiation_check : sig
  type poly_t = ALoc.t * Type.typeparam Nel.t * Type.t

  type operation =
    | Call of Type.funcalltype
    | Constructor of Type.call_arg list

  type t = {
    lhs: Type.t;
    poly_t: poly_t;
    operation: Type.use_op * Reason.t * operation;
  }
end

type computed_property_state =
  | ResolvedOnce of Reason.t
  | ResolvedMultipleTimes

type subst_cache_err =
  | ETooFewTypeArgs of ALoc.t Reason.virtual_reason * int
  | ETooManyTypeArgs of ALoc.t Reason.virtual_reason * int

val empty_master_cx : unit -> master_context

val make_ccx : master_context -> component_t

val make : component_t -> metadata -> File_key.t -> ALoc.table Lazy.t -> Reason.name -> phase -> t

val metadata_of_options : Options.t -> metadata

val docblock_overrides : Docblock.t -> metadata -> metadata

val trust_constructor : t -> unit -> Trust.trust_rep

val cx_with_trust : t -> (unit -> Trust.trust_rep) -> t

val sig_cx : t -> sig_t

(* accessors *)
val current_phase : t -> phase

val all_unresolved : t -> ISet.t IMap.t

val metadata : t -> metadata

val max_literal_length : t -> int

val babel_loose_array_spread : t -> bool

val builtins : t -> Builtins.t

val enable_const_params : t -> bool

val enable_enums : t -> bool

val enable_relay_integration : t -> bool

val relay_integration_module_prefix : t -> string option

val env_mode : t -> Options.env_mode

val enforce_strict_call_arity : t -> bool

val errors : t -> Flow_error.ErrorSet.t

val error_suppressions : t -> Error_suppressions.t

val evaluated : t -> Type.t Type.Eval.Map.t

val goals : t -> Type.t IMap.t

val exact_by_default : t -> bool

val exact_empty_objects : t -> bool

val enforce_local_inference_annotations : t -> bool

val local_inference_annotation_dirs : t -> string list

val enforce_this_annotations : t -> bool

val experimental_infer_indexers : t -> bool

val statement_reorder_checking : t -> Options.statement_order_mode

val cycle_errors : t -> bool

val run_post_inference_implicit_instantiation : t -> bool

val file : t -> File_key.t

val aloc_tables : t -> ALoc.table Lazy.t Utils_js.FilenameMap.t

val find_props : t -> Type.Properties.id -> Type.Properties.t

val find_real_props : t -> Type.Properties.id -> Type.Properties.t

val find_call : t -> int -> Type.t

val find_exports : t -> Type.Exports.id -> Type.Exports.t

val find_require : t -> ALoc.t -> Type.tvar

val find_tvar : t -> Type.ident -> Type.Constraint.node

val graph : t -> Type.Constraint.node IMap.t

val trust_graph : t -> Trust_constraint.node IMap.t

val is_checked : t -> bool

val is_verbose : t -> bool

val is_strict : t -> bool

val is_strict_local : t -> bool

val include_suppressions : t -> bool

val severity_cover : t -> ExactCover.lint_severity_cover Utils_js.FilenameMap.t

val max_trace_depth : t -> int

val module_kind : t -> Module_info.kind

val require_map : t -> Type.tvar ALocMap.t

val module_ref : t -> Reason.name

val property_maps : t -> Type.Properties.map

val call_props : t -> Type.t IMap.t

val export_maps : t -> Type.Exports.map

val react_runtime : t -> Options.react_runtime

val in_react_server_component_file : t -> bool

val recursion_limit : t -> int

val root : t -> Path.t

val facebook_fbs : t -> string option

val facebook_fbt : t -> string option

val facebook_module_interop : t -> bool

val haste_module_ref_prefix : t -> string option

val should_ignore_non_literal_requires : t -> bool

val should_munge_underscores : t -> bool

val should_strip_root : t -> bool

val suppress_types : t -> SSet.t

val trust_mode : t -> Options.trust_mode

val trust_tracking : t -> bool

val trust_errors : t -> bool

val type_asserts : t -> bool

val type_graph : t -> Graph_explorer.graph

val type_asserts_map : t -> (type_assert_kind * ALoc.t) ALocMap.t

val matching_props : t -> (Reason.reason * string * Type.t * Type.t) list

val new_env_matching_props : t -> (string * ALoc.t * ALoc.t) list

val literal_subtypes : t -> (Type.t * Type.use_t) list

val new_env_literal_subtypes : t -> (ALoc.t * Env_api.new_env_literal_check) list

val constrained_writes : t -> (Type.t * Type.use_t) list

val verbose : t -> Verbose.t option

val max_workers : t -> int

val missing_module_generators : t -> (Str.regexp * string) list

val jsx : t -> Options.jsx_mode

val exists_checks : t -> Type.TypeSet.t ALocMap.t

val exists_excuses : t -> ExistsCheck.t ALocMap.t

val voidable_checks : t -> voidable_check list

val implicit_instantiation_checks : t -> Implicit_instantiation_check.t list

val inferred_indexers : t -> Type.dicttype list ALocMap.t

val environment : t -> Loc_env.t

val node_cache : t -> Node_cache.t

val pid_prefix : t -> string

val copy_of_context : t -> t

val merge_into : component_t -> sig_t -> unit

val any_propagation : t -> bool

val automatic_require_default : t -> bool

val env_option_enabled : t -> Options.env_option -> bool

val resolved_env : t -> bool

(* modules *)
val push_declare_module : t -> Module_info.t -> unit

val pop_declare_module : t -> unit

val module_info : t -> Module_info.t

(* mutators *)
val add_error : t -> ALoc.t Flow_error.t -> unit

val add_error_suppression : t -> Loc.t -> Suppression_comments.applicable_codes -> unit

val add_severity_cover : t -> File_key.t -> ExactCover.lint_severity_cover -> unit

val add_lint_suppressions : t -> LocSet.t -> unit

val add_require : t -> ALoc.t -> Type.tvar -> unit

val add_property_map : t -> Type.Properties.id -> Type.Properties.t -> unit

val add_call_prop : t -> int -> Type.t -> unit

val add_export_map : t -> Type.Exports.id -> Type.Exports.t -> unit

val add_tvar : t -> Type.ident -> Type.Constraint.node -> unit

val add_trust_var : t -> Trust_constraint.ident -> Trust_constraint.node -> unit

val add_type_assert : t -> ALoc.t -> type_assert_kind * ALoc.t -> unit

val add_matching_props : t -> Reason.reason * string * Type.t * Type.t -> unit

val add_new_env_matching_props : t -> string * ALoc.t * ALoc.t -> unit

val add_literal_subtypes : t -> Type.t * Type.use_t -> unit

val add_new_env_literal_subtypes : t -> ALoc.t * Env_api.new_env_literal_check -> unit

val add_constrained_write : t -> Type.t * Type.use_t -> unit

val add_voidable_check : t -> voidable_check -> unit

val add_implicit_instantiation_call :
  t ->
  Type.t ->
  Implicit_instantiation_check.poly_t ->
  Type.use_op ->
  Reason.t ->
  Type.funcalltype ->
  unit

val add_implicit_instantiation_ctor :
  t ->
  Type.t ->
  Implicit_instantiation_check.poly_t ->
  Type.use_op ->
  Reason.t ->
  Type.call_arg list ->
  unit

val add_inferred_indexer : t -> ALoc.t -> Type.dicttype -> unit

val set_evaluated : t -> Type.t Type.Eval.Map.t -> unit

val set_goals : t -> Type.t IMap.t -> unit

val set_type_graph : t -> Graph_explorer.graph -> unit

val set_all_unresolved : t -> ISet.t IMap.t -> unit

val set_graph : t -> Type.Constraint.node IMap.t -> unit

val set_trust_graph : t -> Trust_constraint.node IMap.t -> unit

val set_property_maps : t -> Type.Properties.map -> unit

val set_call_props : t -> Type.t IMap.t -> unit

val set_export_maps : t -> Type.Exports.map -> unit

val set_exists_checks : t -> Type.TypeSet.t ALocMap.t -> unit

val add_exists_check : t -> ALoc.t -> Type.t -> unit

val set_exists_excuses : t -> ExistsCheck.t ALocMap.t -> unit

val set_environment : t -> Loc_env.t -> unit

val clear_master_shared : t -> master_context -> unit

val add_env_cache_entry : t -> for_value:bool -> int -> Type.t -> unit

(* Flow allows you test test if a property exists inside a conditional. However, we only wan to
 * allow this test if there's a chance that the property might exist. So `if (foo.bar)` should be
 *
 * - Allowed for the types `{ bar: string }`, `any`, `mixed`, `{ bar: string } | number`, etc
 *
 * - Disallowed for the types ` { baz: string }`, `number`, ` { baz: string} | number`
 *
 * It's really difficult to say that something never happens in Flow. Our best way of approximating
 * this is waiting until typechecking is done and then seeing if something happened. In this case,
 * we record if testing a property ever succeeds. If if never succeeds after typechecking is done,
 * we emit an error.
 *)
val test_prop_hit : t -> Type.ident -> unit

val test_prop_miss :
  t ->
  Type.ident ->
  Reason.name option ->
  Reason.t * Reason.t ->
  Type.use_op ->
  string option ->
  unit

val test_prop_get_never_hit :
  t -> (Reason.name option * (Reason.t * Reason.t) * Type.use_op * string option) list

val computed_property_state_for_id : t -> Type.ident -> computed_property_state option

val computed_property_add_lower_bound : t -> Type.ident -> Reason.t -> unit

val computed_property_add_multiple_lower_bounds : t -> Type.ident -> unit

val spread_widened_types_get_widest : t -> Type.ident -> Type.Object.slice option

val spread_widened_types_add_widest : t -> Type.ident -> Type.Object.slice -> unit

val mark_optional_chain : t -> ALoc.t -> Reason.t -> useful:bool -> unit

val unnecessary_optional_chains : t -> (ALoc.t * Reason.t) list

val mark_invariant : t -> ALoc.t -> Reason.t -> useful:bool -> unit

val unnecessary_invariants : t -> (ALoc.t * Reason.t) list

(* utils *)
val iter_props : t -> Type.Properties.id -> (Reason.name -> Type.Property.t -> unit) -> unit

val iter_real_props : t -> Type.Properties.id -> (Reason.name -> Type.Property.t -> unit) -> unit

val fold_real_props :
  t -> Type.Properties.id -> (Reason.name -> Type.Property.t -> 'a -> 'a) -> 'a -> 'a

val has_prop : t -> Type.Properties.id -> Reason.name -> bool

val get_prop : t -> Type.Properties.id -> Reason.name -> Type.Property.t option

val set_prop : t -> Type.Properties.id -> Reason.name -> Type.Property.t -> unit

val has_export : t -> Type.Exports.id -> Reason.name -> bool

val set_export : t -> Type.Exports.id -> Reason.name -> ALoc.t option * Type.t -> unit

(* constructors *)
val make_aloc_id : t -> ALoc.t -> ALoc.id

val make_generic_id : t -> Subst_name.t -> ALoc.t -> Generic.id

val generate_property_map : t -> Type.Properties.t -> Type.Properties.id

val make_source_property_map : t -> Type.Properties.t -> ALoc.t -> Type.Properties.id

val make_call_prop : t -> Type.t -> int

val make_export_map : t -> Type.Exports.t -> Type.Exports.id

val make_source_poly_id : t -> ALoc.t -> Type.Poly.id

val find_constraints : t -> Type.ident -> Type.ident * Type.Constraint.constraints

val find_graph : t -> Type.ident -> Type.Constraint.constraints

val find_root : t -> Type.ident -> Type.ident * Type.Constraint.root

val find_resolved : t -> Type.t -> Type.t option

val find_trust_constraints :
  t -> Trust_constraint.ident -> Trust_constraint.ident * Trust_constraint.constraints

val find_trust_graph : t -> Trust_constraint.ident -> Trust_constraint.constraints

val find_trust_root : t -> Trust_constraint.ident -> Trust_constraint.ident * Trust_constraint.root

val env_cache_find_opt : t -> for_value:bool -> int -> Type.t option

val constraint_cache : t -> Type.FlowSet.t ref

val subst_cache : t -> (Type.Poly.id * Type.t list, subst_cache_err list * Type.t) Hashtbl.t

val instantiation_cache : t -> (Reason.t * Reason.t * Reason.t Nel.t, Type.t) Hashtbl.t

val repos_cache : t -> Repos_cache.t ref

val eval_id_cache :
  t -> (Type.Eval.id, Type.t) Hashtbl.t * (Type.t * Type.defer_use_t, Type.Eval.id) Hashtbl.t

val eval_repos_cache : t -> (Type.t * Type.defer_use_t * Type.Eval.id, Type.t) Hashtbl.t

val fix_cache : t -> (bool * Type.t, Type.t) Hashtbl.t

val spread_cache : t -> Spread_cache.t

val speculation_state : t -> Speculation_state.t

val speculation_id : t -> (int * int) option

val add_avar : t -> int -> Type.AConstraint.node -> unit

val find_avar : t -> int -> Type.ident * Type.AConstraint.root

val find_avar_exn : t -> int -> Type.ident * Type.AConstraint.root

val iter_annot_dependent_set : t -> (int -> Type.AConstraint.op -> unit) -> ISet.t -> unit
",ocaml
"(**************************************************************************)
(*                                                                        *)
(*                              OCamlFormat                               *)
(*                                                                        *)
(*            Copyright (c) Facebook, Inc. and its affiliates.            *)
(*                                                                        *)
(*      This source code is licensed under the MIT license found in       *)
(*      the LICENSE file in the root directory of this source tree.       *)
(*                                                                        *)
(**************************************************************************)

(** Translation units *)

module Location = Migrate_ast.Location
open Parse_with_comments
open Result.Monad_infix

exception
  Internal_error of
    [ `Cannot_parse of exn
    | `Ast_changed
    | `Doc_comment of Docstring.error list
    | `Comment
    | `Comment_dropped of Cmt.t list
    | `Warning50 of (Location.t * Warnings.t) list ]
    * (string * Sexp.t) list

let internal_error msg kvs = raise (Internal_error (msg, kvs))

let chop_any_extension s =
  match Filename.chop_extension s with
  | r -> r
  | exception Invalid_argument _ -> s

let exe = chop_any_extension (Filename.basename Caml.Sys.argv.(0))

module Error = struct
  type t =
    | Invalid_source of {exn: exn; input_name: string}
    | Unstable of
        {iteration: int; prev: string; next: string; input_name: string}
    | Ocamlformat_bug of {exn: exn; input_name: string}
    | User_error of string

  let user_error x = User_error x

  let equal : t -> t -> bool = Poly.equal

  let print_diff input_name ~prev ~next =
    let ext = Filename.extension input_name in
    let input_name =
      Filename.chop_extension (Filename.basename input_name)
    in
    let p = Filename.temp_file input_name (Printf.sprintf "".prev%s"" ext) in
    let n = Filename.temp_file input_name (Printf.sprintf "".next%s"" ext) in
    Out_channel.write_all p ~data:prev ;
    Out_channel.write_all n ~data:next ;
    ignore
      (Caml.Sys.command
         (Printf.sprintf ""git diff --no-index -u %S %S | sed '1,4d' 1>&2"" p n) ) ;
    Caml.Sys.remove p ;
    Caml.Sys.remove n

  let print ?(debug = false) ?(quiet = false) fmt = function
    | Invalid_source _ when quiet -> ()
    | Invalid_source {exn; input_name} -> (
        let reason =
          match exn with
          | Syntaxerr.Error _ | Lexer.Error _ -> "" (syntax error)""
          | Warning50 _ -> "" (misplaced documentation comments - warning 50)""
          | _ -> """"
        in
        Format.fprintf fmt ""%s: ignoring %S%s\n%!"" exe input_name reason ;
        match exn with
        | Syntaxerr.Error _ | Lexer.Error _ ->
            Location.report_exception fmt exn
        | Warning50 l ->
            List.iter l ~f:(fun (l, w) -> Warning.print_warning l w) ;
            Format.fprintf fmt
              ""@{<warning>Hint@}: (Warning 50) This file contains a \
               documentation comment (** ... *) that the OCaml compiler \
               does not know how to attach to the AST. OCamlformat does not \
               support these cases. You can find more information at: \
               https://github.com/ocaml-ppx/ocamlformat#overview. If you'd \
               like to disable this check and let ocamlformat make a choice \
               (though it might not be consistent with the ocaml compilers \
               and odoc), you can set the --no-comment-check option.\n\
               %!""
        | exn -> Format.fprintf fmt ""%s\n%!"" (Exn.to_string exn) )
    | Unstable {iteration; prev; next; input_name} ->
        if debug then print_diff input_name ~prev ~next ;
        if iteration <= 1 then
          Format.fprintf fmt
            ""%s: %S was not already formatted. ([max-iters = 1])\n%!"" exe
            input_name
        else (
          Format.fprintf fmt
            ""%s: Cannot process %S.\n\
            \  Please report this bug at \
             https://github.com/ocaml-ppx/ocamlformat/issues.\n\
             %!""
            exe input_name ;
          Format.fprintf fmt
            ""  BUG: formatting did not stabilize after %i iterations.\n%!""
            iteration )
    | User_error msg -> Format.fprintf fmt ""%s: %s.\n%!"" exe msg
    | Ocamlformat_bug {exn; input_name} -> (
        Format.fprintf fmt
          ""%s: Cannot process %S.\n\
          \  Please report this bug at \
           https://github.com/ocaml-ppx/ocamlformat/issues.\n\
           %!""
          exe input_name ;
        match exn with
        | Internal_error (m, l) ->
            let s =
              match m with
              | `Cannot_parse _ -> ""generating invalid ocaml syntax""
              | `Ast_changed -> ""ast changed""
              | `Doc_comment _ -> ""doc comments changed""
              | `Comment -> ""comments changed""
              | `Comment_dropped _ -> ""comments dropped""
              | `Warning50 _ -> ""misplaced documentation comments""
            in
            Format.fprintf fmt ""  BUG: %s.\n%!"" s ;
            ( match m with
            | `Doc_comment l when not quiet ->
                List.iter l ~f:(function
                  | Added (loc, msg) ->
                      Format.fprintf fmt
                        ""%!@{<loc>%a@}:@,\
                         @{<error>Error@}: Docstring (** %s *) added.\n\
                         %!""
                        Location.print loc msg
                  | Removed (loc, msg) ->
                      Format.fprintf fmt
                        ""%!@{<loc>%a@}:@,\
                         @{<error>Error@}: Docstring (** %s *) dropped.\n\
                         %!""
                        Location.print loc msg
                  | Moved (loc_before, loc_after, msg) ->
                      if Location.compare loc_before Location.none = 0 then
                        Format.fprintf fmt
                          ""%!@{<loc>%a@}:@,\
                           @{<error>Error@}: Docstring (** %s *) added.\n\
                           %!""
                          Location.print loc_after msg
                      else if Location.compare loc_after Location.none = 0
                      then
                        Format.fprintf fmt
                          ""%!@{<loc>%a@}:@,\
                           @{<error>Error@}: Docstring (** %s *) dropped.\n\
                           %!""
                          Location.print loc_before msg
                      else
                        Format.fprintf fmt
                          ""%!@{<loc>%a@}:@,\
                           @{<error>Error@}: Docstring (** %s *) moved to \
                           @{<loc>%a@}.\n\
                           %!""
                          Location.print loc_before msg Location.print
                          loc_after
                  | Unstable (loc, x, y) ->
                      Format.fprintf fmt
                        ""%!@{<loc>%a@}:@,\
                         @{<error>Error@}: Formatting of doc-comment is \
                         unstable (e.g. parses as a list or not depending \
                         on the margin):\n\
                         %!""
                        Location.print loc ;
                      print_diff input_name ~prev:x ~next:y ;
                      Format.fprintf fmt
                        ""Please tighten up this comment in the source or \
                         disable the formatting using the option \
                         --no-parse-docstrings.\n\
                         %!"" )
            | `Comment_dropped l when not quiet ->
                List.iter l ~f:(fun Cmt.{txt= msg; loc} ->
                    Format.fprintf fmt
                      ""%!@{<loc>%a@}:@,\
                       @{<error>Error@}: Comment (* %s *) dropped.\n\
                       %!""
                      Location.print loc msg )
            | `Cannot_parse ((Syntaxerr.Error _ | Lexer.Error _) as exn) ->
                if debug then Location.report_exception fmt exn
            | `Warning50 l ->
                if debug then
                  List.iter l ~f:(fun (l, w) -> Warning.print_warning l w)
            | _ -> () ) ;
            if debug then
              List.iter l ~f:(fun (msg, sexp) ->
                  Format.fprintf fmt ""  %s: %s\n%!"" msg (Sexp.to_string sexp) )
        | exn ->
            Format.fprintf fmt
              ""  BUG: unhandled exception. Use [--debug] for details.\n%!"" ;
            if debug then Format.fprintf fmt ""%s\n%!"" (Exn.to_string exn) )
end

let with_file input_name output_file suf ext f =
  let dir =
    match output_file with
    | Some filename -> Filename.dirname filename
    | None -> Filename.get_temp_dir_name ()
  in
  let base = Filename.remove_extension (Filename.basename input_name) in
  let tmp = Filename.concat dir (base ^ suf ^ ext) in
  Out_channel.with_file tmp ~f ;
  tmp

let dump_ast ~input_name ?output_file ~suffix fmt =
  let ext = "".ast"" in
  with_file input_name output_file suffix ext (fun oc ->
      fmt (Format.formatter_of_out_channel oc) )

let dump_formatted ~input_name ?output_file ~suffix fmted =
  let ext = Filename.extension input_name in
  with_file input_name output_file suffix ext (fun oc ->
      Out_channel.output_string oc fmted )

let check_all_locations fmt cmts_t =
  match Cmts.remaining_locs cmts_t with
  | [] -> ()
  | l ->
      let print l = Format.fprintf fmt ""%a\n%!"" Location.print l in
      Format.fprintf fmt
        ""Warning: Some locations have not been considered\n%!"" ;
      List.iter ~f:print (List.sort l ~compare:Location.compare)

let check_margin (conf : Conf.t) ~filename ~fmted =
  List.iteri (String.split_lines fmted) ~f:(fun i line ->
      if String.length line > conf.fmt_opts.margin then
        Format.fprintf Format.err_formatter
          ""Warning: %s:%i exceeds the margin\n%!"" filename i )

let with_optional_box_debug ~box_debug k =
  if box_debug then Fmt.with_box_debug k else k

let with_buffer_formatter ~buffer_size k =
  let buffer = Buffer.create buffer_size in
  let fs = Format_.formatter_of_buffer buffer in
  Fmt.eval fs k ;
  Format_.pp_print_flush fs () ;
  if Buffer.length buffer > 0 then Format_.pp_print_newline fs () ;
  Buffer.contents buffer

let recover (type a) : a Extended_ast.t -> _ -> a = function
  | Structure -> Parser_recovery.structure
  | Signature -> Parser_recovery.signature
  | Use_file -> Parser_recovery.use_file
  | Core_type -> failwith ""no recovery for core_type""
  | Module_type -> failwith ""no recovery for module_type""
  | Expression -> failwith ""no recovery for expression""
  | Repl_file -> failwith ""no recovery for repl_file""

let strconst_mapper locs =
  let constant self c =
    match c.Parsetree.pconst_desc with
    | Parsetree.Pconst_string (_, {Location.loc_start; loc_end; _}, Some _)
      ->
        locs := (loc_start.Lexing.pos_cnum, loc_end.Lexing.pos_cnum) :: !locs ;
        c
    | _ -> Ast_mapper.default_mapper.constant self c
  in
  {Ast_mapper.default_mapper with constant}

let collect_strlocs (type a) (fg : a Extended_ast.t) (ast : a) :
    (int * int) list =
  let locs = ref [] in
  let _ = Extended_ast.map fg (strconst_mapper locs) ast in
  let compare (c1, _) (c2, _) = Stdlib.compare c1 c2 in
  List.sort ~compare !locs

let format (type a b) (fg : a Extended_ast.t) (std_fg : b Std_ast.t)
    ?output_file ~input_name ~prev_source ~parsed ~std_parsed (conf : Conf.t)
    =
  let open Result.Monad_infix in
  let dump_ast fg ~suffix ast =
    if conf.opr_opts.debug then
      Some
        (dump_ast ~input_name ?output_file ~suffix (fun fmt ->
             Std_ast.Printast.ast fg fmt ast ) )
    else None
  in
  let dump_formatted ~suffix fmted =
    if conf.opr_opts.debug then
      Some (dump_formatted ~input_name ?output_file ~suffix fmted)
    else None
  in
  Location.input_name := input_name ;
  (* iterate until formatting stabilizes *)
  let rec print_check ~i ~(conf : Conf.t) ~prev_source t std_t =
    let format ~box_debug =
      let open Fmt in
      let cmts_t =
        Cmts.init fg ~debug:conf.opr_opts.debug t.source t.ast t.comments
      in
      let contents =
        with_buffer_formatter
          ~buffer_size:(String.length prev_source)
          ( set_margin conf.fmt_opts.margin
          $ opt conf.fmt_opts.max_indent set_max_indent
          $ fmt_if_k
              (not (String.is_empty t.prefix))
              (str t.prefix $ fmt ""@."")
          $ with_optional_box_debug ~box_debug
              (Fmt_ast.fmt_ast fg ~debug:conf.opr_opts.debug t.source cmts_t
                 conf t.ast ) )
      in
      (contents, cmts_t)
    in
    if conf.opr_opts.debug then
      format ~box_debug:true |> fst
      |> dump_formatted ~suffix:"".boxes""
      |> (ignore : string option -> unit) ;
    let fmted, cmts_t = format ~box_debug:false in
    let conf =
      if conf.opr_opts.debug then conf
      else {conf with opr_opts= {conf.opr_opts with quiet= true}}
    in
    if String.equal prev_source fmted then (
      if conf.opr_opts.debug then
        check_all_locations Format.err_formatter cmts_t ;
      if conf.opr_opts.margin_check then
        check_margin conf ~fmted
          ~filename:(Option.value output_file ~default:input_name) ;
      let strlocs = collect_strlocs fg t.ast in
      Ok (strlocs, fmted) )
    else
      let exn_args () =
        [(""output file"", dump_formatted ~suffix:"".invalid-ast"" fmted)]
        |> List.filter_map ~f:(fun (s, f_opt) ->
               Option.map f_opt ~f:(fun f -> (s, String.sexp_of_t f)) )
      in
      let preserve_beginend =
        Poly.(conf.fmt_opts.exp_grouping = `Preserve)
      in
      let parse_ast = Extended_ast.Parse.ast ~preserve_beginend in
      ( match parse parse_ast ~disable_w50:true fg conf ~source:fmted with
      | exception Sys_error msg -> Error (Error.User_error msg)
      | exception exn -> internal_error (`Cannot_parse exn) (exn_args ())
      | t_new -> Ok t_new )
      >>= fun t_new ->
      ( match parse Std_ast.Parse.ast std_fg conf ~source:fmted with
      | exception Sys_error msg -> Error (Error.User_error msg)
      | exception Warning50 l -> internal_error (`Warning50 l) (exn_args ())
      | exception exn -> internal_error (`Cannot_parse exn) (exn_args ())
      | std_t_new -> Ok std_t_new )
      >>= fun std_t_new ->
      (* Ast not preserved ? *)
      ( if
        (not
           (Normalize_std_ast.equal std_fg conf std_t.ast std_t_new.ast
              ~ignore_doc_comments:(not conf.opr_opts.comment_check) ) )
        && not
             (Normalize_extended_ast.equal fg conf t.ast t_new.ast
                ~ignore_doc_comments:(not conf.opr_opts.comment_check) )
      then
        let old_ast =
          dump_ast std_fg ~suffix:"".old""
            (Normalize_std_ast.ast std_fg conf std_t.ast)
        in
        let new_ast =
          dump_ast std_fg ~suffix:"".new""
            (Normalize_std_ast.ast std_fg conf std_t_new.ast)
        in
        let args ~suffix =
          [ (""output file"", dump_formatted ~suffix fmted)
          ; (""old ast"", old_ast)
          ; (""new ast"", new_ast) ]
          |> List.filter_map ~f:(fun (s, f_opt) ->
                 Option.map f_opt ~f:(fun f -> (s, String.sexp_of_t f)) )
        in
        if
          Normalize_std_ast.equal std_fg ~ignore_doc_comments:true conf
            std_t.ast std_t_new.ast
        then
          let docstrings =
            Normalize_std_ast.moved_docstrings std_fg conf std_t.ast
              std_t_new.ast
          in
          let args = args ~suffix:"".unequal-docs"" in
          internal_error (`Doc_comment docstrings) args
        else
          let args = args ~suffix:"".unequal-ast"" in
          internal_error `Ast_changed args ) ;
      (* Comments not preserved ? *)
      if conf.opr_opts.comment_check then (
        ( match Cmts.remaining_comments cmts_t with
        | [] -> ()
        | l -> internal_error (`Comment_dropped l) [] ) ;
        let is_docstring (Cmt.{txt; loc} as cmt) =
          match txt with
          | """" | ""*"" -> Either.Second cmt
          | _ when Char.equal txt.[0] '*' ->
              (* Doc comments here (comming directly from the lexer) include
                 their leading star *. It is not part of the docstring and
                 should be dropped. *)
              let txt = String.drop_prefix txt 1 in
              let cmt = Cmt.create txt loc in
              if conf.fmt_opts.parse_docstrings then Either.First cmt
              else Either.Second cmt
          | _ -> Either.Second cmt
        in
        let old_docstrings, old_comments =
          List.partition_map t.comments ~f:is_docstring
        in
        let t_newdocstrings, t_newcomments =
          List.partition_map t_new.comments ~f:is_docstring
        in
        let diff_cmts =
          Sequence.append
            (Normalize_extended_ast.diff_cmts conf old_comments t_newcomments)
            (Normalize_extended_ast.diff_docstrings conf old_docstrings
               t_newdocstrings )
        in
        if not (Sequence.is_empty diff_cmts) then
          let old_ast = dump_ast std_fg ~suffix:"".old"" std_t.ast in
          let new_ast = dump_ast std_fg ~suffix:"".new"" std_t_new.ast in
          let args =
            [ ( ""diff""
              , Some
                  (Sequence.sexp_of_t
                     (Either.sexp_of_t String.sexp_of_t String.sexp_of_t)
                     diff_cmts ) )
            ; (""old ast"", Option.map old_ast ~f:String.sexp_of_t)
            ; (""new ast"", Option.map new_ast ~f:String.sexp_of_t) ]
            |> List.filter_map ~f:(fun (s, f_opt) ->
                   Option.map f_opt ~f:(fun f -> (s, f)) )
          in
          internal_error `Comment args ) ;
      (* Too many iteration ? *)
      if i >= conf.opr_opts.max_iters then (
        Caml.flush_all () ;
        Error
          (Unstable {iteration= i; prev= prev_source; next= fmted; input_name}
          ) )
      else
        (* All good, continue *)
        print_check ~i:(i + 1) ~conf ~prev_source:fmted t_new std_t_new
  in
  try print_check ~i:1 ~conf ~prev_source parsed std_parsed with
  | Sys_error msg -> Error (User_error msg)
  | exn -> Error (Ocamlformat_bug {exn; input_name})

let parse_result ?disable_w50 f fragment conf ~source ~input_name =
  match parse ?disable_w50 f fragment conf ~source with
  | exception exn -> Error (Error.Invalid_source {exn; input_name})
  | parsed -> Ok parsed

let normalize_eol ~strlocs ~line_endings s =
  let buf = Buffer.create (String.length s) in
  let add_cr n = Buffer.add_string buf (String.init n ~f:(fun _ -> '\r')) in
  let rec normalize_segment ~seen_cr i stop =
    if i = stop then add_cr seen_cr
    else
      match s.[i] with
      | '\r' -> normalize_segment ~seen_cr:(seen_cr + 1) (i + 1) stop
      | '\n' ->
          Buffer.add_string buf
            (match line_endings with `Crlf -> ""\r\n"" | `Lf -> ""\n"") ;
          normalize_segment ~seen_cr:0 (i + 1) stop
      | c ->
          add_cr seen_cr ;
          Buffer.add_char buf c ;
          normalize_segment ~seen_cr:0 (i + 1) stop
  in
  let rec loop locs i =
    match locs with
    | [] ->
        normalize_segment ~seen_cr:0 i (String.length s) ;
        Buffer.contents buf
    | (start, stop) :: xs ->
        normalize_segment ~seen_cr:0 i start ;
        Buffer.add_substring buf s ~pos:start ~len:(stop - start) ;
        loop xs stop
  in
  loop strlocs 0

let parse_and_format (type a b) (fg : a Extended_ast.t)
    (std_fg : b Std_ast.t) ?output_file ~input_name ~source (conf : Conf.t) =
  Location.input_name := input_name ;
  let preserve_beginend = Poly.(conf.fmt_opts.exp_grouping = `Preserve) in
  let parse_ast = Extended_ast.Parse.ast ~preserve_beginend in
  parse_result parse_ast ~disable_w50:true fg conf ~source ~input_name
  >>= fun parsed ->
  parse_result Std_ast.Parse.ast std_fg conf ~source ~input_name
  >>= fun std_parsed ->
  format fg std_fg ?output_file ~input_name ~prev_source:source ~parsed
    ~std_parsed conf
  >>= fun (strlocs, formatted) ->
  Ok
    (normalize_eol ~strlocs ~line_endings:conf.fmt_opts.line_endings
       formatted )

let parse_and_format = function
  | Syntax.Structure -> parse_and_format Structure Structure
  | Syntax.Signature -> parse_and_format Signature Signature
  | Syntax.Use_file -> parse_and_format Use_file Use_file
  | Syntax.Core_type -> parse_and_format Core_type Core_type
  | Syntax.Module_type -> parse_and_format Module_type Module_type
  | Syntax.Expression -> parse_and_format Expression Expression
  | Syntax.Repl_file -> parse_and_format Repl_file Repl_file

let check_line nlines i =
  (* the last line of the buffer (nlines + 1) should not raise an error *)
  if 1 <= i && i <= nlines + 1 then Ok ()
  else Error (Error.User_error (Format.sprintf ""Invalid line number %i"" i))

let check_range nlines (low, high) =
  check_line nlines low
  >>= fun () ->
  check_line nlines high
  >>= fun () ->
  if low <= high then Ok ()
  else
    Error (Error.User_error (Format.sprintf ""Invalid range %i-%i"" low high))

let numeric (type a b) (fg : a list Extended_ast.t)
    (std_fg : b list Std_ast.t) ~input_name ~source ~range (conf : Conf.t) =
  let lines = String.split_lines source in
  let nlines = List.length lines in
  check_range nlines range
  >>| fun () ->
  Location.input_name := input_name ;
  let preserve_beginend = Poly.(conf.fmt_opts.exp_grouping = `Preserve) in
  let parse_ast = Extended_ast.Parse.ast ~preserve_beginend in
  let fallback () = Indent.Partial_ast.indent_range ~source ~range in
  let indent_parsed parsed std_parsed ~src ~range =
    let {ast= parsed_ast; _} = parsed in
    match
      format fg std_fg ~input_name ~prev_source:src ~parsed ~std_parsed conf
    with
    | Ok (_, fmted_src) -> (
      match parse_result parse_ast fg ~source:fmted_src conf ~input_name with
      | Ok {ast= fmted_ast; source= fmted_src; _} ->
          Indent.Valid_ast.indent_range fg ~lines ~range
            ~unformatted:(parsed_ast, src) ~formatted:(fmted_ast, fmted_src)
      | Error _ -> fallback () )
    | Error _ -> fallback ()
  in
  let parse_or_recover ~src =
    match parse_result parse_ast fg conf ~source:src ~input_name with
    | Ok parsed -> Ok parsed
    | Error _ -> parse_result recover fg conf ~source:src ~input_name
  in
  match parse_or_recover ~src:source with
  | Ok parsed -> (
    match parse_result Std_ast.Parse.ast std_fg conf ~source ~input_name with
    | Ok std_parsed -> indent_parsed parsed std_parsed ~src:source ~range
    | Error _ -> fallback () )
  | Error _ -> fallback ()

let numeric = function
  | Syntax.Structure -> numeric Structure Structure
  | Syntax.Signature -> numeric Signature Signature
  | Syntax.Use_file -> numeric Use_file Use_file
  | Syntax.Core_type -> failwith ""numeric not implemented for Core_type""
  | Syntax.Module_type -> failwith ""numeric not implemented for Module_type""
  | Syntax.Expression -> failwith ""numeric not implemented for Expression""
  | Syntax.Repl_file -> failwith ""numeric not implemented for Repl_file""
",ocaml
"class c = object
  method x = 1
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

let version = ""0.176.3""
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

open Utils_js
module Heap = SharedMem.NewAPI
module MSet = Modulename.Set

module FileHeap =
  SharedMem.NoCacheAddr
    (File_key)
    (struct
      type t = Heap.file
    end)

module FileModuleHeap =
  SharedMem.NoCacheAddr
    (File_key)
    (struct
      type t = Heap.file_module
    end)

module HasteModuleHeap =
  SharedMem.NoCacheAddr
    (StringKey)
    (struct
      type t = Heap.haste_module
    end)

exception File_not_found of string

exception File_not_parsed of string

exception File_not_typed of string

exception Ast_not_found of string

exception ALoc_table_not_found of string

exception Docblock_not_found of string

exception Requires_not_found of string

exception Type_sig_not_found of string

exception Haste_module_not_found of string

exception File_module_not_found of string

exception Resolved_requires_not_found of string

type locs_tbl = Loc.t Type_sig_collections.Locs.t

type type_sig = Type_sig_collections.Locs.index Packed_type_sig.Module.t

type file_addr = Heap.file SharedMem.addr

type +'a parse_addr = 'a Heap.parse SharedMem.addr

type haste_info_addr = Heap.haste_info SharedMem.addr

type haste_module_addr = Heap.haste_module SharedMem.addr

type file_module_addr = Heap.file_module SharedMem.addr

type provider_addr = Heap.file Heap.entity SharedMem.addr

type resolved_requires = {
  resolved_modules: Modulename.t SMap.t;
  phantom_dependencies: SSet.t;
  hash: Xx.hash;
}
[@@deriving show]

let ( let* ) = Option.bind

let mk_resolved_requires ~resolved_modules ~phantom_dependencies =
  let state = Xx.init 0L in
  SMap.iter
    (fun reference modulename ->
      Xx.update state reference;
      Xx.update state (Modulename.to_string modulename))
    resolved_modules;
  SSet.iter (Xx.update state) phantom_dependencies;
  { resolved_modules; phantom_dependencies; hash = Xx.digest state }

(* There's some redundancy in the visitors here, but an attempt to avoid repeated code led,
 * inexplicably, to a shared heap size regression under types-first: D15481813 *)
let loc_compactifier =
  object (this)
    inherit [Loc.t, Loc.t, RelativeLoc.t, RelativeLoc.t] Flow_polymorphic_ast_mapper.mapper

    method private compactify_loc loc = RelativeLoc.of_loc loc

    method on_loc_annot = this#compactify_loc

    method on_type_annot = this#compactify_loc
  end

let compactify_loc ast = loc_compactifier#program ast

let loc_decompactifier source =
  object (this)
    inherit [RelativeLoc.t, RelativeLoc.t, Loc.t, Loc.t] Flow_polymorphic_ast_mapper.mapper

    method private decompactify_loc loc = RelativeLoc.to_loc loc source

    method on_loc_annot = this#decompactify_loc

    method on_type_annot = this#decompactify_loc
  end

let decompactify_loc file ast = (loc_decompactifier (Some file))#program ast

let file_kind_and_name = function
  | File_key.Builtins -> invalid_arg ""builtins""
  | File_key.SourceFile f -> (Heap.Source_file, f)
  | File_key.ResourceFile f -> (Heap.Resource_file, f)
  | File_key.JsonFile f -> (Heap.Json_file, f)
  | File_key.LibFile f -> (Heap.Lib_file, f)

let get_file_addr = FileHeap.get

let get_file_addr_unsafe file =
  match get_file_addr file with
  | Some addr -> addr
  | None -> raise (File_not_found (File_key.to_string file))

let get_haste_module = HasteModuleHeap.get

let get_file_module = FileModuleHeap.get

let get_haste_module_unsafe name =
  match get_haste_module name with
  | Some addr -> addr
  | None -> raise (Haste_module_not_found name)

let get_file_module_unsafe key =
  match get_file_module key with
  | Some addr -> addr
  | None -> raise (File_module_not_found (File_key.to_string key))

let get_provider_ent = function
  | Modulename.String name ->
    let* haste_module = get_haste_module name in
    Some (Heap.get_haste_provider haste_module)
  | Modulename.Filename file_key ->
    let* file_module = get_file_module file_key in
    Some (Heap.get_file_provider file_module)

let haste_modulename m = Modulename.String (Heap.read_string (Heap.get_haste_name m))

let prepare_add_file_module_maybe size file_key =
  match file_key with
  | File_key.LibFile _ -> (size, Fun.const None)
  | _ ->
    let file_module_key = Files.chop_flow_ext file_key in
    (match FileModuleHeap.get file_module_key with
    | Some _ as addr -> (size, Fun.const addr)
    | None ->
      let open Heap in
      let size = size + (2 * header_size) + file_module_size + entity_size in
      let write chunk =
        let provider = write_entity chunk None in
        let m = write_file_module chunk provider in
        Some (FileModuleHeap.add file_module_key m)
      in
      (size, write))

let prepare_add_haste_module_maybe size name =
  match HasteModuleHeap.get name with
  | Some addr -> (size, Fun.const addr)
  | None ->
    let open Heap in
    let size = size + (3 * header_size) + haste_module_size + string_size name + entity_size in
    let write chunk =
      let heap_name = write_string chunk name in
      let provider = write_entity chunk None in
      let m = write_haste_module chunk heap_name provider in
      HasteModuleHeap.add name m
    in
    (size, write)

let prepare_write_new_haste_info_maybe size old_haste_info = function
  | None -> (size, Fun.const None)
  | Some name ->
    let open Heap in
    let haste_module_unchanged old_info =
      let old_name = read_string (get_haste_name (get_haste_module old_info)) in
      String.equal name old_name
    in
    (match old_haste_info with
    | Some old_info when haste_module_unchanged old_info -> (size, Fun.const old_haste_info)
    | _ ->
      let size = size + header_size + haste_info_size in
      let (size, add_haste_module_maybe) = prepare_add_haste_module_maybe size name in
      let write chunk =
        let haste_module = add_haste_module_maybe chunk in
        Some (write_haste_info chunk haste_module)
      in
      (size, write))

(* Calculate the set of dirty modules and prepare those modules to be committed.
 *
 * If this file became a provider to a haste/file module, we add this file to
 * the module's ""all providers"" list and mark the module as dirty.
 *
 * If this file no longer providers a haste/file module, we do not remove the
 * file now, to avoid complexity around concurrent deletion. Instead, old
 * providers are ""logically"" deleted, the module is marked as dirty, and we
 * perform deferred deletions during commit_modules.
 *
 * We also mark modules as dirty even if the module itself does not need to be
 * committed -- that is, we do not need to pick a new provider. A module is also
 * considered dirty if the provider file's contents have changed.
 *
 * TODO: Regarding the above, we might profitably separate these two notions of
 * dirtiness! We can skip re-picking a provider for modules which keep the same
 * provider, but we still need to re-check its dependents.
 *)
let calc_dirty_modules file_key file haste_ent new_file_module =
  let open Heap in
  let (old_haste_info, new_haste_info, changed_haste_info) =
    let new_info = entity_read_latest haste_ent in
    if entity_changed haste_ent then
      let old_info = entity_read_committed haste_ent in
      (old_info, new_info, None)
    else
      (* Changing `file` does not cause `new_m`'s provider to be re-picked,
       * but the module is still dirty because `file` changed. (see TODO) *)
      (None, None, new_info)
  in
  let dirty_modules =
    match old_haste_info with
    | None -> MSet.empty
    | Some info ->
      let m = get_haste_module info in
      MSet.singleton (haste_modulename m)
  in
  let dirty_modules =
    match new_haste_info with
    | None -> dirty_modules
    | Some info ->
      let m = get_haste_module info in
      add_haste_provider m file info;
      MSet.add (haste_modulename m) dirty_modules
  in
  let dirty_modules =
    match changed_haste_info with
    | None -> dirty_modules
    | Some info ->
      let m = get_haste_module info in
      MSet.add (haste_modulename m) dirty_modules
  in
  Option.iter (fun m -> add_file_provider m file) new_file_module;
  (* Changing `file` does not cause the eponymous module's provider to be
   * re-picked, but it is still dirty because `file` changed. (see TODO) *)
  MSet.add (Files.eponymous_module file_key) dirty_modules

let prepare_create_file size file_key module_name =
  let open Heap in
  let (file_kind, file_name) = file_kind_and_name file_key in
  let size = size + (4 * header_size) + (2 * entity_size) + string_size file_name + file_size in
  let (size, write_new_haste_info_maybe) =
    prepare_write_new_haste_info_maybe size None module_name
  in
  let (size, add_file_module_maybe) = prepare_add_file_module_maybe size file_key in
  let write chunk parse =
    let file_name = write_string chunk file_name in
    let parse_ent = write_entity chunk (Some parse) in
    let haste_info = write_new_haste_info_maybe chunk in
    let haste_ent = write_entity chunk haste_info in
    let file_module = add_file_module_maybe chunk in
    let file = write_file chunk file_kind file_name parse_ent haste_ent file_module in
    if file = FileHeap.add file_key file then
      calc_dirty_modules file_key file haste_ent file_module
    else
      (* Two threads raced to add this file and the other thread won. We don't
       * need to mark any files as dirty; the other thread will have done that
       * for us. *)
      MSet.empty
  in
  (size, write)

let prepare_update_file size file_key file parse_ent module_name =
  let open Heap in
  let haste_ent = get_haste_info file in
  let old_haste_info = entity_read_latest haste_ent in
  let (size, write_new_haste_info_maybe) =
    prepare_write_new_haste_info_maybe size old_haste_info module_name
  in
  let new_file_module =
    (* If we are re-parsing an unparsed file, we need to re-add ourselves to the
     * file module's provider list. If the file is already parsed, then we are
     * certainly already a provider, so we don't need to re-add. *)
    match entity_read_latest parse_ent with
    | None -> get_file_module file
    | Some _ -> None
  in
  let write chunk parse =
    entity_advance parse_ent (Some parse);
    let new_haste_info = write_new_haste_info_maybe chunk in
    let () =
      match (old_haste_info, new_haste_info) with
      | (None, None) -> ()
      | (Some old_info, Some new_info) when haste_info_equal old_info new_info -> ()
      | _ -> entity_advance haste_ent new_haste_info
    in
    calc_dirty_modules file_key file haste_ent new_file_module
  in
  (size, write)

(* Write parsed data for checked file to shared memory. If we loaded from saved
 * state, a checked file entry will already exist without parse data and this
 * function will update the existing entry in place. Otherwise, we will create a
 * new entry and add it to the shared hash table. *)
let add_checked_file file_key file_opt hash module_name docblock ast locs type_sig file_sig exports
    =
  let open Type_sig_collections in
  let serialize x = Marshal.to_string x [] in
  let ast = serialize (compactify_loc ast) in
  let docblock = serialize docblock in
  let file_sig = serialize file_sig in
  let aloc_table = Packed_locs.pack (Locs.length locs) (fun f -> Locs.iter f locs) in
  let (sig_bsize, write_sig) = Type_sig_bin.write type_sig in
  let (file_sig_size, write_file_sig) = Heap.prepare_write_file_sig file_sig in
  let (ast_size, write_ast) = Heap.prepare_write_ast ast in
  let open Heap in
  let size =
    (5 * header_size)
    + ast_size
    + docblock_size docblock
    + aloc_table_size aloc_table
    + type_sig_size sig_bsize
    + file_sig_size
  in
  let unchanged_or_fresh_parse =
    match file_opt with
    | None -> Either.Right (prepare_create_file size file_key module_name)
    | Some file ->
      let parse_ent = get_parse file in
      (* If we loaded from a saved state, we will have some existing data with a
       * matching hash. In this case, we want to update the existing data with
       * parse information. *)
      let file_hash_unchanged parse =
        let old_hash = read_int64 (get_file_hash parse) in
        Int64.equal hash old_hash
      in
      (match entity_read_latest parse_ent with
      | Some existing_parse when file_hash_unchanged existing_parse ->
        (* We know that file is typed (we are in add_checked_file) and the
         * existing record's hash matches, so the file must have been typed
         * before as well. *)
        Either.Left (Option.get (coerce_typed existing_parse))
      | _ -> Either.Right (prepare_update_file size file_key file parse_ent module_name))
  in
  let (size, add_file_maybe) =
    match unchanged_or_fresh_parse with
    | Either.Left unchanged_parse -> (size, Fun.const (unchanged_parse, MSet.empty))
    | Either.Right (size, add_file_maybe) ->
      let exports = serialize exports in
      let (exports_size, write_exports) = prepare_write_exports exports in
      let size =
        size + (4 * header_size) + typed_parse_size + int64_size + exports_size + entity_size
      in
      let write chunk =
        let hash = write_int64 chunk hash in
        let exports = write_exports chunk in
        let resolved_requires = write_entity chunk None in
        let parse = write_typed_parse chunk hash exports resolved_requires in
        let dirty_modules = add_file_maybe chunk (parse :> [ `typed | `untyped ] parse_addr) in
        (parse, dirty_modules)
      in
      (size, write)
  in
  alloc size (fun chunk ->
      let (parse, dirty_modules) = add_file_maybe chunk in
      let ast = write_ast chunk in
      let docblock = write_docblock chunk docblock in
      let aloc_table = write_aloc_table chunk aloc_table in
      let type_sig = write_type_sig chunk sig_bsize write_sig in
      let file_sig = write_file_sig chunk in
      set_ast parse ast;
      set_docblock parse docblock;
      set_aloc_table parse aloc_table;
      set_type_sig parse type_sig;
      set_file_sig parse file_sig;
      dirty_modules
  )

let add_unparsed_file file_key file_opt hash module_name =
  let open Heap in
  let size = (2 * header_size) + untyped_parse_size + int64_size in
  let (size, add_file_maybe) =
    match file_opt with
    | None -> prepare_create_file size file_key module_name
    | Some file ->
      let parse_ent = get_parse file in
      prepare_update_file size file_key file parse_ent module_name
  in
  alloc size (fun chunk ->
      let hash = write_int64 chunk hash in
      let parse = write_untyped_parse chunk hash in
      add_file_maybe chunk (parse :> [ `typed | `untyped ] parse_addr)
  )

(* If this file used to exist, but no longer does, then it was deleted. Record
 * the deletion by clearing parse information. Deletion might also require
 * re-picking module providers, so we return dirty modules. *)
let clear_file file_key =
  let open Heap in
  match FileHeap.get file_key with
  | None -> MSet.empty
  | Some file ->
    let parse_ent = get_parse file in
    (match entity_read_latest parse_ent with
    | None -> MSet.empty
    | Some _ ->
      entity_advance parse_ent None;
      let dirty_modules =
        match get_file_module file with
        | None -> MSet.empty
        | Some _ -> MSet.singleton (Files.eponymous_module file_key)
      in
      let haste_ent = get_haste_info file in
      (match entity_read_latest haste_ent with
      | None -> dirty_modules
      | Some haste_info ->
        entity_advance haste_ent None;
        let m = get_haste_module haste_info in
        MSet.add (haste_modulename m) dirty_modules))

(* Rolling back a transaction requires that we undo changes we made to the file
 * as well as changes we made to modules affected by the file changes. Rolling
 * back changes to all_providers in particular is kind of tricky...
 *
 * If we added a file to a module's all_providers, we remove it. This case is
 * relatively simple.
 *
 * Recall that deletions are deferred. During parsing, we ""logically"" delete by
 * changing the file object itself and marking a module dirty. Later we perform
 * the deletions when re-picking a new provider for each dirty module.
 *
 * For a file module (M), a provider file (F) is logically deleted if its parse
 * entity's (E) latest data is null, meaning the file is deleted:
 *
 *  +---+---+---+   +---+---+---+
 *  | M | * |...|   | E | 0 |...|
 *  +---+---+---+   +---+---+---+
 *        |         ^     ^
 *    providers     |     |
 *        |       parse   +- latest data (null)
 *        v         |
 *        +---+---+---+---+
 *        | F |   | * |...|
 *        +---+---+---+---+
 *
 * For a haste module (M), a provider (F) is logically deleted if its haste info
 * entity's (E) latest data (H) no longer points back to the haste module. In
 * this case, the list continues from the committed haste info (H'):
 *
 *  +---+---+---+   +---+---+---+    +---+---+---+
 *  | M | * |...|   | E | * | * |--->| H'| M | * |---> next provider
 *  +---+---+---+   +---+---+---+    +---+---+---+
 *        |         ^     |
 *    providers     |     +---+
 *        |    haste_info     |     +--> haste module
 *        v         |         v     |    null / does not point to M
 *        +---+---+---+---+   +---+---+
 *        | F |   | * |...|   | H | * |
 *        +---+---+---+---+   +---+---+
 *
 * Both of the above rules depend on the latest/committed state of the parse and
 * haste entities, which also needs to be rolled back. We need to be careful
 * about when the parse and haste entities are rolled back.
 *
 * To deal with rolling back deferred deletions, we first ensure that any
 * deferred deletions are fully performed, which must happen before we roll back
 * parse/haste entities.
 *
 * We then can re-add the file to the all providers list, but this must happen
 * *after* we roll back the parse/haste data. Otherwise, the file will still
 * appear to be logically deleted.
 *
 * In addition to rolling back changes to the file and to dirty modules' all
 * providers list, we also roll back each dirty module's provider entity which
 * stores the committed provider.
 *)
let rollback_file =
  let open Heap in
  let get_haste_module_info info = (get_haste_module info, info) in
  let rollback_file file =
    let parse_ent = get_parse file in
    let (old_file_module, new_file_module) =
      match (entity_read_committed parse_ent, entity_read_latest parse_ent) with
      | (None, None)
      | (Some _, Some _) ->
        (None, None)
      | (None, Some _) -> (None, get_file_module file)
      | (Some _, None) -> (get_file_module file, None)
    in
    let haste_ent = get_haste_info file in
    let (old_haste_module, new_haste_module) =
      if entity_changed haste_ent then
        let old_info = entity_read_committed haste_ent in
        let new_info = entity_read_latest haste_ent in
        (Option.map get_haste_module_info old_info, Option.map get_haste_module new_info)
      else
        (None, None)
    in
    (* Remove new providers and process deferred deletions for old providers
     * before rolling back this file's parse and haste entities. *)
    old_file_module
    |> Option.iter (fun m ->
           entity_rollback (get_file_provider m);
           ignore (get_file_all_providers_exclusive m)
       );
    new_file_module
    |> Option.iter (fun m ->
           entity_rollback (get_file_provider m);
           remove_file_provider_exclusive m file
       );
    old_haste_module
    |> Option.iter (fun (m, _) ->
           entity_rollback (get_haste_provider m);
           ignore (get_haste_all_providers_exclusive m)
       );
    new_haste_module
    |> Option.iter (fun m ->
           entity_rollback (get_haste_provider m);
           remove_haste_provider_exclusive m file
       );
    (* Add back the deleted providers after rolling back the file's parse and
     * haste entities. *)
    entity_rollback parse_ent;
    entity_rollback haste_ent;
    old_file_module |> Option.iter (fun m -> add_file_provider m file);
    old_haste_module |> Option.iter (fun (m, info) -> add_haste_provider m file info)
  in
  fun file_key ->
    match FileHeap.get file_key with
    | None -> ()
    | Some file -> if file_changed file then rollback_file file

let read_file_name file =
  let open Heap in
  get_file_name file |> read_string

let read_file_key file =
  let open Heap in
  let fn = read_file_name file in
  match get_file_kind file with
  | Source_file -> File_key.SourceFile fn
  | Json_file -> File_key.JsonFile fn
  | Resource_file -> File_key.ResourceFile fn
  | Lib_file -> File_key.LibFile fn

let read_file_hash parse =
  let open Heap in
  get_file_hash parse |> read_int64

let read_module_name info =
  let open Heap in
  get_haste_module info |> get_haste_name |> read_string

let read_ast file_key parse =
  let open Heap in
  let deserialize x = Marshal.from_string x 0 in
  get_ast parse |> Option.map (fun addr -> read_ast addr |> deserialize |> decompactify_loc file_key)

let read_ast_unsafe file_key parse =
  match read_ast file_key parse with
  | Some ast -> ast
  | None -> raise (Ast_not_found (File_key.to_string file_key))

let read_docblock parse : Docblock.t option =
  let open Heap in
  let deserialize x = Marshal.from_string x 0 in
  get_docblock parse |> Option.map (fun addr -> read_docblock addr |> deserialize)

let read_docblock_unsafe file_key parse =
  match read_docblock parse with
  | Some docblock -> docblock
  | None -> raise (Docblock_not_found (File_key.to_string file_key))

let read_aloc_table file_key parse =
  let open Heap in
  let init = ALoc.ALocRepresentationDoNotUse.init_table file_key in
  get_aloc_table parse
  |> Option.map (fun addr -> read_aloc_table addr |> Packed_locs.unpack (Some file_key) init)

let read_aloc_table_unsafe file_key parse =
  match read_aloc_table file_key parse with
  | Some aloc_table -> aloc_table
  | None -> raise (ALoc_table_not_found (File_key.to_string file_key))

let read_type_sig parse =
  let open Heap in
  get_type_sig parse |> Option.map (fun addr -> read_type_sig addr Type_sig_bin.read)

let read_type_sig_unsafe file_key parse =
  match read_type_sig parse with
  | Some type_sig -> type_sig
  | None -> raise (Type_sig_not_found (File_key.to_string file_key))

let read_tolerable_file_sig parse : File_sig.With_Loc.tolerable_t option =
  let open Heap in
  let deserialize x = Marshal.from_string x 0 in
  get_file_sig parse |> Option.map (fun addr -> read_file_sig addr |> deserialize)

let read_file_sig parse = Option.map fst (read_tolerable_file_sig parse)

let read_tolerable_file_sig_unsafe file_key parse =
  match read_tolerable_file_sig parse with
  | Some file_sig -> file_sig
  | None -> raise (Requires_not_found (File_key.to_string file_key))

let read_file_sig_unsafe file_key parse = fst (read_tolerable_file_sig_unsafe file_key parse)

let read_exports parse : Exports.t =
  let open Heap in
  let deserialize x = Marshal.from_string x 0 in
  get_exports parse |> read_exports |> deserialize

let read_resolved_requires addr : resolved_requires =
  Marshal.from_string (Heap.read_resolved_requires addr) 0

module Reader_cache : sig
  val get_ast : File_key.t -> (Loc.t, Loc.t) Flow_ast.Program.t option

  val add_ast : File_key.t -> (Loc.t, Loc.t) Flow_ast.Program.t -> unit

  val get_aloc_table : File_key.t -> ALoc.table option

  val add_aloc_table : File_key.t -> ALoc.table -> unit

  val remove_batch : FilenameSet.t -> unit
end = struct
  module ASTCache = SharedMem.LocalCache (struct
    type key = File_key.t

    type value = (Loc.t, Loc.t) Flow_ast.Program.t

    let capacity = 1000
  end)

  module ALocTableCache = SharedMem.LocalCache (struct
    type key = File_key.t

    type value = ALoc.table

    let capacity = 1000
  end)

  let get_ast = ASTCache.get

  let add_ast = ASTCache.add

  let get_aloc_table = ALocTableCache.get

  let add_aloc_table = ALocTableCache.add

  let remove file =
    ASTCache.remove file;
    ALocTableCache.remove file

  let remove_batch files = FilenameSet.iter remove files
end

module Mutator_cache : sig
  val get_aloc_table : File_key.t -> ALoc.table option

  val add_aloc_table : File_key.t -> ALoc.table -> unit

  val clear : unit -> unit
end = struct
  module ALocTableCache = SharedMem.LocalCache (struct
    type key = File_key.t

    type value = ALoc.table

    let capacity = 1000
  end)

  let get_aloc_table = ALocTableCache.get

  let add_aloc_table = ALocTableCache.add

  let clear = ALocTableCache.clear
end

let add_parsed file_key file_opt ~exports hash module_name docblock ast file_sig locs type_sig =
  WorkerCancel.with_no_cancellations (fun () ->
      add_checked_file
        file_key
        file_opt
        hash
        module_name
        docblock
        ast
        locs
        type_sig
        file_sig
        exports
  )

let add_unparsed file_key file_opt hash module_name =
  WorkerCancel.with_no_cancellations (fun () -> add_unparsed_file file_key file_opt hash module_name)

let clear_not_found file_key = WorkerCancel.with_no_cancellations (fun () -> clear_file file_key)

module type READER = sig
  type reader

  val get_provider : reader:reader -> Modulename.t -> file_addr option

  val is_typed_file : reader:reader -> file_addr -> bool

  val get_parse : reader:reader -> file_addr -> [ `typed | `untyped ] parse_addr option

  val get_typed_parse : reader:reader -> file_addr -> [ `typed ] parse_addr option

  val get_haste_info : reader:reader -> file_addr -> haste_info_addr option

  val get_haste_name : reader:reader -> file_addr -> string option

  val has_ast : reader:reader -> File_key.t -> bool

  val get_ast : reader:reader -> File_key.t -> (Loc.t, Loc.t) Flow_ast.Program.t option

  val get_aloc_table : reader:reader -> File_key.t -> ALoc.table option

  val get_docblock : reader:reader -> File_key.t -> Docblock.t option

  val get_exports : reader:reader -> File_key.t -> Exports.t option

  val get_tolerable_file_sig : reader:reader -> File_key.t -> File_sig.With_Loc.tolerable_t option

  val get_file_sig : reader:reader -> File_key.t -> File_sig.With_Loc.t option

  val get_type_sig : reader:reader -> File_key.t -> type_sig option

  val get_file_hash : reader:reader -> File_key.t -> Xx.hash option

  val get_parse_unsafe :
    reader:reader -> File_key.t -> file_addr -> [ `typed | `untyped ] parse_addr

  val get_typed_parse_unsafe : reader:reader -> File_key.t -> file_addr -> [ `typed ] parse_addr

  val get_resolved_requires_unsafe :
    reader:reader -> File_key.t -> [ `typed ] parse_addr -> resolved_requires

  val get_ast_unsafe : reader:reader -> File_key.t -> (Loc.t, Loc.t) Flow_ast.Program.t

  val get_aloc_table_unsafe : reader:reader -> File_key.t -> ALoc.table

  val get_docblock_unsafe : reader:reader -> File_key.t -> Docblock.t

  val get_exports_unsafe : reader:reader -> File_key.t -> Exports.t

  val get_tolerable_file_sig_unsafe : reader:reader -> File_key.t -> File_sig.With_Loc.tolerable_t

  val get_file_sig_unsafe : reader:reader -> File_key.t -> File_sig.With_Loc.t

  val get_type_sig_unsafe : reader:reader -> File_key.t -> type_sig

  val get_file_hash_unsafe : reader:reader -> File_key.t -> Xx.hash

  val loc_of_aloc : reader:reader -> ALoc.t -> Loc.t
end

let loc_of_aloc ~reader ~get_aloc_table_unsafe aloc =
  let table =
    lazy
      (let source =
         match ALoc.source aloc with
         | None -> failwith ""Expected `aloc` to have a `source`""
         | Some x -> x
       in
       get_aloc_table_unsafe ~reader source
      )
  in
  ALoc.to_loc table aloc

(* Init/recheck will use Mutator_reader to read the shared memory *)
module Mutator_reader = struct
  type reader = Mutator_state_reader.t

  let read ~reader:_ addr = Heap.entity_read_latest addr

  let read_old ~reader:_ addr = Heap.entity_read_committed addr

  let get_provider ~reader m =
    let* provider = get_provider_ent m in
    read ~reader provider

  let is_typed_file ~reader file =
    match read ~reader (Heap.get_parse file) with
    | Some parse -> Heap.is_typed parse
    | None -> false

  let get_parse ~reader file = read ~reader (Heap.get_parse file)

  let get_typed_parse ~reader file =
    let* parse = get_parse ~reader file in
    Heap.coerce_typed parse

  let get_haste_info ~reader file = read ~reader (Heap.get_haste_info file)

  let get_haste_name ~reader file =
    let* info = get_haste_info ~reader file in
    Some (read_module_name info)

  let get_old_parse ~reader file = read_old ~reader (Heap.get_parse file)

  let get_old_typed_parse ~reader file =
    let* parse = get_old_parse ~reader file in
    Heap.coerce_typed parse

  let get_old_haste_info ~reader file = read_old ~reader (Heap.get_haste_info file)

  let has_ast ~reader file =
    let parse_opt =
      let* file_addr = get_file_addr file in
      get_typed_parse ~reader file_addr
    in
    match parse_opt with
    | None -> false
    | Some parse -> Heap.get_ast parse |> Option.is_some

  let get_ast ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_ast file parse

  let get_aloc_table ~reader file =
    match Mutator_cache.get_aloc_table file with
    | Some _ as cached -> cached
    | None ->
      let* addr = get_file_addr file in
      let* parse = get_typed_parse ~reader addr in
      let* aloc_table = read_aloc_table file parse in
      Mutator_cache.add_aloc_table file aloc_table;
      Some aloc_table

  let get_docblock ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_docblock parse

  let get_exports ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    Some (read_exports parse)

  let get_old_exports ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_old_typed_parse ~reader addr in
    Some (read_exports parse)

  let get_tolerable_file_sig ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_tolerable_file_sig parse

  let get_file_sig ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_file_sig parse

  let get_type_sig ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_type_sig parse

  let get_file_hash ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_parse ~reader addr in
    Some (read_file_hash parse)

  let get_old_file_hash ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_old_parse ~reader addr in
    Some (read_file_hash parse)

  let get_parse_unsafe ~reader file addr =
    match get_parse ~reader addr with
    | Some parse -> parse
    | None -> raise (File_not_parsed (File_key.to_string file))

  let get_typed_parse_unsafe ~reader file addr =
    let parse = get_parse_unsafe ~reader file addr in
    match Heap.coerce_typed parse with
    | Some parse -> parse
    | None -> raise (File_not_typed (File_key.to_string file))

  let get_resolved_requires_unsafe ~reader file parse =
    let resolved_requires = Heap.get_resolved_requires parse in
    match read ~reader resolved_requires with
    | Some resolved_requires -> read_resolved_requires resolved_requires
    | None -> raise (Resolved_requires_not_found (File_key.to_string file))

  let get_ast_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_ast_unsafe file parse

  let get_aloc_table_unsafe ~reader file =
    match Mutator_cache.get_aloc_table file with
    | Some aloc_table -> aloc_table
    | None ->
      let addr = get_file_addr_unsafe file in
      let parse = get_typed_parse_unsafe ~reader file addr in
      let aloc_table = read_aloc_table_unsafe file parse in
      Mutator_cache.add_aloc_table file aloc_table;
      aloc_table

  let get_docblock_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_docblock_unsafe file parse

  let get_exports_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_exports parse

  let get_tolerable_file_sig_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_tolerable_file_sig_unsafe file parse

  let get_file_sig_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_file_sig_unsafe file parse

  let get_type_sig_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_type_sig_unsafe file parse

  let get_file_hash_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_parse_unsafe ~reader file addr in
    read_file_hash parse

  let loc_of_aloc = loc_of_aloc ~get_aloc_table_unsafe
end

(* For use by a worker process *)
type worker_mutator = {
  add_parsed:
    File_key.t ->
    file_addr option ->
    exports:Exports.t ->
    Xx.hash ->
    string option ->
    Docblock.t ->
    (Loc.t, Loc.t) Flow_ast.Program.t ->
    File_sig.With_Loc.tolerable_t ->
    locs_tbl ->
    type_sig ->
    MSet.t;
  add_unparsed: File_key.t -> file_addr option -> Xx.hash -> string option -> MSet.t;
  clear_not_found: File_key.t -> MSet.t;
}

(* Parsing is pretty easy - there is no before state and no chance of rollbacks, so we don't
 * need to worry about a transaction *)
module Parse_mutator : sig
  val create : unit -> worker_mutator
end = struct
  let clear_not_found = Fun.const MSet.empty

  let create () = { add_parsed; add_unparsed; clear_not_found }
end

(* Reparsing is more complicated than parsing, since we need to worry about transactions.
 *
 * Modified files will be advanced based on the current transaction. Advancing a
 * file ensures that the previous committed data is still available. Committing
 * the transaction will publish the new data to all readers by bumping the
 * global transaction counter, see Mutator_state_reader.
 *
 * If the transaction is rolled back, we will revert changed entities. Ideally,
 * we would not need to roll back / undo any writes when a transaction rolls
 * back, assuming the next recheck is guaranteed to contain a superset of this
 * recheck's files.
 *
 * This assumption does not hold for priority rechecks, where we cancel a
 * recheck, schedule a minimal recheck to unblock the IDE request, then
 * re-start the original recheck.
 *)
module Reparse_mutator : sig
  type master_mutator (* Used by the master process *)

  val create : Transaction.t -> FilenameSet.t -> master_mutator * worker_mutator

  val record_unchanged : master_mutator -> FilenameSet.t -> unit

  val record_not_found : master_mutator -> FilenameSet.t -> unit
end = struct
  type master_mutator = unit

  (* We can conservatively invalidate caches for all `files`, but we can be a
   * bit more precise by only invalidating changed files. If parsing reveals
   * unchanged files, we remove them from this set. *)
  let changed_files = ref FilenameSet.empty

  (* When the transaction commits, we will remove these from the shared hash
   * table, so sharedmem GC can collect them. *)
  let not_found_files = ref FilenameSet.empty

  let rollback_changed () = FilenameSet.iter rollback_file !changed_files

  let reset_refs () =
    changed_files := FilenameSet.empty;
    not_found_files := FilenameSet.empty

  let create transaction files =
    changed_files := files;

    let commit () =
      WorkerCancel.with_no_cancellations (fun () ->
          Hh_logger.debug ""Committing parsing heaps"";
          Mutator_cache.clear ();
          Reader_cache.remove_batch !changed_files;
          FileHeap.remove_batch !not_found_files;
          reset_refs ()
      );
      Lwt.return_unit
    in

    let rollback () =
      WorkerCancel.with_no_cancellations (fun () ->
          Hh_logger.debug ""Rolling back parsing heaps"";
          Mutator_cache.clear ();
          rollback_changed ();
          reset_refs ()
      );
      Lwt.return_unit
    in

    Transaction.add ~singleton:""Reparse"" ~commit ~rollback transaction;

    ((), { add_parsed; add_unparsed; clear_not_found })

  let record_unchanged () unchanged = changed_files := FilenameSet.diff !changed_files unchanged

  let record_not_found () not_found = not_found_files := not_found
end

module Commit_modules_mutator = struct
  type t = unit

  let no_providers = ref MSet.empty

  let reset_refs () = no_providers := MSet.empty

  let remove_module = function
    | Modulename.String name -> HasteModuleHeap.remove name
    | Modulename.Filename file_key -> FileModuleHeap.remove file_key

  let commit () =
    WorkerCancel.with_no_cancellations (fun () ->
        MSet.iter remove_module !no_providers;
        reset_refs ()
    );
    Lwt.return_unit

  let rollback () =
    reset_refs ();
    Lwt.return_unit

  let create transaction = Transaction.add ~singleton:""Commit_modules"" ~commit ~rollback transaction

  let record_no_providers () modules = no_providers := modules
end

module Resolved_requires_mutator = struct
  type t = unit

  let dirty_files = ref FilenameSet.empty

  let rollback_resolved_requires file_key =
    let open SharedMem.NewAPI in
    let entity =
      let* file = get_file_addr file_key in
      let* parse = entity_read_latest (get_parse file) in
      let* parse = coerce_typed parse in
      Some (get_resolved_requires parse)
    in
    Option.iter entity_rollback entity

  let commit () =
    dirty_files := FilenameSet.empty;
    Lwt.return_unit

  let rollback () =
    WorkerCancel.with_no_cancellations (fun () ->
        FilenameSet.iter rollback_resolved_requires !dirty_files
    );
    dirty_files := FilenameSet.empty;
    Lwt.return_unit

  let create transaction files =
    dirty_files := files;
    Transaction.add ~commit ~rollback transaction

  (* To detect whether resolved requires have changed, we load the old resolved
   * requires for this file and compare hashes. There are two interesting cases:
   *
   * 1. If this file is unchanged, then we advance the resolved requires entity
   *    of the latest parse. The ""old"" resolved requires is the latest version
   *    before updating.
   *
   * 2. If the file is changed, then the ""old"" resolved requires is the latest
   *    version of the *committed* parse, but we advance the resolved requires
   *    entity of the *latest* parse, as with case (1).
   *
   * If the hashes are unchanged, then for case (1) we can do nothing, but for
   * case (2) we need to advance the resolved requires entity of the latest
   * parse, because fresh parses start out without resolved requires.
   *)
  let add_resolved_requires () file parse resolved_requires =
    let module Heap = SharedMem.NewAPI in
    let old_resolved_requires =
      let* old_parse = Heap.entity_read_committed (Heap.get_parse file) in
      let* old_parse = Heap.coerce_typed old_parse in
      let old_ent = Heap.get_resolved_requires old_parse in
      match Heap.entity_read_latest old_ent with
      | Some addr ->
        let { hash; _ } = read_resolved_requires addr in
        Some (old_ent, hash, addr)
      | None -> None
    in
    let open Heap in
    let ent = get_resolved_requires parse in
    match old_resolved_requires with
    | Some (old_ent, hash, addr) when Int64.equal hash resolved_requires.hash ->
      if ent == old_ent then
        ()
      else
        entity_advance ent (Some addr);
      false
    | _ ->
      let resolved_requires = Marshal.to_string resolved_requires [] in
      let (size, write) = prepare_write_resolved_requires resolved_requires in
      alloc (header_size + size) (fun chunk ->
          let resolved_requires = write chunk in
          entity_advance ent (Some resolved_requires)
      );
      true
end

(* This uses `entity_read_committed` and can be used by code outside of a
 * init/recheck, like commands, to see a consistent snapshot of type state even
 * in the middle of a recheck. *)
module Reader = struct
  type reader = State_reader.t

  let read ~reader:_ addr = Heap.entity_read_latest addr

  let get_provider ~reader m =
    let* provider = get_provider_ent m in
    read ~reader provider

  let is_typed_file ~reader file =
    match read ~reader (Heap.get_parse file) with
    | Some parse -> Heap.is_typed parse
    | None -> false

  let get_parse ~reader file = read ~reader (Heap.get_parse file)

  let get_typed_parse ~reader file =
    let* parse = get_parse ~reader file in
    Heap.coerce_typed parse

  let get_haste_info ~reader file = read ~reader (Heap.get_haste_info file)

  let get_haste_name ~reader file =
    let* info = get_haste_info ~reader file in
    Some (read_module_name info)

  let has_ast ~reader file =
    let parse_opt =
      let* file_addr = get_file_addr file in
      get_typed_parse ~reader file_addr
    in
    match parse_opt with
    | None -> false
    | Some parse -> Heap.get_ast parse |> Option.is_some

  let get_ast ~reader file =
    match Reader_cache.get_ast file with
    | Some _ as cached -> cached
    | None ->
      let* addr = get_file_addr file in
      let* parse = get_typed_parse ~reader addr in
      let* ast = read_ast file parse in
      Reader_cache.add_ast file ast;
      Some ast

  let get_aloc_table ~reader file =
    match Reader_cache.get_aloc_table file with
    | Some _ as cached -> cached
    | None ->
      let* addr = get_file_addr file in
      let* parse = get_typed_parse ~reader addr in
      let* aloc_table = read_aloc_table file parse in
      Reader_cache.add_aloc_table file aloc_table;
      Some aloc_table

  let get_docblock ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_docblock parse

  let get_exports ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    Some (read_exports parse)

  let get_tolerable_file_sig ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_tolerable_file_sig parse

  let get_file_sig ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_file_sig parse

  let get_type_sig ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_typed_parse ~reader addr in
    read_type_sig parse

  let get_file_hash ~reader file =
    let* addr = get_file_addr file in
    let* parse = get_parse ~reader addr in
    Some (read_file_hash parse)

  let get_parse_unsafe ~reader file addr =
    match get_parse ~reader addr with
    | Some parse -> parse
    | None -> raise (File_not_parsed (File_key.to_string file))

  let get_typed_parse_unsafe ~reader file addr =
    let parse = get_parse_unsafe ~reader file addr in
    match Heap.coerce_typed parse with
    | Some parse -> parse
    | None -> raise (File_not_typed (File_key.to_string file))

  let get_resolved_requires_unsafe ~reader file parse =
    let resolved_requires = Heap.get_resolved_requires parse in
    match read ~reader resolved_requires with
    | Some resolved_requires -> read_resolved_requires resolved_requires
    | None -> raise (Resolved_requires_not_found (File_key.to_string file))

  let get_ast_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_ast_unsafe file parse

  let get_aloc_table_unsafe ~reader file =
    match Reader_cache.get_aloc_table file with
    | Some aloc_table -> aloc_table
    | None ->
      let addr = get_file_addr_unsafe file in
      let parse = get_typed_parse_unsafe ~reader file addr in
      let aloc_table = read_aloc_table_unsafe file parse in
      Reader_cache.add_aloc_table file aloc_table;
      aloc_table

  let get_docblock_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_docblock_unsafe file parse

  let get_exports_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_exports parse

  let get_tolerable_file_sig_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_tolerable_file_sig_unsafe file parse

  let get_file_sig_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_file_sig_unsafe file parse

  let get_type_sig_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_typed_parse_unsafe ~reader file addr in
    read_type_sig_unsafe file parse

  let get_file_hash_unsafe ~reader file =
    let addr = get_file_addr_unsafe file in
    let parse = get_parse_unsafe ~reader file addr in
    read_file_hash parse

  let loc_of_aloc = loc_of_aloc ~get_aloc_table_unsafe
end

(* Reader_dispatcher is used by code which may or may not be running inside an init/recheck *)
module Reader_dispatcher : READER with type reader = Abstract_state_reader.t = struct
  type reader = Abstract_state_reader.t

  open Abstract_state_reader

  let get_provider ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_provider ~reader
    | State_reader reader -> Reader.get_provider ~reader

  let is_typed_file ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.is_typed_file ~reader
    | State_reader reader -> Reader.is_typed_file ~reader

  let get_parse ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_parse ~reader
    | State_reader reader -> Reader.get_parse ~reader

  let get_typed_parse ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_typed_parse ~reader
    | State_reader reader -> Reader.get_typed_parse ~reader

  let get_haste_info ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_haste_info ~reader
    | State_reader reader -> Reader.get_haste_info ~reader

  let get_haste_name ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_haste_name ~reader
    | State_reader reader -> Reader.get_haste_name ~reader

  let has_ast ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.has_ast ~reader
    | State_reader reader -> Reader.has_ast ~reader

  let get_ast ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_ast ~reader
    | State_reader reader -> Reader.get_ast ~reader

  let get_aloc_table ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_aloc_table ~reader
    | State_reader reader -> Reader.get_aloc_table ~reader

  let get_docblock ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_docblock ~reader
    | State_reader reader -> Reader.get_docblock ~reader

  let get_exports ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_exports ~reader
    | State_reader reader -> Reader.get_exports ~reader

  let get_tolerable_file_sig ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_tolerable_file_sig ~reader
    | State_reader reader -> Reader.get_tolerable_file_sig ~reader

  let get_file_sig ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_file_sig ~reader
    | State_reader reader -> Reader.get_file_sig ~reader

  let get_type_sig ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_type_sig ~reader
    | State_reader reader -> Reader.get_type_sig ~reader

  let get_file_hash ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_file_hash ~reader
    | State_reader reader -> Reader.get_file_hash ~reader

  let get_parse_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_parse_unsafe ~reader
    | State_reader reader -> Reader.get_parse_unsafe ~reader

  let get_typed_parse_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_typed_parse_unsafe ~reader
    | State_reader reader -> Reader.get_typed_parse_unsafe ~reader

  let get_resolved_requires_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_resolved_requires_unsafe ~reader
    | State_reader reader -> Reader.get_resolved_requires_unsafe ~reader

  let get_ast_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_ast_unsafe ~reader
    | State_reader reader -> Reader.get_ast_unsafe ~reader

  let get_aloc_table_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_aloc_table_unsafe ~reader
    | State_reader reader -> Reader.get_aloc_table_unsafe ~reader

  let get_docblock_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_docblock_unsafe ~reader
    | State_reader reader -> Reader.get_docblock_unsafe ~reader

  let get_exports_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_exports_unsafe ~reader
    | State_reader reader -> Reader.get_exports_unsafe ~reader

  let get_tolerable_file_sig_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_tolerable_file_sig_unsafe ~reader
    | State_reader reader -> Reader.get_tolerable_file_sig_unsafe ~reader

  let get_file_sig_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_file_sig_unsafe ~reader
    | State_reader reader -> Reader.get_file_sig_unsafe ~reader

  let get_type_sig_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_type_sig_unsafe ~reader
    | State_reader reader -> Reader.get_type_sig_unsafe ~reader

  let get_file_hash_unsafe ~reader =
    match reader with
    | Mutator_state_reader reader -> Mutator_reader.get_file_hash_unsafe ~reader
    | State_reader reader -> Reader.get_file_hash_unsafe ~reader

  let loc_of_aloc = loc_of_aloc ~get_aloc_table_unsafe
end

module From_saved_state = struct
  let add_parsed file_key hash module_name exports resolved_requires =
    let (file_kind, file_name) = file_kind_and_name file_key in
    let exports = Marshal.to_string exports [] in
    let resolved_requires = Marshal.to_string resolved_requires [] in
    let open Heap in
    let (exports_size, write_exports) = prepare_write_exports exports in
    let (resolved_requires_size, write_resolved_requires) =
      prepare_write_resolved_requires resolved_requires
    in
    let size =
      (9 * header_size)
      + (3 * entity_size)
      + string_size file_name
      + typed_parse_size
      + file_size
      + int64_size
      + exports_size
      + resolved_requires_size
    in
    let (size, add_file_module_maybe) = prepare_add_file_module_maybe size file_key in
    let (size, write_new_haste_info_maybe) =
      prepare_write_new_haste_info_maybe size None module_name
    in
    alloc size (fun chunk ->
        let file_name = write_string chunk file_name in
        let file_module = add_file_module_maybe chunk in
        let hash = write_int64 chunk hash in
        let haste_info = write_new_haste_info_maybe chunk in
        let haste_ent = write_entity chunk haste_info in
        let exports = write_exports chunk in
        let resolved_requires = write_resolved_requires chunk in
        let resolved_requires_ent = write_entity chunk (Some resolved_requires) in
        let parse = write_typed_parse chunk hash exports resolved_requires_ent in
        let parse_ent = write_entity chunk (Some (parse :> [ `typed | `untyped ] parse_addr)) in
        let file = write_file chunk file_kind file_name parse_ent haste_ent file_module in
        assert (file = FileHeap.add file_key file);
        calc_dirty_modules file_key file haste_ent file_module
    )

  let add_unparsed file_key = add_unparsed file_key None
end

let iter_resolved_requires f =
  SharedMem.NewAPI.iter_resolved_requires (fun file resolved_requires ->
      f file (read_resolved_requires resolved_requires)
  )
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* The Flow server monitor will start one or more Flow servers over its lifetime. This module is how
 * the monitor interacts with the server. The basic idea is that there is a long-lived stream of
 * requests, which outlives servers, and a ServerInstance.t that wraps a connection to the server.
 *
 * When a server is alive, the long lived stream of requests gets written to the server and stored
 * in a RequestMap. When a response is received, we look up the client in the RequestMap and forward
 * the response.
 *
 * When a server dies, the monitor decides whether or not to die with the server. If it doesn't die,
 * it creates a new server. Any request that was written to the old server but never received a
 * response will be written again to the new server
 *)

let spf = Printf.sprintf

module Logger = FlowServerMonitorLogger

type command =
  | Write_ephemeral_request of {
      request: ServerProt.Request.command_with_context;
      client: EphemeralConnection.t;
    }
  | Write_persistent_request of {
      client_id: LspProt.client_id;
      request: LspProt.request_with_metadata;
    }
  | Notify_new_persistent_connection of {
      client_id: LspProt.client_id;
      lsp_init_params: Lsp.Initialize.params;
    }
  | Notify_dead_persistent_connection of { client_id: LspProt.client_id }
  | Notify_file_changes

(* A wrapper for Stdlib.exit which gives other threads a second to handle their business
 * before the monitor exits *)
let exiting = ref false

let exit ?error ~msg exit_status =
  if !exiting then
    (* We're already exiting, so there's nothing to do. But no one expects `exit` to return, so
     * let's just wait forever *)
    let (waiter, _) = Lwt.wait () in
    waiter
  else (
    exiting := true;
    Logger.info ""Monitor is exiting code %d (%s)"" (Exit.error_code exit_status) msg;
    Logger.info ""Broadcasting to threads and waiting 1 second for them to exit"";
    Lwt_condition.broadcast ExitSignal.signal (exit_status, msg);

    (* Protect this thread from getting canceled *)
    Lwt.protected
      (let%lwt () = Lwt_unix.sleep 1.0 in
       FlowEventLogger.exit ?error (Some msg) (Exit.to_string exit_status);
       Stdlib.exit (Exit.error_code exit_status)
      )
  )

type stop_reason =
  | Stopped  (** `flow stop` *)
  | Autostopped  (** no more active connections *)
  | Legacy_client  (** very old client tried to connect *)

let stop reason =
  let (msg, status) =
    match reason with
    | Stopped -> (""Killed by `flow stop`. Exiting."", Exit.No_error)
    | Autostopped -> (""Autostop"", Exit.Autostop)
    | Legacy_client -> (""Killed by legacy client. Exiting."", Exit.Build_id_mismatch)
  in
  exit ~msg status

(* Exit after 7 days of no requests *)
module Doomsday : sig
  val start_clock : unit -> unit Lwt.t

  val postpone : unit -> unit
end = struct
  let seven_days_in_secs = 3600. *. 24. *. 7.

  let time_in_seven_days () = Unix.time () +. seven_days_in_secs

  let doomsday_time = ref (time_in_seven_days ())

  let postpone () = doomsday_time := time_in_seven_days ()

  let rec start_clock () =
    let time_til_doomsday = !doomsday_time -. Unix.time () in
    if time_til_doomsday <= 0. then
      exit ~msg:""Exiting server. Last used >7 days ago"" Exit.Unused_server
    else
      let%lwt () = Lwt_unix.sleep time_til_doomsday in
      start_clock ()
end

(* The long-lived stream of requests in the monitor that have arrived from client *)
(* This is unbounded, because otherwise lspCommand might deadlock. *)
let (command_stream, push_to_command_stream) = Lwt_stream.create ()

(* ServerInstance.t is an individual Flow server instance. The code inside this module handles
 * interacting with a Flow server instance *)
module ServerInstance : sig
  type t

  val start : FlowServerMonitorOptions.t -> ServerStatus.restart_reason option -> t Lwt.t

  val cleanup : t -> unit Lwt.t

  val pid_of : t -> int
end = struct
  type t = {
    pid: int;
    watcher: FileWatcher.watcher;
    connection: ServerConnection.t;
    command_loop: unit Lwt.t;
    file_watcher_loop: unit Lwt.t;
    on_exit_thread: unit Lwt.t;
    file_watcher_exit_thread: unit Lwt.t;
  }

  let handle_response ~msg ~connection:_ =
    match msg with
    | MonitorProt.Response (request_id, response) ->
      Logger.debug ""Read a response to request '%s' from the server!"" request_id;
      let%lwt request = RequestMap.remove ~request_id in
      (match request with
      | None -> Logger.error ""Failed to look up request '%s'"" request_id
      | Some (_, client) ->
        let msg = MonitorProt.Data response in
        if not (EphemeralConnection.write_and_close ~msg client) then
          Logger.debug ""Client for request '%s' is dead. Throwing away response"" request_id);
      Lwt.return_unit
    | MonitorProt.RequestFailed (request_id, exn_str) ->
      Logger.error ""Server threw exception when processing '%s': %s"" request_id exn_str;
      let%lwt request = RequestMap.remove ~request_id in
      (match request with
      | None -> Logger.error ""Failed to look up request '%s'"" request_id
      | Some (_, client) ->
        let msg = MonitorProt.ServerException exn_str in
        if not (EphemeralConnection.write_and_close ~msg client) then
          Logger.debug ""Client for request '%s' is dead. Throwing away response"" request_id);
      Lwt.return_unit
    | MonitorProt.StatusUpdate status ->
      StatusStream.update ~status;
      Lwt.return_unit
    | MonitorProt.PersistentConnectionResponse (client_id, response) ->
      (match PersistentConnectionMap.get ~client_id with
      | None -> Logger.error ""Failed to look up persistent client #%d"" client_id
      | Some connection ->
        if not (PersistentConnection.write ~msg:response connection) then
          Logger.debug ""Persistent client #%d is dead. Throwing away response"" client_id);
      Lwt.return_unit

  module CommandLoop = LwtLoop.Make (struct
    type acc = FileWatcher.watcher * ServerConnection.t

    (* Writes a message to the out-stream of the monitor, to be eventually *)
    (* picked up by the server. *)
    let send_request ~msg conn =
      if not (ServerConnection.write ~msg conn) then
        (* Another Lwt thread has already closed ServerConnection. We trust
           that it will properly handle the server dying, so we can just drop
           it here. *)
        Logger.debug ""Server connection is closed. Throwing away request""

    (* In order to try and avoid races between the file system and a command (like `flow status`),
     * we check for file system notification before sending a request to the server *)
    let send_file_watcher_notification watcher conn =
      let%lwt (files, metadata, initial) = watcher#get_and_clear_changed_files in
      if not (SSet.is_empty files) then (
        let count = SSet.cardinal files in
        Logger.info
          ""File watcher reported %d file%s changed""
          count
          ( if count = 1 then
            """"
          else
            ""s""
          );
        send_request ~msg:(MonitorProt.FileWatcherNotification { files; metadata; initial }) conn
      );
      Lwt.return_unit

    let main (watcher, conn) =
      let%lwt command = Lwt_stream.next command_stream in
      let%lwt () =
        match command with
        | Write_ephemeral_request { request; client } ->
          Doomsday.postpone ();
          if not (EphemeralConnection.is_closed client) then (
            let%lwt () = send_file_watcher_notification watcher conn in
            let%lwt request_id = RequestMap.add ~request ~client in
            Logger.debug ""Writing '%s' to the server connection"" request_id;
            send_request ~msg:(MonitorProt.Request (request_id, request)) conn;
            Lwt.return_unit
          ) else (
            Logger.debug ""Skipping request from a dead ephemeral connection"";
            Lwt.return_unit
          )
        | Write_persistent_request { client_id; request } ->
          Doomsday.postpone ();
          let%lwt () = send_file_watcher_notification watcher conn in
          let msg = MonitorProt.PersistentConnectionRequest (client_id, request) in
          send_request ~msg conn;
          Lwt.return_unit
        | Notify_new_persistent_connection { client_id; lsp_init_params } ->
          let msg = MonitorProt.NewPersistentConnection (client_id, lsp_init_params) in
          send_request ~msg conn;
          Lwt.return_unit
        | Notify_dead_persistent_connection { client_id } ->
          let () = PersistentConnectionMap.remove ~client_id in
          let msg = MonitorProt.DeadPersistentConnection client_id in
          send_request ~msg conn;
          Lwt.return_unit
        | Notify_file_changes -> send_file_watcher_notification watcher conn
      in
      Lwt.return (watcher, conn)

    let catch _ exn =
      Logger.fatal ~exn:(Exception.to_exn exn) ""Uncaught exception in Server command loop"";
      Exception.reraise exn
  end)

  module FileWatcherLoop = LwtLoop.Make (struct
    type acc = FileWatcher.watcher

    (* Poll for file changes every second *)
    let main (watcher : acc) =
      let%lwt () = watcher#wait_for_changed_files in
      push_to_command_stream (Some Notify_file_changes);
      Lwt.return watcher

    let catch (_ : acc) exn =
      Logger.fatal ~exn:(Exception.to_exn exn) ""Uncaught exception in Server file watcher loop"";
      Exception.reraise exn
  end)

  (* The monitor is exiting. Let's try and shut down the server gracefully *)
  let cleanup_on_exit ~exit_status ~exit_msg ~connection ~pid =
    let () =
      let msg = MonitorProt.(PleaseDie (MonitorExiting (exit_status, exit_msg))) in
      if not (ServerConnection.write ~msg connection) then
        (* Connection to the server has already closed. The server is likely already dead *)
        ()
    in
    (* The monitor waits 1 second before exiting. So let's give the server .75 seconds to shutdown
     * gracefully. *)
    try%lwt
      let%lwt server_status =
        Lwt.pick
          [
            (let%lwt (_, status) = LwtSysUtils.blocking_waitpid pid in
             Lwt.return (Some status)
            );
            (let%lwt () = Lwt_unix.sleep 0.75 in
             Lwt.return None
            );
          ]
      in
      let%lwt () = ServerConnection.close_immediately connection in
      let pretty_pid = Sys_utils.pid_of_handle pid in
      let still_alive =
        match server_status with
        | Some (Unix.WEXITED exit_status) ->
          let exit_type =
            try Some (Exit.error_type exit_status) with
            | Not_found -> None
          in
          begin
            if exit_type = Some Exit.Killed_by_monitor then
              Logger.info ""Successfully killed the server process""
            else
              let exit_status_string =
                Base.Option.value_map ~default:""Invalid_exit_code"" ~f:Exit.to_string exit_type
              in
              Logger.error
                ""Tried to kill the server process (%d), which exited with the wrong exit code: %s""
                pretty_pid
                exit_status_string
          end;
          false
        | Some (Unix.WSIGNALED signal) ->
          Logger.error
            ""Tried to kill the server process (%d), but for some reason it was killed with %s signal""
            pretty_pid
            (PrintSignal.string_of_signal signal);
          false
        | Some (Unix.WSTOPPED signal) ->
          Logger.error
            ""Tried to kill the server process (%d), but for some reason it was stopped with %s signal""
            pretty_pid
            (PrintSignal.string_of_signal signal);
          true
        | None ->
          Logger.error ""Tried to kill the server process (%d), but it didn't die"" pretty_pid;
          true
      in
      ( if still_alive then
        try Unix.kill pid Sys.sigkill with
        | Unix.Unix_error (Unix.ESRCH, _, _) ->
          Logger.info ""Server process (%d) no longer exists"" pretty_pid
      );

      Lwt.return_unit
    with
    | Unix.Unix_error (Unix.ECHILD, _, _) ->
      Logger.info ""Server process has already exited. No need to kill it"";
      Lwt.return_unit

  let cleanup t =
    Lwt.cancel t.command_loop;
    Lwt.cancel t.file_watcher_loop;
    Lwt.cancel t.file_watcher_exit_thread;
    Lwt.cancel t.on_exit_thread;

    (* Lwt.join will run these threads in parallel and only return when EVERY thread has returned
     * or failed *)
    Lwt.join [t.watcher#stop; ServerConnection.close_immediately t.connection]

  let handle_file_watcher_exit ?error ?msg ?(code = Exit.Dfind_died) watcher =
    (* TODO (glevi) - We probably don't need to make the monitor exit when the file watcher dies.
     * We could probably just restart it. For dfind, we'd also need to start a new server, but for
     * watchman we probably could just start a new watchman daemon and use the clockspec *)
    let msg = Base.Option.value ~default:(spf ""File watcher (%s) died"" watcher#name) msg in
    exit ?error ~msg code

  (** `close_if_open fd` closes the `fd` file descriptor, ignoring errors if it's already closed.

      So it's actually important that we close the Lwt_unix.file_descr and not just the
      underlying Unix.file_descr. Why?

      1. Unix.file_descr is just an int
      2. File descriptors can be reused after they are closed
      3. You might get a reaaaally weird bug where your seemly closed Lwt_unix.file_descr
         suddenly starts getting data again. This totally happened to Gabe on halloween and it
         totally freaked him out.

      Lwt_unix.file_descr, on the otherhand, carries around some state, like whether it is open
      or closed. So a closed Lwt_unix.file_descr won't resurrect.
   *)
  let close_if_open (fd : Lwt_unix.file_descr) =
    try Lwt_unix.close fd (* If it's already closed, we'll get EBADF *) with
    | Unix.Unix_error (Unix.EBADF, _, _) -> Lwt.return_unit

  let server_num = ref 0

  (* Spawn a brand new Flow server *)
  let start monitor_options restart_reason =
    Logger.info ""Creating a new Flow server"";
    let {
      FlowServerMonitorOptions.shared_mem_config;
      server_options;
      server_log_file = log_file;
      argv;
      file_watcher;
      file_watcher_timeout;
      file_watcher_mergebase_with = mergebase_with;
      _;
    } =
      monitor_options
    in
    let%lwt () = StatusStream.reset file_watcher restart_reason in
    let watcher =
      match file_watcher with
      | FlowServerMonitorOptions.NoFileWatcher -> new FileWatcher.dummy
      | FlowServerMonitorOptions.DFind -> new FileWatcher.dfind monitor_options
      | FlowServerMonitorOptions.Watchman watchman_options ->
        new FileWatcher.watchman ~mergebase_with server_options watchman_options
    in
    Logger.debug ""Initializing file watcher (%s)"" watcher#name;
    watcher#start_init;
    let file_watcher_pid = watcher#getpid in
    Base.Option.iter file_watcher_pid ~f:(fun pid ->
        Logger.info ""Spawned file watcher (pid=%d)"" (Sys_utils.pid_of_handle pid)
    );
    let handle =
      let init_id = Random_id.short_string () in
      Server.daemonize ~init_id ~log_file ~shared_mem_config ~argv ~file_watcher_pid server_options
    in
    let (ic, oc) = handle.Daemon.channels in
    (* we explicitly want to let Lwt determine the blocking mode here.
       the fd's created by Server.daemonize are (currently) pipes
       from Unix.pipe. Unix pipes are non-blocking, but Windows pipes
       are (currently?) blocking. we could explicitly use blocking mode
       on Windows, but it's too many implicit assumptions. *)
    let blocking = None in
    let in_fd =
      ic |> Daemon.descr_of_in_channel |> Lwt_unix.of_unix_file_descr ?blocking ~set_flags:true
    in
    let out_fd =
      oc |> Daemon.descr_of_out_channel |> Lwt_unix.of_unix_file_descr ?blocking ~set_flags:true
    in
    let close () =
      (* Lwt.join will run these threads in parallel and only finish when EVERY thread has finished
       * or failed *)
      Lwt.join [close_if_open in_fd; close_if_open out_fd]
    in
    incr server_num;
    let name = spf ""server #%d"" !server_num in
    let%lwt (start, connection) =
      ServerConnection.create ~name ~in_fd ~out_fd ~close ~on_read:handle_response
    in
    start ();

    let pid = handle.Daemon.pid in

    Logger.info ""Spawned %s (pid=%d)"" name (Sys_utils.pid_of_handle pid);

    (* Close the connection to the server when we're about to exit *)
    let on_exit_thread =
      try%lwt
        let%lwt (exit_status, exit_msg) = Lwt_condition.wait ExitSignal.signal in
        cleanup_on_exit ~exit_status ~exit_msg ~connection ~pid
      with
      | Lwt.Canceled -> Lwt.return_unit
      | exn ->
        let exn = Exception.wrap exn in
        Logger.fatal ~exn:(Exception.to_exn exn) ""Uncaught exception in on_exit_thread"";
        Exception.reraise exn
    in
    (* This may block for quite awhile. No messages will be sent to the server process until the
     * file watcher is up and running *)
    let%lwt () =
      match%lwt watcher#wait_for_init ~timeout:file_watcher_timeout with
      | Ok x -> Lwt.return x
      | Error msg ->
        Logger.fatal ""%s"" msg;
        handle_file_watcher_exit ~msg watcher
    in
    Logger.debug ""File watcher (%s) ready!"" watcher#name;
    let file_watcher_exit_thread =
      match%lwt watcher#waitpid with
      | exception (Lwt.Canceled as exn) ->
        let exn = Exception.wrap exn in
        Exception.reraise exn
      | exception e ->
        let exn = Exception.wrap e in
        Logger.error ~exn:(Exception.to_exn exn) ""Uncaught exception in watcher#waitpid"";
        let error =
          (Exception.get_ctor_string exn, Utils.Callstack (Exception.get_backtrace_string exn))
        in
        handle_file_watcher_exit ~error watcher
      | FileWatcher.Watcher_stopped ->
        (* file watcher was shut down intentionally, i.e. watcher#stop *)
        Lwt.return_unit
      | FileWatcher.Watcher_died -> handle_file_watcher_exit watcher
      | FileWatcher.Watcher_missed_changes ->
        let msg = spf ""File watcher (%s) missed changes"" watcher#name in
        handle_file_watcher_exit ~code:Exit.File_watcher_missed_changes ~msg watcher
    in
    StatusStream.file_watcher_ready ();

    let command_loop = CommandLoop.run ~cancel_condition:ExitSignal.signal (watcher, connection) in
    let file_watcher_loop =
      if file_watcher = FlowServerMonitorOptions.NoFileWatcher then
        (* Don't even bother *)
        Lwt.return_unit
      else
        FileWatcherLoop.run ~cancel_condition:ExitSignal.signal watcher
    in

    (* Check for changed files, which processes any files that have changed since the mergebase
       before we started up. *)
    push_to_command_stream (Some Notify_file_changes);

    Lwt.return
      {
        pid;
        watcher;
        connection;
        command_loop;
        file_watcher_loop;
        on_exit_thread;
        file_watcher_exit_thread;
      }

  let pid_of t = t.pid
end

(* A loop who's job is to start a server and then wait for it to die *)
module KeepAliveLoop = LwtLoop.Make (struct
  type acc = FlowServerMonitorOptions.t * ServerStatus.restart_reason option

  (* Given that a Flow server has just exited with this exit status, should the monitor exit too?
   *
   * Returns the tuple (should_monitor_exit_with_server, restart_reason)
   *)
  let process_server_exit monitor_options exit_status =
    if monitor_options.FlowServerMonitorOptions.no_restart then
      (true, None)
    else
      Exit.(
        match exit_status with
        (**** Things the server might exit with that implies that the monitor should exit too ****)
        | No_error
        (* Server exited cleanly *)
        | Windows_killed_by_task_manager
        (* Windows task manager killed the server *)
        | Invalid_flowconfig
        (* Parse/version/etc error. Server will never start correctly. *)
        | Path_is_not_a_file
        (* Required a file but privided path was not a file *)
        | Flowconfig_changed
        (* We could survive some config changes, but it's too hard to tell *)
        | Invalid_saved_state
        (* The saved state file won't automatically recover by restarting *)
        | Unused_server
        (* The server appears unused for long enough that it decided to just die *)
        | Unknown_error
        (* Uncaught exn. We probably could survive this, but it's a little risky *)
        | Watchman_error
        (* We ran into an issue with Watchman *)
        | Watchman_failed
        (* We ran into an issue with Watchman *)
        | File_watcher_missed_changes
        (* Watchman restarted. We probably could survive this by recrawling *)
        | Hash_table_full
        (* The hash table is full. It accumulates cruft, so restarting _might_ help, but
           if it's just too small, we could get stuck in a crash loop. Ideally we'd delete
           unused keys so that it being full is definitely a permanent failure. *)
        | Heap_full
        (* The heap is full. Restarting might help clear out cruft, but it could also just
           be too small, leading to a crash loop. We should limit how often we try restarting
           before recovering from this. *)
        | Could_not_extract_flowlibs
        (**** Things that the server shouldn't use, but would imply that the monitor should exit ****)
        | Interrupted
        | Build_id_mismatch
        (* Client build differs from server build - only monitor uses this *)
        | Lock_stolen
        (* Lock lost - only monitor should use this *)
        | Socket_error
        (* Failed to set up socket - only monitor should use this *)
        | Dfind_died (* Any file watcher died (it's misnamed) - only monitor should use this *) ->
          (true, None)
        (**** Things the server might exit with which the monitor can survive ****)
        | Server_out_of_date (* Server needs to restart, but monitor can survive *) ->
          (false, Some ServerStatus.Server_out_of_date)
        | Out_of_shared_memory (* The monitor doesn't used sharedmem so we can survive *) ->
          (false, Some ServerStatus.Out_of_shared_memory)
        | Killed_by_monitor (* The server died because we asked it to die *) -> (false, None)
        | Restart (* The server asked to be restarted *) -> (false, Some ServerStatus.Restart)
        (**** Unrelated exit codes. If we see them then something is wrong ****)
        | Type_error
        | Out_of_time
        | Kill_error
        | No_server_running
        | Out_of_retries
        | EventLogger_restart_out_of_retries
        | Input_error
        | Could_not_find_flowconfig
        | Commandline_usage_error
        | No_input
        | Missing_flowlib
        | Server_start_failed _
        | Autostop (* is used by monitor to exit, not server *) ->
          (true, None)
      )

  (* Ephemeral commands are stateless, so they can survive a server restart. However a persistent
   * connection might have state, so it's wrong to allow it to survive. Maybe in the future we can
   * tell the persistent connection that the server has died and let it adjust its state, but for
   * now lets close all persistent connections *)
  let killall_persistent_connections exit_type =
    PersistentConnectionMap.get_all_clients ()
    |> Lwt_list.iter_p (fun conn ->
           let wrote =
             PersistentConnection.write
               ~msg:LspProt.(NotificationFromServer (ServerExit exit_type))
               conn
           in
           (* it's ok if the stream is already closed, we must be shutting down already *)
           ignore wrote;
           (* it's also ok if the flush fails because the socket is already closed *)
           PersistentConnection.try_flush_and_close conn
       )

  let should_monitor_exit_with_signaled_server signal =
    (* While there are many scary things which can cause segfaults, in practice we've mostly seen
     * them when the Flow server hits some infinite or very deep recursion (like Base.List.map ~f:on a
     * very large list). Often, this is triggered by some ephemeral command, which is rerun when
     * the server starts back up, leading to a cycle of segfaulting servers.
     *
     * The easiest solution is for the monitor to exit as well when the server segfaults. This
     * will cause the bad command to consume retries and eventually exit. This doesn't prevent
     * future bad commands, but is better than the alternative.
     *)
    signal = Sys.sigsegv

  let wait_for_server_to_die monitor_options server =
    let pid = ServerInstance.pid_of server in
    let%lwt (_, status) = LwtSysUtils.blocking_waitpid pid in
    let%lwt () = ServerInstance.cleanup server in
    if
      Sys.unix
      &&
      try Sys_utils.check_dmesg_for_oom pid ""flow"" with
      | _ -> false
    then
      FlowEventLogger.murdered_by_oom_killer ();

    match status with
    | Unix.WEXITED exit_status ->
      let exit_type =
        try Some (Exit.error_type exit_status) with
        | Not_found -> None
      in
      let exit_status_string =
        Base.Option.value_map ~default:""Invalid_exit_code"" ~f:Exit.to_string exit_type
      in
      Logger.error
        ""Flow server (pid %d) exited with code %s (%d)""
        pid
        exit_status_string
        exit_status;
      begin
        match exit_type with
        | None ->
          exit
            ~msg:(spf ""Flow server exited with invalid exit code (%d)"" exit_status)
            Exit.Unknown_error
        | Some exit_type ->
          let (should_monitor_exit_with_server, restart_reason) =
            process_server_exit monitor_options exit_type
          in
          if should_monitor_exit_with_server then
            exit ~msg:""Dying along with server"" exit_type
          else
            let%lwt () = killall_persistent_connections exit_type in
            Lwt.return restart_reason
      end
    | Unix.WSIGNALED signal ->
      Logger.error
        ""Flow server (pid %d) was killed with %s signal""
        pid
        (PrintSignal.string_of_signal signal);
      FlowEventLogger.report_from_monitor_server_exit_due_to_signal signal;
      if should_monitor_exit_with_signaled_server signal then
        exit ~msg:""Dying along with signaled server"" Exit.Interrupted
      else
        Lwt.return_none
    | Unix.WSTOPPED signal ->
      (* If a Flow server has been stopped but hasn't exited then what should we do? I suppose we
         * could try to signal it to resume. Or we could wait for it to start up again. But killing
         * it and starting a new server seems easier *)
      Logger.error
        ""Flow server (pid %d) was stopped with %s signal. Sending sigkill""
        pid
        (PrintSignal.string_of_signal signal);

      (* kill is not a blocking system call, which is likely why it is missing from Lwt_unix *)
      Unix.kill pid Sys.sigkill;
      Lwt.return_none

  (* The RequestMap will contain all the requests which have been sent to the server but never
   * received a response. If we're starting up a new server, we can resend all these requests to
   * the new server *)
  let requeue_stalled_requests () =
    let%lwt requests = RequestMap.remove_all () in
    Lwt_list.iter_p
      (fun (request, client) ->
        Lwt.return (push_to_command_stream (Some (Write_ephemeral_request { request; client }))))
      requests

  let main (monitor_options, restart_reason) =
    let%lwt () = requeue_stalled_requests () in
    let%lwt server = ServerInstance.start monitor_options restart_reason in
    let%lwt restart_reason = wait_for_server_to_die monitor_options server in
    Lwt.return (monitor_options, restart_reason)

  let catch _ exn =
    Logger.error ~exn:(Exception.to_exn exn) ""Exception in KeepAliveLoop"";
    Exception.reraise exn
end)

let setup_signal_handlers =
  let signals =
    [
      Sys.sigint (* Interrupt - ctrl-c *);
      Sys.sigterm (* Termination - like a nicer sigkill giving you a chance to cleanup *);
      Sys.sighup (* Hang up - the terminal went away *);
      Sys.sigquit (* Dump core - Kind of a meaner sigterm *);
    ]
  in
  let handle_signal signal =
    Lwt.async (fun () ->
        exit ~msg:(spf ""Received %s signal"" (PrintSignal.string_of_signal signal)) Exit.Interrupted
    )
  in
  let set_signal s =
    try Sys_utils.set_signal s (Sys.Signal_handle handle_signal) with
    | exn ->
      Logger.error ~exn ""Failed to install signal handler for %s"" (PrintSignal.string_of_signal s)
  in
  (fun () -> List.iter set_signal signals)

let start monitor_options =
  Lwt.async Doomsday.start_clock;
  setup_signal_handlers ();
  KeepAliveLoop.run ~cancel_condition:ExitSignal.signal (monitor_options, None)

let send_request ~client ~request =
  Logger.debug
    ""Adding request (%s) to the command stream""
    (ServerProt.Request.to_string request.ServerProt.Request.command);
  push_to_command_stream (Some (Write_ephemeral_request { request; client }))

let send_persistent_request ~client_id ~request =
  Logger.debug
    ""Adding request (%s) to the command stream""
    (LspProt.string_of_request_with_metadata request);
  push_to_command_stream (Some (Write_persistent_request { client_id; request }))

let notify_new_persistent_connection ~client_id ~lsp_init_params =
  Logger.debug ""Adding notification that there's a new persistent client #%d"" client_id;
  push_to_command_stream (Some (Notify_new_persistent_connection { client_id; lsp_init_params }))

let notify_dead_persistent_connection ~client_id =
  Logger.debug ""Adding notification that persistent client #%d died"" client_id;
  push_to_command_stream (Some (Notify_dead_persistent_connection { client_id }))
",ocaml
"open MenhirSdk.Cmly_api

module type RECOVERY = sig
  module G : GRAMMAR

  type item = G.lr1 * G.production * int

  type recovery = { prefix : int; cases : (G.lr1 option * item list) list }
  (** [prefix] is the size of the known prefix of the stack. It means that in
      the kernel of current state, there is an item whose dot is at position
      [prefix]. (we know the incoming symbols for these stack frames and we can
      enumerate the possible state numbers).

      [cases] is a mapping that associates to each possible state found at
      stack.[-prefix] (or None if the stack is empty) a list of reductions to
      execute.

      The actual list of actions to reduce an item [(state, prod, pos)] is given
      by [Synthesizer.solution (Trail (state, prod, pos))] *)

  val recover : G.lr1 -> recovery
end

module type RECOVER = functor
  (G : GRAMMAR)
  (S : Synthesis.SYNTHESIZER with module G := G)
  -> RECOVERY with module G := G
",ocaml
"open Utils

external addClass : Dom.domTokenList -> string -> unit = ""add"" [@@bs.send]
external addEventListener : Dom.element -> string -> (unit -> unit) -> unit = ""addEventListener"" [@@bs.send]
external appendChild : Dom.element -> Dom.element -> unit = ""appendChild"" [@@bs.send]
external createElement : string -> Dom.element = ""createElement"" [@@bs.val][@@bs.scope ""document""]
external getClassList : Dom.element -> Dom.domTokenList = ""classList"" [@@bs.get]
external getFirstChild : Dom.element -> Dom.element Js.null = ""firstChild"" [@@bs.get]
external getStyles : Dom.element -> Dom.cssStyleDeclaration = ""style"" [@@bs.get]
external getValue : Dom.element -> string = ""value"" [@@bs.get]
external normalize : string -> string -> string = ""normalize"" [@@bs.send]
external querySelector : string -> Dom.element option = ""querySelector"" [@@bs.val][@@bs.scope ""document""][@@bs.return nullable]
external removeChild : Dom.element -> Dom.element -> unit = ""removeChild"" [@@bs.send]
external setStyle : Dom.cssStyleDeclaration -> string -> string -> unit = """" [@@bs.set_index]
external setTextContent : Dom.element -> string -> unit = ""textContent"" [@@bs.set]
external setTitle : Dom.element -> string -> unit = ""title"" [@@bs.set]
external toLowerCase : string -> string = ""toLowerCase"" [@@bs.send]

type layout = Horz | Vert
let string_of_layout = function
  | Horz -> ""horz""
  | Vert -> ""vert""

type color = string
type flex = bool
type size = float
type width = float
type help = string

type component
  = BorderBox of color * width * component
  | Box of layout * flex * component list
  | HelpText of color * size * string * help
  | Space of float
  | Text of color * size * string



let rec draw : component -> Dom.element = function
  | BorderBox(color, width, c) ->
      let ele = createElement ""div"" in
      let sty = getStyles ele in
      setStyle sty ""border-color"" color;
      setStyle sty ""border-style"" ""solid"";
      setStyle sty ""border-width"" (Js.Float.toString width ^ ""px"");
      appendChild ele (draw c);
      ele
  | Box(layout, flex, cs) ->
      let ele = createElement ""div"" in
      if flex then
        addClass (getClassList ele) ""flex"";
      addClass (getClassList ele) ""box"";
      addClass (getClassList ele) (string_of_layout layout);
      List.iter (appendChild ele % draw) cs;
      ele
  | HelpText(color, size, text, altText) ->
      let ele = createElement ""span"" in
      addClass (getClassList ele) ""help"";
      let sty = getStyles ele in
      setStyle sty ""color"" color;
      setStyle sty ""font-size"" (Js.Float.toString size ^ ""em"");
      setTextContent ele text;
      setTitle ele altText;
      ele
  | Space(size) ->
      let ele = createElement ""span"" in
      setStyle (getStyles ele) ""font-size"" (Js.Float.toString size ^ ""em"");
      setTextContent ele ""\xa0"";
      ele
  | Text(color, size, text) ->
      let ele = createElement ""span"" in
      let sty = getStyles ele in
      setStyle sty ""color"" color;
      setStyle sty ""font-size"" (Js.Float.toString size ^ ""em"");
      setTextContent ele text;
      ele

let rec removeAllChildren (ele: Dom.element) : unit =
  match Js.nullToOption (getFirstChild ele) with
  | Some child -> removeChild ele child; removeAllChildren ele
  | None -> ()

let update (c: component) (ui: Dom.element) =
  let c' = draw c in
  removeAllChildren ui;
  appendChild ui c'



let error (s: string) : component = Text(""#ff0000"", 2.0, s)

let ui_func : (Theme.t -> string -> component) ref =
  ref (fun _ _ -> error ""No ui_func set!"")

let set_func (f: Theme.t -> string -> component) : unit =
  ui_func := f

let theme : Theme.t ref = ref Theme.default

let set_theme (t: Theme.t) : unit =
  theme := t

let () =
  match querySelector ""#ui"" with
  | Some ui ->
    begin
      match querySelector ""#text"" with
      | Some ele -> addEventListener ele ""change"" (fun () ->
          let c = try
            (!ui_func) (!theme) (normalize (toLowerCase (getValue ele)) ""NFC"")
          with
            | Failure(s) -> error s
            | Js.Exn.Error e ->
              let msg = match Js.Exn.message e with
              | Some message -> error message
              | None -> error ""An unknown error occurred""
              in begin
                match Js.Exn.stack e with
                | Some stack -> Box(Vert, true, [msg; error stack])
                | None -> msg
              end
            | exc -> error (Printexc.to_string exc)
          in update c ui)
      | None -> failwith ""No #text element!""
    end
  | None -> failwith ""No #ui element!""
",ocaml
"(* Options and arguments parsing *)

open Arg

(* Todo : find a proper place to put the file *)
let _index_file_path = ref ((Sys.getcwd ())^""/opam-doc.idx"")
let _default_index_name = ref ""index.html""
let _filter_pervasives = ref false
let _clear_index = ref false
let _always_proceed = ref false
let _package_descr = ref """"
let _current_package = ref ""test""
let _base_uri = ref ""/""
let _summary = ref None

let index_file_path () = !_index_file_path
let default_index_name () = !_default_index_name
let filter_pervasives () = !_filter_pervasives
let clear_index () = !_clear_index
let always_proceed () = !_always_proceed
let package_descr () = !_package_descr
let current_package () = !_current_package
let base_uri () = !_base_uri
let summary () = !_summary

let set_current_package p = _current_package := p
let set_summary s = _summary := Some s

let options  = 
  [ (""--package"", Set_string _current_package, ""Specify the package"")
  ; (""-p"", Set_string _current_package, ""Specify the package"")
  ; (""--package-description"", Set_string _package_descr, ""Add a description to the package"")
  ; (""-descr"", Set_string _package_descr, ""Add a description to the package"")
  ; (""--base"", Set_string _base_uri, ""Specify the base url"")
  ; (""--summary"", String set_summary, ""Specify the summary page"")
  ; (""-index"", Set_string _index_file_path, ""Use a specific index file to use rather than the default one"")
  ; (""--filter-pervasives"", Set _filter_pervasives, ""Remove the 'Pervasives' label to Pervasives' references"")
  ; (""--clear-index"", Set _clear_index, ""Clear the global index before processing"")
  ; (""-y"", Set _always_proceed, ""Answer yes to all questions prompted"")
  ]

let usage = ""Usage: opam-doc [--package 'package_name'] <cm[dt] files>""


(* Html config *)

let doctype = ""<!DOCTYPE HTML>\n""
let character_encoding =
  <:html<<meta content=""text/html; charset=iso-8859-1"" http-equiv=""Content-Type"" />&>>

let default_stylesheet_css =
  let open Cow in
  <:css<

  .footer {
    color: #555555;
    border-top: 1px solid #eeeeee;
    font-size: 0.8rem;
    font-style: italic;
    padding-top: 0.4rem;
    margin-top: 1rem;
  }

  table.typetable { background: none; border: none; }
  table.typetable thead,
  table.typetable tfoot {
    background: none; font-weight: bold; }
  table.typetable thead tr th,
  table.typetable thead tr td,
  table.typetable tfoot tr th,
  table.typetable tfoot tr td {
    font-size: 1rem;
    color: #222222;
    text-align: left; }
  table.typetable tr th,
  table.typetable tr td {
    padding: 0px;
    font-size: 1rem;
    color: #222222; }
  table.typetable tr.even, table.typetable tr.alt, table.typetable tr:nth-of-type(even) {
    background: none; }
  table.typetable thead tr th,
  table.typetable tfoot tr th,
  table.typetable tbody tr td,
  table.typetable tr td,
  table.typetable tfoot tr td {
    display: table-cell;
  } 

  table.indextable { background: white; border: none; }
  table.indextable thead,
  table.indextable tfoot {
    background: white; font-weight: bold; }
  table.indextable thead tr th,
  table.indextable thead tr td,
  table.indextable tfoot tr th,
  table.indextable tfoot tr td {
    font-size: 1rem;
    color: #222222;
    text-align: left; }
  table.indextable tr th,
  table.indextable tr td {
    padding: 0.2625rem 0.225rem;
    font-size: 1rem;
    color: black; }
  table.indextable tr.even, table.indextable tr.alt, table.indextable tr:nth-of-type(even) {
    background: whitegrey; }
  table.indextable thead tr th,
  table.indextable tfoot tr th,
  table.indextable tbody tr td,
  table.indextable tr td,
  table.indextable tfoot tr td {
    display: table-cell;
  } 

  #opamdocroot .panel.callout { 
    padding: 0.5rem;
    background: #fdfdfd;
    border: none;
  }

  p { line-height: 1.1rem; margin-bottom: 0.8rem; }
  body { 
    font-family: 'Source Sans Pro', sans-serif;
    color: black;
  }
  #opamdocroot h1 {
    font-family: ""Source Sans Pro"", sans-serif;
    font-weight: bold;
    font-size: 1.6rem;
  }
  #opamdocroot h2 {
    font-family: ""Source Sans Pro"", sans-serif;
    font-weight: bold;
    font-size: 1.4rem;
  }
  #opamdocroot h3 {
    font-family: ""Source Sans Pro"", sans-serif;
    font-weight: bold;
    font-size: 1.2rem;
  }
  #opamdocroot h4 {
    font-family: ""Source Sans Pro"", sans-serif;
    font-weight: bold;
    font-size: 1.2em;
  }
  #opamdocroot h5 {
    font-family: ""Source Sans Pro"", sans-serif;
    font-weight: bold;
    font-size: 1.2rem;
  }
  #opamdocroot h6 {
    font-family: ""Source Sans Pro"", sans-serif;
    font-weight: bold;
    font-size: 1.2rem;
  }

  pre.odoccode {
    background: #eeeeee;
    border-top: 1px solid #cccccc;
    padding: 5px;
    margin-top: 10px;
  }
  .top-bar input { height: 2.1em; }
  .keyword { color: #f47421; font-weight: bold; }
  .keywordsign { color: #f47421; }
  .superscript { font-size: 4; }
  .subscript { font-size: 4; }
  .comment { color: #747474; font-style: italic; }
  .constructor { color: #15c17a; }
  .type { color: #c746cc; }
  .string { color: #09a7e2; }
  .warning { color: Red ; font-weight: bold; }
  .param_info { margin-top: 4px; margin-left: 3em; margin-right: 3em; }
  .code { color: #465F91 ; }
  .typetable { border-style: hidden; }
  .paramstable { border-style: hidden ; padding: 5pt 5pt; }
   td.typefieldcomment { font-size: smaller ;}
   div.sig_block {margin-left: 2em; }
   *:target { background: yellow; }

  pre { font-family: monospace; margin-bottom: 0.8rem; }
  #opamdocroot pre {
    white-space: pre-wrap;       /* css-3 */
    white-space: -moz-pre-wrap;  /* Mozilla, since 1999 */
    white-space: -pre-wrap;      /* Opera 4-6 */
    white-space: -o-pre-wrap;    /* Opera 7 */
    word-wrap: break-word;       /* Internet Explorer 5.5+ */
    font-weight: normal;
    color: #333333;
    font-family: monospace;
  }

  #opamdocroot code {
    font-weight: normal;
    color: #333333;
    font-family: monospace;
  }

  .deprecated {color: #888; font-style: italic; }

  ul.indexlist { margin-left: 0; padding-left: 0; }
  ul.indexlist li { list-style-type: none ; margin-left: 0; padding-left: 0; }

  .ocaml_expanded_include_0 { background-color: #FFF0F0; border-width: thin; border-style: solid; border-color: #E5E0E0;}
  .ocaml_expanded_include_1 { background-color: #F0F0FF; border-width: thin; border-style: solid; border-color: #E0E0E5;}
  .ocaml_expanded_include_2 { background-color: #F0FFF0; border-width: thin; border-style: solid; border-color: #E0E5E0;}
  .ocaml_expanded_include_3 { background-color: #FFF0FF; border-width: thin; border-style: solid; border-color: #E5E0E5;}
  .ocaml_expanded_include_4 { background-color: #FFFFF0; border-width: thin; border-style: solid; border-color: #E5E5E0;}
  .ocaml_expanded_include_5 { background-color: #F0FFFF; border-width: thin; border-style: solid; border-color: #E0E5E5;}
  .ocaml_expanded_include_6 { background-color: #F0F5F0; border-width: thin; border-style: solid; border-color: #E5E0E0;}
  pre.ocaml_include_handle { display: inline; }

  .ocaml_expander_plus {
     position: relative;
     float: left;
     width: 7px;
     height: 7px;
     background: silver;
     border-style: solid;
     border-width: 1px;
     margin: 3px;
  }
  .ocaml_expander_plus::before {
     content: '';
     position: absolute;
     left: 3px;
     top: 1px;
     width: 1px;
     height: 5px;
     background: black;
  }
  .ocaml_expander_plus::after {
     content: '';
     position: absolute;
     left: 1px;
     top: 3px;
     width: 5px;
     height: 1px;
     background: black;
  }
  .ocaml_expander_minus {
     position: relative;
     float: left;
     width: 7px;
     height: 7px;
     background: silver;
     border-style: solid;
     border-width: 1px;
     margin: 3px;
  }
  .ocaml_expander_minus:hover {
     background: grey;
  }
  .ocaml_expander_minus::after {
     content: '';
     position: absolute;
     left: 1px;
     top: 3px;
     width: 5px;
     height: 1px;
     background: black;
  }
  .ocaml_expander_disabled {
     position: relative;
     float: left;
     width: 7px;
     height: 7px;
     background: silver;
     border-style: solid;
     border-color: grey;
     border-width: 1px;
     margin: 3px;
  }
  .ocaml_expander_disabled::before {
     content: '';
     position: absolute;
     left: 3px;
     top: 1px;
     width: 1px;
     height: 5px;
     background: grey;
  }
  .ocaml_expander_disabled::after {
     content: '';
     position: absolute;
     left: 1px;
     top: 3px;
     width: 5px;
     height: 1px;
     background: grey;
  }
   >>
let default_stylesheet = Cow.Css.to_string default_stylesheet_css

(** Marks used to generate id attributes *)
type mark = Attribute | Type | Type_elt | Function | Exception | Value | Method | Title

let jquery_online_url = ""http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js""

let style_filename = ""style.css""

let style_url () = base_uri () ^ ""/"" ^ style_filename

let style_tag () =
  <:html<<link rel=""stylesheet"" href=""$str:style_url ()$"" type=""text/css"" />&>>

(* Config script *)

let config_tag () = 
  <:html<<script type=""text/javascript"">
var ocaml_package = '$str:current_package ()$'
var ocaml_base = '$str:base_uri ()$'
</script>&>>

(* Ajax loading *)

let script_filename = ""doc_loader.js""

let script_url () = base_uri () ^ ""/"" ^ script_filename

let script_tag () =
  <:html<<script type=""text/javascript"" src=""$str:jquery_online_url$""> </script>
<script type=""text/javascript"" src=""$str:script_url ()$""> </script>&>>

let default_script = 
""var opamdoc_contents = '#opamdocroot'

// utility - Fetch HTML from URL using ajax
function ajax(url, cont){
    console.log('AJAX request : ' + url);
    $.ajax({
        type: 'GET',
        url:url,
        async:true,
        dataType: 'html'
    }).done(function(data){
        cont($(data));
    }).fail(function(){
        console.log('AJAX request failed : ' + url);
    });
}

function isLIdent(ident) {
    var chr = ident.charAt(0);
    return (chr !== chr.toUpperCase()
            && chr === chr.toLowerCase())
}

var url_regexp = /^(.*)\/([^/]*)\/(?:#(.*))?$/

function Path(url){

    this.package = null;
    this.module = null;
    this.subnames = [];
    this.subkinds = [];

    var match = url_regexp.exec(url);

    var base = match[1];
    var package = match[2];
    var hash = match[3];

    if(base === ocaml_base) {

      this.package = package;

      if(typeof hash !== 'undefined' && hash !== '') {
          var modstring = hash;
          var names = [];
          var kinds = [];
          var done = false;
          var sep = '.'
          var i = 0;
          while(!done) {
              var dot_index = modstring.indexOf('.');
              var colon_index = modstring.indexOf(':');
              if(dot_index > 0 && (dot_index < colon_index || colon_index < 0)) {
                  names[i] = modstring.substring(0, dot_index);
                  if(sep === ':') {
                    kinds[i] = 'modtype';
                  } else if(isLIdent(names[i])) {
                    kinds[i] = 'class';
                  } else {
                    kinds[i] = 'module';
                  }
                  sep = '.';
                  modstring = modstring.substring(dot_index + 1);
              } else if(colon_index > -1) {
                  names[i] = modstring.substring(0, colon_index);
                  if(sep === ':') {
                    kinds[i] = 'modtype';
                  } else if(isLIdent(names[i])) {
                    kinds[i] = 'class';
                  } else {
                    kinds[i] = 'module';
                  }
                  sep = ':';
                  modstring = modstring.substring(colon_index + 1);
              } else {
                  names[i] = modstring;
                  if(sep === ':') {
                    kinds[i] = 'modtype';
                  } else if(isLIdent(names[i])) {
                    kinds[i] = 'class';
                  } else {
                    kinds[i] = 'module';
                  }
                  done = true;
              }
              i++;
          }
          this.module = names[0];
          if(names.length > 1) {
              this.subnames = names.splice(1);
              this.subkinds = kinds.splice(1);
          }
      }
  }
}

Path.prototype.name = function () {
    var name = null;
    if(this.package !== null) {
        name = this.package;
        if(this.module !== null) {
            name = this.module;
            if(this.subnames.length > 0){
                name += '.' + this.subnames.join('.');
            } 
        }
    }        
    return name;
}

Path.prototype.url = function () { 
    var url = null;
    if(this.package !== null) {
        url = ocaml_base + '/' + this.package;
        if(this.module !== null) {
            url += '/#' + this.module;
            for(var i = 0; i < this.subnames.length; i++) {
                if(this.subkinds[i] === 'modtype') {
                    url += ':' + this.subnames[i];
                } else {
                    url += '.' + this.subnames[i];
                }
            } 
        }
    }        
    return url;
}

function Copy(path) {
    this.package = path.package;
    this.module = path.module;
    this.subnames = path.subnames.slice(0);
    this.subkinds = path.subkinds.slice(0);
}

Copy.prototype = Path.prototype

Path.prototype.copy = function () { return new Copy(this) }

Path.prototype.extend = function (name, kind) { 
    this.subnames[this.subnames.length] = name;
    this.subkinds[this.subkinds.length] = kind;
}

Path.prototype.substitute = function (from, to) {
    if(this.package === from.package) {
        if(this.module === from.module) {
            if(this.subnames.length > from.subnames.length) {
                var equal = true;
                for(var i = 0; i < from.subnames.length; i++) {
                    if(from.subnames[i] !== this.subnames[i]) {
                        equal = false;
                    } else if(from.subkinds[i] !== this.subkinds[i]) {
                        equal = false;
                    }
                }
                if(equal) {
                    this.package = to.package;
                    this.module = to.module;
                    var subnames = to.subnames.slice(0);
                    var subkinds = to.subkinds.slice(0);
                    for(var i = from.subnames.length; i < this.subnames.length; i++) {
                        subnames[subnames.length] = this.subnames[i];
                        subkinds[subkinds.length] = this.subkinds[i];
                    }
                    this.subnames = subnames;
                    this.subkinds = subkinds;
                    return true;
                }
            }
        }
    }
    return false;
}

function Parent(path) {
    this.package = null;
    this.module = null;
    this.subnames = [];
    this.subkinds = [];

    if(path.package !== null) {
        if(path.module !== null) {
            this.package = path.package;
            if(path.subnames.length > 0) {
                this.module = path.module;
                this.subnames = path.subnames.slice(0, -1);
                this.subkinds = path.subkinds.slice(0, -1);
            }
        } 
    }
}

Parent.prototype = Path.prototype

Path.prototype.parent = function () { return new Parent(this) }

function PathVisitor(path) {
    this.path = path;
    this.subnames = path.subnames.slice(0);
    this.subkinds = path.subkinds.slice(0);
}

PathVisitor.prototype.current = function (){
    if(this.subnames.length > 0) {
        return {kind: this.subkinds[0], name: this.subnames[0]};
    } else {
        return null;
    }
}

PathVisitor.prototype.next = function (){
    if(this.subnames.length > 0) {
        this.subnames.shift();
        this.subkinds.shift();
    }
    return this;
}

PathVisitor.prototype.concat = function(pv){
    this.subnames = this.subnames.concat(pv.subnames);
    this.subkinds = this.subkinds.concat(pv.subkinds);
    this.path.subnames = this.path.subnames.concat(pv.subnames);
    this.path.subkinds = this.path.subkinds.concat(pv.subkinds);

    return this;
}


function Page(path, kind){
    this.path = path;
    this.kind = kind;
    this.alias = null;
    this.summary = null;
    this.body = null;
    this.constraints = null;
    this.typ = null;
}

Page.prototype.parent_link = function() {
    var parent = this.path.parent();
    var title = parent.name();
    var url = parent.url();
    if (title === null || url === null) {
        title = this.path.name();
        url = ocaml_base + '/';
        $('#bccurpkg').attr('class','current').html(this.path.name());
        $('#bccurpkgmod').attr('class','hide');
    } else {
        $('#bccurpkg').attr('class','').html(
          $('<a>', {title: title, href: url, text: title }));
        $('#bccurpkg').attr('class','');
        $('#bccurpkgmod').attr('class','current');
        $('#bccurpkgmod').html(this.path.name ());
    }
}

Page.prototype.title = function(){
    var name = this.path.name();
    if(this.kind === 'module') {
        fullName = 'Module ' + name;
    } else if(this.kind === 'modtype') {
        fullName = 'Module type ' + name;
    } else if(this.kind === 'class') {
        fullName = 'Class ' + name;
    } else {
        fullName = 'Package ' + name;
    }

    var alias = null;
    var sep = '';
    if(this.alias !== null) {
        if(this.path.modtype !== null) {
          sep = ' = ';
        } else {
          sep = ' : ';
        }
        alias = $('<a>', 
                  {href    : this.alias.url(),
                   text    : this.alias.name()});
    }
     
    return $('<h1>')
        .addClass('ocaml_title')
        .append(fullName + sep)
        .append(alias);
}

function display_page(page){
    page.parent_link();
    var title = page.title();
    var summary = page.summary;
    var head = $('<div>')
        .addClass('panel')
        .addClass('callout')
        .append(title)
        .append(summary);
    var rule = $('<hr/>').attr('width','100%');
    var body = $('<div>')
        .addClass('column')
        .addClass('small-12')
        .addClass('medium-11')
        .addClass('large-9')
        .addClass('ocaml_body')
        .append(page.body);

    var content = $('<div>')
        .addClass('ocaml_page')
        .append(head)
        .append(body);

    $(opamdoc_contents).html(content);
}

function show_type(typ) {
    if(typ !== null) {
        var types = $('pre > span.TYPE'+typ).filter(':visible');
        if (types.length == 0){
            types = $('pre > code > span.TYPE'+typ).filter(':visible');;
        }
        if (types.length > 0) {
            var pos = types.position().top - (window.innerHeight / 5);
            if(pos < 0) {
                pos = 0;
            }
            window.scrollTo(0, pos);
            types.css('background', 'yellow');
        }
    }
}

function load_page(page, pv, input, cont) {

    var current = pv.current();
    var data = $('> div.ocaml_content', input);

    if(current === null) {
        page.summary = $('> div.ocaml_summary', input);
        page.body = data;
        if(page.path !== pv.path) {
            page.alias = pv.path
        }
        cont(page);
    } else {

        var kind = current.kind;
        var name = current.name;

        var query = '> div.ocaml_' + kind + '[name=' + name + ']'
        var subdata = $(query, data)

        if(subdata.length === 0) {

            var try_type = (kind === 'class');

            var includes = $('> div.ocaml_include', data);

            for (var i = 0; i < includes.length; i++){

                var items = JSON.parse($(includes[i]).attr('items'));

                if (items.indexOf(name) !== -1){
                    try_type = false;

                    var pathAttr = $(includes[i]).attr('path');

                    if (typeof pathAttr === 'undefined'){
                        load_page(page, pv, includes[i], cont);
                    } else {
                        var include_path = new Path(pathAttr);
                        var include_pv = new PathVisitor(include_path);

                        var include_url = ocaml_base + '/' + include_path.package + '/' + include_path.module +'.html'
                        
                        ajax(include_url, function(data){
                            load_page(page, include_pv.concat(pv), data, cont);
                        });
                    }
                }
            }

            if(try_type) {
                var types = $('pre > span.TYPE'+name, data);
                if (types.length == 0){
                    types = $('pre > code > span.TYPE'+name, data);
                }
                if (types.length > 0){
                    page.summary = $('> div.ocaml_summary', input);
                    page.body = data;
                    page.typ = name;
                    if(page.path !== pv.path) {
                        page.alias = pv.path.parent();
                    }
                    page.path = page.path.parent();
                    cont(page);
                } else {
                    for (var i = 0; i < includes.length; i++){
                        var items = JSON.parse($(includes[i]).attr('types'));
                        if (items.indexOf(name) !== -1){
                            page.summary = $('> div.ocaml_summary', input);
                            page.body = data;
                            page.typ = name;
                            if(page.path !== pv.path) {
                                page.alias = pv.path.parent();
                            }
                            page.path = page.path.parent();
                            cont(page);
                        }
                    }
                }
            }

        } else {
            page.kind = kind;

            var pathAttr = subdata.attr('path');

            if (typeof pathAttr === 'undefined'){
                load_page(page, pv.next(), subdata, cont);
            } else {
               
                var alias_path = new Path(pathAttr);
                var alias_pv = new PathVisitor(alias_path);

                var alias_url = ocaml_base + '/' + alias_path.package + '/' + alias_path.module +'.html'

                ajax(alias_url, function(data){
                    load_page(page, alias_pv.concat(pv.next()), data, cont);
                });
            }
        }
    }
}

function load_path(path, cont) {
    if(path.module !== null) {
        var url = ocaml_base + '/' + path.package + '/' + path.module + '.html';
        ajax(url, function(data){
            var pg = new Page(path, 'module');
            var pv = new PathVisitor(path);
            
            load_page(pg, pv, data, cont);
        });
    } else {
        var url = ocaml_base + '/' + path.package + '/summary.html';
        ajax(url, function(data){
            var pg = new Page(path, 'package');
            pg.body = data;
            cont(pg);
        });
    }
}

function Group(parent, node) {
    if(typeof parent !== 'undefined' && typeof node !== 'undefined'){
        this.typ = null;
        if(parent !== null) {
            this.depth = parent.depth + 1;
            this.icount = parent.icount;
            this.auto_expand = parent.auto_expand;
            this.filters = parent.filters;
            this.current = parent.current;
            this.decorate = parent.decorate_children;
            this.decorate_children = parent.decorate_children;
        } else {
            this.depth = 0;
            this.icount = 6;
            this.auto_expand = true;
            this.filters = [];
            this.current = null;
            this.decorate = true;
            this.decorate_children = true;
        }
        this.expanded = this.auto_expand;
        this.loading = false;
        if(node !== null) {
            this.node = node;
            this.content = null;
            var pathAttr = this.node.attr('path');
            if(typeof pathAttr !== 'undefined') {
                this.path = new Path(pathAttr);
            } else {
                this.path = null;
            }
            this.handle = this.node.children();
        } else {
            this.node = null;
            this.content = null;
            this.path = null;
            this.handle = null;
        }
    }
}

Group.prototype.load_content = function(data){
    this.update_links(data);
    this.load_children(data);
    this.content = data;
}

Group.prototype.add_filter = function(from, to){
    this.filters = this.filters.slice(0);
    this.filters[this.filters.length] = { from: from, to: to };
}

Group.prototype.show_unexpanded = function(){ }

Group.prototype.show_expanded = function(){ }

Group.prototype.show_disabled = function(){ }

Group.prototype.expand = function(expand){
    if(typeof expand === 'undefined') {
        expand = ! this.expanded;
    }
    if(expand) {
        if(this.content === null) {
            if(! this.loading) {
                this.loading = true;
                var self = this;
                var load = function(page){
                    if(page.alias !== null) {
                        self.add_filter(page.alias, self.current);
                    } else {
                        self.add_filter(page.path, self.current);
                    }
                    self.load_content(page.body);
                    self.show_expanded(true);
                };
                load_path(this.path, load);
            }
        } else {
            this.show_expanded(true);
        }
    } else {
        this.show_unexpanded(true);
    }
}

Group.prototype.show = function(){
    if(this.content === null && this.path === null) {
        this.show_disabled();
    } else {
        if(this.auto_expand) {
            if(this.content === null) {
                this.loading = true;
                this.show_unexpanded(false);
                var self = this;
                var load = function(page){
                    if(page.alias !== null) {
                        self.add_filter(page.alias, self.current);
                    } else {
                        self.add_filter(page.path, self.current);
                    }
                    self.load_content(page.body);
                    self.show_expanded(false);
                    show_type(self.typ)
                };
                load_path(this.path, load);
            } else {
                this.show_expanded(false);
            }
        } else {
            this.show_unexpanded(false);
        }
    }
}

Group.prototype.update_links = function(data) {
    var links = $('a.ocaml_internal', data);
    var filters = this.filters;
    links.each(function(){
        var url = $(this).attr('href');
        var path = new Path(url);
        var changed = false;
        for(var i = 0; i < filters.length; i++) {
            if(path.substitute(filters[i].from, filters[i].to)) {
                changed = true;
                break;
            }
        }
        if(changed) {
            $(this).attr('href', path.url())
        }
    });
}

function IncludeGroup(parent, node, label, idx) {
    Group.call(this, parent, node);
    this.icount = (parent.icount + idx + 2) % 7;
    if(this.icount === parent.icount) {
        this.icount = (this.icount + 4) % 7;
    }
    if(this.depth > 4) {
        this.auto_expand = false;
    }
    this.typ = parent.typ;
    var typesAttr = JSON.parse(this.node.attr('types'));
    if (typesAttr.indexOf(this.typ) !== -1){
        this.auto_expand = true;
    }
    this.button = null;
    this.block = null;
    this.inner_block = null;
    this.summary = null;
    this.content_added = false;
    var indent = 250 - (10 * this.depth);
    var indent = 0; /* TODO anil */
    this.pindent = '+=' + indent.toString() + 'px';
    this.nindent = '-=' + indent.toString() + 'px';
    var exdent = 40 - (2 * this.depth);
    this.pexdent = '+=' + exdent.toString() + 'px';
    this.nexdent = '-=' + exdent.toString() + 'px';
}

IncludeGroup.prototype = new Group();

IncludeGroup.prototype.prepare = function(){
    if(this.decorate) {
        if(this.button === null) {
            this.button = $('<div>').addClass('ocaml_expander_plus');
            var self = this;
            this.button.click(function () { self.expand() });
        }
        if(this.block === null) {
            this.summary = this.handle.filter('div.ocaml_summary');
            this.handle = $('<div>')
                             .append(this.button)
                             .append(this.handle);
            this.inner_block = $('<div>')
                             .addClass('ocaml_expanded_include_' + this.icount)
                             .css('display', 'inline-block')
                             .css('padding-top', '3px')
                             .css('padding-right', '3px')
                             .css('padding-bottom', '3px')
                             .append(this.handle);
            this.block = $('<div>').append(this.inner_block);
            this.node.append(this.block);
        }
        if(!this.content_added && this.content !== null) {
            this.inner_block.append(this.content);
            this.content_added = true;
        }
    }
}

IncludeGroup.prototype.show_unexpanded = function(animate){
    this.prepare();
    if(this.button !== null) {
        this.button.removeClass('ocaml_expander_minus');
        this.button.addClass('ocaml_expander_plus');
    }
    if(animate) {
        if(this.content !== null) {
            this.content.hide({duration: 'fast', queue: false});
            if(this.decorate) {
                this.summary.show({duration: 'fast', queue: false});
                this.block.animate({marginLeft: '0', marginRight: '0'}, {duration: 'fast', queue: false});
                this.inner_block.animate({minWidth: '0'}, {duration: 'fast', queue: false});
                this.content.animate({marginLeft: '0', marginRight: '0'}, {duration: 'fast', queue: false});
                //this.handle.animate({fontSize : '13px'}, {duration: 'fast', queue: false});
            }
        }
    } else {
        if(this.content !== null) {
            this.content.hide();
            if(this.decorate) {
                this.summary.show();
                this.block.css('margin-left', '');
                this.block.css('margin-right', '');
                this.inner_block.css('min-width', '');
                this.content.css('margin-left', '');
                this.content.css('margin-right', '');
                //this.handle.css('font-size', '13px');
            }
        }
    }
    this.expanded = false;
}

IncludeGroup.prototype.show_expanded = function(animate){
    this.prepare();
    if(this.button !== null) {
        this.button.removeClass('ocaml_expander_plus');
        this.button.addClass('ocaml_expander_minus');
    }
    if(animate) {
        if(this.content !== null) {
            this.content.show({duration: 'fast', queue: false});
            this.summary.hide({duration: 'fast', queue: false});
            this.block.animate({marginLeft: this.nindent, marginRight: this.nexdent}, {duration: 'fast', queue: false});
            this.inner_block.animate({minWidth: '100%'}, {duration: 'fast', queue: false});
            this.content.animate({marginLeft: this.pindent, marginRight: this.pexdent}, {duration: 'fast', queue: false});
            //this.handle.animate({fontSize : '11px'}, {duration: 'fast', queue: false});
        }
    } else {
        if(this.content !== null) {
            this.content.show();
            this.summary.hide();
            this.block.css('margin-left', this.nindent);
            this.block.css('margin-right', this.nexdent);
            this.block.css('margin-top', '1rem');
            this.inner_block.css('min-width', '100%');
            this.content.css('margin-left', this.pindent);
            this.content.css('margin-right', this.pexdent);
            //this.handle.css('font-size', '11px');
        }
    }
    this.expanded = true;
}

IncludeGroup.prototype.show_disabled = function(){
    if(this.button !== null) {
        this.button.removeClass('ocaml_expander_plus');
        this.button.removeClass('ocaml_expander_minus');
        this.button.addClass('ocaml_expander_disabled');
        this.button.off('click');
    }
    if(this.content !== null) {
        this.content.hide();
    }
    this.expanded = false;
}

function SigGroup(parent, node, label, idx) {
    Group.call(this, parent, node);
    this.icount = (parent.icount - idx - 1) % 7;
    this.auto_expand = false;
    this.decorate_children = false;
    var nameAttr = this.node.attr('name');
    this.current = this.current.copy();
    this.current.extend(nameAttr, label);
    this.button = null;
    this.block = null;
    this.content_added = false;
}

SigGroup.prototype = new Group();

SigGroup.prototype.prepare = function(){
    if(this.decorate && this.button === null) {
        this.button = $('<div>').addClass('ocaml_expander_plus');
        var self = this;
        this.button.click(function () { self.expand() });
    }
    if(this.block === null) {
        this.block = $('<div>')
                         .addClass('expanding_sig')
                         .append(this.button)
                         .append(this.handle);
        this.node.append(this.block);
    }
    if(!this.content_added && this.content !== null) {
        this.content.css('margin-left', '2em');
        this.content.css('padding-left', '2em');
        this.content.css('border-left', '3px solid lightgrey');
        this.block.append(this.content);
        this.content_added = true;
    }
}

SigGroup.prototype.show_unexpanded = function(animate){
    this.prepare();
    if(this.button !== null) {
        this.button.removeClass('ocaml_expander_minus');
        this.button.addClass('ocaml_expander_plus');
    }
    if(animate) {
        if(this.content !== null) {
            this.content.hide('fast');
        }
    } else {
        if(this.content !== null) {
            this.content.hide();
        }
    }
    this.expanded = false;
}

SigGroup.prototype.show_expanded = function(animate){
    this.prepare();
    if(this.button !== null) {
        this.button.removeClass('ocaml_expander_plus');
        this.button.addClass('ocaml_expander_minus');
    }
    if(animate) {
        if(this.content !== null) {
            this.content.show('fast');
        }
    } else {
        if(this.content !== null) {
            this.content.show();
        }
    }
    this.expanded = true;
}

SigGroup.prototype.show_disabled = function(){
    this.prepare();
    if(this.button !== null) {
        this.button.removeClass('ocaml_expander_plus');
        this.button.removeClass('ocaml_expander_minus');
        this.button.addClass('ocaml_expander_disabled');
        this.button.off('click');
    }
    if(this.content !== null) {
        this.content.hide();
    }
    this.expanded = false;
}

Group.prototype.load_children = function(data, Kind, label){
    if(typeof Kind === 'undefined') {
        this.load_children(data, IncludeGroup, 'include');
        this.load_children(data, SigGroup, 'module');
        this.load_children(data, SigGroup, 'modtype');
        this.load_children(data, SigGroup, 'class');
    } else {
        var children = $('> div.ocaml_' + label, data);
        var self = this;
        children.each(function(idx) {
            var grp = new Kind(self, $(this), label, idx);
            var content = $('> div.ocaml_content', $(this));
            if(content.length > 0) {
                grp.load_content(content);
            }
            grp.show();
        });
    }
}

$(document).ready(function () {
    var url = ocaml_base + '/' + ocaml_package + '/' + location.hash;
    var p = new Path(url);
    var grp = new Group(null, null);
    load_path(p, function(page){
        grp.typ = page.typ;
        grp.current = page.path;
        if(page.alias !== null) {
          grp.add_filter(page.alias, page.path);
        }
        grp.load_content(page.body);
        display_page(page);
        show_type(page.typ);
    });
});

$(window).on('hashchange', function () {
    var url = ocaml_base + '/' + ocaml_package + '/' + location.hash;
    var p = new Path(url);
    var grp = new Group(null, null);
    load_path(p, function(page){
        grp.typ = page.typ;
        grp.current = page.path;
        if(page.alias !== null) {
          grp.add_filter(page.alias, page.path);
        }
        grp.load_content(page.body);
        display_page(page);
        scrollTo(0,0);
        show_type(page.typ);
    });
});
""
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

module Ast = Flow_ast
module Tast_utils = Typed_ast_utils

(* This module contains the traversal functions which set up subtyping
   constraints for every expression, statement, and declaration form in a
   JavaScript AST; the subtyping constraints are themselves solved in module
   Flow_js. It also manages environments, including not only the maintenance of
   scope information for every function (pushing/popping scopes, looking up
   variables) but also flow-sensitive information about local variables at every
   point inside a function (and when to narrow or widen their types). *)

module Flow = Flow_js
open Utils_js
open Reason
open Type
open TypeUtil

module Make
    (Env : Env_sig.S)
    (Destructuring : Destructuring_sig.S)
    (Func_stmt_config : Func_stmt_config_sig.S)
    (Statement : Statement_sig.S with module Env := Env) : Statement_sig.S with module Env := Env =
struct
  module Abnormal = Abnormal.Make (Env)
  module Anno = Type_annotation.Make (Env) (Abnormal) (Statement)
  module Class_type_sig = Anno.Class_type_sig
  module Toplevels = Toplevels.DependencyToplevels (Env) (Abnormal)
  module Refinement = Refinement.Make (Env)
  module Import_export = Import_export.Make (Env)
  open Env_sig.LookupMode

  (*************)
  (* Utilities *)
  (*************)

  type class_member_kind =
    | Class_Member_Field
    | Class_Member_Getter
    | Class_Member_GetterSetter
    | Class_Member_Method
    | Class_Member_Setter

  type seen_names = {
    static_names: class_member_kind SMap.t;
    instance_names: class_member_kind SMap.t;
  }

  let empty_seen_names = { static_names = SMap.empty; instance_names = SMap.empty }

  (* We use this function to indicate places where an annotation is potentially available but
   * must be decomposed in some way before it is passed down *)
  let hint_decompose_opt_todo (x : Type.t option) : Type.t option = x

  let hint_of_type (t : Type.t) = Some t

  let hint_of_loc_todo loc = Some (AnyT.at (AnyError None) loc)

  module ObjectExpressionAcc = struct
    type element =
      | Spread of Type.t
      | Slice of { slice_pmap: Type.Properties.t }

    type t = {
      obj_pmap: Type.Properties.t;
      tail: element list;
      proto: Type.t option;
      obj_sealed: bool;
      obj_key_autocomplete: bool;
    }

    let empty ~allow_sealed =
      {
        obj_pmap = NameUtils.Map.empty;
        tail = [];
        proto = None;
        obj_sealed = allow_sealed;
        obj_key_autocomplete = false;
      }

    let empty_slice = Slice { slice_pmap = NameUtils.Map.empty }

    let head_slice { obj_pmap; _ } =
      if NameUtils.Map.is_empty obj_pmap then
        None
      else
        Some (Slice { slice_pmap = obj_pmap })

    let add_prop f acc = { acc with obj_pmap = f acc.obj_pmap }

    let add_proto p acc = { acc with proto = Some p }

    let add_spread t acc =
      let tail =
        match head_slice acc with
        | None -> acc.tail
        | Some slice -> slice :: acc.tail
      in
      { acc with obj_pmap = NameUtils.Map.empty; tail = Spread t :: tail }

    let set_seal ~allow_sealed sealed acc = { acc with obj_sealed = allow_sealed && sealed }

    let sealed acc = acc.obj_sealed

    let set_obj_key_autocomplete acc = { acc with obj_key_autocomplete = true }

    let obj_key_autocomplete acc = acc.obj_key_autocomplete

    let elements_rev acc =
      match head_slice acc with
      | Some slice -> (slice, acc.tail)
      | None ->
        (match acc.tail with
        | [] -> (empty_slice, [])
        | x :: xs -> (x, xs))

    let proto { proto; _ } = proto

    let mk_object_from_spread_acc cx acc reason ~frozen ~default_proto ~empty_unsealed =
      let sealed = sealed acc in
      match elements_rev acc with
      | (Slice { slice_pmap }, []) ->
        let sealed = sealed && not (NameUtils.Map.is_empty slice_pmap && empty_unsealed) in
        let proto = Base.Option.value ~default:default_proto (proto acc) in
        let obj_kind =
          if sealed || frozen || obj_key_autocomplete acc then
            Exact
          else
            UnsealedInFile (ALoc.source (Reason.aloc_of_reason reason))
        in
        let obj_t = Obj_type.mk_with_proto cx reason ~obj_kind ~frozen ~props:slice_pmap proto in
        if obj_key_autocomplete acc then
          Tvar.mk_where cx reason (fun tvar -> Flow_js.flow_t cx (obj_t, tvar))
        else
          obj_t
      | os ->
        let (t, ts, head_slice) =
          let (t, ts) = os in
          (* We don't need to do this recursively because every pair of slices must be separated
           * by a spread *)
          match (t, ts) with
          | (Spread t, ts) ->
            let ts =
              Base.List.map
                ~f:(function
                  | Spread t -> Object.Spread.Type t
                  | Slice { slice_pmap } ->
                    Object.Spread.Slice
                      {
                        Object.Spread.reason;
                        prop_map = slice_pmap;
                        dict = None;
                        generics = Generic.spread_empty;
                      })
                ts
            in
            (t, ts, None)
          | (Slice { slice_pmap = prop_map }, Spread t :: ts) ->
            let head_slice =
              { Type.Object.Spread.reason; prop_map; dict = None; generics = Generic.spread_empty }
            in
            let ts =
              Base.List.map
                ~f:(function
                  | Spread t -> Object.Spread.Type t
                  | Slice { slice_pmap } ->
                    Object.Spread.Slice
                      {
                        Object.Spread.reason;
                        prop_map = slice_pmap;
                        dict = None;
                        generics = Generic.spread_empty;
                      })
                ts
            in
            (t, ts, Some head_slice)
          | _ -> failwith ""Invariant Violation: spread list has two slices in a row""
        in
        let seal = Obj_type.mk_seal reason ~sealed ~frozen in
        let target = Object.Spread.Value { make_seal = seal } in
        let tool = Object.Resolve Object.Next in
        let state =
          {
            Object.Spread.todo_rev = ts;
            acc =
              Base.Option.value_map
                ~f:(fun x -> [Object.Spread.InlineSlice x])
                ~default:[]
                head_slice;
            spread_id = Reason.mk_id ();
            union_reason = None;
            curr_resolve_idx = 0;
          }
        in
        let tout = Tvar.mk cx reason in
        let use_op = Op (ObjectSpread { op = reason }) in
        let l = Flow.widen_obj_type cx ~use_op reason t in
        Flow.flow cx (l, ObjKitT (use_op, reason, tool, Type.Object.Spread (target, state), tout));
        tout
  end

  let ident_name = Flow_ast_utils.name_of_ident

  let mk_ident ~comments name = { Ast.Identifier.name; comments }

  let snd_fst ((_, x), _) = x

  let inference_hook_tvar cx ploc =
    let r = mk_annot_reason (AnyT.desc (Unsound InferenceHooks)) ploc in
    let tvar = Tvar.mk_no_wrap cx r in
    Flow.flow
      cx
      ( OpenT (r, tvar),
        BecomeT { reason = r; t = Unsoundness.at InferenceHooks ploc; empty_success = true }
      );
    (r, tvar)

  let translate_identifier_or_literal_key t =
    let open Ast.Expression.Object in
    function
    | Property.Identifier (loc, name) -> Property.Identifier ((loc, t), name)
    | Property.Literal (loc, lit) -> Property.Literal ((loc, t), lit)
    | Property.PrivateName _
    | Property.Computed _ ->
      assert_false ""precondition not met""

  let is_call_to_invariant callee =
    match callee with
    | (_, Ast.Expression.Identifier (_, { Ast.Identifier.name = ""invariant""; _ })) -> true
    | _ -> false

  let convert_call_targs =
    let open Ast.Expression.CallTypeArg in
    let rec loop ts tasts cx tparams_map = function
      | [] -> (List.rev ts, List.rev tasts)
      | ast :: asts ->
        begin
          match ast with
          | Explicit ast ->
            let (((_, t), _) as tast) = Anno.convert cx tparams_map ast in
            loop (ExplicitArg t :: ts) (Explicit tast :: tasts) cx tparams_map asts
          | Implicit (loc, impl) ->
            let reason = mk_reason RImplicitInstantiation loc in
            let id = Tvar.mk_no_wrap cx reason in
            loop
              (ImplicitArg (reason, id) :: ts)
              (Implicit ((loc, OpenT (reason, id)), impl) :: tasts)
              cx
              tparams_map
              asts
        end
    in
    fun cx tparams_map call_targs ->
      let open Ast.Expression.CallTypeArgs in
      let { arguments; comments } = call_targs in
      let (ts, tasts) = loop [] [] cx tparams_map arguments in
      (ts, { arguments = tasts; comments })

  let convert_call_targs_opt cx = function
    | None -> (None, None)
    | Some (loc, args) ->
      let (targts, targs_ast) = convert_call_targs cx Subst_name.Map.empty args in
      (Some targts, Some (loc, targs_ast))

  class return_finder =
    object (this)
      inherit [bool, ALoc.t] Flow_ast_visitor.visitor ~init:false as super

      method! return _ node =
        (* TODO we could pass over `return;` since it's definitely returning `undefined`. It will likely
         * reposition existing errors from the `return;` to the location of the type annotation. *)
        this#set_acc true;
        node

      method! call _loc expr =
        if is_call_to_invariant Ast.Expression.Call.(expr.callee) then this#set_acc true;
        expr

      method! throw _loc stmt =
        this#set_acc true;
        stmt

      method! function_body_any body =
        begin
          match body with
          (* If it's a body expression, some value is implicitly returned *)
          | Flow_ast.Function.BodyExpression _ -> this#set_acc true
          | _ -> ()
        end;
        super#function_body_any body

      (* Any returns in these constructs would be for nested function definitions, so we short-circuit
     *)
      method! class_ _ x = x

      method! function_declaration _ x = x
    end

  let might_have_nonvoid_return loc function_ast =
    let finder = new return_finder in
    finder#eval (finder#function_ loc) function_ast

  module ALoc_this_finder = This_finder.Make (Loc_collections.ALocSet)

  let error_on_this_uses_in_object_methods cx =
    let open Ast in
    let open Expression in
    Base.List.iter ~f:(function
        | Object.Property (prop_loc, Object.Property.Method { key; value = (_, func); _ }) ->
          let finder = new ALoc_this_finder.finder in
          finder#eval (finder#function_ prop_loc) func
          |> Loc_collections.ALocSet.iter (fun loc ->
                 let reason =
                   match key with
                   | Object.Property.Identifier (_, { Identifier.name; _ })
                   | Object.Property.PrivateName (_, { PrivateName.name; _ })
                   | Object.Property.Literal (_, { Literal.raw = name; _ }) ->
                     mk_reason (RMethod (Some name)) prop_loc
                   | _ -> mk_reason (RMethod None) prop_loc
                 in
                 Flow_js.add_output cx (Error_message.EObjectThisReference (loc, reason))
             )
        | _ -> ()
        )

  module Func_stmt_params = Func_params.Make (Func_stmt_config)
  module Func_stmt_sig = Func_sig.Make (Env) (Abnormal) (Statement) (Func_stmt_params)
  module Class_stmt_sig = Class_sig.Make (Env) (Abnormal) (Func_stmt_sig)

  (* In positions where an annotation may be present or an annotation can be pushed down,
   * we should prefer the annotation over the pushed-down annotation. *)
  let mk_inference_target_with_annots annot_or_inferred local_annot =
    match (annot_or_inferred, local_annot) with
    | (Annotated _, _) -> annot_or_inferred
    | (_, Some _) ->
      (* TODO: When we actually pass types down, we should create a type annotation
       * here *)
      let _t' = hint_decompose_opt_todo local_annot in
      Annotated (type_t_of_annotated_or_inferred annot_or_inferred)
    | _ -> annot_or_inferred

  (************)
  (* Visitors *)
  (************)

  (********************************************************************
   * local inference preliminary pass: traverse AST, collecting
   * declarations and populating variable environment (scope stack)
   * in prep for main pass
   ********************************************************************)

  let rec variable_decl cx { Ast.Statement.VariableDeclaration.kind; declarations; comments = _ } =
    let bind =
      match kind with
      | Ast.Statement.VariableDeclaration.Const -> Env.bind_const
      | Ast.Statement.VariableDeclaration.Let -> Env.bind_let
      | Ast.Statement.VariableDeclaration.Var -> Env.bind_var
    in
    Flow_ast_utils.fold_bindings_of_variable_declarations
      (fun has_anno () (loc, { Ast.Identifier.name; comments = _ }) ->
        let reason = mk_reason (RIdentifier (OrdinaryName name)) loc in
        let t =
          let tvar = Tvar.mk cx reason in
          if has_anno then
            Annotated tvar
          else
            Inferred tvar
        in
        bind cx name t loc)
      ()
      declarations

  and toplevel_decls cx = List.iter (statement_decl cx)

  (* TODO: detect structural misuses abnormal control flow constructs *)
  and statement_decl cx =
    let open Ast.Statement in
    let block_body cx { Block.body; comments = _ } =
      Env.in_lex_scope (fun () -> toplevel_decls cx body)
    in
    let catch_clause cx { Try.CatchClause.body = (_, b); _ } = block_body cx b in
    let function_ ~bind function_loc { Ast.Function.id; async; generator; _ } =
      let handle_named_function name_loc name =
        let r = func_reason ~async ~generator name_loc in
        let tvar = Tvar.mk cx r in
        bind cx name tvar name_loc
      in
      match id with
      | Some (name_loc, { Ast.Identifier.name; comments = _ }) ->
        handle_named_function name_loc (OrdinaryName name)
      | None -> handle_named_function function_loc (internal_name ""*default*"")
    in
    function
    | (_, Empty _) -> ()
    | (_, Block b) -> block_body cx b
    | (_, Expression _) -> ()
    | (_, If { If.consequent; alternate; _ }) ->
      statement_decl cx consequent;
      (match alternate with
      | None -> ()
      | Some (_, { If.Alternate.body; comments = _ }) -> statement_decl cx body)
    | (_, Labeled { Labeled.body; _ }) -> statement_decl cx body
    | (_, Break _) -> ()
    | (_, Continue _) -> ()
    | (_, With _) ->
      (* TODO disallow or push vars into env? *)
      ()
    | (_, DeclareTypeAlias { TypeAlias.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ })
    | (_, TypeAlias { TypeAlias.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ }) ->
      let r = DescFormat.type_reason (OrdinaryName name) name_loc in
      let tvar = Tvar.mk cx r in
      Env.bind_type cx name tvar name_loc
    | (_, DeclareOpaqueType { OpaqueType.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ })
    | (_, OpaqueType { OpaqueType.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ }) ->
      let r = DescFormat.type_reason (OrdinaryName name) name_loc in
      let tvar = Tvar.mk cx r in
      Env.bind_type cx name tvar name_loc
    | (_, Switch { Switch.cases; _ }) ->
      Env.in_lex_scope (fun () ->
          cases |> List.iter (fun (_, { Switch.Case.consequent; _ }) -> toplevel_decls cx consequent)
      )
    | (_, Return _) -> ()
    | (_, Throw _) -> ()
    | (_, Try { Try.block = (_, b); handler; finalizer; comments = _ }) ->
      block_body cx b;

      (match handler with
      | None -> ()
      | Some (_, h) -> catch_clause cx h);

      (match finalizer with
      | None -> ()
      | Some (_, b) -> block_body cx b)
    | (_, While { While.body; _ }) -> statement_decl cx body
    | (_, DoWhile { DoWhile.body; _ }) -> statement_decl cx body
    | (_, For { For.init; body; _ }) ->
      Env.in_lex_scope (fun () ->
          (match init with
          | Some (For.InitDeclaration (_, decl)) -> variable_decl cx decl
          | _ -> ());
          statement_decl cx body
      )
    | (_, ForIn { ForIn.left; body; _ }) ->
      Env.in_lex_scope (fun () ->
          (match left with
          | ForIn.LeftDeclaration (_, decl) -> variable_decl cx decl
          | _ -> ());
          statement_decl cx body
      )
    | (_, ForOf { ForOf.left; body; _ }) ->
      Env.in_lex_scope (fun () ->
          (match left with
          | ForOf.LeftDeclaration (_, decl) -> variable_decl cx decl
          | _ -> ());
          statement_decl cx body
      )
    | (_, Debugger _) -> ()
    | (function_loc, FunctionDeclaration func) -> function_ ~bind:Env.bind_fun function_loc func
    | (_, EnumDeclaration { EnumDeclaration.id = (name_loc, { Ast.Identifier.name; _ }); _ }) ->
      if Context.enable_enums cx then
        let r = DescFormat.type_reason (OrdinaryName name) name_loc in
        let tvar = Tvar.mk cx r in
        Env.bind_implicit_const Scope.Entry.EnumNameBinding cx name (Annotated tvar) name_loc
    | ( _,
        DeclareVariable { DeclareVariable.id = (id_loc, { Ast.Identifier.name; comments = _ }); _ }
      ) ->
      let r = mk_reason (RIdentifier (OrdinaryName name)) id_loc in
      let t = Tvar.mk cx r in
      Env.bind_declare_var cx (OrdinaryName name) t id_loc
    | ( loc,
        DeclareFunction
          ( { DeclareFunction.id = (id_loc, { Ast.Identifier.name; comments = _ }); _ } as
          declare_function
          )
      ) ->
      (match declare_function_to_function_declaration cx loc declare_function with
      | Some (FunctionDeclaration func, _) ->
        function_ ~bind:(Env.bind_declare_fun ~predicate:true) loc func
      | _ ->
        let r = mk_reason (RIdentifier (OrdinaryName name)) id_loc in
        let t = Tvar.mk cx r in
        Env.bind_declare_fun cx ~predicate:false (OrdinaryName name) t id_loc)
    | (_, VariableDeclaration decl) -> variable_decl cx decl
    | (_, ClassDeclaration { Ast.Class.id = None; _ }) -> ()
    | (_, ClassDeclaration { Ast.Class.id = Some id; _ }) ->
      let (name_loc, { Ast.Identifier.name; comments = _ }) = id in
      let name = OrdinaryName name in
      let reason = mk_reason (RType name) name_loc in
      let tvar = Tvar.mk cx reason in
      Env.bind_implicit_let Scope.Entry.ClassNameBinding cx name (Inferred tvar) name_loc
    | ( (_, DeclareClass { DeclareClass.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ })
      | (_, DeclareInterface { Interface.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ })
      | ( _,
          InterfaceDeclaration
            { Interface.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ }
        ) ) as stmt ->
      let is_interface =
        match stmt with
        | (_, DeclareInterface _) -> true
        | (_, InterfaceDeclaration _) -> true
        | _ -> false
      in
      let r = mk_reason (RType (OrdinaryName name)) name_loc in
      let tvar = Tvar.mk cx r in
      (* interface is a type alias, declare class is a var *)
      if is_interface then
        Env.bind_type cx name tvar name_loc
      else
        Env.bind_declare_var cx (OrdinaryName name) tvar name_loc
    | (loc, DeclareModule { DeclareModule.id; _ }) ->
      let name =
        match id with
        | DeclareModule.Identifier (_, { Ast.Identifier.name = value; comments = _ })
        | DeclareModule.Literal (_, { Ast.StringLiteral.value; _ }) ->
          value
      in
      let r = mk_reason (RModule (OrdinaryName name)) loc in
      let t = Tvar.mk cx r in
      Env.bind_declare_var cx (internal_module_name name) t loc
    | (_, DeclareExportDeclaration { DeclareExportDeclaration.default; declaration; _ }) ->
      DeclareExportDeclaration.(
        (match declaration with
        | Some (Variable (loc, v)) -> statement_decl cx (loc, DeclareVariable v)
        | Some (Function (loc, f)) -> statement_decl cx (loc, DeclareFunction f)
        | Some (Class (loc, c)) -> statement_decl cx (loc, DeclareClass c)
        | Some (DefaultType _) -> ()
        | Some (NamedType (loc, t)) -> statement_decl cx (loc, TypeAlias t)
        | Some (NamedOpaqueType (loc, t)) -> statement_decl cx (loc, OpaqueType t)
        | Some (Interface (loc, i)) -> statement_decl cx (loc, InterfaceDeclaration i)
        | None ->
          if Base.Option.is_none default then
            ()
          else
            failwith
              (""Parser Error: declare export default must always have an ""
              ^ ""associated declaration or type!""
              ))
      )
    | (_, DeclareModuleExports _) -> ()
    | (_, ExportNamedDeclaration { ExportNamedDeclaration.declaration; _ }) ->
      (match declaration with
      | Some stmt -> statement_decl cx stmt
      | None -> ())
    | (_, ExportDefaultDeclaration { ExportDefaultDeclaration.declaration; _ }) ->
      (match declaration with
      | ExportDefaultDeclaration.Declaration stmt -> statement_decl cx stmt
      | ExportDefaultDeclaration.Expression _ -> ())
    | ( decl_loc,
        ImportDeclaration
          { ImportDeclaration.import_kind; specifiers; default; source = _; comments = _ }
      ) ->
      let isType =
        match import_kind with
        | ImportDeclaration.ImportType -> true
        | ImportDeclaration.ImportTypeof -> true
        | ImportDeclaration.ImportValue -> false
      in
      let is_global_lib_scope = File_key.is_lib_file (Context.file cx) && Env.in_global_scope () in
      if is_global_lib_scope then
        Flow_js.add_output cx Error_message.(EToplevelLibraryImport decl_loc);
      let bind_import local_name (loc : ALoc.t) isType =
        let reason =
          if isType then
            DescFormat.type_reason (OrdinaryName local_name) loc
          else
            mk_reason (RIdentifier (OrdinaryName local_name)) loc
        in
        let t =
          if is_global_lib_scope then
            AnyT.error reason
          else
            Tvar.mk cx reason
        in
        if isType then
          Env.bind_import_type cx local_name t loc
        else
          Env.bind_import cx local_name t loc
      in
      Base.Option.iter ~f:(fun local -> bind_import (ident_name local) (fst local) isType) default;

      Base.Option.iter
        ~f:(function
          | ImportDeclaration.ImportNamespaceSpecifier (_, local) ->
            bind_import (ident_name local) (fst local) isType
          | ImportDeclaration.ImportNamedSpecifiers named_specifiers ->
            List.iter
              (fun { ImportDeclaration.local; remote; kind } ->
                let (loc, { Ast.Identifier.name = local_name; comments = _ }) =
                  Base.Option.value ~default:remote local
                in
                let isType =
                  isType
                  ||
                  match kind with
                  | None -> isType
                  | Some kind ->
                    kind = ImportDeclaration.ImportType || kind = ImportDeclaration.ImportTypeof
                in
                bind_import local_name loc isType)
              named_specifiers)
        specifiers

  (***************************************************************
   * local inference main pass: visit AST statement list, calling
   * flow to check types/create graphs for merge-time checking
   ***************************************************************)

  (* can raise Abnormal.(Exn (Stmt _, _)) *)
  and statement cx : 'a -> (ALoc.t, ALoc.t * Type.t) Ast.Statement.t =
    let open Ast.Statement in
    let variables cx decls =
      VariableDeclaration.(
        let { declarations; kind; comments } = decls in
        let declarations =
          Base.List.map
            ~f:(fun (loc, { Declarator.id; init }) ->
              let (id, init) = variable cx kind id init in
              (loc, { Declarator.id; init }))
            declarations
        in
        { declarations; kind; comments }
      )
    in
    let check cx b =
      Abnormal.catch_stmts_control_flow_exception (fun () ->
          toplevel_decls cx b.Block.body;
          Toplevels.toplevels statement cx b.Block.body
      )
    in
    let catch_clause cx catch_clause =
      let { Try.CatchClause.param; body = (b_loc, b); comments } = catch_clause in
      let open Ast.Pattern in
      match param with
      | Some p ->
        (match p with
        | ( loc,
            Identifier
              {
                Identifier.name = (name_loc, ({ Ast.Identifier.name; comments = _ } as id));
                annot = Ast.Type.Missing mloc;
                optional;
              }
          ) ->
          let r = mk_reason (RCustom ""catch"") loc in
          let t = AnyT.why CatchAny r in
          let (stmts, abnormal_opt) =
            Env.in_lex_scope (fun () ->
                Scope.(
                  Env.bind_implicit_let
                    ~state:State.Initialized
                    Entry.(CatchParamBinding)
                    cx
                    (OrdinaryName name)
                    (Inferred t)
                    loc
                );

                check cx b
            )
          in
          ( {
              Try.CatchClause.param =
                Some
                  ( (loc, t),
                    Ast.Pattern.Identifier
                      {
                        Ast.Pattern.Identifier.name = ((name_loc, t), id);
                        annot = Ast.Type.Missing (mloc, t);
                        optional;
                      }
                  );
              body = (b_loc, { Block.body = stmts; comments = b.Block.comments });
              comments;
            },
            abnormal_opt
          )
        | (loc, Identifier _) ->
          Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, CatchParameterAnnotation));
          (Tast_utils.error_mapper#catch_clause catch_clause, None)
        | (loc, _) ->
          Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, CatchParameterDeclaration));
          (Tast_utils.error_mapper#catch_clause catch_clause, None))
      | None ->
        let (stmts, abnormal_opt) = Env.in_lex_scope (fun () -> check cx b) in
        ( {
            Try.CatchClause.param = None;
            body = (b_loc, { Block.body = stmts; comments = b.Block.comments });
            comments;
          },
          abnormal_opt
        )
    in
    let function_ loc func =
      match func with
      | { Ast.Function.id = None; _ } -> failwith ""unexpected anonymous function statement""
      | { Ast.Function.id = Some id; _ } ->
        let { Ast.Function.sig_loc; async; generator; _ } = func in
        let (name_loc, { Ast.Identifier.name; comments = _ }) = id in
        let name = OrdinaryName name in
        let reason = func_reason ~async ~generator sig_loc in
        let general =
          Tvar.mk_where cx reason (Env.unify_declared_type ~is_func:true cx name name_loc)
        in
        let (fn_type, func_ast) = mk_function_declaration cx ~general reason func in
        (fn_type, id, (loc, FunctionDeclaration func_ast))
    in
    function
    | (_, Empty _) as stmt -> stmt
    | (loc, Block { Block.body; comments }) ->
      let (body, abnormal_opt) =
        Abnormal.catch_stmts_control_flow_exception (fun () ->
            Env.in_lex_scope (fun () ->
                toplevel_decls cx body;
                Toplevels.toplevels statement cx body
            )
        )
      in
      Abnormal.check_stmt_control_flow_exception
        ((loc, Block { Block.body; comments }), abnormal_opt)
    | (loc, Expression { Expression.expression = e; directive; comments }) ->
      (loc, Expression { Expression.expression = expression cx ~hint:None e; directive; comments })
    (* Refinements for `if` are derived by the following Hoare logic rule:

       [Pre & c] S1 [Post1]
       [Pre & ~c] S2 [Post2]
       Post = Post1 | Post2
       ----------------------------
       [Pre] if c S1 else S2 [Post]
    *)
    | (loc, If { If.test; consequent; alternate; comments }) ->
      let (loc_test, _) = test in
      let (test_ast, preds, not_preds, xts) = predicates_of_condition cx ~cond:OtherTest test in
      (* grab a reference to the incoming env -
         we'll restore it and merge branched envs later *)
      let start_env = Env.peek_env () in
      let oldset = Changeset.Global.clear () in
      (* swap in a refined clone of initial env for then *)
      Env.(
        update_env loc (clone_env start_env);
        ignore (refine_with_preds cx loc_test preds xts)
      );

      let (then_ast, then_abnormal) =
        Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx consequent)
      in
      (* grab a reference to env after then branch *)
      let then_env = Env.peek_env () in
      (* then swap in a refined clone of initial env for else *)
      Env.(
        update_env loc (clone_env start_env);
        ignore (refine_with_preds cx loc_test not_preds xts)
      );

      let (else_ast, else_abnormal) =
        match alternate with
        | None -> (None, None)
        | Some (loc, { If.Alternate.body; comments }) ->
          let (body_ast, else_abnormal) =
            Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
          in
          (Some (loc, { If.Alternate.body = body_ast; comments }), else_abnormal)
      in
      (* grab a reference to env after else branch *)
      let else_env = Env.peek_env () in
      (* snapshot if-else changes and merge old changes back into state *)
      let newset = Changeset.Global.merge oldset in
      (* adjust post-if environment. if we've returned from one arm,
         swap in the env generated by the other, otherwise merge *)
      let end_env =
        match (then_abnormal, else_abnormal) with
        | (Some Abnormal.Return, None)
        | (Some Abnormal.Throw, None) ->
          else_env
        | (None, Some Abnormal.Return)
        | (None, Some Abnormal.Throw) ->
          then_env
        | (None, Some _)
        | (Some _, None)
        | (Some _, Some _) ->
          Env.merge_env cx loc (start_env, then_env, else_env) newset;
          start_env
        | (None, None) ->
          (* if neither branch has abnormal flow, then refinements that happen in
             the branches should be forgotten since the original type covers
             all of the options. *)
          Env.merge_env cx loc (start_env, then_env, else_env) (Changeset.exclude_refines newset);
          start_env
      in
      Env.update_env loc end_env;

      let ast =
        (loc, If { If.test = test_ast; consequent = then_ast; alternate = else_ast; comments })
      in
      (* handle control flow in cases where we've thrown from both sides *)
      begin
        match (then_abnormal, else_abnormal) with
        | (Some Abnormal.Throw, Some Abnormal.Return)
        | (Some Abnormal.Return, Some Abnormal.Throw) ->
          Abnormal.throw_stmt_control_flow_exception ast Abnormal.Return
        | (Some then_exn, Some else_exn) when then_exn = else_exn ->
          Abnormal.throw_stmt_control_flow_exception ast then_exn
        | (Some (Abnormal.Break then_opt_label), Some (Abnormal.Continue else_opt_label))
        | (Some (Abnormal.Continue then_opt_label), Some (Abnormal.Break else_opt_label))
          when then_opt_label = else_opt_label ->
          Abnormal.throw_stmt_control_flow_exception ast (Abnormal.Continue then_opt_label)
        | _ -> ast
      end
    | ( top_loc,
        Labeled
          { Labeled.label = (_, { Ast.Identifier.name; comments = _ }) as lab_ast; body; comments }
      ) ->
      (match body with
      | (loc, While _)
      | (loc, DoWhile _)
      | (loc, For _)
      | (loc, ForIn _) ->
        let oldset = Changeset.Global.clear () in
        let label = Some name in
        let save_break = Abnormal.clear_saved (Abnormal.Break label) in
        let save_continue = Abnormal.clear_saved (Abnormal.Continue label) in
        let env = Env.peek_env () in
        Env.widen_env cx loc;

        let loop_env = Env.clone_env env in
        Env.update_env loc loop_env;

        let (body_ast, body_abnormal) =
          Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
          |> Abnormal.ignore_break_or_continue_to_label label
        in
        let ast = (top_loc, Labeled { Labeled.label = lab_ast; body = body_ast; comments }) in
        ignore
          ( Abnormal.check_stmt_control_flow_exception (ast, body_abnormal)
            : (ALoc.t, ALoc.t * Type.t) Ast.Statement.t
            );

        let newset = Changeset.Global.merge oldset in
        if Abnormal.swap_saved (Abnormal.Continue label) save_continue <> None then
          Env.havoc_vars newset;

        Env.copy_env cx loc (env, loop_env) newset;

        if Abnormal.swap_saved (Abnormal.Break label) save_break <> None then Env.havoc_vars newset;

        ast
      | _ ->
        let oldset = Changeset.Global.clear () in
        let label = Some name in
        let save_break = Abnormal.clear_saved (Abnormal.Break label) in
        let (body_ast, body_abnormal) =
          Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
          |> Abnormal.ignore_break_to_label label
        in
        let ast = (top_loc, Labeled { Labeled.label = lab_ast; body = body_ast; comments }) in
        ignore
          ( Abnormal.check_stmt_control_flow_exception (ast, body_abnormal)
            : (ALoc.t, ALoc.t * Type.t) Ast.Statement.t
            );

        let newset = Changeset.Global.merge oldset in
        if Abnormal.swap_saved (Abnormal.Break label) save_break <> None then Env.havoc_vars newset;

        ast)
    | (loc, Break { Break.label; comments }) ->
      (* save environment at unlabeled breaks, prior to activation clearing *)
      let (label_opt, env, label_ast) =
        match label with
        | None -> (None, Env.(clone_env (peek_env ())), None)
        | Some ((_, { Ast.Identifier.name; comments = _ }) as lab_ast) ->
          (Some name, [], Some lab_ast)
      in
      Env.reset_current_activation loc;
      let ast = (loc, Break { Break.label = label_ast; comments }) in
      let abnormal = Abnormal.Break label_opt in
      Abnormal.save abnormal ~env;
      Abnormal.throw_stmt_control_flow_exception ast abnormal
    | (loc, Continue { Continue.label; comments }) ->
      let (label_opt, label_ast) =
        match label with
        | None -> (None, None)
        | Some ((_, { Ast.Identifier.name; comments = _ }) as lab_ast) -> (Some name, Some lab_ast)
      in
      Env.reset_current_activation loc;
      let ast = (loc, Continue { Continue.label = label_ast; comments }) in
      let abnormal = Abnormal.Continue label_opt in
      Abnormal.save abnormal;
      Abnormal.throw_stmt_control_flow_exception ast abnormal
    | (_, With _) as s ->
      (* TODO or disallow? *)
      Tast_utils.error_mapper#statement s
    | ( ( loc,
          DeclareTypeAlias
            ({ TypeAlias.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } as alias)
        )
      | ( loc,
          TypeAlias
            ({ TypeAlias.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } as alias)
        ) ) as stmt ->
      let (type_, type_alias_ast) = type_alias cx loc alias in
      Env.init_type cx name type_ name_loc;
      (match stmt with
      | (_, DeclareTypeAlias _) -> (loc, DeclareTypeAlias type_alias_ast)
      | (_, TypeAlias _) -> (loc, TypeAlias type_alias_ast)
      | _ -> assert false)
    | ( ( loc,
          DeclareOpaqueType
            ({ OpaqueType.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } as otype)
        )
      | ( loc,
          OpaqueType
            ({ OpaqueType.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } as otype)
        ) ) as stmt ->
      let (type_, opaque_type_ast) = opaque_type cx loc otype in
      Env.init_type cx name type_ name_loc;
      (match stmt with
      | (_, DeclareOpaqueType _) -> (loc, DeclareOpaqueType opaque_type_ast)
      | (_, OpaqueType _) -> (loc, OpaqueType opaque_type_ast)
      | _ -> assert false)
    (*******************************************************)
    | (switch_loc, Switch { Switch.discriminant; cases; comments }) ->
      (* typecheck discriminant *)
      let discriminant_ast = expression cx ~hint:None discriminant in
      let exhaustive_check_incomplete_out =
        Tvar.mk cx (mk_reason (RCustom ""exhaustive check incomplete out"") switch_loc)
      in
      (* switch body is a single lexical scope *)
      Env.in_lex_scope (fun () ->
          (* save incoming env state, clear changeset *)
          let incoming_changes = Changeset.Global.clear () in
          let incoming_env = Env.peek_env () in
          let incoming_depth = List.length incoming_env in
          (* set up all bindings *)
          cases |> List.iter (fun (_, { Switch.Case.consequent; _ }) -> toplevel_decls cx consequent);

          (* each case starts with this env - begins as clone of incoming_env
             plus bindings, also accumulates negative refis from case tests *)
          let case_start_env = Env.clone_env incoming_env in
          let update_switch_state current_state (case_env, case_writes, _, loc) =
            let case_env =
              (* keep the last `incoming_depth` items *)
              let to_drop = Base.List.length case_env - incoming_depth in
              Base.List.drop case_env to_drop
            in
            let state =
              match current_state with
              | None -> (case_env, Changeset.empty, case_writes)
              | Some (env, partial_writes, total_writes) ->
                let case_diff = Changeset.comp case_writes total_writes in
                let partial_writes = Changeset.union partial_writes case_diff in
                let total_writes = Changeset.inter case_writes total_writes in
                (* merge new case into switch env *)
                Env.merge_env cx loc (env, env, case_env) case_writes;
                (env, partial_writes, total_writes)
            in
            Some state
          in
          (* traverse case list, get list of control flow exits and list of ASTs *)
          let (exits_rev, cases_ast_rev, switch_state, fallthrough_case, has_default) =
            cases
            |> Base.List.fold_left
                 ~init:([], [], None, None, false)
                 ~f:(fun
                      (exits, cases_ast, switch_state, fallthrough_case, has_default)
                      (loc, { Switch.Case.test; consequent; comments })
                    ->
                   (* compute predicates implied by case expr or default *)
                   let (test_ast, preds, not_preds, xtypes) =
                     match test with
                     | None -> (None, Key_map.empty, Key_map.empty, Key_map.empty)
                     | Some expr ->
                       let open Ast.Expression in
                       let fake_discriminant =
                         match discriminant with
                         | (mem_loc, Member ({ Member._object = (_, x) as _object; _ } as mem))
                           when Base.Option.is_some (Refinement.key ~allow_optional:true _object) ->
                           (mem_loc, Member { mem with Member._object = (loc, x) })
                         | _ -> discriminant
                       in
                       let fake =
                         ( loc,
                           Binary
                             {
                               Binary.operator = Binary.StrictEqual;
                               left = fake_discriminant;
                               right = expr;
                               comments = None;
                             }
                         )
                       in
                       let case_test_reason = mk_reason (RCustom ""case test"") (fst expr) in
                       let switch_discriminant_reason =
                         mk_reason (RCustom ""switch discriminant"") (fst discriminant)
                       in
                       let ((_, fake_ast), preds, not_preds, xtypes) =
                         predicates_of_condition
                           cx
                           ~cond:(SwitchTest { case_test_reason; switch_discriminant_reason })
                           fake
                       in
                       let expr_ast =
                         match fake_ast with
                         | Ast.Expression.(Binary { Binary.right; _ }) -> right
                         | _ -> assert false
                       in
                       (Some expr_ast, preds, not_preds, xtypes)
                   in
                   (* swap in case's starting env and clear changeset *)
                   let case_env = Env.clone_env case_start_env in
                   Env.update_env loc case_env;
                   let save_changes = Changeset.Global.clear () in
                   (* add test refinements - save changelist for later *)
                   let test_refis = Env.refine_with_preds cx loc preds xtypes in
                   (* merge env changes from fallthrough case, if present *)
                   Base.Option.iter fallthrough_case ~f:(fun (env, writes, refis, _) ->
                       let changes = Changeset.union writes refis in
                       Env.merge_env cx loc (case_env, case_env, env) changes
                   );

                   (* process statements, track control flow exits: exit will be an
                      unconditional exit, break_opt will be any break *)
                   let save_break = Abnormal.clear_saved (Abnormal.Break None) in
                   let (consequent_ast, exit) =
                     Abnormal.catch_stmts_control_flow_exception (fun () ->
                         Toplevels.toplevels statement cx consequent
                     )
                   in
                   let break_opt = Abnormal.swap_saved (Abnormal.Break None) save_break in
                   (* restore ambient changes and save case writes *)
                   let case_writes =
                     Changeset.include_writes save_changes |> Changeset.Global.merge
                   in
                   (* track fallthrough to next case and/or break to switch end *)
                   let (falls_through, breaks_to_end) =
                     match exit with
                     | Some Abnormal.Throw
                     | Some Abnormal.Return
                     | Some (Abnormal.Break (Some _))
                     | Some (Abnormal.Continue _) ->
                       (false, false)
                     | Some (Abnormal.Break None) -> (false, true)
                     | None -> (true, Base.Option.is_some break_opt)
                   in
                   (* save state for fallthrough *)
                   let fallthrough_case =
                     if falls_through then
                       Some (case_env, case_writes, test_refis, loc)
                     else
                       None
                   in

                   (* if we break to end, add effects to terminal state *)
                   let switch_state =
                     if breaks_to_end then
                       match break_opt with
                       | None ->
                         Flow.add_output cx Error_message.(EInternal (loc, BreakEnvMissingForCase));
                         switch_state
                       | Some break_env ->
                         update_switch_state switch_state (break_env, case_writes, test_refis, loc)
                     else
                       switch_state
                   in

                   (* add negative refis of this case's test to common start env *)
                   (* TODO add API to do this without having to swap in env *)
                   Env.update_env loc case_start_env;
                   let _ = Env.refine_with_preds cx loc not_preds xtypes in
                   ( exit :: exits,
                     (loc, { Switch.Case.test = test_ast; consequent = consequent_ast; comments })
                     :: cases_ast,
                     switch_state,
                     fallthrough_case,
                     has_default || Base.Option.is_none test
                   )
               )
          in
          let cases_ast = List.rev cases_ast_rev in
          let exits = List.rev exits_rev in
          (* If no default was present, record a write to maybe_exhaustively_checked and then update
           * the switch state to account for this write in the total/partial writes. We need to also
           * merge in the fallthrough case if one existed. *)
          let (switch_state, fallthrough_case) =
            if not has_default then (
              let case_env = Env.clone_env case_start_env in
              Env.update_env switch_loc case_env;
              let save_changes = Changeset.Global.clear () in
              Base.Option.iter fallthrough_case ~f:(fun (env, writes, refis, _) ->
                  let changes = Changeset.union writes refis in
                  Env.merge_env cx switch_loc (case_env, case_env, env) changes
              );
              if Base.Option.is_none fallthrough_case then
                Env.init_let
                  cx
                  ~use_op:unknown_use
                  (internal_name ""maybe_exhaustively_checked"")
                  ~has_anno:false
                  exhaustive_check_incomplete_out
                  (loc_of_t exhaustive_check_incomplete_out);
              let case_writes = Changeset.include_writes save_changes |> Changeset.Global.merge in
              (* If we handle the fallthrough case explicitly here then there is no need to merge
               * in those changes a second time. Instead, we set the fallthrough_case to None *)
              ( update_switch_state switch_state (case_env, case_writes, Changeset.empty, switch_loc),
                None
              )
            ) else
              (switch_state, fallthrough_case)
          in

          (* if last case fell out, update terminal switch state with it *)
          let switch_state =
            Base.Option.fold ~init:switch_state fallthrough_case ~f:update_switch_state
          in

          (* env in switch_state has accumulated switch effects. now merge in
             original types for partially written values, and swap env in *)
          Base.Option.iter switch_state ~f:(fun (env, partial_writes, _) ->
              Env.merge_env cx switch_loc (env, env, incoming_env) partial_writes;
              Env.update_env switch_loc env
          );

          (* merge original changeset back in *)
          let _ = Changeset.Global.merge incoming_changes in
          (* abnormal exit: if every case exits abnormally the same way (or falls
              through to a case that does), then the switch as a whole exits that way.
             (as with if/else, we merge `throw` into `return` when both appear) *)
          let uniform_switch_exit case_exits =
            let rec loop = function
              | (acc, fallthrough, []) ->
                (* end of cases: if nothing is falling through, we made it *)
                if fallthrough then
                  None
                else
                  acc
              | (_, _, Some (Abnormal.Break _) :: _) ->
                (* break wrecks everything *)
                None
              | (acc, _, None :: exits) ->
                (* begin or continue to fall through *)
                loop (acc, true, exits)
              | (acc, _, exit :: exits) when exit = acc ->
                (* current case exits the same way as prior cases *)
                loop (acc, acc = None, exits)
              | (Some Abnormal.Throw, _, Some Abnormal.Return :: exits)
              | (Some Abnormal.Return, _, Some Abnormal.Throw :: exits) ->
                (* fuzz throw into return *)
                loop (Some Abnormal.Return, false, exits)
              | (None, _, exit :: exits) ->
                (* terminate an initial sequence of fall-thruugh cases *)
                (* (later sequences will have acc = Some _ ) *)
                loop (exit, false, exits)
              | (_, _, _) ->
                (* the new case exits differently from previous ones - fail *)
                None
            in
            if has_default then
              loop (None, false, case_exits)
            else
              None
          in
          let enum_exhaustive_check = enum_exhaustive_check_of_switch_cases cases_ast in
          let ((_, discriminant_t), _) = discriminant_ast in
          let discriminant_after_check =
            if not has_default then
              let refinement_key = Refinement.key ~allow_optional:true discriminant in
              Env.discriminant_after_negated_cases cx switch_loc refinement_key discriminant
            else
              None
          in
          Flow.flow
            cx
            ( discriminant_t,
              EnumExhaustiveCheckT
                {
                  reason = reason_of_t discriminant_t;
                  check = enum_exhaustive_check;
                  incomplete_out = exhaustive_check_incomplete_out;
                  discriminant_after_check;
                }
            );
          let ast =
            ( switch_loc,
              Switch { Switch.discriminant = discriminant_ast; cases = cases_ast; comments }
            )
          in
          match uniform_switch_exit exits with
          | None -> ast
          | Some abnormal -> Abnormal.throw_stmt_control_flow_exception ast abnormal
      )
    (*******************************************************)
    | (loc, Return { Return.argument; comments }) ->
      let reason = mk_reason (RCustom ""return"") loc in
      let ret = Env.get_internal_var cx ""return"" loc in
      let (t, argument_ast) =
        match argument with
        | None -> (VoidT.at loc |> with_trust literal_trust, None)
        | Some expr ->
          if Env.in_predicate_scope () then
            let ((((_, t), _) as ast), p_map, n_map, _) =
              predicates_of_condition ~cond:OtherTest cx expr
            in
            let pred_reason = update_desc_reason (fun desc -> RPredicateOf desc) reason in
            (OpenPredT { reason = pred_reason; base_t = t; m_pos = p_map; m_neg = n_map }, Some ast)
          else
            let hint = Env.get_var_annotation cx (internal_name ""return"") loc in
            let (((_, t), _) as ast) = expression cx ~hint expr in
            (t, Some ast)
      in
      let t =
        match Env.var_scope_kind () with
        | Scope.Async ->
          (* Convert the return expression's type T to Promise<T>. If the
           * expression type is itself a Promise<T>, ensure we still return
           * a Promise<T> via Promise.resolve. *)
          let reason = mk_reason (RCustom ""async return"") loc in
          let t' =
            Flow.get_builtin_typeapp
              cx
              reason
              (OrdinaryName ""Promise"")
              [
                Tvar.mk_where cx reason (fun tvar ->
                    let funt = Flow.get_builtin cx (OrdinaryName ""$await"") reason in
                    let callt = mk_functioncalltype reason None [Arg t] (open_tvar tvar) in
                    let reason = repos_reason (aloc_of_reason (reason_of_t t)) reason in
                    Flow.flow cx (funt, CallT (unknown_use, reason, callt))
                );
              ]
          in
          Flow.reposition cx ~desc:(desc_of_t t) loc t'
        | Scope.Generator ->
          (* Convert the return expression's type R to Generator<Y,R,N>, where
           * Y and R are internals, installed earlier. *)
          let reason = mk_reason (RCustom ""generator return"") loc in
          let t' =
            Flow.get_builtin_typeapp
              cx
              reason
              (OrdinaryName ""Generator"")
              [
                Env.get_internal_var cx ""yield"" loc;
                Tvar.mk_where cx reason (fun tvar -> Flow.flow_t cx (t, tvar));
                Env.get_internal_var cx ""next"" loc;
              ]
          in
          Flow.reposition cx ~desc:(desc_of_t t) loc t'
        | Scope.AsyncGenerator ->
          let reason = mk_reason (RCustom ""async generator return"") loc in
          let t' =
            Flow.get_builtin_typeapp
              cx
              reason
              (OrdinaryName ""AsyncGenerator"")
              [
                Env.get_internal_var cx ""yield"" loc;
                Tvar.mk_where cx reason (fun tvar -> Flow.flow_t cx (t, tvar));
                Env.get_internal_var cx ""next"" loc;
              ]
          in
          Flow.reposition cx ~desc:(desc_of_t t) loc t'
        | _ -> t
      in
      let use_op =
        Op
          (FunReturnStatement
             {
               value =
                 Base.Option.value_map argument ~default:(reason_of_t t) ~f:mk_expression_reason;
             }
          )
      in
      Flow.flow cx (t, UseT (use_op, ret));
      Env.reset_current_activation loc;
      Abnormal.save Abnormal.Return;
      Abnormal.throw_stmt_control_flow_exception
        (loc, Return { Return.argument = argument_ast; comments })
        Abnormal.Return
    | (loc, Throw { Throw.argument; comments }) ->
      let argument_ast = expression cx ~hint:None argument in
      Env.reset_current_activation loc;
      Abnormal.save Abnormal.Throw;
      Abnormal.throw_stmt_control_flow_exception
        (loc, Throw { Throw.argument = argument_ast; comments })
        Abnormal.Throw
    (***************************************************************************)
    (* Try-catch-finally statements have a lot of control flow possibilities. (To
     simplify matters, a missing catch block is considered to to be a catch
     block that throws, and a missing finally block is considered to be an empty
     block.)

     A try block may either

     * exit normally: in this case, it proceeds to the finally block.

     * exit abnormally: in this case, it proceeds to the catch block.

     A catch block may either:

     * exit normally: in this case, it proceeds to the finally block.

     * exit abnormally: in this case, it proceeds to the finally block and
     throws at the end of the finally block.

     A finally block may either:

     * exit normally: in this case, the try-catch-finally statement exits
     normally. (Note that to be in this case, either the try block exited
     normally, or it didn't and the catch block exited normally.)

     * exit abnormally: in this case, the try-catch-finally statement exits
     abnormally.

     Based on these possibilities, approximations for the local state at various
     points in a try-catch-finally statement can be derived.

     * The start of a catch block is reachable via anywhere in the try
     block. Thus, the local state must be conservative.

     * The start of a finally block is reachable via the end of the try block,
     or anywhere in the catch block. Thus, the local state must be conservative.

     * The end of a try-catch-finally statement is reachable via the end of the
     finally block. However, in this case we can assume that either

     ** the try block exited normally, in which case the local state at the
     start of the finally block is the same as the local state at the end of the
     try block.

     ** the catch block exited normally, in which case the local state at the
     start of the finally block is the same as the local state at the end of
     the catch block.

     Thus, a finally block should be analyzed twice, with each of the following
     assumptions for the local state at its start: (1) conservative (to model
     abnormal exits in the try or catch blocks); (2) whatever is at the end of
     the try block merged with whatever is at the end of the catch block (for
     normal exits in the try and catch blocks).

     Important to understand: since (1) is conservative, it should produce
     errors whenever (2) does, so that's not why we do them separately.
     But since (2) models exactly the states from which subsequent code is
     reachable, we can use its tighter approximation as the basis for
     subsequent analysis without loss of soundness.
     *)
    (***************************************************************************)
    | (loc, Try { Try.block = (b_loc, b); handler; finalizer; comments }) ->
      let oldset = Changeset.Global.clear () in
      (* save ref to initial env and swap in a clone *)
      let start_env = Env.peek_env () in
      Env.(update_env loc (clone_env start_env));

      let (try_block_ast, try_abnormal) =
        Env.in_lex_scope (fun () ->
            Abnormal.catch_stmts_control_flow_exception (fun () ->
                toplevel_decls cx b.Block.body;
                Toplevels.toplevels statement cx b.Block.body
            )
        )
      in
      (* save ref to env at end of try *)
      let try_env = Env.peek_env () in
      (* traverse catch block, save exceptions *)
      let (catch_ast, catch_abnormal) =
        match handler with
        | None ->
          (* a missing catch is equivalent to a catch that always throws *)
          (None, Some Abnormal.Throw)
        | Some (h_loc, h) ->
          (* if try throws to here, we need an env that's conservative
             over everything that happened from start_env to try_env *)
          Env.(
            let e = clone_env start_env in
            merge_env cx loc (e, e, try_env) (Changeset.Global.peek ());
            update_env loc e
          );

          let (catch_block_ast, catch_abnormal) = catch_clause cx h in
          (Some (h_loc, catch_block_ast), catch_abnormal)
      in
      (* save ref to env at end of catch *)
      let catch_env = Env.peek_env () in
      (* build initial env for non-throwing finally *)
      let nonthrow_finally_env =
        Env.(
          match catch_abnormal with
          | None ->
            (* if catch ends normally, then non-throwing finally can be
               reached via it or a non-throwing try. merge terminal states *)
            let e = clone_env start_env in
            merge_env cx loc (e, try_env, catch_env) (Changeset.Global.peek ());
            e
          | Some _ ->
            (* if catch throws, then the only way into non-throwing finally
               is via non-throwing try *)
            try_env
        )
      in
      (* traverse finally block, save exceptions,
         and leave in place the terminal env of the non-throwing case
         (in which subsequent code is reachable) *)
      let (finally_ast, finally_abnormal) =
        match finalizer with
        | None ->
          Env.update_env loc nonthrow_finally_env;
          (None, None)
        | Some (f_loc, { Block.body; comments }) ->
          (* analyze twice, with different start states *)

          (* 1. throwing-finally case. *)
          (* env may be in any state from start of try through end of catch *)
          Env.(
            let e = clone_env start_env in
            merge_env cx loc (e, e, catch_env) (Changeset.Global.peek ());
            update_env loc e
          );

          let (_, finally_abnormal) =
            Env.in_lex_scope (fun () ->
                Abnormal.catch_stmts_control_flow_exception (fun () ->
                    toplevel_decls cx body;
                    Toplevels.toplevels statement cx body
                )
            )
          in
          (* 2. non-throwing finally case. *)
          Env.update_env loc nonthrow_finally_env;

          (* (exceptions will be the same in both cases) *)
          let (finally_block_ast, _) =
            Env.in_lex_scope (fun () ->
                Abnormal.catch_stmts_control_flow_exception (fun () ->
                    toplevel_decls cx body;
                    Toplevels.toplevels statement cx body
                )
            )
          in
          (Some (f_loc, { Block.body = finally_block_ast; comments }), finally_abnormal)
      in
      let newset = Changeset.Global.merge oldset in
      ignore newset;

      let ast =
        ( loc,
          Try
            {
              Try.block = (b_loc, { Block.body = try_block_ast; comments = b.Block.comments });
              handler = catch_ast;
              finalizer = finally_ast;
              comments;
            }
        )
      in
      (* if finally has abnormal control flow, we throw here *)
      ignore
        ( Abnormal.check_stmt_control_flow_exception (ast, finally_abnormal)
          : (ALoc.t, ALoc.t * Type.t) Ast.Statement.t
          );

      (* other ways we throw due to try/catch abends *)
      begin
        match (try_abnormal, catch_abnormal) with
        | (Some (Abnormal.Throw as try_abnormal), Some Abnormal.Throw)
        | (Some (Abnormal.Return as try_abnormal), Some _) ->
          Abnormal.throw_stmt_control_flow_exception ast try_abnormal
        | (Some Abnormal.Throw, Some (Abnormal.Return as catch_abnormal)) ->
          Abnormal.throw_stmt_control_flow_exception ast catch_abnormal
        | _ -> ast
      end
    (***************************************************************************)
    (* Refinements for `while` are derived by the following Hoare logic rule:

       [Pre' & c] S [Post']
       Pre' = Pre | Post'
       Post = Pre' & ~c
       ----------------------
       [Pre] while c S [Post]
    *)
    (***************************************************************************)
    | (loc, While { While.test; body; comments }) ->
      let save_break = Abnormal.clear_saved (Abnormal.Break None) in
      let save_continue = Abnormal.clear_saved (Abnormal.Continue None) in
      (* generate loop test preds and their complements *)
      let (test_ast, preds, not_preds, orig_types) =
        predicates_of_condition ~cond:OtherTest cx test
      in
      (* save current changeset and install an empty one *)
      let oldset = Changeset.Global.clear () in
      (* widen_env wraps specifics in tvars, anticipating widening inflows *)
      Env.widen_env cx loc;

      (* start_env is Pre above: env as of loop top *)
      let start_env = Env.peek_env () in
      (* swap in Pre & c *)
      Env.(
        update_env loc (clone_env start_env);
        ignore (refine_with_preds cx loc preds orig_types)
      );

      (* traverse loop body - after this, body_env = Post' *)
      let (body_ast, _) =
        Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
      in
      (* save ref to env after loop body *)
      let body_env = Env.peek_env () in
      (* save loop body changeset to newset, install merged changes *)
      let newset = Changeset.Global.merge oldset in
      (* if we continued out of the loop, havoc vars changed by loop body *)
      if Abnormal.swap_saved (Abnormal.Continue None) save_continue <> None then
        Env.havoc_vars newset;

      (* widen start_env with new specifics from body_env
         (turning Pre into Pre' = Pre | Post')
         then reinstall and add ~c to make Post *)
      Env.(
        copy_env cx loc (start_env, body_env) newset;
        update_env loc start_env;
        ignore (refine_with_preds cx loc not_preds orig_types)
      );

      (* if we broke out of the loop, havoc vars changed by loop body *)
      if Abnormal.swap_saved (Abnormal.Break None) save_break <> None then Env.havoc_vars newset;

      (loc, While { While.test = test_ast; body = body_ast; comments })
    (***************************************************************************)
    (* Refinements for `do-while` are derived by the following Hoare logic rule:

       [Pre'] S [Post']
       Pre' = Pre | (Post' & c)
       Post = Post' & ~c
       -------------------------
       [Pre] do S while c [Post]
    *)
    (***************************************************************************)
    | (loc, DoWhile { DoWhile.body; test; comments }) ->
      let save_break = Abnormal.clear_saved (Abnormal.Break None) in
      let save_continue = Abnormal.clear_saved (Abnormal.Continue None) in
      let env = Env.peek_env () in
      let oldset = Changeset.Global.clear () in
      (* env = Pre *)
      (* ENV = [env] *)
      Env.widen_env cx loc;

      (* env = Pre', Pre' > Pre *)
      let body_env = Env.clone_env env in
      Env.update_env loc body_env;

      (* body_env = Pre' *)
      (* ENV = [body_env] *)
      let (body_ast, body_abnormal) =
        Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
        |> Abnormal.ignore_break_or_continue_to_label None
      in
      if Abnormal.swap_saved (Abnormal.Continue None) save_continue <> None then
        Env.havoc_vars (Changeset.Global.peek ());

      let (test_ast, preds, not_preds, xtypes) = predicates_of_condition ~cond:OtherTest cx test in
      (* body_env = Post' *)
      let done_env = Env.clone_env body_env in
      (* done_env = Post' *)
      let _ = Env.refine_with_preds cx loc preds xtypes in
      (* body_env = Post' & c *)
      let newset = Changeset.Global.merge oldset in
      Env.copy_env cx loc (env, body_env) newset;

      (* Pre' > Post' & c *)
      Env.update_env loc done_env;
      let _ = Env.refine_with_preds cx loc not_preds xtypes in
      if Abnormal.swap_saved (Abnormal.Break None) save_break <> None then Env.havoc_vars newset;

      (* ENV = [done_env] *)
      (* done_env = Post' & ~c *)
      let ast = (loc, DoWhile { DoWhile.body = body_ast; test = test_ast; comments }) in
      Abnormal.check_stmt_control_flow_exception (ast, body_abnormal)
    (***************************************************************************)
    (* Refinements for `for` are derived by the following Hoare logic rule:

       [Pre] i [Init]
       [Pre' & c] S;u [Post']
       Pre' = Init | Post'
       Post = Pre' & ~c
       --------------------------
       [Pre] for (i;c;u) S [Post]

       NOTE: This rule is similar to that for `while`.
    *)
    (***************************************************************************)
    | (loc, For { For.init; test; update; body; comments }) ->
      Env.in_lex_scope (fun () ->
          let save_break = Abnormal.clear_saved (Abnormal.Break None) in
          let save_continue = Abnormal.clear_saved (Abnormal.Continue None) in
          let init_ast =
            match init with
            | None -> None
            | Some (For.InitDeclaration (decl_loc, decl)) ->
              variable_decl cx decl;
              Some (For.InitDeclaration (decl_loc, variables cx decl))
            | Some (For.InitExpression expr) ->
              Some (For.InitExpression (expression cx ~hint:None expr))
          in
          let env = Env.peek_env () in
          let oldset = Changeset.Global.clear () in
          Env.widen_env cx loc;

          let do_env = Env.clone_env env in
          Env.update_env loc do_env;

          let (test_ast, preds, not_preds, xtypes) =
            match test with
            | None ->
              (None, Key_map.empty, Key_map.empty, Key_map.empty) (* TODO: prune the ""not"" case *)
            | Some expr ->
              let (expr_ast, preds, not_preds, xtypes) =
                predicates_of_condition ~cond:OtherTest cx expr
              in
              (Some expr_ast, preds, not_preds, xtypes)
          in
          let body_env = Env.clone_env do_env in
          Env.update_env loc body_env;
          let _ = Env.refine_with_preds cx loc preds xtypes in
          let (body_ast, _) =
            Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
          in
          if Abnormal.swap_saved (Abnormal.Continue None) save_continue <> None then
            Env.havoc_vars (Changeset.Global.peek ());

          let update_ast = Base.Option.map ~f:(expression cx ~hint:None) update in
          let newset = Changeset.Global.merge oldset in
          Env.copy_env cx loc (do_env, body_env) newset;

          Env.update_env loc do_env;
          let _ = Env.refine_with_preds cx loc not_preds xtypes in
          if Abnormal.swap_saved (Abnormal.Break None) save_break <> None then Env.havoc_vars newset;

          ( loc,
            For
              {
                For.init = init_ast;
                test = test_ast;
                update = update_ast;
                body = body_ast;
                comments;
              }
          )
      )
    (***************************************************************************)
    (* Refinements for `for-in` are derived by the following Hoare logic rule:

       [Pre] o [Init]
       [Pre'] S [Post']
       Pre' = Init | Post'
       Post = Pre'
       --------------------------
       [Pre] for (i in o) S [Post]
    *)
    (***************************************************************************)
    | (loc, ForIn { ForIn.left; right; body; each; comments }) ->
      let reason = mk_reason (RCustom ""for-in"") loc in
      let save_break = Abnormal.clear_saved (Abnormal.Break None) in
      let save_continue = Abnormal.clear_saved (Abnormal.Continue None) in
      Env.in_lex_scope (fun () ->
          let env = Env.peek_env () in
          let oldset = Changeset.Global.clear () in
          Env.widen_env cx loc;

          let body_env = Env.clone_env env in
          Env.update_env loc body_env;

          let eval_right () =
            let ((((right_loc, _), _) as right_ast), preds, _, xtypes) =
              predicates_of_condition ~cond:OtherTest cx right
            in
            let (_ : Changeset.t) = Env.refine_with_preds cx right_loc preds xtypes in
            right_ast
          in
          let (left_ast, right_ast) =
            match left with
            | ForIn.LeftDeclaration
                ( decl_loc,
                  ( {
                      VariableDeclaration.kind;
                      declarations =
                        [(vdecl_loc, { VariableDeclaration.Declarator.id; init = None })];
                      comments;
                    } as decl
                  )
                ) ->
              variable_decl cx decl;
              let right_ast = eval_right () in
              let (id_ast, _) =
                variable cx kind id None ~if_uninitialized:(StrT.at %> with_trust bogus_trust)
              in
              ( ForIn.LeftDeclaration
                  ( decl_loc,
                    {
                      VariableDeclaration.kind;
                      declarations =
                        [(vdecl_loc, { VariableDeclaration.Declarator.id = id_ast; init = None })];
                      comments;
                    }
                  ),
                right_ast
              )
            | ForIn.LeftPattern
                ( pat_loc,
                  Ast.Pattern.Identifier
                    {
                      Ast.Pattern.Identifier.name =
                        (name_loc, ({ Ast.Identifier.name = name_str; comments = _ } as id));
                      optional;
                      annot;
                    }
                ) ->
              let right_ast = eval_right () in
              let t = StrT.at pat_loc |> with_trust bogus_trust in
              let use_op =
                Op
                  (AssignVar
                     {
                       var = Some (mk_reason (RIdentifier (OrdinaryName name_str)) pat_loc);
                       init = reason_of_t t;
                     }
                  )
              in
              Env.set_var cx ~use_op name_str t pat_loc;
              ( ForIn.LeftPattern
                  ( (pat_loc, t),
                    Ast.Pattern.Identifier
                      {
                        Ast.Pattern.Identifier.name = ((name_loc, t), id);
                        annot =
                          (match annot with
                          | Ast.Type.Available _ ->
                            Tast_utils.unchecked_mapper#type_annotation_hint annot
                          | Ast.Type.Missing loc -> Ast.Type.Missing (loc, t));
                        optional;
                      }
                  ),
                right_ast
              )
            | _ ->
              let right_ast = eval_right () in
              Flow.add_output cx Error_message.(EInternal (loc, ForInLHS));
              (Tast_utils.error_mapper#for_in_statement_lhs left, right_ast)
          in
          let ((_, right_t), _) = right_ast in
          Flow.flow cx (right_t, AssertForInRHST reason);

          let (body_ast, _) =
            Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
          in
          let newset = Changeset.Global.merge oldset in
          if Abnormal.swap_saved (Abnormal.Continue None) save_continue <> None then
            Env.havoc_vars newset;
          Env.copy_env cx loc (env, body_env) newset;

          Env.update_env loc env;
          if Abnormal.swap_saved (Abnormal.Break None) save_break <> None then Env.havoc_vars newset;

          (loc, ForIn { ForIn.left = left_ast; right = right_ast; body = body_ast; each; comments })
      )
    | (loc, ForOf { ForOf.left; right; body; await; comments }) ->
      let reason_desc =
        match left with
        | ForOf.LeftDeclaration
            ( _,
              {
                VariableDeclaration.declarations =
                  [
                    ( _,
                      {
                        VariableDeclaration.Declarator.id =
                          ( _,
                            Ast.Pattern.Identifier
                              {
                                Ast.Pattern.Identifier.name =
                                  (_, { Ast.Identifier.name; comments = _ });
                                _;
                              }
                          );
                        _;
                      }
                    );
                  ];
                _;
              }
            ) ->
          RIdentifier (OrdinaryName name)
        | ForOf.LeftPattern
            ( _,
              Ast.Pattern.Identifier
                { Ast.Pattern.Identifier.name = (_, { Ast.Identifier.name; comments = _ }); _ }
            ) ->
          RIdentifier (OrdinaryName name)
        | _ -> RCustom ""for-of element""
      in
      let reason = mk_reason reason_desc loc in
      let save_break = Abnormal.clear_saved (Abnormal.Break None) in
      let save_continue = Abnormal.clear_saved (Abnormal.Continue None) in
      let eval_right () =
        let ((((right_loc, t), _) as right_ast), preds, _, xtypes) =
          predicates_of_condition ~cond:OtherTest cx right
        in
        let (_ : Changeset.t) = Env.refine_with_preds cx right_loc preds xtypes in
        let elem_t = for_of_elemt cx t reason await in

        (* null/undefined are NOT allowed *)
        (Flow.reposition cx (loc_of_t t) elem_t, right_ast)
      in
      Env.in_lex_scope (fun () ->
          let env = Env.peek_env () in
          let oldset = Changeset.Global.clear () in
          Env.widen_env cx loc;

          let body_env = Env.clone_env env in
          Env.update_env loc body_env;

          let (left_ast, right_ast) =
            match left with
            | ForOf.LeftDeclaration
                ( decl_loc,
                  ( {
                      VariableDeclaration.kind;
                      declarations =
                        [(vdecl_loc, { VariableDeclaration.Declarator.id; init = None })];
                      comments;
                    } as decl
                  )
                ) ->
              variable_decl cx decl;
              let (elem_t, right_ast) = eval_right () in
              let (id_ast, _) = variable cx kind id None ~if_uninitialized:(fun _ -> elem_t) in
              ( ForOf.LeftDeclaration
                  ( decl_loc,
                    {
                      VariableDeclaration.kind;
                      declarations =
                        [(vdecl_loc, { VariableDeclaration.Declarator.id = id_ast; init = None })];
                      comments;
                    }
                  ),
                right_ast
              )
            | ForOf.LeftPattern
                ( pat_loc,
                  Ast.Pattern.Identifier
                    {
                      Ast.Pattern.Identifier.name =
                        (name_loc, ({ Ast.Identifier.name = name_str; comments = _ } as id));
                      optional;
                      annot;
                    }
                ) ->
              let (elem_t, right_ast) = eval_right () in
              let use_op =
                Op
                  (AssignVar
                     {
                       var = Some (mk_reason (RIdentifier (OrdinaryName name_str)) pat_loc);
                       init = reason_of_t elem_t;
                     }
                  )
              in
              Env.set_var cx ~use_op name_str elem_t pat_loc;
              ( ForOf.LeftPattern
                  ( (pat_loc, elem_t),
                    Ast.Pattern.Identifier
                      {
                        Ast.Pattern.Identifier.name = ((name_loc, elem_t), id);
                        annot =
                          (match annot with
                          | Ast.Type.Available annot ->
                            Ast.Type.Available (Tast_utils.error_mapper#type_annotation annot)
                          | Ast.Type.Missing loc -> Ast.Type.Missing (loc, elem_t));
                        optional;
                      }
                  ),
                right_ast
              )
            | _ ->
              let (_, right_ast) = eval_right () in
              Flow.add_output cx Error_message.(EInternal (loc, ForOfLHS));
              (Tast_utils.error_mapper#for_of_statement_lhs left, right_ast)
          in
          let (body_ast, _) =
            Abnormal.catch_stmt_control_flow_exception (fun () -> statement cx body)
          in
          let newset = Changeset.Global.merge oldset in
          if Abnormal.swap_saved (Abnormal.Continue None) save_continue <> None then
            Env.havoc_vars newset;
          Env.copy_env cx loc (env, body_env) newset;

          Env.update_env loc env;
          if Abnormal.swap_saved (Abnormal.Break None) save_break <> None then Env.havoc_vars newset;

          (loc, ForOf { ForOf.left = left_ast; right = right_ast; body = body_ast; await; comments })
      )
    | (_, Debugger _) as stmt -> stmt
    | (loc, FunctionDeclaration func) ->
      let (fn_type, (name_loc, { Ast.Identifier.name; comments = _ }), node) = function_ loc func in
      let use_op =
        Op
          (AssignVar
             {
               var = Some (mk_reason (RIdentifier (OrdinaryName name)) loc);
               init = reason_of_t fn_type;
             }
          )
      in
      Env.init_fun cx ~use_op (OrdinaryName name) fn_type name_loc;
      node
    | (loc, EnumDeclaration enum) ->
      let open EnumDeclaration in
      let { id = (name_loc, ident); body; comments } = enum in
      let { Ast.Identifier.name; _ } = ident in
      let reason = mk_reason (REnum name) name_loc in
      let t =
        if Context.enable_enums cx then (
          let enum_t = mk_enum cx ~enum_reason:reason name_loc body in
          let t = DefT (reason, literal_trust (), EnumObjectT enum_t) in
          Env.declare_implicit_const Scope.Entry.EnumNameBinding cx (OrdinaryName name) name_loc;
          let use_op =
            Op
              (AssignVar
                 {
                   var = Some (mk_reason (RIdentifier (OrdinaryName name)) name_loc);
                   init = reason;
                 }
              )
          in
          Env.init_implicit_const
            Scope.Entry.EnumNameBinding
            cx
            ~use_op
            (OrdinaryName name)
            ~has_anno:false
            t
            name_loc;
          t
        ) else (
          Flow.add_output cx (Error_message.EEnumsNotEnabled loc);
          AnyT.error reason
        )
      in
      let id' = ((name_loc, t), ident) in
      (loc, EnumDeclaration { id = id'; body; comments })
    | ( loc,
        DeclareVariable
          {
            DeclareVariable.id = (id_loc, ({ Ast.Identifier.name; comments = _ } as id));
            annot;
            comments;
          }
      ) ->
      let (t, annot_ast) = Anno.mk_type_available_annotation cx Subst_name.Map.empty annot in
      Env.unify_declared_type cx (OrdinaryName name) id_loc t;
      (loc, DeclareVariable { DeclareVariable.id = ((id_loc, t), id); annot = annot_ast; comments })
    | (loc, DeclareFunction declare_function) ->
      (match declare_function_to_function_declaration cx loc declare_function with
      | Some (FunctionDeclaration func, reconstruct_ast) ->
        let (fn_type, (id_loc, { Ast.Identifier.name; comments = _ }), node) = function_ loc func in
        Env.unify_declared_fun_type cx (OrdinaryName name) id_loc fn_type;
        (loc, DeclareFunction (reconstruct_ast node))
      | _ ->
        (* error case *)
        let { DeclareFunction.id = (id_loc, id_name); annot; predicate; comments } =
          declare_function
        in
        let { Ast.Identifier.name; comments = _ } = id_name in
        let (t, annot_ast) = Anno.mk_type_available_annotation cx Subst_name.Map.empty annot in
        Env.unify_declared_fun_type cx (OrdinaryName name) id_loc t;
        let predicate = Base.Option.map ~f:Tast_utils.error_mapper#type_predicate predicate in
        ( loc,
          DeclareFunction
            { DeclareFunction.id = ((id_loc, t), id_name); annot = annot_ast; predicate; comments }
        ))
    | (loc, VariableDeclaration decl) -> (loc, VariableDeclaration (variables cx decl))
    | (_, ClassDeclaration { Ast.Class.id = None; _ }) ->
      failwith ""unexpected anonymous class declaration""
    | (class_loc, ClassDeclaration ({ Ast.Class.id = Some id; _ } as c)) ->
      let (name_loc, { Ast.Identifier.name; comments = _ }) = id in
      let name = OrdinaryName name in
      let kind = Scope.Entry.ClassNameBinding in
      let reason = DescFormat.instance_reason name name_loc in
      Env.declare_implicit_let kind cx name name_loc;
      let general = Tvar.mk_where cx reason (Env.unify_declared_type cx name name_loc) in
      (* ClassDeclarations are statements, so we will never have an annotation to push down here *)
      let (class_t, c_ast) = mk_class cx class_loc ~name_loc ~general reason c in
      let use_op =
        Op
          (AssignVar
             { var = Some (mk_reason (RIdentifier name) name_loc); init = reason_of_t class_t }
          )
      in
      Env.init_implicit_let kind cx ~use_op name ~has_anno:false class_t name_loc;
      (class_loc, ClassDeclaration c_ast)
    | ( loc,
        DeclareClass
          ( { Ast.Statement.DeclareClass.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ }
          as decl
          )
      ) ->
      let (t, decl_ast) = declare_class cx loc decl in
      let use_op =
        Op
          (AssignVar
             { var = Some (mk_reason (RIdentifier (OrdinaryName name)) loc); init = reason_of_t t }
          )
      in
      Env.init_var ~has_anno:false cx ~use_op (OrdinaryName name) t name_loc;
      (loc, DeclareClass decl_ast)
    | ( loc,
        DeclareInterface
          ( { Ast.Statement.Interface.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } as
          decl
          )
      ) ->
      let (t, decl_ast) = interface cx loc decl in
      Env.init_type cx name t name_loc;
      (loc, DeclareInterface decl_ast)
    | ( loc,
        InterfaceDeclaration
          ( { Ast.Statement.Interface.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } as
          decl
          )
      ) ->
      let (t, decl_ast) = interface cx loc decl in
      Env.init_type cx name t name_loc;
      (loc, InterfaceDeclaration decl_ast)
    | (loc, DeclareModule { DeclareModule.id; body; kind; comments }) ->
      let (_, name) =
        match id with
        | DeclareModule.Identifier (id_loc, { Ast.Identifier.name = value; comments = _ })
        | DeclareModule.Literal (id_loc, { Ast.StringLiteral.value; _ }) ->
          (id_loc, value)
      in
      let (body_loc, { Ast.Statement.Block.body = elements; comments = elements_comments }) =
        body
      in
      let module_ref = Reason.internal_module_name name in
      let module_scope = Scope.fresh () in
      Scope.add_entry
        (Reason.internal_name ""exports"")
        (Scope.Entry.new_var
           ~loc:ALoc.none
           ~provider:(Locationless.MixedT.t |> with_trust bogus_trust)
           ~specific:(Locationless.EmptyT.t |> with_trust bogus_trust)
           (Inferred (Locationless.MixedT.t |> with_trust bogus_trust))
        )
        module_scope;

      Env.push_var_scope module_scope;
      let excluded_symbols = Env.save_excluded_symbols () in
      Context.push_declare_module cx (Module_info.empty_cjs_module module_ref);

      let (elements_ast, elements_abnormal) =
        Abnormal.catch_stmts_control_flow_exception (fun () ->
            toplevel_decls cx elements;
            Toplevels.toplevels statement cx elements
        )
      in
      let reason = mk_reason (RModule (OrdinaryName name)) loc in
      let () =
        match Context.module_kind cx with
        | Module_info.ES _ -> ()
        | Module_info.CJS clobbered ->
          Scope.(
            Entry.(
              let () =
                match clobbered with
                | Some _ -> ()
                | None ->
                  let props =
                    NameUtils.Map.fold
                      (fun x entry acc ->
                        match entry with
                        | Value { specific; _ } ->
                          let loc = Some (entry_loc entry) in
                          Properties.add_field x Polarity.Positive loc specific acc
                        | Type _
                        | Class _ ->
                          acc)
                      module_scope.entries
                      NameUtils.Map.empty
                  in
                  let proto = ObjProtoT reason in
                  let t = Obj_type.mk_with_proto cx reason ~obj_kind:Exact ~props proto in
                  Import_export.set_module_exports cx loc t
              in
              NameUtils.Map.iter
                (fun x entry ->
                  match entry with
                  | Type { type_; type_binding_kind = TypeBinding; _ } ->
                    (* TODO we may want to provide a location here *)
                    Import_export.export_type cx x None type_
                  | Type { type_binding_kind = ImportTypeBinding; _ }
                  | Value _
                  | Class _ ->
                    ())
                module_scope.entries
            )
          )
      in
      let module_t = Import_export.mk_module_t cx reason in
      let ast =
        ( loc,
          DeclareModule
            {
              DeclareModule.id =
                begin
                  match id with
                  | DeclareModule.Identifier (id_loc, id) ->
                    DeclareModule.Identifier ((id_loc, module_t), id)
                  | DeclareModule.Literal (id_loc, lit) ->
                    DeclareModule.Literal ((id_loc, module_t), lit)
                end;
              body = (body_loc, { Block.body = elements_ast; comments = elements_comments });
              kind;
              comments;
            }
        )
      in
      ignore
        ( Abnormal.check_stmt_control_flow_exception (ast, elements_abnormal)
          : (ALoc.t, ALoc.t * Type.t) Ast.Statement.t
          );

      let t = Env.get_var_declared_type cx module_ref loc in
      Flow.flow_t cx (module_t, t);

      Context.pop_declare_module cx;
      Env.pop_var_scope ();
      Env.restore_excluded_symbols excluded_symbols;

      ast
    | (loc, DeclareExportDeclaration decl) ->
      let module D = DeclareExportDeclaration in
      let { D.default; declaration; specifiers; source; comments = _ } = decl in
      let declaration =
        let export_maybe_default_binding id =
          let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
          let name = OrdinaryName name in
          match default with
          | None -> Import_export.export_binding cx name id_loc Ast.Statement.ExportValue
          | Some default_loc ->
            let t = Env.get_var_declared_type ~lookup_mode:Env_sig.LookupMode.ForType cx name loc in
            Import_export.export cx (OrdinaryName ""default"") default_loc t
        in
        (* error-handling around calls to `statement` is omitted here because we
           don't expect declarations to have abnormal control flow *)
        let f = function
          | D.Variable (loc, ({ DeclareVariable.id; _ } as v)) ->
            let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
            let dec_var = statement cx (loc, DeclareVariable v) in
            Import_export.export_binding cx (OrdinaryName name) id_loc Ast.Statement.ExportValue;
            begin
              match dec_var with
              | (_, DeclareVariable v_ast) -> D.Variable (loc, v_ast)
              | _ -> assert_false ""DeclareVariable typed AST doesn't preserve structure""
            end
          | D.Function (loc, f) ->
            let dec_fun = statement cx (loc, DeclareFunction f) in
            export_maybe_default_binding f.DeclareFunction.id;
            begin
              match dec_fun with
              | (_, DeclareFunction f_ast) -> D.Function (loc, f_ast)
              | _ -> assert_false ""DeclareFunction typed AST doesn't preserve structure""
            end
          | D.Class (loc, c) ->
            let dec_class = statement cx (loc, DeclareClass c) in
            export_maybe_default_binding c.DeclareClass.id;
            begin
              match dec_class with
              | (_, DeclareClass c_ast) -> D.Class (loc, c_ast)
              | _ -> assert_false ""DeclareClass typed AST doesn't preserve structure""
            end
          | D.DefaultType (loc, t) ->
            let default_loc = Base.Option.value_exn default in
            let (((_, t), _) as t_ast) = Anno.convert cx Subst_name.Map.empty (loc, t) in
            Import_export.export cx (OrdinaryName ""default"") default_loc t;
            D.DefaultType t_ast
          | D.NamedType (loc, ({ TypeAlias.id; _ } as t)) ->
            let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
            let type_alias = statement cx (loc, TypeAlias t) in
            Import_export.export_binding cx (OrdinaryName name) id_loc Ast.Statement.ExportType;
            begin
              match type_alias with
              | (_, TypeAlias talias) -> D.NamedType (loc, talias)
              | _ -> assert_false ""TypeAlias typed AST doesn't preserve structure""
            end
          | D.NamedOpaqueType (loc, ({ OpaqueType.id; _ } as t)) ->
            let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
            let opaque_type = statement cx (loc, OpaqueType t) in
            Import_export.export_binding cx (OrdinaryName name) id_loc Ast.Statement.ExportType;
            begin
              match opaque_type with
              | (_, OpaqueType opaque_t) -> D.NamedOpaqueType (loc, opaque_t)
              | _ -> assert_false ""OpaqueType typed AST doesn't preserve structure""
            end
          | D.Interface (loc, ({ Interface.id; _ } as i)) ->
            let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
            let int_dec = statement cx (loc, InterfaceDeclaration i) in
            Import_export.export_binding cx (OrdinaryName name) id_loc Ast.Statement.ExportType;
            begin
              match int_dec with
              | (_, InterfaceDeclaration i_ast) -> D.Interface (loc, i_ast)
              | _ -> assert_false ""InterfaceDeclaration typed AST doesn't preserve structure""
            end
        in
        Option.map f declaration
      in
      Option.iter (export_specifiers cx loc source Ast.Statement.ExportValue) specifiers;
      (loc, DeclareExportDeclaration { decl with D.declaration })
    | (loc, DeclareModuleExports { Ast.Statement.DeclareModuleExports.annot = (t_loc, t); comments })
      ->
      let (((_, t), _) as t_ast) = Anno.convert cx Subst_name.Map.empty t in
      Import_export.cjs_clobber cx loc t;
      ( loc,
        DeclareModuleExports { Ast.Statement.DeclareModuleExports.annot = (t_loc, t_ast); comments }
      )
    | ( loc,
        ExportNamedDeclaration
          ( { ExportNamedDeclaration.declaration; specifiers; source; export_kind; comments = _ } as
          export_decl
          )
      ) ->
      let declaration =
        match declaration with
        | None -> None
        | Some (loc, stmt) ->
          let stmt' = statement cx (loc, stmt) in
          begin
            match stmt with
            | FunctionDeclaration { Ast.Function.id = Some id; _ }
            | ClassDeclaration { Ast.Class.id = Some id; _ }
            | TypeAlias { TypeAlias.id; _ }
            | OpaqueType { OpaqueType.id; _ }
            | InterfaceDeclaration { Interface.id; _ }
            | EnumDeclaration { EnumDeclaration.id; _ } ->
              let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
              Type_inference_hooks_js.dispatch_export_named_hook name id_loc;
              Import_export.export_binding cx (OrdinaryName name) id_loc export_kind
            | VariableDeclaration { VariableDeclaration.declarations; _ } ->
              Flow_ast_utils.fold_bindings_of_variable_declarations
                (fun _ () id ->
                  let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
                  Type_inference_hooks_js.dispatch_export_named_hook name id_loc;
                  Import_export.export_binding cx (OrdinaryName name) id_loc export_kind)
                ()
                declarations
            | _ -> failwith ""Parser Error: Invalid export-declaration type!""
          end;
          Some stmt'
      in
      Option.iter (export_specifiers cx loc source export_kind) specifiers;
      (loc, ExportNamedDeclaration { export_decl with ExportNamedDeclaration.declaration })
    | (loc, ExportDefaultDeclaration { ExportDefaultDeclaration.default; declaration; comments }) ->
      let module D = ExportDefaultDeclaration in
      Type_inference_hooks_js.dispatch_export_named_hook ""default"" default;
      let (export_loc, t, declaration) =
        match declaration with
        | D.Declaration (loc, stmt) ->
          let (export_loc, t, stmt) =
            match stmt with
            | FunctionDeclaration ({ Ast.Function.id = None; _ } as fn) ->
              let { Ast.Function.sig_loc; async; generator; _ } = fn in
              let reason = func_reason ~async ~generator sig_loc in
              let general = Tvar.mk cx reason in
              let (t, fn) = mk_function_declaration cx ~general reason fn in
              Flow_js.flow_t cx (t, general);
              (loc, general, (loc, FunctionDeclaration fn))
            | ClassDeclaration ({ Ast.Class.id = None; _ } as c) ->
              let reason = DescFormat.instance_reason (internal_name ""*default*"") loc in
              let general = Tvar.mk cx reason in
              let (t, c) = mk_class cx loc ~name_loc:loc ~general reason c in
              Flow_js.flow_t cx (t, general);
              (loc, general, (loc, ClassDeclaration c))
            | FunctionDeclaration { Ast.Function.id = Some id; _ }
            | ClassDeclaration { Ast.Class.id = Some id; _ }
            | EnumDeclaration { EnumDeclaration.id; _ } ->
              let stmt = statement cx (loc, stmt) in
              let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
              let t =
                Env.get_var_declared_type ~lookup_mode:ForValue cx (OrdinaryName name) id_loc
              in
              (id_loc, t, stmt)
            | _ -> failwith ""unexpected default export declaration""
          in
          (export_loc, t, D.Declaration stmt)
        | D.Expression expr ->
          let (((loc, t), _) as expr) = expression cx ~hint:None expr in
          (loc, t, D.Expression expr)
      in
      Import_export.export cx (OrdinaryName ""default"") export_loc t;
      (loc, ExportDefaultDeclaration { ExportDefaultDeclaration.default; declaration; comments })
    | (import_loc, ImportDeclaration import_decl) ->
      let { ImportDeclaration.source; specifiers; default; import_kind; comments } = import_decl in
      let (source_loc, { Ast.StringLiteral.value = module_name; _ }) = source in

      let (specifiers, specifiers_ast) =
        match specifiers with
        | Some (ImportDeclaration.ImportNamedSpecifiers named_specifiers) ->
          let (named_specifiers, named_specifiers_ast) =
            named_specifiers
            |> Base.List.map ~f:(function
                   | { Ast.Statement.ImportDeclaration.local; remote; kind } ->
                   let ( remote_name_loc,
                         ({ Ast.Identifier.name = remote_name; comments = _ } as rmt)
                       ) =
                     remote
                   in
                   let (loc, { Ast.Identifier.name = local_name; comments = _ }) =
                     Base.Option.value ~default:remote local
                   in
                   let import_reason =
                     mk_reason (RNamedImportedType (module_name, local_name)) (fst remote)
                   in
                   let import_kind = Base.Option.value ~default:import_kind kind in
                   let imported_t =
                     import_named_specifier_type
                       cx
                       import_reason
                       import_kind
                       ~source_loc
                       ~module_name
                       ~remote_name_loc
                       ~remote_name
                       ~local_name
                   in
                   let remote_ast = ((remote_name_loc, imported_t), rmt) in
                   let local_ast =
                     Base.Option.map local ~f:(fun (local_loc, local_id) ->
                         let { Ast.Identifier.name = local_name; comments } = local_id in
                         ((local_loc, imported_t), mk_ident ~comments local_name)
                     )
                   in
                   ( (loc, local_name, imported_t, kind),
                     {
                       Ast.Statement.ImportDeclaration.local = local_ast;
                       remote = remote_ast;
                       kind;
                     }
                   )
                   )
            |> List.split
          in
          (named_specifiers, Some (ImportDeclaration.ImportNamedSpecifiers named_specifiers_ast))
        | Some
            (ImportDeclaration.ImportNamespaceSpecifier
              ( loc_with_star,
                (local_loc, ({ Flow_ast.Identifier.name = local_name; _ } as local_id))
              )
              ) ->
          let (specifier, namespace_specifier_ast) =
            let import_reason =
              let import_reason_desc =
                match import_kind with
                | ImportDeclaration.ImportType -> RImportStarType local_name
                | ImportDeclaration.ImportTypeof -> RImportStarTypeOf local_name
                | ImportDeclaration.ImportValue -> RImportStar local_name
              in
              mk_reason import_reason_desc local_loc
            in
            let t =
              import_namespace_specifier_type
                cx
                import_reason
                import_kind
                ~source_loc
                ~module_name
                ~local_loc
            in

            let local_ast = ((local_loc, t), local_id) in
            ((local_loc, local_name, t, None), local_ast)
          in
          ( [specifier],
            Some
              (ImportDeclaration.ImportNamespaceSpecifier (loc_with_star, namespace_specifier_ast))
          )
        | None -> ([], None)
      in
      let (specifiers, default_ast) =
        match default with
        | Some (loc, ({ Ast.Identifier.name = local_name; comments = _ } as id)) ->
          let (specifier, ast) =
            let import_reason = mk_reason (RDefaultImportedType (local_name, module_name)) loc in
            let imported_t =
              import_default_specifier_type
                cx
                import_reason
                import_kind
                ~source_loc
                ~module_name
                ~local_loc:loc
                ~local_name
            in
            ((loc, local_name, imported_t, None), ((loc, imported_t), id))
          in
          (specifier :: specifiers, Some ast)
        | None -> (specifiers, None)
      in
      List.iter
        (fun (loc, local_name, t, specifier_kind) ->
          let lookup_mode =
            match Base.Option.value ~default:import_kind specifier_kind with
            | ImportDeclaration.ImportType -> ForType
            | ImportDeclaration.ImportTypeof -> ForType
            | ImportDeclaration.ImportValue -> ForValue
          in
          Env.init_import ~lookup_mode cx (OrdinaryName local_name) loc t)
        specifiers;

      ( import_loc,
        ImportDeclaration
          {
            ImportDeclaration.source;
            specifiers = specifiers_ast;
            default = default_ast;
            import_kind;
            comments;
          }
      )

  and for_of_elemt cx right_t reason await =
    let elem_t = Tvar.mk cx reason in
    let loc = aloc_of_reason reason in
    (* Second and third args here are never relevant to the loop, but they should be as
       general as possible to allow iterating over arbitrary generators *)
    let targs =
      [
        elem_t;
        MixedT.why reason |> with_trust bogus_trust;
        EmptyT.why reason |> with_trust bogus_trust;
      ]
    in
    let (async, iterable_reason) =
      if await then
        (true, mk_reason (RCustom ""async iteration expected on AsyncIterable"") loc)
      else
        (false, mk_reason (RCustom ""iteration expected on Iterable"") loc)
    in
    Flow.flow
      cx
      (right_t, AssertIterableT { use_op = unknown_use; reason = iterable_reason; async; targs });
    elem_t

  and type_alias
      cx
      loc
      {
        Ast.Statement.TypeAlias.id = (name_loc, ({ Ast.Identifier.name; comments = _ } as id));
        tparams;
        right;
        comments;
      } =
    let cache = Context.node_cache cx in
    match Node_cache.get_alias cache loc with
    | Some info ->
      Debug_js.Verbose.print_if_verbose_lazy
        cx
        (lazy [spf ""Alias cache hit at %s"" (ALoc.debug_to_string loc)]);
      info
    | None ->
      let r = DescFormat.type_reason (OrdinaryName name) name_loc in
      let (tparams, tparams_map, tparams_ast) = Anno.mk_type_param_declarations cx tparams in
      let (((_, t), _) as right_ast) = Anno.convert cx tparams_map right in
      let t =
        mod_reason_of_t (update_desc_reason (fun desc -> RTypeAlias (name, Some name_loc, desc))) t
      in
      let type_ =
        poly_type_of_tparams
          (Type.Poly.generate_id ())
          tparams
          (DefT (r, bogus_trust (), TypeT (TypeAliasKind, t)))
      in
      begin
        match tparams with
        | None -> ()
        | Some (_, tps) ->
          (* TODO: use tparams_map *)
          let tparams =
            Nel.fold_left (fun acc tp -> Subst_name.Map.add tp.name tp acc) Subst_name.Map.empty tps
          in
          Flow.check_polarity cx tparams Polarity.Positive t
      end;

      let type_alias_ast =
        {
          Ast.Statement.TypeAlias.id = ((name_loc, type_), id);
          tparams = tparams_ast;
          right = right_ast;
          comments;
        }
      in
      (type_, type_alias_ast)

  and opaque_type
      cx
      loc
      {
        Ast.Statement.OpaqueType.id = (name_loc, ({ Ast.Identifier.name; comments = _ } as id));
        tparams;
        impltype;
        supertype;
        comments;
      } =
    let cache = Context.node_cache cx in
    match Node_cache.get_opaque cache loc with
    | Some info ->
      Debug_js.Verbose.print_if_verbose_lazy
        cx
        (lazy [spf ""Opaque type cache hit at %s"" (ALoc.debug_to_string loc)]);
      info
    | None ->
      let r = DescFormat.type_reason (OrdinaryName name) name_loc in
      let (tparams, tparams_map, tparams_ast) = Anno.mk_type_param_declarations cx tparams in
      let (underlying_t, impltype_ast) = Anno.convert_opt cx tparams_map impltype in
      let (super_t, supertype_ast) = Anno.convert_opt cx tparams_map supertype in
      begin
        match tparams with
        | None -> ()
        | Some (_, tps) ->
          (* TODO: use tparams_map *)
          let tparams =
            Nel.fold_left (fun acc tp -> Subst_name.Map.add tp.name tp acc) Subst_name.Map.empty tps
          in
          Base.Option.iter underlying_t ~f:(Flow.check_polarity cx tparams Polarity.Positive);
          Base.Option.iter super_t ~f:(Flow.check_polarity cx tparams Polarity.Positive)
      end;
      let opaque_type_args =
        Base.List.map
          ~f:(fun { name; reason; polarity; _ } ->
            let t = Subst_name.Map.find name tparams_map in
            (name, reason, t, polarity))
          (TypeParams.to_list tparams)
      in
      let opaque_id = Context.make_aloc_id cx name_loc in
      let opaquetype = { underlying_t; super_t; opaque_id; opaque_type_args; opaque_name = name } in
      let t = OpaqueT (mk_reason (ROpaqueType name) name_loc, opaquetype) in
      let type_ =
        poly_type_of_tparams
          (Type.Poly.generate_id ())
          tparams
          (DefT (r, bogus_trust (), TypeT (OpaqueKind, t)))
      in
      let () =
        Flow.(
          match (underlying_t, super_t) with
          | (Some l, Some u) -> flow_t cx (l, u)
          | _ -> ()
        )
      in

      let opaque_type_ast =
        {
          Ast.Statement.OpaqueType.id = ((name_loc, type_), id);
          tparams = tparams_ast;
          impltype = impltype_ast;
          supertype = supertype_ast;
          comments;
        }
      in
      (type_, opaque_type_ast)

  and type_kind_of_kind = function
    | Ast.Statement.ImportDeclaration.ImportType -> Type.ImportType
    | Ast.Statement.ImportDeclaration.ImportTypeof -> Type.ImportTypeof
    | Ast.Statement.ImportDeclaration.ImportValue -> Type.ImportValue

  and get_imported_t cx get_reason module_name module_t import_kind remote_export_name local_name =
    Tvar.mk_where cx get_reason (fun t ->
        let import_type =
          if remote_export_name = ""default"" then
            ImportDefaultT
              (get_reason, import_kind, (local_name, module_name), t, Context.is_strict cx)
          else
            ImportNamedT
              (get_reason, import_kind, remote_export_name, module_name, t, Context.is_strict cx)
        in
        Flow.flow cx (module_t, import_type)
    )

  and import_named_specifier_type
      cx
      import_reason
      import_kind
      ~source_loc
      ~module_name
      ~remote_name_loc
      ~remote_name
      ~local_name =
    let module_t = OpenT (Import_export.import cx (source_loc, module_name)) in
    if Type_inference_hooks_js.dispatch_member_hook cx remote_name remote_name_loc module_t then
      Unsoundness.why InferenceHooks import_reason
    else
      let import_kind = type_kind_of_kind import_kind in
      get_imported_t cx import_reason module_name module_t import_kind remote_name local_name

  and import_namespace_specifier_type
      cx import_reason import_kind ~source_loc ~module_name ~local_loc =
    let open Ast.Statement in
    match import_kind with
    | ImportDeclaration.ImportType -> assert_false ""import type * is a parse error""
    | ImportDeclaration.ImportTypeof ->
      let bind_reason = repos_reason local_loc import_reason in
      let module_ns_t = Import_export.import_ns cx import_reason (source_loc, module_name) in
      Tvar.mk_where cx bind_reason (fun t ->
          Flow.flow cx (module_ns_t, ImportTypeofT (bind_reason, ""*"", t))
      )
    | ImportDeclaration.ImportValue ->
      let reason = mk_reason (RModule (OrdinaryName module_name)) local_loc in
      Import_export.import_ns cx reason (source_loc, module_name)

  and import_default_specifier_type
      cx import_reason import_kind ~source_loc ~module_name ~local_loc ~local_name =
    let module_t = OpenT (Import_export.import cx (source_loc, module_name)) in
    if Type_inference_hooks_js.dispatch_member_hook cx ""default"" local_loc module_t then
      Unsoundness.why InferenceHooks import_reason
    else
      let import_kind = type_kind_of_kind import_kind in
      get_imported_t cx import_reason module_name module_t import_kind ""default"" local_name

  and export_specifiers cx loc source export_kind =
    let open Ast.Statement in
    let module E = ExportNamedDeclaration in
    let lookup_mode =
      match export_kind with
      | Ast.Statement.ExportValue -> ForValue
      | Ast.Statement.ExportType -> ForType
    in
    let source =
      match source with
      | Some (loc, { Ast.StringLiteral.value; raw = _; comments = _ }) -> Some (loc, value)
      | None -> None
    in
    (* [declare] export [type] {foo [as bar]}; *)
    let export_ref loc local_name remote_name =
      let t = Env.var_ref ~lookup_mode cx local_name loc in
      match export_kind with
      | Ast.Statement.ExportType ->
        let reason = mk_reason (RType local_name) loc in
        let t =
          Tvar.mk_where cx reason (fun tout ->
              Flow.flow cx (t, AssertExportIsTypeT (reason, local_name, tout))
          )
        in
        Import_export.export_type cx remote_name (Some loc) t
      | Ast.Statement.ExportValue -> Import_export.export cx remote_name loc t
    in
    (* [declare] export [type] {foo [as bar]} from 'module' *)
    let export_from loc (source_loc, source) local_name remote_name =
      let source_ns_t =
        let reason = mk_reason (RModule (OrdinaryName source)) source_loc in
        Import_export.import_ns cx reason (source_loc, source)
      in
      let t =
        let reason = mk_reason (RIdentifier local_name) loc in
        Tvar.mk_no_wrap_where cx reason (fun tout ->
            let use_t = GetPropT (unknown_use, reason, None, Named (reason, local_name), tout) in
            Flow.flow cx (source_ns_t, use_t)
        )
      in
      match export_kind with
      | Ast.Statement.ExportType -> Import_export.export_type cx remote_name (Some loc) t
      | Ast.Statement.ExportValue -> Import_export.export cx remote_name loc t
    in
    let export_specifier (loc, { E.ExportSpecifier.local; exported }) =
      let (local_name, remote_name, local_name_loc) =
        let (local_name_loc, { Ast.Identifier.name = local_name; comments = _ }) = local in
        let local_name = OrdinaryName local_name in
        match exported with
        | None -> (local_name, local_name, local_name_loc)
        | Some (_, { Ast.Identifier.name = remote_name; comments = _ }) ->
          (local_name, OrdinaryName remote_name, local_name_loc)
      in
      match source with
      | Some source -> export_from loc source local_name remote_name
      | None -> export_ref local_name_loc local_name remote_name
    in
    function
    (* [declare] export [type] {foo [as bar]} [from ...]; *)
    | E.ExportSpecifiers specifiers -> List.iter export_specifier specifiers
    (* [declare] export [type] * as id from ""source""; *)
    | E.ExportBatchSpecifier (_, Some id) ->
      let (id_loc, { Ast.Identifier.name; comments = _ }) = id in
      let reason = mk_reason (RIdentifier (OrdinaryName name)) id_loc in
      let remote_namespace_t = Import_export.import_ns cx reason (Base.Option.value_exn source) in
      Import_export.export cx (OrdinaryName name) loc remote_namespace_t
    (* [declare] export [type] * from ""source""; *)
    | E.ExportBatchSpecifier (_, None) ->
      let source_module_t = OpenT (Import_export.import cx (Base.Option.value_exn source)) in
      let reason = mk_reason (RCustom ""batch export"") loc in
      Flow.flow cx (source_module_t, CheckUntypedImportT (reason, ImportValue));
      (match export_kind with
      | Ast.Statement.ExportValue -> Import_export.export_star cx loc source_module_t
      | Ast.Statement.ExportType -> Import_export.export_type_star cx loc source_module_t)

  and interface_helper cx loc (iface_sig, self) =
    let def_reason = mk_reason (desc_of_t self) loc in
    Class_type_sig.check_super cx def_reason iface_sig;
    Class_type_sig.check_implements cx def_reason iface_sig;
    Class_type_sig.check_methods cx def_reason iface_sig;
    let (t_internal, t) = Class_type_sig.classtype ~check_polarity:false cx iface_sig in
    Flow.unify cx self t_internal;
    t

  and interface cx loc decl =
    let node_cache = Context.node_cache cx in
    match Node_cache.get_interface node_cache loc with
    | Some node ->
      Debug_js.Verbose.print_if_verbose_lazy
        cx
        (lazy [spf ""Interface cache hit at %s"" (ALoc.debug_to_string loc)]);
      node
    | None ->
      let { Ast.Statement.Interface.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } =
        decl
      in
      let reason = DescFormat.instance_reason (OrdinaryName name) name_loc in
      let (iface_sig, iface_t, decl_ast) = Anno.mk_interface_sig cx reason decl in
      let t = interface_helper cx loc (iface_sig, iface_t) in
      (t, decl_ast)

  and declare_class cx loc decl =
    let node_cache = Context.node_cache cx in
    match Node_cache.get_declared_class node_cache loc with
    | Some node ->
      Debug_js.Verbose.print_if_verbose_lazy
        cx
        (lazy [spf ""Declared class cache hit at %s"" (ALoc.debug_to_string loc)]);
      node
    | None ->
      let { Ast.Statement.DeclareClass.id = (name_loc, { Ast.Identifier.name; comments = _ }); _ } =
        decl
      in
      let reason = DescFormat.instance_reason (OrdinaryName name) name_loc in
      let (class_sig, class_t, decl_ast) = Anno.mk_declare_class_sig cx reason decl in
      let t = interface_helper cx loc (class_sig, class_t) in
      (t, decl_ast)

  and object_prop cx ~(object_hint : Type.t option) acc prop =
    let open Ast.Expression.Object in
    match prop with
    (* named prop *)
    | Property
        ( prop_loc,
          Property.Init
            {
              key =
                ( Property.Identifier (loc, { Ast.Identifier.name; _ })
                | Property.Literal (loc, { Ast.Literal.value = Ast.Literal.String name; _ }) ) as
                key;
              value = v;
              shorthand;
            }
        ) ->
      let (acc, key, value) =
        if Type_inference_hooks_js.dispatch_obj_prop_decl_hook cx name loc then
          let t = Unsoundness.at InferenceHooks loc in
          let key = translate_identifier_or_literal_key t key in
          (* don't add `name` to `acc` because `name` is the autocomplete token *)
          let acc = ObjectExpressionAcc.set_obj_key_autocomplete acc in
          let (((_, _t), _) as value) =
            expression cx ~hint:(hint_decompose_opt_todo object_hint) v
          in
          (acc, key, value)
        else
          let (((_, t), _) as value) =
            expression cx ~hint:(hint_decompose_opt_todo object_hint) v
          in
          let key = translate_identifier_or_literal_key t key in
          let acc =
            ObjectExpressionAcc.add_prop
              (Properties.add_field (OrdinaryName name) Polarity.Neutral (Some loc) t)
              acc
          in
          (acc, key, value)
      in
      (acc, Property (prop_loc, Property.Init { key; value; shorthand }))
    (* named method *)
    | Property
        ( prop_loc,
          Property.Method
            {
              key =
                ( Property.Identifier (loc, { Ast.Identifier.name; comments = _ })
                | Property.Literal (loc, { Ast.Literal.value = Ast.Literal.String name; _ }) ) as
                key;
              value = (fn_loc, func);
            }
        ) ->
      let reason = func_reason ~async:false ~generator:false prop_loc in
      let tvar = Tvar.mk cx reason in
      let (t, func) =
        mk_function_expression
          cx
          ~hint:(hint_decompose_opt_todo object_hint)
          ~general:tvar
          ~needs_this_param:false
          reason
          func
      in
      Flow.flow_t cx (t, tvar);
      ( ObjectExpressionAcc.add_prop (Properties.add_method (OrdinaryName name) (Some loc) t) acc,
        Property
          ( prop_loc,
            Property.Method
              { key = translate_identifier_or_literal_key t key; value = (fn_loc, func) }
          )
      )
    (* We enable some unsafe support for getters and setters. The main unsafe bit
     *  is that we don't properly havok refinements when getter and setter methods
     *  are called. *)
    (* unsafe getter property *)
    | Property
        ( loc,
          Property.Get
            {
              key =
                ( Property.Identifier (id_loc, { Ast.Identifier.name; comments = _ })
                | Property.Literal (id_loc, { Ast.Literal.value = Ast.Literal.String name; _ }) ) as
                key;
              value = (vloc, func);
              comments;
            }
        ) ->
      Flow_js.add_output cx (Error_message.EUnsafeGettersSetters loc);
      let reason = func_reason ~async:false ~generator:false vloc in
      let tvar = Tvar.mk cx reason in
      let (function_type, func) =
        mk_function_expression
          ~hint:(hint_decompose_opt_todo object_hint)
          cx
          ~general:tvar
          ~needs_this_param:false
          reason
          func
      in
      Flow.flow_t cx (function_type, tvar);
      let return_t = Type.extract_getter_type function_type in
      ( ObjectExpressionAcc.add_prop
          (Properties.add_getter (OrdinaryName name) (Some id_loc) return_t)
          acc,
        Property
          ( loc,
            Property.Get
              {
                key = translate_identifier_or_literal_key return_t key;
                value = (vloc, func);
                comments;
              }
          )
      )
    (* unsafe setter property *)
    | Property
        ( loc,
          Property.Set
            {
              key =
                ( Property.Identifier (id_loc, { Ast.Identifier.name; comments = _ })
                | Property.Literal (id_loc, { Ast.Literal.value = Ast.Literal.String name; _ }) ) as
                key;
              value = (vloc, func);
              comments;
            }
        ) ->
      Flow_js.add_output cx (Error_message.EUnsafeGettersSetters loc);
      let reason = func_reason ~async:false ~generator:false vloc in
      let tvar = Tvar.mk cx reason in
      let (function_type, func) =
        mk_function_expression
          cx
          ~hint:(hint_decompose_opt_todo object_hint)
          ~general:tvar
          ~needs_this_param:false
          reason
          func
      in
      Flow.flow_t cx (function_type, tvar);
      let param_t = Type.extract_setter_type function_type in
      ( ObjectExpressionAcc.add_prop
          (Properties.add_setter (OrdinaryName name) (Some id_loc) param_t)
          acc,
        Property
          ( loc,
            Property.Set
              {
                key = translate_identifier_or_literal_key param_t key;
                value = (vloc, func);
                comments;
              }
          )
      )
    (* non-string literal LHS *)
    | Property (loc, Property.Init { key = Property.Literal _; _ })
    | Property (loc, Property.Method { key = Property.Literal _; _ })
    | Property (loc, Property.Get { key = Property.Literal _; _ })
    | Property (loc, Property.Set { key = Property.Literal _; _ }) ->
      Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, ObjectPropertyLiteralNonString));
      (acc, Tast_utils.error_mapper#object_property_or_spread_property prop)
    (* computed getters and setters aren't supported yet regardless of the
       `enable_getters_and_setters` config option *)
    | Property (loc, Property.Get { key = Property.Computed _; _ })
    | Property (loc, Property.Set { key = Property.Computed _; _ }) ->
      Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, ObjectPropertyComputedGetSet));
      (acc, Tast_utils.error_mapper#object_property_or_spread_property prop)
    (* computed LHS silently ignored for now *)
    | Property (_, Property.Init { key = Property.Computed _; _ })
    | Property (_, Property.Method { key = Property.Computed _; _ }) ->
      (acc, Tast_utils.error_mapper#object_property_or_spread_property prop)
    (* spread prop *)
    | SpreadProperty _ -> (acc, Tast_utils.error_mapper#object_property_or_spread_property prop)
    | Property (_, Property.Init { key = Property.PrivateName _; _ })
    | Property (_, Property.Method { key = Property.PrivateName _; _ })
    | Property (_, Property.Get { key = Property.PrivateName _; _ })
    | Property (_, Property.Set { key = Property.PrivateName _; _ }) ->
      failwith ""Internal Error: Non-private field with private name""

  and prop_map_of_object cx props =
    let (acc, rev_prop_asts) =
      List.fold_left
        (fun (map, rev_prop_asts) prop ->
          let (map, prop) = object_prop cx ~object_hint:None map prop in
          (map, prop :: rev_prop_asts))
        (ObjectExpressionAcc.empty ~allow_sealed:true, [])
        props
    in
    (acc.ObjectExpressionAcc.obj_pmap, List.rev rev_prop_asts)

  and object_ cx ~hint reason ~frozen ?(allow_sealed = true) props =
    let open Ast.Expression.Object in
    (* Use the same reason for proto and the ObjT so we can walk the proto chain
       and use the root proto reason to build an error. *)
    let obj_proto = ObjProtoT reason in
    (* Add property to object, using optional tout argument to SetElemT to wait
       for the write to happen. This defers any reads until writes have happened,
       to avoid race conditions. *)
    let mk_computed key value =
      Tvar.mk_where cx reason (fun t ->
          let tout_id = Tvar.mk_no_wrap cx reason in
          let tvar = (reason, tout_id) in
          Flow.flow
            cx
            (key, CreateObjWithComputedPropT { reason = reason_of_t key; value; tout_tvar = tvar });
          Flow.flow cx (OpenT tvar, ObjSealT (reason, t))
      )
    in
    let (acc, rev_prop_asts) =
      List.fold_left
        (fun (acc, rev_prop_asts) -> function
          (* Enforce that the only way to make unsealed object literals is ...{} (spreading empty object
             literals). Otherwise, spreading always returns sealed object literals.

             Also enforce that a spread of an inexact object can only appear as the first element of an
             object literal, because otherwise we cannot determine the type of the object literal without
             significantly losing precision about elements preceding that spread.

             Finally, the exactness of an object literal type is determined solely by its sealedness.

             TODO: This treatment of spreads is oblivious to issues that arise when spreading expressions
             of union type.
          *)
          | SpreadProperty (prop_loc, { SpreadProperty.argument; comments }) ->
            let (((_, spread), _) as argument) =
              expression cx ~hint:(hint_decompose_opt_todo hint) argument
            in
            let not_empty_object_literal_argument =
              match spread with
              | DefT (_, _, ObjT { flags; _ }) -> Obj_type.sealed_in_op reason flags.obj_kind
              | _ -> true
            in
            let acc =
              if not_empty_object_literal_argument then
                ObjectExpressionAcc.add_spread spread acc
              else
                acc
            in
            ( ObjectExpressionAcc.set_seal ~allow_sealed not_empty_object_literal_argument acc,
              SpreadProperty (prop_loc, { SpreadProperty.argument; comments }) :: rev_prop_asts
            )
          | Property
              ( prop_loc,
                Property.Init
                  {
                    key = Property.Computed (k_loc, { Ast.ComputedKey.expression = k; comments });
                    value = v;
                    shorthand;
                  }
              ) ->
            let (((_, kt), _) as k) = expression cx ~hint:None k in
            let (((_, vt), _) as v) = expression cx ~hint:(hint_decompose_opt_todo hint) v in
            let computed = mk_computed kt vt in
            ( ObjectExpressionAcc.add_spread computed acc,
              Property
                ( prop_loc,
                  Property.Init
                    {
                      key = Property.Computed (k_loc, { Ast.ComputedKey.expression = k; comments });
                      value = v;
                      shorthand;
                    }
                )
              :: rev_prop_asts
            )
          | Property
              ( prop_loc,
                Property.Method
                  {
                    key = Property.Computed (k_loc, { Ast.ComputedKey.expression = k; comments });
                    value = (fn_loc, fn);
                  }
              ) ->
            let (((_, kt), _) as k) = expression cx ~hint:None k in
            let ((_, vt), v) =
              expression cx ~hint:(hint_decompose_opt_todo hint) (fn_loc, Ast.Expression.Function fn)
            in
            let fn =
              match v with
              | Ast.Expression.Function fn -> fn
              | _ -> assert false
            in
            let computed = mk_computed kt vt in
            ( ObjectExpressionAcc.add_spread computed acc,
              Property
                ( prop_loc,
                  Property.Method
                    {
                      key = Property.Computed (k_loc, { Ast.ComputedKey.expression = k; comments });
                      value = (fn_loc, fn);
                    }
                )
              :: rev_prop_asts
            )
          | Property
              ( prop_loc,
                Property.Init
                  {
                    key =
                      ( Property.Identifier (_, { Ast.Identifier.name = ""__proto__""; comments = _ })
                      | Property.Literal
                          (_, { Ast.Literal.value = Ast.Literal.String ""__proto__""; _ }) ) as key;
                    value = v;
                    shorthand = false;
                  }
              ) ->
            let reason = mk_reason RPrototype (fst v) in
            let (((_, vt), _) as v) = expression cx ~hint:None v in
            let t =
              Tvar.mk_where cx reason (fun t -> Flow.flow cx (vt, ObjTestProtoT (reason, t)))
            in
            ( ObjectExpressionAcc.add_proto t acc,
              Property
                ( prop_loc,
                  Property.Init
                    {
                      key = translate_identifier_or_literal_key vt key;
                      value = v;
                      shorthand = false;
                    }
                )
              :: rev_prop_asts
            )
          | prop ->
            let (acc, prop) = object_prop cx ~object_hint:(hint_decompose_opt_todo hint) acc prop in
            (acc, prop :: rev_prop_asts))
        (ObjectExpressionAcc.empty ~allow_sealed, [])
        props
    in
    let t =
      ObjectExpressionAcc.mk_object_from_spread_acc
        cx
        acc
        reason
        ~frozen
        ~default_proto:obj_proto
        ~empty_unsealed:(not @@ Context.exact_empty_objects cx)
    in
    (t, List.rev rev_prop_asts)

  and variable cx kind ?if_uninitialized id init =
    let open Ast.Statement in
    let (init_var, declare_var) =
      match kind with
      | VariableDeclaration.Const -> (Env.init_const, Env.declare_const)
      | VariableDeclaration.Let -> (Env.init_let, Env.declare_let)
      | VariableDeclaration.Var -> (Env.init_var, (fun _ _ _ -> ()))
    in
    let annot = Destructuring.type_of_pattern id in
    let has_anno =
      match annot with
      | Ast.Type.Missing _ -> false
      | Ast.Type.Available _ -> true
    in
    let id_reason =
      match id with
      | (_, Ast.Pattern.Identifier { Ast.Pattern.Identifier.name; _ }) ->
        let (id_loc, { Ast.Identifier.name; _ }) = name in
        mk_reason (RIdentifier (OrdinaryName name)) id_loc
      | (ploc, _) -> mk_reason RDestructuring ploc
    in
    let (annot_or_inferred, annot_ast) =
      Anno.mk_type_annotation cx Subst_name.Map.empty id_reason annot
    in
    let annot_t = type_t_of_annotated_or_inferred annot_or_inferred in
    (* Identifiers do not need to be initialized at the declaration site as long
     * as they are definitely initialized before use. Destructuring patterns must
     * be initialized, since their declaration involves some operation on the
     * right hand side, like a property access. *)
    let (init_opt, init_ast) =
      match (id, init, if_uninitialized) with
      | ((_, Ast.Pattern.Identifier _), None, None) -> (None, None)
      | (_, Some expr, _) ->
        let hint =
          if has_anno then
            hint_of_type annot_t
          else
            None
        in
        let (((_, t), _) as init_ast) = expression cx ~hint expr in
        let r = mk_expression_reason expr in
        (Some (t, r), Some init_ast)
      | ((ploc, _), None, Some f) ->
        let t = f ploc in
        let r = reason_of_t t in
        (Some (t, r), None)
      | ((ploc, _), None, None) ->
        let t = VoidT.at ploc |> with_trust bogus_trust in
        let r = reason_of_t t in
        (Some (t, r), None)
    in

    let id_ast =
      match id with
      | (ploc, Ast.Pattern.Identifier { Ast.Pattern.Identifier.name; annot = _; optional }) ->
        let (id_loc, { Ast.Identifier.name; comments }) = name in
        (* move const/let bindings from undeclared to declared *)
        declare_var cx (OrdinaryName name) id_loc;
        Env.unify_declared_type cx (OrdinaryName name) id_loc annot_t;
        begin
          match init_opt with
          | Some (init_t, init_reason) ->
            let use_op = Op (AssignVar { var = Some id_reason; init = init_reason }) in
            init_var cx ~use_op (OrdinaryName name) ~has_anno init_t id_loc
          | None when has_anno -> Env.install_provider cx annot_t (OrdinaryName name) id_loc
          | None -> ()
        end;
        Type_inference_hooks_js.(dispatch_lval_hook cx name id_loc (Val annot_t));
        let ast_t = Env.constraining_type ~default:annot_t cx (OrdinaryName name) id_loc in
        ( (ploc, ast_t),
          Ast.Pattern.Identifier
            {
              Ast.Pattern.Identifier.name = ((id_loc, ast_t), { Ast.Identifier.name; comments });
              annot = annot_ast;
              optional;
            }
        )
      | _ ->
        Base.Option.iter init_opt ~f:(fun (init_t, init_reason) ->
            let use_op = Op (AssignVar { var = Some id_reason; init = init_reason }) in
            Flow.flow cx (init_t, UseT (use_op, annot_t))
        );
        let init =
          Destructuring.empty
            ?init
            annot_t
            ~annot:
              (match annot with
              | Ast.Type.Missing _ -> false
              | Ast.Type.Available _ -> true)
        in
        Destructuring.pattern cx init id ~f:(fun ~use_op ~name_loc name default t ->
            let reason = mk_reason (RIdentifier (OrdinaryName name)) name_loc in
            declare_var cx (OrdinaryName name) name_loc;

            (* The bindings introduced by destructuring an annotation should themselves behave
             * like annotations. That is, subsequent writes to this binding should be compatible
             * with the relevant part of the annotation. *)
            let t =
              if has_anno then
                AnnotT
                  ( reason,
                    Tvar.mk_where cx reason (fun t' ->
                        Flow.flow cx (t, BecomeT { reason; t = t'; empty_success = true })
                    ),
                    false
                  )
              else
                t
            in

            (* If this is a variable declaration without a type annotation
               constraining writes, we need the type of the identifier to be the
               general type of the variable in order to detect if a generic escapes
               into it.

               If there is an annotation, the specific and the general will be
               unified. *)
            let id_node_type =
              if has_anno then (
                Env.unify_declared_type cx (OrdinaryName name) name_loc t;
                Env.pseudo_init_declared_type cx name name_loc;
                t
              ) else (
                init_var cx ~use_op (OrdinaryName name) ~has_anno t name_loc;
                Env.constraining_type
                  ~default:(Env.get_var_declared_type cx (OrdinaryName name) name_loc)
                  cx
                  (OrdinaryName name)
                  name_loc
              )
            in
            Flow.flow cx (t, AssertImportIsValueT (reason, name));
            Base.Option.iter default ~f:(fun d ->
                let default_t = Flow.mk_default cx reason d in
                Flow.flow cx (default_t, UseT (use_op, t))
            );

            id_node_type
        )
    in
    (id_ast, init_ast)

  and expression_or_spread cx =
    let open Ast.Expression in
    function
    | Expression ((loc, _) as e) ->
      let hint = hint_of_loc_todo loc in
      let (((_, t), _) as e') = expression cx ~hint e in
      (Arg t, Expression e')
    | Spread (loc, { SpreadElement.argument; comments }) ->
      let hint = hint_of_loc_todo loc in
      let (((_, t), _) as e') = expression cx ~hint argument in
      (SpreadArg t, Spread (loc, { SpreadElement.argument = e'; comments }))

  and array_elements cx ~array_hint undef_loc =
    let open Ast.Expression.Array in
    Fn.compose
      List.split
      (Base.List.map ~f:(function
          | Expression e ->
            let (((_, t), _) as e) = expression cx ~hint:(hint_decompose_opt_todo array_hint) e in
            (UnresolvedArg (t, None), Expression e)
          | Hole loc ->
            (UnresolvedArg (EmptyT.at undef_loc |> with_trust bogus_trust, None), Hole loc)
          | Spread (loc, { Ast.Expression.SpreadElement.argument; comments }) ->
            let (((_, t), _) as argument) = expression cx ~hint:array_hint argument in
            ( UnresolvedSpreadArg t,
              Spread (loc, { Ast.Expression.SpreadElement.argument; comments })
            )
          )
          )

  (* can raise Abnormal.(Exn (Stmt _, _))
   * annot should become a Type.t option when we have the ability to
   * inspect annotations and recurse into them *)
  and expression ?cond cx ~hint (loc, e) =
    let node_cache = Context.node_cache cx in
    match Node_cache.get_expression node_cache loc with
    | Some node ->
      Debug_js.Verbose.print_if_verbose_lazy
        cx
        (lazy [spf ""Expression cache hit at %s"" (ALoc.debug_to_string loc)]);
      node
    | None -> expression_ ~cond ~hint cx loc e

  and this_ cx loc this =
    let open Ast.Expression in
    match Refinement.get ~allow_optional:true cx (loc, This this) loc with
    | Some t -> t
    | None -> Env.var_ref cx (internal_name ""this"") loc

  and super_ cx loc = Env.var_ref cx (internal_name ""super"") loc

  and expression_ ~cond ~hint cx loc e : (ALoc.t, ALoc.t * Type.t) Ast.Expression.t =
    let make_trust = Context.trust_constructor cx in
    let ex = (loc, e) in
    let open Ast.Expression in
    match e with
    | Ast.Expression.Literal lit -> ((loc, literal cx loc lit), Ast.Expression.Literal lit)
    (* Treat the identifier `undefined` as an annotation for error reporting
     * purposes. Like we do with other literals. Otherwise we end up pointing to
     * `void` in `core.js`. While possible to re-declare `undefined`, it is
     * unlikely. The tradeoff is worth it. *)
    | Identifier (id_loc, ({ Ast.Identifier.name = ""undefined""; comments = _ } as name)) ->
      let t = Flow.reposition cx loc ~annot_loc:loc (identifier cx name loc) in
      ((loc, t), Identifier ((id_loc, t), name))
    | Identifier (id_loc, name) ->
      let t = identifier cx name loc in
      ((loc, t), Identifier ((id_loc, t), name))
    | This this ->
      let t = this_ cx loc this in
      ((loc, t), This this)
    | Super s -> ((loc, identifier cx (mk_ident ~comments:None ""super"") loc), Super s)
    | Unary u ->
      let (t, u) = unary cx loc u in
      ((loc, t), Unary u)
    | Update u ->
      let (t, u) = update cx loc u in
      ((loc, t), Update u)
    | Binary b ->
      let (t, b) = binary cx loc b in
      ((loc, t), Binary b)
    | Logical l ->
      let (t, l) = logical cx loc l in
      ((loc, t), Logical l)
    | TypeCast { TypeCast.expression = e; annot; comments } ->
      let (t, annot') = Anno.mk_type_available_annotation cx Subst_name.Map.empty annot in
      let (((_, infer_t), _) as e') = expression cx ~hint:(hint_of_type t) e in
      let use_op = Op (Cast { lower = mk_expression_reason e; upper = reason_of_t t }) in
      Flow.flow cx (infer_t, TypeCastT (use_op, t));
      ((loc, t), TypeCast { TypeCast.expression = e'; annot = annot'; comments })
    | Member _ -> subscript ~cond cx ex
    | OptionalMember _ -> subscript ~cond cx ex
    | Object { Object.properties; comments } ->
      error_on_this_uses_in_object_methods cx properties;
      let reason = mk_reason RObjectLit loc in
      let (t, properties) = object_ ~hint ~frozen:false cx reason properties in
      ((loc, t), Object { Object.properties; comments })
    | Array { Array.elements; comments } ->
      let reason = mk_reason RArrayLit loc in
      (match elements with
      | [] ->
        (* empty array, analogous to object with implicit properties *)
        let element_reason = mk_reason Reason.unknown_elem_empty_array_desc loc in
        let elemt = Tvar.mk cx element_reason in
        let reason = replace_desc_reason REmptyArrayLit reason in
        ( (loc, DefT (reason, make_trust (), ArrT (ArrayAT (elemt, Some [])))),
          Array { Array.elements = []; comments }
        )
      | elems ->
        let (elem_spread_list, elements) = array_elements cx ~array_hint:hint loc elems in
        ( ( loc,
            Tvar.mk_where cx reason (fun tout ->
                let reason_op = reason in
                let element_reason =
                  replace_desc_reason Reason.inferred_union_elem_array_desc reason_op
                in
                let elem_t = Tvar.mk cx element_reason in
                let resolve_to = ResolveSpreadsToArrayLiteral (mk_id (), elem_t, tout) in
                Flow.resolve_spread_list
                  cx
                  ~use_op:unknown_use
                  ~reason_op
                  elem_spread_list
                  resolve_to
            )
          ),
          Array { Array.elements; comments }
        ))
    | New
        {
          New.callee =
            ( callee_loc,
              Identifier (id_loc, ({ Ast.Identifier.name = ""Function""; comments = _ } as name))
            );
          targs;
          arguments;
          comments;
        } ->
      let targts_opt =
        Base.Option.map targs ~f:(fun (targts_loc, args) ->
            (targts_loc, convert_call_targs cx Subst_name.Map.empty args)
        )
      in
      let (argts, arges) =
        match arguments with
        | Some arguments ->
          let (argts, arges) = arg_list cx arguments in
          (argts, Some arges)
        | None -> ([], None)
      in
      let id_t = identifier cx name callee_loc in
      let callee_annot = (callee_loc, id_t) in
      (match targts_opt with
      | None ->
        List.iter
          (function
            | Arg t
            | SpreadArg t ->
              Flow.flow_t cx (t, StrT.at loc |> with_trust bogus_trust))
          argts;
        let reason = mk_reason (RCustom ""new Function(..)"") loc in
        let proto = ObjProtoT reason in
        ( ( loc,
            DefT
              ( reason,
                bogus_trust (),
                FunT
                  ( dummy_static reason,
                    mk_functiontype
                      reason
                      []
                      ~rest_param:None
                      ~def_reason:reason
                      ~params_names:[]
                      proto
                  )
              )
          ),
          New
            {
              New.callee = (callee_annot, Identifier ((id_loc, id_t), name));
              targs = None;
              arguments = arges;
              comments;
            }
        )
      | Some (targts_loc, targts) ->
        Flow.add_output
          cx
          Error_message.(
            ECallTypeArity
              {
                call_loc = loc;
                is_new = true;
                reason_arity = Reason.(locationless_reason (RType (OrdinaryName ""Function"")));
                expected_arity = 0;
              }
          );
        ( (loc, AnyT.at (AnyError None) loc),
          New
            {
              New.callee = (callee_annot, Identifier ((id_loc, id_t), name));
              targs = Some (targts_loc, snd targts);
              arguments = arges;
              comments;
            }
        ))
    | New
        {
          New.callee =
            ( callee_loc,
              Identifier (id_loc, ({ Ast.Identifier.name = ""Array"" as n; comments = _ } as name))
            );
          targs;
          arguments;
          comments;
        } ->
      let targts =
        Base.Option.map targs ~f:(fun (loc, args) ->
            (loc, convert_call_targs cx Subst_name.Map.empty args)
        )
      in
      let (argts, args) =
        match arguments with
        | Some arguments ->
          let (argts, args) = arg_list cx arguments in
          (argts, Some args)
        | None -> ([], None)
      in
      let result =
        match (targts, argts) with
        | ( Some (loc, ([t], ({ CallTypeArgs.arguments = [_]; comments = _ } as call_targs))),
            [Arg argt]
          ) ->
          Ok (Some (loc, call_targs, t), argt)
        | (None, [Arg argt]) -> Ok (None, argt)
        | (None, _) -> Error (Error_message.EUseArrayLiteral loc)
        | (Some _, _) ->
          Error
            Error_message.(
              ECallTypeArity
                {
                  call_loc = loc;
                  is_new = true;
                  reason_arity = Reason.(locationless_reason (RType (OrdinaryName n)));
                  expected_arity = 1;
                }
            )
      in
      (match result with
      | Ok (targ_t, arg_t) ->
        let reason = mk_reason (RCustom ""new Array(..)"") loc in
        let length_reason = replace_desc_reason (RCustom ""array length"") reason in
        Flow.flow_t cx (arg_t, DefT (length_reason, bogus_trust (), NumT AnyLiteral));
        let (t, targs) =
          match targ_t with
          | Some (loc, ast, ExplicitArg t) -> (t, Some (loc, ast))
          | Some (_, _, ImplicitArg _)
          | None ->
            let element_reason = replace_desc_reason (RCustom ""array element"") reason in
            (Tvar.mk cx element_reason, None)
        in
        let id_t = identifier cx name callee_loc in
        (* TODO - tuple_types could be undefined x N if given a literal *)
        ( (loc, DefT (reason, bogus_trust (), ArrT (ArrayAT (t, None)))),
          New
            {
              New.callee = ((callee_loc, id_t), Identifier ((id_loc, id_t), name));
              targs;
              arguments = args;
              comments;
            }
        )
      | Error err ->
        Flow.add_output cx err;
        Tast_utils.error_mapper#expression ex)
    | New { New.callee; targs; arguments; comments } ->
      let (((_, class_), _) as callee_ast) = expression cx ~hint:None callee in
      let (targts, targs_ast) = convert_call_targs_opt cx targs in
      let (argts, args_reasons, arguments_ast) =
        match arguments with
        | Some arguments ->
          let (argst, arguments_ast) = arg_list cx arguments in
          let args_reasons = mk_initial_arguments_reason arguments in
          (argst, args_reasons, Some arguments_ast)
        | None -> ([], [], None)
      in
      let reason = mk_reason (RConstructorCall (desc_of_t class_)) loc in
      let use_op =
        Op
          (FunCall
             {
               op = mk_expression_reason ex;
               fn = mk_expression_reason callee;
               args = args_reasons;
               local = true;
             }
          )
      in
      ( (loc, new_call cx reason ~use_op class_ targts argts),
        New { New.callee = callee_ast; targs = targs_ast; arguments = arguments_ast; comments }
      )
    | Call _ -> subscript ~cond cx ex
    | OptionalCall _ -> subscript ~cond cx ex
    | Conditional { Conditional.test; consequent; alternate; comments } ->
      let reason = mk_reason RConditional loc in
      let (test, preds, not_preds, xtypes) = predicates_of_condition ~cond:OtherTest cx test in
      let env = Env.peek_env () in
      let oldset = Changeset.Global.clear () in
      let then_env = Env.clone_env env in
      Env.update_env loc then_env;
      let _ = Env.refine_with_preds cx loc preds xtypes in
      let ((((_, t1), _) as consequent), then_abnormal) =
        Abnormal.catch_expr_control_flow_exception (fun () -> expression cx ~hint:None consequent)
      in
      let else_env = Env.clone_env env in
      Env.update_env loc else_env;
      let _ = Env.refine_with_preds cx loc not_preds xtypes in
      let ((((_, t2), _) as alternate), else_abnormal) =
        Abnormal.catch_expr_control_flow_exception (fun () -> expression cx ~hint:None alternate)
      in
      let newset = Changeset.Global.merge oldset in
      let (end_env, combined_type) =
        match (then_abnormal, else_abnormal) with
        (* If one side throws (using invariant()) only refine with the other
           side.*)
        | (Some Abnormal.Throw, None) -> (else_env, t2)
        | (None, Some Abnormal.Throw) -> (then_env, t1)
        | (Some Abnormal.Throw, Some Abnormal.Throw) ->
          Env.merge_env cx loc (env, then_env, else_env) newset;
          (env, EmptyT.at loc |> with_trust bogus_trust)
        (* Both sides threw--see below for where we re-raise *)
        | (None, None) ->
          Env.merge_env cx loc (env, then_env, else_env) (Changeset.exclude_refines newset);
          (env, UnionT (reason, UnionRep.make t1 t2 []))
        (* NOTE: In general it is dangerous to express the least upper bound of
           some types as a union: it might pin down the least upper bound
           prematurely (before all the types have been inferred), and when the
           union appears as an upper bound, it might lead to speculative matching.

           However, here a union is safe, because this union is guaranteed to only
           appear as a lower bound.

           In such ""covariant"" positions, avoiding unnecessary indirection via
           tvars is a good thing, because it improves precision. In particular, it
           enables more types to be fully resolvable, which improves results of
           speculative matching.

           It should be possible to do this more broadly and systematically. For
           example, results of operations on annotations (like property gets on
           objects, calls on functions) are often represented as unresolved tvars,
           where they could be pinned down to resolved types.
        *)
        | _ ->
          (* The only kind of abnormal control flow that should be raised from
             an expression is a Throw. The other kinds (return, break, continue)
             can only arise from statements, and while statements can appear within
             expressions (eg function expressions), any abnormals will be handled
             before they get here. *)
          assert_false ""Unexpected abnormal control flow from within expression""
      in
      Env.update_env loc end_env;

      (* TODO call loc_of_predicate on some pred?
         t1 is wrong but hopefully close *)
      let ast =
        ((loc, combined_type), Conditional { Conditional.test; consequent; alternate; comments })
      in
      (* handle control flow in cases where we've thrown from both sides *)
      begin
        match (then_abnormal, else_abnormal) with
        | (Some then_exn, Some else_exn) when then_exn = else_exn ->
          Abnormal.throw_expr_control_flow_exception loc ast then_exn
        | _ -> ast
      end
    | Assignment { Assignment.operator; left; right; comments } ->
      let (t, left, right) = assignment cx loc (left, operator, right) in
      ((loc, t), Assignment { Assignment.operator; left; right; comments })
    | Sequence { Sequence.expressions; comments } ->
      let expressions = Base.List.map ~f:(expression cx ~hint:None) expressions in
      (* t = last element of ts. The parser guarantees sequence expressions are nonempty. *)
      let t = List.(expressions |> map snd_fst |> rev |> hd) in
      ((loc, t), Sequence { Sequence.expressions; comments })
    | Function func ->
      let { Ast.Function.id; predicate; sig_loc; generator; async; _ } = func in
      (match predicate with
      | Some (_, { Ast.Type.Predicate.kind = Ast.Type.Predicate.Inferred; comments = _ }) ->
        Flow.add_output
          cx
          Error_message.(EUnsupportedSyntax (loc, PredicateDeclarationWithoutExpression))
      | _ -> ());
      let reason = func_reason ~async ~generator sig_loc in
      let tvar = Tvar.mk cx reason in
      let (t, func) =
        match id with
        | None -> mk_function_expression cx ~hint reason ~needs_this_param:true ~general:tvar func
        | Some (name_loc, { Ast.Identifier.name; comments = _ }) ->
          let scope = Scope.fresh () in
          Env.push_var_scope scope;
          let name = OrdinaryName name in
          Env.bind_fun cx name tvar name_loc;
          let (t, func) =
            mk_function_expression cx ~hint reason ~needs_this_param:true ~general:tvar func
          in
          let use_op =
            Op (AssignVar { var = Some (mk_reason (RIdentifier name) loc); init = reason_of_t t })
          in
          Env.init_fun cx ~use_op name t name_loc;
          Env.pop_var_scope ();
          (t, func)
      in
      Flow.flow_t cx (t, tvar);
      ((loc, t), Function func)
    | ArrowFunction func ->
      let reason = Ast.Function.(func_reason ~async:func.async ~generator:func.generator loc) in
      let (t, f) = mk_arrow cx ~hint reason func in
      ((loc, t), ArrowFunction f)
    (*
     * GraphQL literals, e.g.:
     * graphql`fragment Foo {}`
     *)
    | TaggedTemplate
        {
          TaggedTemplate.tag = (_, Identifier (_, { Ast.Identifier.name = ""graphql""; _ })) as tag;
          quasi;
          comments;
        }
      when Context.enable_relay_integration cx ->
      let module_prefix = Context.relay_integration_module_prefix cx in
      let t =
        match Graphql.extract_module_name ~module_prefix quasi with
        | Ok module_name -> Import_export.require cx (loc, module_name) loc
        | Error err ->
          Flow.add_output cx (Error_message.EInvalidGraphQL (loc, err));
          let reason = mk_reason (RCustom ""graphql tag"") loc in
          AnyT.error reason
      in
      let tag_ast = expression cx ~hint:None tag in
      let quasi_ast =
        let (quasi_loc, { TemplateLiteral.quasis; expressions; comments }) = quasi in
        let expressions = Base.List.map ~f:(expression cx ~hint:None) expressions in
        (quasi_loc, { TemplateLiteral.quasis; expressions; comments })
      in
      ((loc, t), TaggedTemplate { TaggedTemplate.tag = tag_ast; quasi = quasi_ast; comments })
    | TaggedTemplate
        {
          TaggedTemplate.tag;
          (* TODO: walk quasis? *)
          quasi = (quasi_loc, { TemplateLiteral.quasis; expressions; comments = quasi_comments });
          comments = tagged_template_comments;
        } ->
      let expressions = Base.List.map ~f:(expression cx ~hint:None) expressions in
      let (((_, t), _) as tag_ast) = expression cx ~hint:None tag in
      let reason = mk_reason (RCustom ""encaps tag"") loc in
      let reason_array = replace_desc_reason RArray reason in
      let ret = (reason, Tvar.mk_no_wrap cx reason) in
      (* tag`a${b}c${d}` -> tag(['a', 'c'], b, d) *)
      let call_t =
        let args =
          let quasi_t =
            DefT
              ( reason_array,
                bogus_trust (),
                ArrT (ArrayAT (StrT.why reason |> with_trust bogus_trust, None))
              )
          in
          let exprs_t = Base.List.map ~f:(fun ((_, t), _) -> Arg t) expressions in
          Arg quasi_t :: exprs_t
        in
        let ft = mk_functioncalltype reason None args ret in
        let use_op =
          Op
            (FunCall
               {
                 op = mk_expression_reason ex;
                 fn = mk_expression_reason tag;
                 args = [];
                 local = true;
               }
            )
        in
        CallT (use_op, reason, ft)
      in
      Flow.flow cx (t, call_t);

      ( (loc, OpenT ret),
        TaggedTemplate
          {
            TaggedTemplate.tag = tag_ast;
            quasi = (quasi_loc, { TemplateLiteral.quasis; expressions; comments = quasi_comments });
            comments = tagged_template_comments;
          }
      )
    | TemplateLiteral { TemplateLiteral.quasis; expressions; comments } ->
      let (t, expressions) =
        match quasis with
        | [head] ->
          let ( elem_loc,
                { TemplateLiteral.Element.value = { TemplateLiteral.Element.raw; cooked }; _ }
              ) =
            head
          in
          let lit = { Ast.Literal.value = Ast.Literal.String cooked; raw; comments = None } in
          (literal cx elem_loc lit, [])
        | _ ->
          let t_out = StrT.at loc |> with_trust bogus_trust in
          let expressions =
            Base.List.map
              ~f:(fun expr ->
                let (((_, t), _) as e) = expression cx ~hint:None expr in
                Flow.flow
                  cx
                  ( t,
                    UseT
                      ( Op
                          (Coercion { from = mk_expression_reason expr; target = reason_of_t t_out }),
                        t_out
                      )
                  );
                e)
              expressions
          in
          (t_out, expressions)
      in
      ((loc, t), TemplateLiteral { TemplateLiteral.quasis; expressions; comments })
    | JSXElement e ->
      let (t, e) = jsx cx loc e in
      ((loc, t), JSXElement e)
    | JSXFragment f ->
      let (t, f) = jsx_fragment cx loc f in
      ((loc, t), JSXFragment f)
    | Class c ->
      let class_loc = loc in
      let (name_loc, name) =
        match Ast.Class.(c.id) with
        | Some (name_loc, { Ast.Identifier.name; comments = _ }) -> (name_loc, name)
        | None -> (class_loc, ""<<anonymous class>>"")
      in
      let reason = mk_reason (RIdentifier (OrdinaryName name)) class_loc in
      let tvar = Tvar.mk cx reason in
      (match c.Ast.Class.id with
      | Some _ ->
        let scope = Scope.fresh () in
        Scope.(
          let kind = Entry.ClassNameBinding in
          let entry =
            Entry.(
              new_let (Annotated tvar) ~provider:tvar ~loc:name_loc ~state:State.Declared ~kind
            )
          in
          add_entry (OrdinaryName name) entry scope
        );
        Env.push_var_scope scope;
        let (class_t, c) = mk_class cx class_loc ~name_loc ~general:tvar reason c in
        (* mk_class above ensures that the function name in the inline declaration
           has the same type as its references inside the class.
           However, in the new env, we need to perform a bind of the class declaration type to the
           name to ensure that the environment knows the type of both the declaration and usages. *)
        if Env.new_env then (
          let name = OrdinaryName name in
          let reason = mk_reason (RType name) name_loc in
          let tvar = Tvar.mk cx reason in
          Env.bind_implicit_let Scope.Entry.ClassNameBinding cx name (Inferred tvar) name_loc;

          let kind = Scope.Entry.ClassNameBinding in
          Env.declare_implicit_let kind cx name name_loc;
          let use_op =
            Op
              (AssignVar
                 { var = Some (mk_reason (RIdentifier name) name_loc); init = reason_of_t class_t }
              )
          in
          Env.init_implicit_let kind cx ~use_op name ~has_anno:false class_t name_loc
        );
        Env.pop_var_scope ();
        Flow.flow_t cx (class_t, tvar);
        ((class_loc, class_t), Class c)
      | None ->
        let (class_t, c) = mk_class cx class_loc ~name_loc ~general:tvar reason c in
        Flow.flow_t cx (class_t, tvar);
        ((class_loc, class_t), Class c))
    | Yield { Yield.argument; delegate = false; comments } ->
      let yield = Env.get_internal_var cx ""yield"" loc in
      let (t, argument_ast) =
        match argument with
        | Some expr ->
          let (((_, t), _) as expr) = expression cx ~hint:None expr in
          (t, Some expr)
        | None -> (VoidT.at loc |> with_trust bogus_trust, None)
      in
      Env.havoc_heap_refinements ();
      Env.havoc_local_refinements ~all:true cx;
      let use_op =
        Op
          (GeneratorYield
             {
               value =
                 (match argument with
                 | Some expr -> mk_expression_reason expr
                 | None -> reason_of_t t);
             }
          )
      in
      Flow.flow cx (t, UseT (use_op, yield));
      ( (loc, Env.get_internal_var cx ""next"" loc),
        Yield { Yield.argument = argument_ast; delegate = false; comments }
      )
    | Yield { Yield.argument; delegate = true; comments } ->
      let reason = mk_reason (RCustom ""yield* delegate"") loc in
      let next = Env.get_internal_var cx ""next"" loc in
      let yield = Env.get_internal_var cx ""yield"" loc in
      let (t, argument_ast) =
        match argument with
        | Some expr ->
          let (((_, t), _) as expr) = expression cx ~hint:None expr in
          (t, Some expr)
        | None -> assert_false ""delegate yield without argument""
      in
      let ret_reason =
        update_desc_reason
          (fun desc -> RCustom (spf ""return of child generator in %s"" (string_of_desc desc)))
          reason
      in
      let ret = Tvar.mk cx ret_reason in
      (* widen yield with the element type of the delegated-to iterable *)
      let targs = [yield; ret; next] in
      let (async, iterable_reason) =
        if Env.in_async_scope () then
          (true, mk_reason (RCustom ""async iteration expected on AsyncIterable"") loc)
        else
          (false, mk_reason (RCustom ""iteration expected on Iterable"") loc)
      in
      Env.havoc_heap_refinements ();
      let use_op =
        Op
          (GeneratorYield
             {
               value =
                 (match argument with
                 | Some expr -> mk_expression_reason expr
                 | None -> reason_of_t t);
             }
          )
      in
      Flow.flow cx (t, AssertIterableT { use_op; reason = iterable_reason; async; targs });

      ((loc, ret), Yield { Yield.argument = argument_ast; delegate = true; comments })
    (* TODO *)
    | Comprehension _ ->
      Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, ComprehensionExpression));
      Tast_utils.error_mapper#expression ex
    | Generator _ ->
      Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, GeneratorExpression));
      Tast_utils.error_mapper#expression ex
    | MetaProperty
        {
          MetaProperty.meta = (_, { Ast.Identifier.name = ""new""; _ }) as meta;
          property = (_, { Ast.Identifier.name = ""target""; _ }) as property;
          comments;
        } ->
      let t = bogus_trust () |> MixedT.at loc in
      ((loc, t), MetaProperty { MetaProperty.meta; property; comments })
    | MetaProperty
        {
          MetaProperty.meta = (_, { Ast.Identifier.name = ""import""; _ }) as meta;
          property = (_, { Ast.Identifier.name = ""meta""; _ }) as property;
          comments;
        } ->
      let reason = mk_reason (RCustom ""import.meta"") loc in
      let t = Flow.get_builtin_type cx reason (OrdinaryName ""Import$Meta"") in
      ((loc, t), MetaProperty { MetaProperty.meta; property; comments })
    | MetaProperty _ ->
      Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, MetaPropertyExpression));
      Tast_utils.error_mapper#expression ex
    | Import { Import.argument; comments } ->
      (match argument with
      | ( source_loc,
          Ast.Expression.Literal
            { Ast.Literal.value = Ast.Literal.String module_name; raw; comments = _ }
        )
      | ( source_loc,
          TemplateLiteral
            {
              TemplateLiteral.quasis =
                [
                  ( _,
                    {
                      TemplateLiteral.Element.value =
                        { TemplateLiteral.Element.cooked = module_name; raw };
                      _;
                    }
                  );
                ];
              expressions = [];
              comments = _;
            }
        ) ->
        let literal_comments =
          match argument with
          | (_, Ast.Expression.Literal { Ast.Literal.comments; _ }) -> comments
          | _ -> None
        in
        let imported_module_t =
          let import_reason = mk_reason (RModule (OrdinaryName module_name)) loc in
          Import_export.import_ns cx import_reason (source_loc, module_name)
        in
        let reason = mk_annot_reason RAsyncImport loc in
        let t = Flow.get_builtin_typeapp cx reason (OrdinaryName ""Promise"") [imported_module_t] in
        ( (loc, t),
          Import
            {
              Import.argument =
                ( (source_loc, t),
                  Ast.Expression.Literal
                    {
                      Ast.Literal.value = Ast.Literal.String module_name;
                      raw;
                      comments = literal_comments;
                    }
                );
              comments;
            }
        )
      | _ ->
        let ignore_non_literals = Context.should_ignore_non_literal_requires cx in
        if not ignore_non_literals then (
          Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, ImportDynamicArgument));
          Tast_utils.error_mapper#expression ex
        ) else
          Tast_utils.unchecked_mapper#expression ex)

  (* Handles operations that may traverse optional chains.
     If there is some cond, will allow non-existent properties to be looked up
       at the top-level of the chain.
     If is_existence_check is true and the top of the chain is a member lookup
       ""a.x"", generate the predicate ""a.x exists"" and ""a has property x"".
     In addition to checking chains, this function produces predicates of the above
     form for all optional member accesses in the chain: everywhere we see an
     expression like ""a.x?.y"", generate the predicate ""a.x exists"" and ""a has
     property x"", because if that was not the case, the optional chain operator
     would short-circuit the evaluation of the chain at runtime.

     This function also generates the inverse of the predicates, for when the chain
     does short-circuit. So for example, if called with
     ~is_existence_check:true, a?.b.c?.d generates the following predicates
     for the non-short-circuit case:
       ""a exists"" /\ ""a.b.c exists"" /\ ""a.b has property c"" /\ ""a.b.c.d exists"" /\ ""a.b.c has property d""
     and the negation of the above for the short-circuiting/falsy case.

     There is also an optional sentinel_refine argument which is applied to the
     top of the chain, and which can produce an additional refinement, but which
     callers will handle specially. See usage in condition_of_maybe_sentinel.

     Returns a tuple:
       * type of expression if no optional chains short-circuited,
       * optional type of all possible short-circuitings,
       * typed AST of expression, where the type is the combination of
         short-circuiting and non short-circuiting (i.e. representing the actual
         range of possible types of the expression),
       * predicates that hold if the chain does not short-circuit and if it
         does.
       * result of applying sentinel_refine to the top of the chain, if anything.
  *)
  and optional_chain ~cond ~is_existence_check ?sentinel_refine cx ((loc, e) as ex) =
    let open Ast.Expression in
    let factor_out_optional (_, e) =
      let (opt_state, e') =
        match e with
        | OptionalCall { OptionalCall.call; optional } ->
          let opt_state =
            if optional then
              NewChain
            else
              ContinueChain
          in
          (opt_state, Call call)
        | OptionalMember { OptionalMember.member; optional } ->
          let opt_state =
            if optional then
              NewChain
            else
              ContinueChain
          in
          (opt_state, Member member)
        | _ -> (NonOptional, e)
      in
      let call_ast call =
        match opt_state with
        | NewChain -> OptionalCall { OptionalCall.call; optional = true }
        | ContinueChain -> OptionalCall { OptionalCall.call; optional = false }
        | NonOptional -> Call call
      in
      let member_ast member =
        match opt_state with
        | NewChain -> OptionalMember { OptionalMember.member; optional = true }
        | ContinueChain -> OptionalMember { OptionalMember.member; optional = false }
        | NonOptional -> Member member
      in
      (e', opt_state, call_ast, member_ast)
    in
    let mk_preds =
      List.fold_left
        (fun preds (key, pred, ty) ->
          match preds with
          | Some (preds, not_preds, xtys) ->
            Some
              ( Key_map.add key pred preds,
                Key_map.add key (NotP pred) not_preds,
                Key_map.add key ty xtys
              )
          | None ->
            Some
              ( Key_map.singleton key pred,
                Key_map.singleton key (NotP pred),
                Key_map.singleton key ty
              ))
        None
    in
    (* Later bindings for the same key in pred_list will override earlier bindings.
       They are treated as a unit in both positive and negative branches of the
       refinements: if the positive branch is ""a.b truthy /\ a has truthy prop b"",
       then the negative branch is ""a.b not truthy /\ a does not have truthy prop b"".
       This unit is itself then AND'ed to the positive branch and OR'ed to the
       negative branch of any existing predicates.
    *)
    let combine_preds existing_preds pred_list =
      let new_preds = mk_preds pred_list in
      match (existing_preds, new_preds) with
      | (Some existing_preds, None) -> Some existing_preds
      | ( Some (existing_preds, existing_not_preds, existing_xtys),
          Some (new_preds, new_not_preds, new_xtys)
        ) ->
        Some
          ( mk_and existing_preds new_preds,
            mk_or existing_not_preds new_not_preds,
            Key_map.union existing_xtys new_xtys
          )
      | (None, _) -> new_preds
    in
    let exists_pred ((loc, _) as expr) lhs_t =
      if is_existence_check then
        let pred =
          (* there is some cond when this expression is the top-level of a conditional,
             ""if ([expr]) {...}"". In this case, we check both that the expression exists and
             that it has a truthy type (that's what the ""ExistsP"" predicate does). If we're
             deeper in the chain, then cond will be None, and we only care if the expression
             is null or undefined, not if it's false/0/"""". *)
          if Base.Option.is_some cond then (
            Context.add_exists_check cx loc lhs_t;
            ExistsP
          ) else
            NotP MaybeP
        in
        match Refinement.key ~allow_optional:true expr with
        | Some key_name -> [(key_name, pred, lhs_t)]
        | None -> []
      else
        []
    in
    let prop_exists_pred object_ name obj_t prop_reason =
      if is_existence_check then
        let prop_pred =
          (* see comment on exists_pred *)
          if Base.Option.is_some cond then
            PropExistsP (name, prop_reason)
          else
            PropNonMaybeP (name, prop_reason)
        in
        match Refinement.key ~allow_optional:true object_ with
        | Some key_name -> [(key_name, prop_pred, obj_t)]
        | None -> []
      else
        []
    in
    let try_non_chain cx loc e ~call_ast ~member_ast =
      (* Special cases where optional chaining doesn't occur *)
      match e with
      | Call
          {
            Call.callee =
              ( callee_loc,
                Identifier (id_loc, ({ Ast.Identifier.name = ""require"" as n; comments = _ } as name))
              );
            targs;
            arguments;
            comments;
          }
        when not (Env.local_scope_entry_exists cx id_loc n) ->
        let targs =
          Base.Option.map targs ~f:(fun (args_loc, args) ->
              (args_loc, snd (convert_call_targs cx Subst_name.Map.empty args))
          )
        in
        let (lhs_t, arguments) =
          match (targs, arguments) with
          | ( None,
              ( args_loc,
                {
                  ArgList.arguments =
                    [
                      Expression
                        ( ( source_loc,
                            Ast.Expression.Literal
                              { Ast.Literal.value = Ast.Literal.String module_name; _ }
                          ) as lit_exp
                        );
                    ];
                  comments;
                }
              )
            ) ->
            ( Import_export.require cx (source_loc, module_name) loc,
              ( args_loc,
                { ArgList.arguments = [Expression (expression cx ~hint:None lit_exp)]; comments }
              )
            )
          | ( None,
              ( args_loc,
                {
                  ArgList.arguments =
                    [
                      Expression
                        ( ( source_loc,
                            TemplateLiteral
                              {
                                TemplateLiteral.quasis =
                                  [
                                    ( _,
                                      {
                                        TemplateLiteral.Element.value =
                                          { TemplateLiteral.Element.cooked = module_name; _ };
                                        _;
                                      }
                                    );
                                  ];
                                expressions = [];
                                comments = _;
                              }
                          ) as lit_exp
                        );
                    ];
                  comments;
                }
              )
            ) ->
            ( Import_export.require cx (source_loc, module_name) loc,
              ( args_loc,
                { ArgList.arguments = [Expression (expression cx ~hint:None lit_exp)]; comments }
              )
            )
          | (Some _, arguments) ->
            ignore (arg_list cx arguments);
            Flow.add_output
              cx
              Error_message.(
                ECallTypeArity
                  {
                    call_loc = loc;
                    is_new = false;
                    reason_arity = Reason.(locationless_reason (RFunction RNormal));
                    expected_arity = 0;
                  }
              );
            (AnyT.at (AnyError None) loc, Tast_utils.error_mapper#arg_list arguments)
          | (None, arguments) ->
            ignore (arg_list cx arguments);
            let ignore_non_literals = Context.should_ignore_non_literal_requires cx in
            if not ignore_non_literals then
              Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, RequireDynamicArgument));
            (AnyT.at (AnyError None) loc, Tast_utils.error_mapper#arg_list arguments)
        in
        let id_t = bogus_trust () |> MixedT.at callee_loc in
        Env.havoc_heap_refinements ();
        Env.havoc_local_refinements cx;
        Some
          ( ( (loc, lhs_t),
              call_ast
                {
                  Call.callee = ((callee_loc, id_t), Identifier ((id_loc, id_t), name));
                  targs;
                  arguments;
                  comments;
                }
            ),
            None,
            None
          )
      | Call
          {
            Call.callee =
              ( callee_loc,
                Member
                  {
                    Member._object =
                      (_, Identifier (_, { Ast.Identifier.name = ""Object""; comments = _ })) as obj;
                    property =
                      Member.PropertyIdentifier
                        (prop_loc, ({ Ast.Identifier.name; comments = _ } as id));
                    comments = member_comments;
                  }
              ) as expr;
            targs;
            arguments;
            comments;
          } ->
        let (((_, obj_t), _) as obj_ast) = expression cx ~hint:None obj in
        let (lhs_t, targs, arguments) =
          static_method_call_Object cx loc callee_loc prop_loc expr obj_t name targs arguments
        in
        Some
          ( ( (loc, lhs_t),
              let t = bogus_trust () |> MixedT.at callee_loc in
              call_ast
                {
                  Call.callee (* TODO(vijayramamurthy): what is the type of `Object.name` ? *) =
                    ( (callee_loc, t),
                      Member
                        {
                          Member._object = obj_ast;
                          property = Member.PropertyIdentifier ((prop_loc, t), id);
                          comments = member_comments;
                        }
                    );
                  targs;
                  arguments;
                  comments;
                }
            ),
            None,
            None
          )
      | Call
          {
            Call.callee =
              ( callee_loc,
                Member
                  {
                    Member._object = (super_loc, Super super);
                    property =
                      Member.PropertyIdentifier (ploc, ({ Ast.Identifier.name; comments = _ } as id));
                    comments = member_comments;
                  }
              ) as callee;
            targs;
            arguments;
            comments;
          } ->
        let reason = mk_reason (RMethodCall (Some name)) loc in
        let reason_lookup = mk_reason (RProperty (Some (OrdinaryName name))) callee_loc in
        let reason_prop = mk_reason (RProperty (Some (OrdinaryName name))) ploc in
        let super_t = super_ cx super_loc in
        let meth_generic_this = this_ cx loc { This.comments = None } in
        let (targts, targs) = convert_call_targs_opt cx targs in
        let (argts, arguments_ast) = arg_list cx arguments in
        Type_inference_hooks_js.dispatch_call_hook cx name ploc super_t;
        let prop_t = Tvar.mk cx reason_prop in
        let lhs_t =
          Tvar.mk_no_wrap_where cx reason (fun t ->
              let funtype = mk_methodcalltype ~meth_generic_this targts argts t in
              let use_op =
                Op
                  (FunCallMethod
                     {
                       op = mk_expression_reason ex;
                       fn = mk_expression_reason callee;
                       prop = reason_prop;
                       args = mk_initial_arguments_reason arguments;
                       local = true;
                     }
                  )
              in
              Flow.flow
                cx
                ( super_t,
                  MethodT
                    ( use_op,
                      reason,
                      reason_lookup,
                      Named (reason_prop, OrdinaryName name),
                      CallM funtype,
                      Some prop_t
                    )
                )
          )
        in
        Some
          ( ( (loc, lhs_t),
              call_ast
                {
                  Call.callee =
                    ( (callee_loc, prop_t),
                      Member
                        {
                          Member._object = ((super_loc, super_t), Super super);
                          property = Member.PropertyIdentifier ((ploc, prop_t), id);
                          comments = member_comments;
                        }
                    );
                  targs;
                  arguments = arguments_ast;
                  comments;
                }
            ),
            None,
            None
          )
      | Call { Call.callee = (super_loc, Super super) as callee; targs; arguments; comments } ->
        let (targts, targs) = convert_call_targs_opt cx targs in
        let reason = mk_reason (RFunctionCall RSuper) loc in
        define_internal cx reason ""super"";
        let super_t = super_ cx super_loc in
        let (argts, arguments_ast) =
          (* TODO use hint in arg_list *)
          let _hint = hint_decompose_opt_todo (Some super_t) in
          arg_list cx arguments
        in
        (* switch back env entries for this and super from undefined *)
        define_internal cx reason ""this"";

        let meth_generic_this = this_ cx loc { This.comments = None } in
        let super_reason = reason_of_t super_t in
        let lhs_t =
          Tvar.mk_no_wrap_where cx reason (fun t ->
              let funtype = mk_methodcalltype ~meth_generic_this targts argts t in
              let propref = Named (super_reason, OrdinaryName ""constructor"") in
              let use_op =
                Op
                  (FunCall
                     {
                       op = mk_expression_reason ex;
                       fn = mk_expression_reason callee;
                       args = mk_initial_arguments_reason arguments;
                       local = true;
                     }
                  )
              in
              Flow.flow
                cx
                (super_t, MethodT (use_op, reason, super_reason, propref, CallM funtype, None))
          )
        in
        Some
          ( ( (loc, lhs_t),
              call_ast
                {
                  Call.callee = ((super_loc, super_t), Super super);
                  targs;
                  arguments = arguments_ast;
                  comments;
                }
            ),
            None,
            None
          )
      (******************************************)
      (* See ~/www/static_upstream/core/ *)
      | Call { Call.callee; targs; arguments; comments } when is_call_to_invariant callee ->
        (* TODO: require *)
        let (((_, callee_t), _) as callee) = expression cx ~hint:None callee in
        let targs =
          Base.Option.map targs ~f:(fun (loc, args) ->
              (loc, snd (convert_call_targs cx Subst_name.Map.empty args))
          )
        in
        (* NOTE: if an invariant expression throws abnormal control flow, the
           entire statement it was in is reconstructed in the typed AST as an
           expression statement containing just the invariant call. This should
           be ok for the most part since this is the most common way to call
           invariant. It's worth experimenting with whether people use invariant
           in other ways, and if not, restricting it to this pattern. *)
        let arguments =
          match (targs, arguments) with
          | (None, (args_loc, { ArgList.arguments = []; comments = args_comments })) ->
            (* invariant() is treated like a throw *)
            Env.reset_current_activation loc;
            Abnormal.save Abnormal.Throw;
            Abnormal.throw_expr_control_flow_exception
              loc
              ( (loc, VoidT.at loc |> with_trust bogus_trust),
                Ast.Expression.Call
                  {
                    Call.callee;
                    targs;
                    arguments = (args_loc, { ArgList.arguments = []; comments = args_comments });
                    comments;
                  }
              )
              Abnormal.Throw
          | ( None,
              ( args_loc,
                {
                  ArgList.arguments =
                    Expression
                      ( ( _,
                          Ast.Expression.Literal
                            { Ast.Literal.value = Ast.Literal.Boolean false; _ }
                        ) as lit_exp
                      )
                    :: arguments;
                  comments = args_comments;
                }
              )
            ) ->
            (* invariant(false, ...) is treated like a throw *)
            let arguments = Base.List.map ~f:(Fn.compose snd (expression_or_spread cx)) arguments in
            Env.reset_current_activation loc;
            Abnormal.save Abnormal.Throw;
            let lit_exp = expression cx ~hint:None lit_exp in
            Abnormal.throw_expr_control_flow_exception
              loc
              ( (loc, VoidT.at loc |> with_trust bogus_trust),
                Ast.Expression.Call
                  {
                    Call.callee;
                    targs;
                    arguments =
                      ( args_loc,
                        {
                          ArgList.arguments = Expression lit_exp :: arguments;
                          comments = args_comments;
                        }
                      );
                    comments;
                  }
              )
              Abnormal.Throw
          | ( None,
              ( args_loc,
                { ArgList.arguments = Expression cond :: arguments; comments = args_comments }
              )
            ) ->
            let arguments = Base.List.map ~f:(Fn.compose snd (expression_or_spread cx)) arguments in
            let ((((_, cond_t), _) as cond), preds, _, xtypes) =
              predicates_of_condition ~cond:OtherTest cx cond
            in
            let _ = Env.refine_with_preds cx loc preds xtypes in
            let reason = mk_reason (RFunctionCall (desc_of_t callee_t)) loc in
            Flow.flow cx (cond_t, InvariantT reason);
            ( args_loc,
              { ArgList.arguments = Expression cond :: arguments; comments = args_comments }
            )
          | (_, (_, { ArgList.arguments = Spread _ :: _; comments = _ })) ->
            ignore (arg_list cx arguments);
            Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, InvariantSpreadArgument));
            Tast_utils.error_mapper#arg_list arguments
          | (Some _, arguments) ->
            ignore (arg_list cx arguments);
            Flow.add_output
              cx
              Error_message.(
                ECallTypeArity
                  {
                    call_loc = loc;
                    is_new = false;
                    reason_arity = Reason.(locationless_reason (RFunction RNormal));
                    expected_arity = 0;
                  }
              );
            Tast_utils.error_mapper#arg_list arguments
        in
        let lhs_t = VoidT.at loc |> with_trust bogus_trust in
        Some (((loc, lhs_t), call_ast { Call.callee; targs; arguments; comments }), None, None)
      | Member
          {
            Member._object =
              ( object_loc,
                Identifier (id_loc, ({ Ast.Identifier.name = ""module""; comments = _ } as id_name))
              );
            property =
              Member.PropertyIdentifier
                (ploc, ({ Ast.Identifier.name = ""exports""; comments = _ } as exports_name));
            comments;
          }
        when not (Env.local_scope_entry_exists cx id_loc ""module"") ->
        let lhs_t = Import_export.get_module_exports cx loc in
        let module_reason = mk_reason (RCustom ""module"") object_loc in
        let module_t = MixedT.why module_reason |> with_trust bogus_trust in
        let _object =
          ((object_loc, module_t), Ast.Expression.Identifier ((id_loc, module_t), id_name))
        in
        Some
          ( ( (loc, lhs_t),
              member_ast
                {
                  Member._object;
                  property = Member.PropertyIdentifier ((ploc, lhs_t), exports_name);
                  comments;
                }
            ),
            None,
            None
          )
      | Member
          {
            Member._object =
              ( object_loc,
                Identifier
                  ( id_loc,
                    { Ast.Identifier.name = ""ReactGraphQL"" | ""ReactGraphQLLegacy""; comments = _ }
                  )
              );
            property =
              Member.PropertyIdentifier
                (ploc, ({ Ast.Identifier.name = ""Mixin""; comments = _ } as name));
            comments;
          } ->
        let reason = mk_reason (RCustom ""ReactGraphQLMixin"") loc in
        let lhs_t = Flow.get_builtin cx (OrdinaryName ""ReactGraphQLMixin"") reason in
        Some
          ( ( (loc, lhs_t),
              (* TODO(vijayramamurthy) what's the type of ""ReactGraphQL""? *)
              let t = AnyT.at Untyped object_loc in
              let property = Member.PropertyIdentifier ((ploc, t), name) in
              member_ast
                {
                  Member._object = ((object_loc, t), Identifier ((id_loc, t), name));
                  property;
                  comments;
                }
            ),
            None,
            None
          )
      | Member
          {
            Member._object = (super_loc, Super super);
            property =
              Member.PropertyIdentifier (ploc, ({ Ast.Identifier.name; comments = _ } as id));
            comments;
          } ->
        let super_t = super_ cx super_loc in
        let expr_reason = mk_reason (RProperty (Some (OrdinaryName name))) loc in
        let prop_reason = mk_reason (RProperty (Some (OrdinaryName name))) ploc in
        let lhs_t =
          match Refinement.get ~allow_optional:true cx (loc, e) loc with
          | Some t -> t
          | None ->
            if Type_inference_hooks_js.dispatch_member_hook cx name ploc super_t then
              Unsoundness.at InferenceHooks ploc
            else
              let use_op = Op (GetProperty (mk_expression_reason ex)) in
              get_prop ~use_op ~cond cx expr_reason super_t (prop_reason, name)
        in
        let property = Member.PropertyIdentifier ((ploc, lhs_t), id) in
        let ast =
          ( (loc, lhs_t),
            member_ast { Member._object = ((super_loc, super_t), Super super); property; comments }
          )
        in
        (* Even though there's no optional chaining for Super member accesses, we
           can still get predicates *)
        let sentinel_refinement =
          Base.Option.value_map ~f:(fun f -> f lhs_t) ~default:None sentinel_refine
        in
        let preds =
          exists_pred (loc, e) lhs_t
          @ prop_exists_pred (super_loc, Super super) name super_t prop_reason
        in
        Some (ast, mk_preds preds, sentinel_refinement)
      | _ -> None
    in
    let (e', opt_state, call_ast, member_ast) = factor_out_optional ex in

    (*
     When traversing an optional chain, we need to track the ""successful"" types
     (if all optional chain operators in the sequence filtered out null/void),
     the nullish results if any, from the possibility of the optional chain
     short-circuiting (there may be multiple sources of null, from multiple
     chain operators in the chain) and the ""actual""/final type of the overall
     expression, which can be seen as a union of the successful type and all
     possible nullish failure types.

     The optional_chain function therefore returns a 5-tuple:
       * T1: the type of the expression modulo optional chaining--i.e., the
         type in the case where any optional chain tests succeed,
       * T2: optionally, a type representing the union of all optional chain
         *failures*, if they may exist
       * exp: the typed AST expression, where the type of the node is the
         ""actual"" type of the expression, including both chain failures and
         chain successes.
       * preds: any predicates that can be used to refine elements of the
         optional chain based on whether a ?. operator short-circuits. If any
         predicates exist, this will be a Key_map.t of positive refinements
         (the chain didn't short circuit), a Key_map.t of negative refinements
         (the chain did short-circuit), and a Key_map.t of the original types
         of refined expressions. See predicates_of_condition for how these
         are used.
       * sentinel_refinement: optional additional predicate obtained by applying
         sentinel_refine to the top of the chain

     So, if `a: ?{b?: {c: number}}`, and the checked expression is `a?.b?.c`,
       then the output would be (T1, T2, T3, exp), where:
       * T1 = number
       * T2 = void, both from `a: ?{...}` and from `a: {b? : {...}}`
       * exp = ast for `a?.b?.c` with type T1 U T2
       * preds = assuming the overall function was called with ~cond,
             ""a exists and has non-nullish property b"", ""a.b exists and has
             truthy property c"", and ""a.b.c is truthy"", as well as the
             types of a, a.b, and a.b.c
       * possibly an additional refinement based on the sentinel_refine function,
         passed in by the caller.

    Below are several helper functions for setting up this tuple in the
    presence of chaining.
  *)
    let join_optional_branches voided filtered =
      match voided with
      | None -> filtered
      | Some void ->
        Tvar.mk_where cx (reason_of_t filtered) (fun t ->
            Flow.flow_t cx (filtered, t);
            Flow.flow_t cx (void, t)
        )
    in
    let noop _ = None in
    let in_env preds f =
      match preds with
      | Some (preds, _, xtypes) -> Env.in_refined_env cx loc preds xtypes f
      | None -> f ()
    in
    let handle_new_chain
        lhs_reason
        loc
        (chain_t, voided_t, object_ast, preds, _)
        ~this_reason
        ~subexpressions
        ~get_reason
        ~test_hooks
        ~get_opt_use =
      (* We've encountered an optional chaining operator.
         We need to flow the ""success"" type of object_ into a OptionalChainT
         type, which will ""filter out"" VoidT and NullT from the type of
         object_ and flow them into `voided_out`, and then flow any non-void
         type into a use_t created by applying an opt_use_t (representing the
         operation that will occur on the upper bound) to a new ""output"" tvar.

         This might not be the first optional chain operator in the chain, so
         we need to take chain_t, which is equivalent to T1 above and
         represents the result if any previous operator succeeded--this is the
         type that we want to flow into the OptionalChainT, because if the
         previous operator failed we wouldn't reach this point in the chain in
         the first place. We also take voided_t, equivalent to T2 above and
         representing any previous chain short-circuits, and it will
         contribute to the failure/short-circuit output of this function,
         `voided_out`.

         Method calls need a little bit of extra support, because MethodT
         acts as both a lookup and a call. Suppose `a: ?{b?: () => number}`
         and `a?.b?.().` We need to generate a funcalltype for the call to
         () => number, and funcalltypes include the receiver (""this"") of the
         call. However, we don't want the receiver to be the type of `a`,
         ?{b?: () => number}, because before calling the method, we've
         already filtered out the nullish case on `a`. The receiver instead
         should be {b?: () => number} (not optional). The bind_t parameter is
         (if present) the receiver of the method call, and is included in the
         OptionalChainT; see the rules in flow_js for how it's used, but
         essentially the successfully filtered receiver of the function call
         is flowed into it, and it is used as the `this`-parameter of the
         calltype that the method call will flow into. *)
      let (subexpression_types, subexpression_asts) = subexpressions preds in
      let reason = get_reason chain_t in
      let chain_reason = mk_reason ROptionalChain loc in
      let mem_tvar =
        match test_hooks chain_t with
        | Some hit -> hit
        | None -> (reason, Tvar.mk_no_wrap cx reason)
      in
      let voided_out =
        Tvar.mk_where cx reason (fun t ->
            Base.Option.iter ~f:(fun voided_t -> Flow.flow_t cx (voided_t, t)) voided_t
        )
      in
      let this_t = Tvar.mk cx this_reason in
      let opt_use = get_opt_use subexpression_types reason this_t in
      Flow.flow
        cx
        ( chain_t,
          OptionalChainT
            {
              reason = chain_reason;
              lhs_reason;
              this_t;
              t_out = apply_opt_use opt_use mem_tvar;
              voided_out;
            }
        );
      let lhs_t =
        Tvar.mk_where cx reason (fun t ->
            Flow.flow_t cx (OpenT mem_tvar, t);
            Flow.flow_t cx (voided_out, t)
        )
      in
      (OpenT mem_tvar, Some voided_out, lhs_t, chain_t, object_ast, subexpression_asts, preds)
    in
    let handle_continue_chain
        (chain_t, voided_t, object_ast, preds, _)
        ~refine
        ~refinement_action
        ~subexpressions
        ~get_result
        ~test_hooks
        ~get_reason =
      (* We're looking at a non-optional call or member access, but one where
         deeper in the chain there was an optional chaining operator. We don't
         need to do anything special locally, but we do need to remember that
         we might have short-circuited before getting here--that's the
         voided_t parameter. We'll flow that type into the type of the overall
         expression to account for that possibility.
      *)
      let (subexpression_types, subexpression_asts) = subexpressions preds in
      let reason = get_reason chain_t in
      let res_t =
        match (test_hooks chain_t, refine ()) with
        | (Some hit, _) -> OpenT hit
        | (None, Some refi) ->
          Base.Option.value_map
            ~f:(fun refinement_action -> refinement_action subexpression_types chain_t refi)
            ~default:refi
            refinement_action
        | (None, None) -> get_result subexpression_types reason chain_t
      in
      let lhs_t = join_optional_branches voided_t res_t in
      (res_t, voided_t, lhs_t, chain_t, object_ast, subexpression_asts, preds)
    in
    let handle_chaining
        ?refinement_action
        opt
        object_
        loc
        ~refine
        ~this_reason
        ~subexpressions
        ~get_result
        ~test_hooks
        ~get_opt_use
        ~get_reason =
      match opt with
      | NonOptional ->
        (* Proceeding as normal: no need to worry about optionality, so T2 from
           above is None. We don't need to consider optional short-circuiting, so
           we can call expression_ rather than optional_chain. *)
        let (((_, obj_t), _) as object_ast) = expression cx ~hint:None object_ in
        let (subexpression_types, subexpression_asts) = subexpressions None in
        let reason = get_reason obj_t in
        let lhs_t =
          match (test_hooks obj_t, refine ()) with
          | (Some hit, _) -> OpenT hit
          | (None, Some refi) ->
            Base.Option.value_map
              ~f:(fun refinement_action -> refinement_action subexpression_types obj_t refi)
              ~default:refi
              refinement_action
          | (None, None) -> get_result subexpression_types reason obj_t
        in
        (lhs_t, None, lhs_t, obj_t, object_ast, subexpression_asts, None)
      | NewChain ->
        let lhs_reason = mk_expression_reason object_ in
        let ((filtered_t, voided_t, object_ast, preds, _) as object_data) =
          optional_chain ~cond:None ~is_existence_check:true cx object_
        in
        begin
          match refine () with
          | Some t ->
            Context.mark_optional_chain cx loc lhs_reason ~useful:false;
            let (subexpression_types, subexpression_asts) = subexpressions preds in
            let tout =
              Base.Option.value_map
                ~f:(fun refinement_action -> refinement_action subexpression_types filtered_t t)
                ~default:t
                refinement_action
            in
            ( tout,
              voided_t,
              join_optional_branches voided_t tout,
              filtered_t,
              object_ast,
              subexpression_asts,
              preds
            )
          | _ ->
            handle_new_chain
              lhs_reason
              loc
              object_data
              ~subexpressions
              ~this_reason
              ~get_reason
              ~test_hooks
              ~get_opt_use
        end
      | ContinueChain ->
        handle_continue_chain
          (optional_chain ~cond:None ~is_existence_check:false cx object_)
          ~refine
          ~refinement_action
          ~subexpressions
          ~get_result
          ~test_hooks
          ~get_reason
    in
    let result =
      match try_non_chain cx loc e' ~call_ast ~member_ast with
      | Some ((((_, lhs_t), _) as res), preds, sentinel_refinement) ->
        (* Nothing to do with respect to optional chaining, because we're in a
           case where chaining isn't allowed. *)
        (lhs_t, None, res, preds, sentinel_refinement)
      | None ->
        let (e', method_receiver_and_state) =
          (* If we're looking at a call, look ""one level deeper"" to see if the
           * next element of the chain is an member access, in which case we're
           * looking at an optional method call and we need to process both
           * ""levels"" at once.  Similar to the call to factor_out_optional above,
           * we then factor out the optionality of the member lookup component of
           * the method call. However, we can skip this if the callee is optional
           * and the call is non-optional--this means that the callee is in
           * parentheses, so we can treat it as a regular GetProp followed by a
           * regular Call instead of using the special method call machinery. Such
           * a case would look like this:
           *
           *     callee
           *    vvvvvvvvv
           *   (obj?.meth)()
           *    ^^^
           *     member._object
           *)
          match (e', opt_state) with
          | ( Call
                ( {
                    Call.callee = (callee_loc, OptionalMember { OptionalMember.member; optional });
                    targs = _;
                    arguments = _;
                    comments = _;
                  } as call
                ),
              (NewChain | ContinueChain)
            ) ->
            let receiver_ast member = OptionalMember { OptionalMember.member; optional } in
            let member_opt =
              if optional then
                (* In this case:
                 *
                 *   callee
                 *  vvvvvvvvv
                 *  obj?.meth() (or obj?.meth?.())
                 *  ^^^
                 *   member._object
                 *
                 * There may or may not be other links in the chain earlier than obj, and the call
                 * to meth() may be optional itself (e.g. obj?.meth?.()) -- this has already been
                 * factored out.
                 *)
                NewChain
              else
                (* In this case:
                 *
                 *             callee
                 *            vvvvvvvv
                 * other_obj?.obj.meth() (or other_obj?.obj.meth?.())
                 *            ^^^
                 *             member._object
                 *)
                ContinueChain
            in
            ( Call { call with Call.callee = (callee_loc, Member member) },
              Some (member_opt, member, receiver_ast)
            )
          | (Call { Call.callee = (_, Member member); targs = _; arguments = _; comments = _ }, _)
            ->
            (e', Some (NonOptional, member, (fun member -> Member member)))
          | _ -> (e', None)
        in
        (match (e', method_receiver_and_state) with
        (* e1[e2] *)
        | (Member { Member._object; property = Member.PropertyExpression index; comments }, _) ->
          let reason = mk_reason (RProperty None) loc in
          let use_op = Op (GetProperty (mk_expression_reason ex)) in
          let get_opt_use tind _ _ = OptGetElemT (use_op, reason, tind) in
          let get_mem_t tind reason obj_t =
            Tvar.mk_no_wrap_where cx reason (fun t ->
                let use = apply_opt_use (get_opt_use tind reason obj_t) t in
                Flow.flow cx (obj_t, use)
            )
          in
          let eval_index preds =
            in_env preds (fun () ->
                let (((_, tind), _) as index) = expression cx ~hint:None index in
                (tind, index)
            )
          in
          let (filtered_out, voided_out, lhs_t, obj_t, object_ast, index, preds) =
            handle_chaining
              opt_state
              _object
              loc
              ~this_reason:(mk_expression_reason _object)
              ~subexpressions:eval_index
              ~get_result:get_mem_t
              ~test_hooks:noop
              ~get_opt_use
              ~refine:(fun () -> Refinement.get ~allow_optional:true cx (loc, e) loc)
              ~get_reason:(Fn.const reason)
          in
          let sentinel_refinement =
            Base.Option.value_map ~f:(fun f -> f obj_t) ~default:None sentinel_refine
          in
          let new_pred_list = exists_pred (loc, e') lhs_t in
          let preds = combine_preds preds new_pred_list in
          ( filtered_out,
            voided_out,
            ( (loc, lhs_t),
              member_ast
                {
                  Member._object = object_ast;
                  property = Member.PropertyExpression index;
                  comments;
                }
            ),
            preds,
            sentinel_refinement
          )
        (* e.l *)
        | ( Member
              {
                Member._object;
                property =
                  Member.PropertyIdentifier (ploc, ({ Ast.Identifier.name; comments = _ } as id));
                comments;
              },
            _
          ) ->
          let expr_reason = mk_expression_reason ex in
          let prop_reason = mk_reason (RProperty (Some (OrdinaryName name))) ploc in
          let use_op = Op (GetProperty expr_reason) in
          let opt_use = get_prop_opt_use ~cond expr_reason ~use_op (prop_reason, name) in
          let test_hooks obj_t =
            if Type_inference_hooks_js.dispatch_member_hook cx name ploc obj_t then
              Some (inference_hook_tvar cx ploc)
            else
              None
          in
          let get_mem_t () _ obj_t =
            Tvar.mk_no_wrap_where cx expr_reason (fun t ->
                let use = apply_opt_use opt_use t in
                Flow.flow cx (obj_t, use)
            )
          in
          let (filtered_out, voided_out, lhs_t, obj_t, object_ast, _, preds) =
            handle_chaining
              opt_state
              _object
              loc
              ~subexpressions:(Fn.const ((), ()))
              ~this_reason:(mk_expression_reason _object)
              ~get_result:get_mem_t
              ~refine:(fun () -> Refinement.get ~allow_optional:true cx (loc, e) loc)
              ~test_hooks
              ~get_opt_use:(fun _ _ _ -> opt_use)
              ~get_reason:(Fn.const expr_reason)
          in
          let sentinel_refinement =
            Base.Option.value_map ~f:(fun f -> f obj_t) ~default:None sentinel_refine
          in
          let new_pred_list =
            exists_pred (loc, e') filtered_out @ prop_exists_pred _object name obj_t prop_reason
          in
          let preds = combine_preds preds new_pred_list in
          let property = Member.PropertyIdentifier ((ploc, lhs_t), id) in
          ( filtered_out,
            voided_out,
            ((loc, lhs_t), member_ast { Member._object = object_ast; property; comments }),
            preds,
            sentinel_refinement
          )
        (* e.#l *)
        | ( Member
              {
                Member._object;
                property =
                  Member.PropertyPrivateName (ploc, { Ast.PrivateName.name; comments = _ }) as
                  property;
                comments;
              },
            _
          ) ->
          let expr_reason = mk_reason (RPrivateProperty name) loc in
          let use_op = Op (GetProperty (mk_expression_reason ex)) in
          let opt_use = get_private_field_opt_use expr_reason ~use_op name in
          let test_hooks obj_t =
            if Type_inference_hooks_js.dispatch_member_hook cx name ploc obj_t then
              Some (inference_hook_tvar cx ploc)
            else
              None
          in
          let get_mem_t () _ obj_t =
            Tvar.mk_no_wrap_where cx expr_reason (fun t ->
                let use = apply_opt_use opt_use t in
                Flow.flow cx (obj_t, use)
            )
          in
          let (filtered_out, voided_out, lhs_t, _, object_ast, _, preds) =
            handle_chaining
              opt_state
              _object
              loc
              ~this_reason:(mk_expression_reason _object)
              ~subexpressions:(Fn.const ((), ()))
              ~get_result:get_mem_t
              ~refine:(fun () -> Refinement.get ~allow_optional:true cx (loc, e) loc)
              ~test_hooks
              ~get_opt_use:(fun _ _ _ -> opt_use)
              ~get_reason:(Fn.const expr_reason)
          in
          let new_pred_list = exists_pred (loc, e') lhs_t in
          let preds = combine_preds preds new_pred_list in
          ( filtered_out,
            voided_out,
            ((loc, lhs_t), member_ast { Member._object = object_ast; property; comments }),
            preds,
            None
          )
        (* Method calls: e.l(), e.#l(), and e1[e2]() *)
        | ( Call { Call.callee = (lookup_loc, callee_expr) as callee; targs; arguments; comments },
            Some
              ( member_opt,
                ({ Member._object; property; comments = member_comments } as receiver),
                receiver_ast
              )
          ) ->
          let (targts, targs) = convert_call_targs_opt cx targs in
          let expr_reason = mk_expression_reason ex in
          let ( filtered_out,
                lookup_voided_out,
                call_voided_out,
                member_lhs_t,
                prop_t,
                object_ast,
                property,
                argument_asts
              ) =
            match property with
            | Member.PropertyPrivateName (prop_loc, { Ast.PrivateName.name; comments = _ })
            | Member.PropertyIdentifier (prop_loc, { Ast.Identifier.name; comments = _ }) ->
              let reason_call = mk_reason (RMethodCall (Some name)) loc in
              let reason_prop = mk_reason (RProperty (Some (OrdinaryName name))) prop_loc in
              let this_reason = mk_expression_reason callee in
              let use_op =
                Op
                  (FunCallMethod
                     {
                       op = expr_reason;
                       fn = mk_expression_reason (lookup_loc, receiver_ast receiver);
                       prop = reason_prop;
                       args = mk_initial_arguments_reason arguments;
                       local = true;
                     }
                  )
              in
              let prop_t = Tvar.mk cx reason_prop in
              let call_voided_out = Tvar.mk cx reason_call in
              let private_ =
                match property with
                | Member.PropertyExpression _ ->
                  Utils_js.assert_false ""unexpected property expression""
                | Member.PropertyPrivateName _ -> true
                | Member.PropertyIdentifier _ -> false
              in
              let get_opt_use argts _ _ =
                method_call_opt_use
                  cx
                  opt_state
                  ~prop_t
                  ~voided_out:call_voided_out
                  reason_call
                  ~use_op
                  ~private_
                  prop_loc
                  (callee, name)
                  loc
                  targts
                  argts
              in
              let test_hooks obj_t =
                if Type_inference_hooks_js.dispatch_member_hook cx name prop_loc obj_t then
                  Some (inference_hook_tvar cx prop_loc)
                else
                  None
              in
              let handle_refined_callee argts obj_t f =
                Env.havoc_heap_refinements ();
                Env.havoc_local_refinements cx;
                Tvar.mk_no_wrap_where cx reason_call (fun t ->
                    let app =
                      mk_boundfunctioncalltype obj_t targts argts t ~call_strict_arity:true
                    in
                    Flow.unify cx f prop_t;
                    let call_t =
                      match opt_state with
                      | NewChain ->
                        let chain_reason = mk_reason ROptionalChain loc in
                        let lhs_reason = mk_expression_reason callee in
                        let this_t = Tvar.mk cx this_reason in
                        OptionalChainT
                          {
                            reason = chain_reason;
                            lhs_reason;
                            this_t;
                            t_out = CallT (use_op, reason_call, app);
                            voided_out = OpenT t;
                          }
                      | _ -> CallT (use_op, reason_call, app)
                    in
                    Flow.flow cx (f, call_t)
                )
              in
              let get_mem_t argts reason obj_t =
                Type_inference_hooks_js.dispatch_call_hook cx name prop_loc obj_t;
                Tvar.mk_no_wrap_where cx reason_call (fun t ->
                    let use = apply_opt_use (get_opt_use argts reason obj_t) t in
                    Flow.flow cx (obj_t, use)
                )
              in
              let eval_args preds = in_env preds (fun () -> arg_list cx arguments) in
              let (filtered_out, lookup_voided_out, member_lhs_t, _, object_ast, argument_asts, _) =
                handle_chaining
                  member_opt
                  _object
                  lookup_loc
                  ~this_reason
                  ~subexpressions:eval_args
                  ~get_result:get_mem_t
                  ~test_hooks
                  ~get_opt_use
                  ~refine:(fun () ->
                    Refinement.get ~allow_optional:true cx (lookup_loc, callee_expr) lookup_loc)
                  ~refinement_action:handle_refined_callee
                  ~get_reason:(Fn.const expr_reason)
              in
              let prop_ast =
                match property with
                | Member.PropertyExpression _ ->
                  Utils_js.assert_false ""unexpected property expression""
                | Member.PropertyPrivateName (_, id) -> Member.PropertyPrivateName (prop_loc, id)
                | Member.PropertyIdentifier (_, id) ->
                  Member.PropertyIdentifier ((prop_loc, prop_t), id)
              in
              ( filtered_out,
                lookup_voided_out,
                call_voided_out,
                member_lhs_t,
                prop_t,
                object_ast,
                prop_ast,
                argument_asts
              )
            | Member.PropertyExpression expr ->
              let reason_call = mk_reason (RMethodCall None) loc in
              let reason_lookup = mk_reason (RProperty None) lookup_loc in
              let call_voided_out = Tvar.mk cx expr_reason in
              let prop_t = Tvar.mk cx reason_lookup in
              let get_opt_use (argts, elem_t) _ _ =
                elem_call_opt_use
                  opt_state
                  ~prop_t
                  ~voided_out:call_voided_out
                  ~reason_call
                  ~reason_lookup
                  ~reason_expr:expr_reason
                  ~reason_chain:(mk_reason ROptionalChain loc)
                  targts
                  argts
                  elem_t
              in
              let get_mem_t arg_and_elem_ts reason obj_t =
                Tvar.mk_no_wrap_where cx reason_call (fun t ->
                    let use = apply_opt_use (get_opt_use arg_and_elem_ts reason obj_t) t in
                    Flow.flow cx (obj_t, use);
                    Flow.flow_t cx (obj_t, prop_t)
                )
              in
              let eval_args_and_expr preds =
                in_env preds (fun () ->
                    let (((_, elem_t), _) as expr) = expression cx ~hint:None expr in
                    let (argts, arguments_ast) = arg_list cx arguments in
                    ((argts, elem_t), (arguments_ast, expr))
                )
              in
              let this_reason = mk_expression_reason callee in
              let ( filtered_out,
                    lookup_voided_out,
                    member_lhs_t,
                    _,
                    object_ast,
                    (argument_asts, expr_ast),
                    _
                  ) =
                handle_chaining
                  member_opt
                  _object
                  lookup_loc
                  ~this_reason
                  ~subexpressions:eval_args_and_expr
                  ~get_result:get_mem_t
                  ~test_hooks:noop
                  ~get_opt_use
                  ~refine:noop
                  ~get_reason:(Fn.const expr_reason)
              in
              ( filtered_out,
                lookup_voided_out,
                call_voided_out,
                member_lhs_t,
                prop_t,
                object_ast,
                Member.PropertyExpression expr_ast,
                argument_asts
              )
          in
          let voided_out = join_optional_branches lookup_voided_out call_voided_out in
          let lhs_t =
            Tvar.mk_where cx (reason_of_t member_lhs_t) (fun t ->
                Flow.flow_t cx (member_lhs_t, t);
                Flow.flow_t cx (voided_out, t)
            )
          in
          ( filtered_out,
            Some voided_out,
            ( (loc, lhs_t),
              call_ast
                {
                  Call.callee =
                    ( (lookup_loc, prop_t),
                      receiver_ast
                        { Member._object = object_ast; property; comments = member_comments }
                    );
                  targs;
                  arguments = argument_asts;
                  comments;
                }
            ),
            None,
            None
          )
        (* e1(e2...) *)
        | (Call { Call.callee; targs; arguments; comments }, None) ->
          let (targts, targs) = convert_call_targs_opt cx targs in
          let use_op =
            Op
              (FunCall
                 {
                   op = mk_expression_reason ex;
                   fn = mk_expression_reason callee;
                   args = mk_initial_arguments_reason arguments;
                   local = true;
                 }
              )
          in
          let get_opt_use argts reason _ = func_call_opt_use cx reason ~use_op targts argts in
          let get_reason lhs_t = mk_reason (RFunctionCall (desc_of_t lhs_t)) loc in
          let get_result argts reason f =
            Tvar.mk_no_wrap_where cx reason (fun t ->
                let use = apply_opt_use (get_opt_use argts reason f) t in
                Flow.flow cx (f, use)
            )
          in
          let eval_args preds = in_env preds (fun () -> arg_list cx arguments) in
          let (filtered_out, voided_out, lhs_t, _, object_ast, argument_asts, _) =
            handle_chaining
              opt_state
              callee
              loc
              ~subexpressions:eval_args
              ~this_reason:(mk_expression_reason ex)
              ~refine:noop
              ~get_result
              ~test_hooks:noop
              ~get_opt_use
              ~get_reason
          in
          let exp callee = call_ast { Call.callee; targs; arguments = argument_asts; comments } in
          (filtered_out, voided_out, ((loc, lhs_t), exp object_ast), None, None)
        | (This _, _)
        | (Identifier _, _)
          when is_existence_check ->
          (* if optional_chain is called from a conditional position and we're generating
             predicates, we might recursively reach an identifier, and if the level ""above""
             it in the chain was a ""?."" operator, we'll need to add the predicate that the
             property exists, so that e.g. ""a?.b"" generates the predicates ""a.b exists"",
             ""a has prop b"", and ""a exists"". *)
          let (((_, t), _) as res) = expression ?cond ~hint:None cx ex in
          let preds = mk_preds @@ exists_pred (loc, e') t in
          (t, None, res, preds, None)
        | _ ->
          let (((_, t), _) as res) = expression ?cond ~hint:None cx ex in
          (t, None, res, None, None))
    in
    let (t, _, ((loc, _), _), _, _) = result in
    Env.record_expression_type_if_needed cx loc t;
    result

  and arg_list cx (args_loc, { Ast.Expression.ArgList.arguments; comments }) =
    let (argts, arg_asts) = arguments |> Base.List.map ~f:(expression_or_spread cx) |> List.split in
    (argts, (args_loc, { Ast.Expression.ArgList.arguments = arg_asts; comments }))

  and subscript ~cond cx ex =
    let (_, _, ast, _, _) = optional_chain ~cond ~is_existence_check:false cx ex in
    ast

  (* Handles function calls that appear in conditional contexts. The main
     distinction from the case handled in `expression_` is that we also return
     the inferred types for the call receiver and the passed arguments, and
     potenially the keys that correspond to the supplied arguments.
  *)
  and predicated_call_expression cx loc call =
    let (f, argks, argts, t, call) = predicated_call_expression_ cx loc call in
    (f, argks, argts, t, call)

  (* Returns a quadruple containing:
     - the function type
     - argument keys
     - the arguments types
     - the returned type
  *)
  and predicated_call_expression_
      cx
      loc
      {
        Ast.Expression.Call.callee;
        targs;
        arguments =
          (args_loc, { Ast.Expression.ArgList.arguments = args; comments = args_comments }) as
          arguments;
        comments;
      } =
    let (targts, targ_asts) = convert_call_targs_opt cx targs in
    let args =
      args
      |> Base.List.map ~f:(function
             | Ast.Expression.Expression e -> e
             | _ -> Utils_js.assert_false ""No spreads should reach here""
             )
    in
    let (((_, f), _) as callee_ast) = expression cx ~hint:None callee in
    let reason = mk_reason (RFunctionCall (desc_of_t f)) loc in
    let arg_asts =
      Base.List.map ~f:(fun ((loc, _) as e) -> expression cx ~hint:(hint_of_loc_todo loc) e) args
    in
    let argts = Base.List.map ~f:snd_fst arg_asts in
    let argks = Base.List.map ~f:(Refinement.key ~allow_optional:false) args in
    let use_op =
      Op
        (FunCall
           {
             op = reason;
             fn = mk_expression_reason callee;
             args = mk_initial_arguments_reason arguments;
             local = true;
           }
        )
    in
    let t = func_call cx reason ~use_op f targts (Base.List.map ~f:(fun e -> Arg e) argts) in
    let arguments_ast =
      ( args_loc,
        {
          Ast.Expression.ArgList.arguments =
            Base.List.map ~f:(fun e -> Ast.Expression.Expression e) arg_asts;
          comments = args_comments;
        }
      )
    in
    ( f,
      argks,
      argts,
      t,
      {
        Ast.Expression.Call.callee = callee_ast;
        targs = targ_asts;
        arguments = arguments_ast;
        comments;
      }
    )

  (* We assume that constructor functions return void
     and constructions return objects.
     TODO: This assumption does not always hold.
     If construction functions return non-void values (e.g., functions),
     then those values are returned by constructions.
  *)
  and new_call cx reason ~use_op class_ targs args =
    Env.havoc_heap_refinements ();
    Env.havoc_local_refinements cx;
    Tvar.mk_where cx reason (fun t ->
        Flow.flow cx (class_, ConstructorT (use_op, reason, targs, args, t))
    )

  and func_call_opt_use cx reason ~use_op ?(havoc = true) ?(call_strict_arity = true) targts argts =
    Env.havoc_heap_refinements ();
    if havoc then Env.havoc_local_refinements cx;
    let opt_app = mk_opt_functioncalltype reason targts argts call_strict_arity in
    OptCallT (use_op, reason, opt_app)

  and func_call cx reason ~use_op ?(havoc = true) ?(call_strict_arity = true) func_t targts argts =
    let opt_use = func_call_opt_use cx reason ~use_op ~havoc ~call_strict_arity targts argts in
    Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (func_t, apply_opt_use opt_use t))

  and method_call_opt_use
      cx
      opt_state
      ~voided_out
      ~prop_t
      reason
      ~use_op
      ~private_
      ?(havoc = true)
      ?(call_strict_arity = true)
      prop_loc
      (expr, name)
      chain_loc
      targts
      argts =
    Env.havoc_heap_refinements ();
    if havoc then Env.havoc_local_refinements cx;
    let (expr_loc, _) = expr in
    let reason_prop = mk_reason (RProperty (Some (OrdinaryName name))) prop_loc in
    let reason_expr = mk_reason (RProperty (Some (OrdinaryName name))) expr_loc in
    let app = mk_opt_methodcalltype targts argts call_strict_arity in
    let propref = Named (reason_prop, OrdinaryName name) in
    let action =
      match opt_state with
      | NewChain ->
        let chain_reason = mk_reason ROptionalChain chain_loc in
        OptChainM (chain_reason, mk_expression_reason expr, prop_t, app, voided_out)
      | _ -> OptCallM app
    in
    if private_ then
      let class_entries = Env.get_class_entries () in
      OptPrivateMethodT
        (use_op, reason, reason_expr, name, class_entries, false, action, Some prop_t)
    else
      OptMethodT (use_op, reason, reason_expr, propref, action, Some prop_t)

  (* returns (type of method itself, type returned from method) *)
  and method_call
      cx
      reason
      ~use_op
      ?(havoc = true)
      ?(call_strict_arity = true)
      prop_loc
      (expr, obj_t, name)
      targts
      argts =
    Type_inference_hooks_js.dispatch_call_hook cx name prop_loc obj_t;
    let (expr_loc, _) = expr in
    match Refinement.get ~allow_optional:true cx expr (aloc_of_reason reason) with
    | Some f ->
      (* note: the current state of affairs is that we understand
         member expressions as having refined types, rather than
         understanding receiver objects as carrying refined properties.
         generalizing this properly is a todo, and will deliver goodness.
         meanwhile, here we must hijack the property selection normally
         performed by the flow algorithm itself. *)
      Env.havoc_heap_refinements ();
      if havoc then Env.havoc_local_refinements cx;
      ( f,
        Tvar.mk_no_wrap_where cx reason (fun t ->
            let app = mk_boundfunctioncalltype obj_t targts argts t ~call_strict_arity in
            Flow.flow cx (f, CallT (use_op, reason, app))
        )
      )
    | None ->
      Env.havoc_heap_refinements ();
      if havoc then Env.havoc_local_refinements cx;
      let reason_prop = mk_reason (RProperty (Some (OrdinaryName name))) prop_loc in
      let prop_t = Tvar.mk cx reason_prop in
      ( prop_t,
        Tvar.mk_no_wrap_where cx reason (fun t ->
            let reason_expr = mk_reason (RProperty (Some (OrdinaryName name))) expr_loc in
            let app = mk_methodcalltype targts argts t ~meth_strict_arity:call_strict_arity in
            let propref = Named (reason_prop, OrdinaryName name) in
            Flow.flow
              cx
              (obj_t, MethodT (use_op, reason, reason_expr, propref, CallM app, Some prop_t))
        )
      )

  and elem_call_opt_use
      opt_state
      ~voided_out
      ~prop_t
      ~reason_call
      ~reason_lookup
      ~reason_expr
      ~reason_chain
      targts
      argts
      elem_t =
    Env.havoc_heap_refinements ();
    let app = mk_opt_methodcalltype targts argts true in
    let action =
      match opt_state with
      | NewChain -> OptChainM (reason_chain, reason_expr, prop_t, app, voided_out)
      | _ -> OptCallM app
    in
    OptCallElemT (reason_call, reason_lookup, elem_t, action)

  and identifier_ cx name loc =
    let reason = mk_reason (RIdentifier (OrdinaryName name)) loc in
    if Type_inference_hooks_js.dispatch_id_hook cx name loc then
      Tvar.mk cx reason
    else
      let t = Env.var_ref ~lookup_mode:ForValue cx (OrdinaryName name) loc in
      (* We want to make sure that the reason description for the type we return
       * is always `RIdentifier name`. *)
      match (desc_of_t t, t) with
      | (RIdentifier name', _) when OrdinaryName name = name' -> t
      | (_, OpenT _) ->
        (* If this is an `OpenT` we can change its reason description directly. *)
        mod_reason_of_t (replace_desc_new_reason (RIdentifier (OrdinaryName name))) t
      (* If this is not an `OpenT` then create a new type variable with our
       * desired reason and unify it with our type. This adds a level of
       * indirection so that we don't modify the underlying reason of our type. *)
      | _ ->
        let reason = mk_reason (RIdentifier (OrdinaryName name)) loc in
        Tvar.mk_where cx reason (Flow.unify cx t)

  and identifier cx { Ast.Identifier.name; comments = _ } loc =
    let t = identifier_ cx name loc in
    t

  (* traverse a literal expression, return result type *)
  and literal cx loc lit =
    if Type_inference_hooks_js.dispatch_literal_hook cx loc then
      Tvar.mk cx (mk_reason (RCustom ""literal"") loc)
    else
      let make_trust = Context.trust_constructor cx in
      let open Ast.Literal in
      match lit.Ast.Literal.value with
      | String s ->
        begin
          match Context.haste_module_ref_prefix cx with
          | Some prefix when String_utils.string_starts_with s prefix ->
            let m = String_utils.lstrip s prefix in
            let t = Import_export.require cx (loc, m) loc in
            let reason = mk_reason (RCustom ""module reference"") loc in
            Flow.get_builtin_typeapp cx reason (OrdinaryName ""$Flow$ModuleRef"") [t]
          | _ ->
            (* It's too expensive to track literal information for large strings.*)
            let max_literal_length = Context.max_literal_length cx in
            let (lit, r_desc) =
              if max_literal_length = 0 || String.length s <= max_literal_length then
                (Literal (None, OrdinaryName s), RString)
              else
                (AnyLiteral, RLongStringLit max_literal_length)
            in
            DefT (mk_annot_reason r_desc loc, make_trust (), StrT lit)
        end
      | Boolean b -> DefT (mk_annot_reason RBoolean loc, make_trust (), BoolT (Some b))
      | Null -> NullT.at loc |> with_trust make_trust
      | Number f ->
        DefT (mk_annot_reason RNumber loc, make_trust (), NumT (Literal (None, (f, lit.raw))))
      | BigInt _ ->
        let reason = mk_annot_reason (RBigIntLit lit.raw) loc in
        Flow.add_output cx (Error_message.EBigIntNotYetSupported reason);
        AnyT.error reason
      | RegExp _ -> Flow.get_builtin_type cx (mk_annot_reason RRegExp loc) (OrdinaryName ""RegExp"")

  (* traverse a unary expression, return result type *)
  and unary cx loc =
    let open Ast.Expression.Unary in
    function
    | { operator = Not; argument; comments } ->
      let (((_, arg), _) as argument) = expression cx ~hint:None argument in
      let reason = mk_reason (RUnaryOperator (""not"", desc_of_t arg)) loc in
      ( Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (arg, NotT (reason, t))),
        { operator = Not; argument; comments }
      )
    | { operator = Plus; argument; comments } ->
      let argument = expression cx ~hint:None argument in
      (NumT.at loc |> with_trust literal_trust, { operator = Plus; argument; comments })
    | { operator = Minus; argument; comments } ->
      let (((_, argt), _) as argument) = expression cx ~hint:None argument in
      ( begin
          match argt with
          | DefT (reason, trust, NumT (Literal (sense, (value, raw)))) ->
            (* special case for negative number literals, to avoid creating an unnecessary tvar. not
               having a tvar allows other special cases that match concrete lower bounds to proceed
               (notably, Object.freeze upgrades literal props to singleton types, and a tvar would
               make a negative number not look like a literal.) *)
            let annot_loc = loc in
            let reason = annot_reason ~annot_loc @@ repos_reason annot_loc reason in
            let (value, raw) = Flow_ast_utils.negate_number_literal (value, raw) in
            DefT (reason, trust, NumT (Literal (sense, (value, raw))))
          | arg ->
            let reason = mk_reason (desc_of_t arg) loc in
            Tvar.mk_where cx reason (fun t -> Flow.flow cx (arg, UnaryMinusT (reason, t)))
        end,
        { operator = Minus; argument; comments }
      )
    | { operator = BitNot; argument; comments } ->
      let t = NumT.at loc |> with_trust literal_trust in
      let (((_, argt), _) as argument) = expression cx ~hint:None argument in
      Flow.flow_t cx (argt, t);
      (t, { operator = BitNot; argument; comments })
    | { operator = Typeof; argument; comments } ->
      let argument = expression cx ~hint:None argument in
      (StrT.at loc |> with_trust literal_trust, { operator = Typeof; argument; comments })
    | { operator = Void; argument; comments } ->
      let argument = expression cx ~hint:None argument in
      (VoidT.at loc |> with_trust literal_trust, { operator = Void; argument; comments })
    | { operator = Ast.Expression.Unary.Delete; argument; comments } ->
      let argument = delete cx loc argument in
      ( BoolT.at loc |> with_trust literal_trust,
        { operator = Ast.Expression.Unary.Delete; argument; comments }
      )
    | { operator = Await; argument; comments } ->
      (* TODO: await should look up Promise in the environment instead of going
         directly to the core definition. Otherwise, the following won't work
         with a polyfilled Promise! **)
      (* see declaration of $await in core.js:
         if argument is a Promise<T>, then (await argument) returns T.
         otherwise it just returns the argument type.
         TODO update this comment when recursive unwrapping of
         Promise is done.
      *)
      let reason = mk_reason (RCustom ""await"") loc in
      let await = Flow.get_builtin cx (OrdinaryName ""$await"") reason in
      let (((_, arg), _) as argument_ast) = expression cx ~hint:None argument in
      let use_op =
        Op
          (FunCall
             {
               op = reason;
               fn = reason_of_t await;
               args = [mk_expression_reason argument];
               local = true;
             }
          )
      in
      ( func_call cx reason ~use_op await None [Arg arg],
        { operator = Await; argument = argument_ast; comments }
      )

  (* numeric pre/post inc/dec *)
  and update cx loc expr =
    let open Ast.Expression.Update in
    let reason = mk_reason (RCustom ""update"") loc in
    let result_t = NumT.at loc |> with_trust literal_trust in
    let { argument; _ } = expr in
    ( result_t,
      match argument with
      | ( arg_loc,
          Ast.Expression.Identifier (id_loc, ({ Ast.Identifier.name; comments = _ } as id_name))
        ) ->
        Flow.flow cx (identifier cx id_name id_loc, AssertArithmeticOperandT reason);

        (* enforce state-based guards for binding update, e.g., const *)
        let use_op =
          Op
            (AssignVar
               {
                 var = Some (mk_reason (RIdentifier (OrdinaryName name)) id_loc);
                 init = reason_of_t result_t;
               }
            )
        in
        Env.set_var cx ~use_op name result_t id_loc;
        let t = NumT.at arg_loc |> with_trust bogus_trust in
        { expr with argument = ((arg_loc, t), Ast.Expression.Identifier ((id_loc, t), id_name)) }
      | (lhs_loc, Ast.Expression.Member mem) ->
        (* Updating involves both reading and writing. We need to model both of these, and ensuring
         * an arithmetic operand should use the read type, which is affected by refinements. *)
        let ((_, arg_val_t), _) = expression cx ~hint:None argument in
        Flow.flow cx (arg_val_t, AssertArithmeticOperandT reason);
        let make_op ~lhs ~prop = Op (UpdateProperty { lhs; prop }) in
        let lhs_prop_reason = mk_expression_reason argument in
        let reconstruct_ast mem = Ast.Expression.Member mem in
        let arg_update_ast =
          assign_member
            cx
            ~make_op
            ~t:result_t
            ~lhs_loc
            ~lhs_expr:(Ast.Expression.Member mem)
            ~reconstruct_ast
            ~lhs_prop_reason
            ~mode:Assign
            mem
        in
        { expr with argument = arg_update_ast }
      | _ ->
        let (((_, arg_t), _) as arg_ast) = expression cx ~hint:None argument in
        Flow.flow cx (arg_t, AssertArithmeticOperandT reason);
        { expr with argument = arg_ast }
    )

  (* traverse a binary expression, return result type *)
  and binary cx loc { Ast.Expression.Binary.operator; left; right; comments } =
    let open Ast.Expression.Binary in
    match operator with
    | Equal
    | NotEqual ->
      let (((_, t1), _) as left) = expression cx ~hint:None left in
      let (((_, t2), _) as right) = expression cx ~hint:None right in
      let desc =
        RBinaryOperator
          ( Flow_ast_utils.string_of_binary_operator operator,
            desc_of_reason (reason_of_t t1),
            desc_of_reason (reason_of_t t2)
          )
      in
      let reason = mk_reason desc loc in
      Flow.flow cx (t1, EqT { reason; flip = false; arg = t2 });
      (BoolT.at loc |> with_trust literal_trust, { operator; left; right; comments })
    | In ->
      let (loc1, _) = left in
      let (loc2, _) = right in
      let (((_, t1), _) as left) = expression cx ~hint:None left in
      let (((_, t2), _) as right) = expression cx ~hint:None right in
      let reason_lhs = mk_reason (RCustom ""LHS of `in` operator"") loc1 in
      let reason_rhs = mk_reason (RCustom ""RHS of `in` operator"") loc2 in
      Flow.flow cx (t1, AssertBinaryInLHST reason_lhs);
      Flow.flow cx (t2, AssertBinaryInRHST reason_rhs);
      (BoolT.at loc |> with_trust literal_trust, { operator; left; right; comments })
    | StrictEqual
    | StrictNotEqual ->
      let (((_, t1), _) as left) = expression cx ~hint:None left in
      let (((_, t2), _) as right) = expression cx ~hint:None right in
      let desc =
        RBinaryOperator
          ( Flow_ast_utils.string_of_binary_operator operator,
            desc_of_reason (reason_of_t t1),
            desc_of_reason (reason_of_t t2)
          )
      in
      let reason = mk_reason desc loc in
      Flow.flow cx (t1, StrictEqT { reason; cond_context = None; flip = false; arg = t2 });
      (BoolT.at loc |> with_trust literal_trust, { operator; left; right; comments })
    | Instanceof ->
      let left = expression cx ~hint:None left in
      let (((right_loc, right_t), _) as right) = expression cx ~hint:None right in
      Env.record_expression_type_if_needed cx right_loc right_t;
      let reason_rhs = mk_reason (RCustom ""RHS of `instanceof` operator"") right_loc in
      Flow.flow cx (right_t, AssertInstanceofRHST reason_rhs);
      (BoolT.at loc |> with_trust literal_trust, { operator; left; right; comments })
    | LessThan
    | LessThanEqual
    | GreaterThan
    | GreaterThanEqual ->
      let (((_, t1), _) as left) = expression cx ~hint:None left in
      let (((_, t2), _) as right) = expression cx ~hint:None right in
      let desc =
        RBinaryOperator
          ( Flow_ast_utils.string_of_binary_operator operator,
            desc_of_reason (reason_of_t t1),
            desc_of_reason (reason_of_t t2)
          )
      in
      let reason = mk_reason desc loc in
      Flow.flow cx (t1, ComparatorT { reason; flip = false; arg = t2 });
      (BoolT.at loc |> with_trust literal_trust, { operator; left; right; comments })
    | LShift
    | RShift
    | RShift3
    | Minus
    | Mult
    | Exp
    | Div
    | Mod
    | BitOr
    | Xor
    | BitAnd ->
      let reason = mk_reason (RCustom ""arithmetic operation"") loc in
      let (((_, t1), _) as left) = expression cx ~hint:None left in
      let (((_, t2), _) as right) = expression cx ~hint:None right in
      Flow.flow cx (t1, AssertArithmeticOperandT reason);
      Flow.flow cx (t2, AssertArithmeticOperandT reason);
      (NumT.at loc |> with_trust literal_trust, { operator; left; right; comments })
    | Plus ->
      let (((_, t1), _) as left_ast) = expression cx ~hint:None left in
      let (((_, t2), _) as right_ast) = expression cx ~hint:None right in
      let desc =
        RBinaryOperator (""+"", desc_of_reason (reason_of_t t1), desc_of_reason (reason_of_t t2))
      in
      let reason = mk_reason desc loc in
      ( Tvar.mk_where cx reason (fun t ->
            let use_op =
              Op
                (Addition
                   {
                     op = reason;
                     left = mk_expression_reason left;
                     right = mk_expression_reason right;
                   }
                )
            in
            Flow.flow cx (t1, AdderT (use_op, reason, false, t2, t))
        ),
        { operator; left = left_ast; right = right_ast; comments }
      )

  and logical cx loc { Ast.Expression.Logical.operator; left; right; comments } =
    let open Ast.Expression.Logical in
    (* With logical operators the LHS is always evaluated. So if the LHS throws, the whole
     * expression throws. To model this we do not catch abnormal exceptions on the LHS.
     * As such, we only analyze the RHS expression if the LHS does not throw.
     * If the LHS does not throw, and the RHS does throw, then we cannot say that the
     * entire expression throws, because we only evaluate the RHS depending on the value of the LHS.
     * Thus, we catch abnormal control flow exceptions on the RHS and do not rethrow them.
     *
     * Note that the only kind of abnormal control flow that should be raised from an
     * expression is a Throw. The other kinds (Return, Break, Continue) can only arise from
     * statements, and while statements can appear within expressions (e.g. function expressions),
     * any abnormals will be handled before they get here.
     *)
    match operator with
    | Or ->
      let () = check_default_pattern cx left right in
      let ((((_, t1), _) as left), _, not_map, xtypes) =
        predicates_of_condition ~cond:OtherTest cx left
      in
      let ((((_, t2), _) as right), right_abnormal) =
        Abnormal.catch_expr_control_flow_exception (fun () ->
            Env.in_refined_env cx loc not_map xtypes (fun () -> expression cx ~hint:None right)
        )
      in
      let t2 =
        match right_abnormal with
        | Some Abnormal.Throw -> EmptyT.at loc |> with_trust bogus_trust
        | None -> t2
        | Some _ -> assert_false ""Unexpected abnormal control flow from within expression""
      in
      let reason = mk_reason (RLogical (""||"", desc_of_t t1, desc_of_t t2)) loc in
      ( Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (t1, OrT (reason, t2, t))),
        { operator = Or; left; right; comments }
      )
    | And ->
      let ((((_, t1), _) as left), map, _, xtypes) =
        predicates_of_condition ~cond:OtherTest cx left
      in
      let ((((_, t2), _) as right), right_abnormal) =
        Abnormal.catch_expr_control_flow_exception (fun () ->
            Env.in_refined_env cx loc map xtypes (fun () -> expression cx ~hint:None right)
        )
      in
      let t2 =
        match right_abnormal with
        | Some Abnormal.Throw -> EmptyT.at loc |> with_trust bogus_trust
        | None -> t2
        | Some _ -> assert_false ""Unexpected abnormal control flow from within expression""
      in
      let reason = mk_reason (RLogical (""&&"", desc_of_t t1, desc_of_t t2)) loc in
      ( Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (t1, AndT (reason, t2, t))),
        { operator = And; left; right; comments }
      )
    | NullishCoalesce ->
      let (((_, t1), _) as left) = expression cx ~hint:None left in
      let ((((_, t2), _) as right), right_abnormal) =
        Abnormal.catch_expr_control_flow_exception (fun () ->
            expression cx ~hint:(hint_of_loc_todo (fst right)) right
        )
      in
      let t2 =
        match right_abnormal with
        | Some Abnormal.Throw -> EmptyT.at loc |> with_trust bogus_trust
        | None -> t2
        | Some _ -> assert_false ""Unexpected abnormal control flow from within expression""
      in
      let reason = mk_reason (RLogical (""??"", desc_of_t t1, desc_of_t t2)) loc in
      ( Tvar.mk_no_wrap_where cx reason (fun t ->
            Flow.flow cx (t1, NullishCoalesceT (reason, t2, t))
        ),
        { operator = NullishCoalesce; left; right; comments }
      )

  and assignment_lhs cx patt =
    match patt with
    | ( pat_loc,
        Ast.Pattern.Identifier { Ast.Pattern.Identifier.name = (loc, name); optional; annot }
      ) ->
      let t = identifier cx name loc in
      ( (pat_loc, t),
        Ast.Pattern.Identifier
          {
            Ast.Pattern.Identifier.name = ((loc, t), name);
            annot =
              (match annot with
              | Ast.Type.Available annot ->
                Ast.Type.Available (Tast_utils.error_mapper#type_annotation annot)
              | Ast.Type.Missing hint -> Ast.Type.Missing (hint, AnyT.locationless Untyped));
            optional;
          }
      )
    | (loc, Ast.Pattern.Expression ((_, Ast.Expression.Member _) as m)) ->
      let (((_, t), _) as m) = expression cx ~hint:None m in
      ((loc, t), Ast.Pattern.Expression m)
    (* TODO: object, array and non-member expression patterns are invalid
       (should be a parse error but isn't yet) *)
    | (lhs_loc, Ast.Pattern.Object _)
    | (lhs_loc, Ast.Pattern.Array _)
    | (lhs_loc, Ast.Pattern.Expression _) ->
      Flow.add_output cx (Error_message.EInvalidLHSInAssignment lhs_loc);
      Tast_utils.error_mapper#pattern patt

  (* write a type t into a member.
     - the `optional` parameter should be set to NewChain when the member access
       is optional (a?.b) and should be ContinueChain when it is not itself
       optional but is part of an optional chain (a?.b.c). *)
  and assign_member
      cx
      ?(optional = NonOptional)
      ~make_op
      ~t
      ~lhs_loc
      ~lhs_expr
      ~lhs_prop_reason
      ~reconstruct_ast
      ~mode
      lhs =
    let open Ast.Expression in
    let maybe_chain lhs_reason use_t =
      match (optional, mode) with
      | (NewChain, Delete) ->
        let reason = mk_reason ROptionalChain lhs_loc in

        (* When deleting an optional chain, we only really care about the case
           where the object type is non-nullable. The specification is:

             delete a?.b
              is equivalent to
             a == null ? true : delete a.b
           So if a is null, no work has to be done. Hence, the nullable output
           and this-type for the optional chain are mixed.
        *)
        let mixed = MixedT.at lhs_loc (literal_trust ()) in
        OptionalChainT { reason; lhs_reason; this_t = mixed; t_out = use_t; voided_out = mixed }
      | _ -> use_t
    in
    let typecheck_object obj =
      (* If we're deleting a member expression, it's allowed to be an optional chain, and we
         need to respect short-circuiting, which means the type that's flowed into the
         SetPropT (or similar) upper bound must be the ""filtered,"" non-nullish type.
         However, syntactically `a?.x = e` is banned, so if this is an assignment expression,
         we should just use `expression` to evaluate the object. It still might contain
         an optional chain, but if so the chain is in parentheses (like `(a?.b).x = e`),
         which means that the type that flows into SetPropT should include the nullish
         case.
      *)
      match (optional, mode) with
      | ((NewChain | ContinueChain), Delete) ->
        let (o, _, _object, preds, _) =
          optional_chain ~cond:None ~is_existence_check:false cx obj
        in
        (o, _object, preds)
      | _ ->
        let (((_, o), _) as _object) = expression cx ~hint:None obj in
        (o, _object, None)
    in
    match lhs with
    (* module.exports = e *)
    | {
     Member._object =
       ( object_loc,
         Ast.Expression.Identifier
           (id_loc, ({ Ast.Identifier.name = ""module""; comments = _ } as mod_name))
       );
     property =
       Member.PropertyIdentifier (ploc, ({ Ast.Identifier.name = ""exports""; comments = _ } as name));
     comments;
    }
      when not (Env.local_scope_entry_exists cx id_loc ""module"") ->
      Import_export.cjs_clobber cx lhs_loc t;
      let module_reason = mk_reason (RCustom ""module"") object_loc in
      let module_t = MixedT.why module_reason |> with_trust bogus_trust in
      let _object =
        ((object_loc, module_t), Ast.Expression.Identifier ((id_loc, module_t), mod_name))
      in
      let property = Member.PropertyIdentifier ((ploc, t), name) in
      ((lhs_loc, t), reconstruct_ast { Member._object; property; comments })
    (* super.name = e *)
    | {
     Member._object = (super_loc, Super super);
     property = Member.PropertyIdentifier (prop_loc, ({ Ast.Identifier.name; comments = _ } as id));
     comments;
    } ->
      let reason = mk_reason (RPropertyAssignment (Some name)) lhs_loc in
      let prop_reason = mk_reason (RProperty (Some (OrdinaryName name))) prop_loc in
      let super_t = super_ cx lhs_loc in
      let prop_t = Tvar.mk cx prop_reason in
      let use_op =
        make_op ~lhs:reason ~prop:(mk_reason (desc_of_reason lhs_prop_reason) prop_loc)
      in
      Flow.flow
        cx
        ( super_t,
          SetPropT
            (use_op, reason, Named (prop_reason, OrdinaryName name), mode, Normal, t, Some prop_t)
        );
      let property = Member.PropertyIdentifier ((prop_loc, prop_t), id) in
      ( (lhs_loc, prop_t),
        reconstruct_ast { Member._object = ((super_loc, super_t), Super super); property; comments }
      )
    (* _object.#name = e *)
    | {
     Member._object;
     property =
       Member.PropertyPrivateName (prop_loc, { Ast.PrivateName.name; comments = _ }) as property;
     comments;
    } ->
      let lhs_reason = mk_expression_reason _object in
      let (o, _object, _) = typecheck_object _object in
      let prop_t =
        (* if we fire this hook, it means the assignment is a sham. *)
        if Type_inference_hooks_js.dispatch_member_hook cx name prop_loc o then
          Unsoundness.at InferenceHooks prop_loc
        else
          let reason = mk_reason (RPropertyAssignment (Some name)) lhs_loc in
          (* flow type to object property itself *)
          let class_entries = Env.get_class_entries () in
          let prop_reason = mk_reason (RPrivateProperty name) prop_loc in
          let prop_t = Tvar.mk cx prop_reason in
          let use_op =
            make_op ~lhs:reason ~prop:(mk_reason (desc_of_reason lhs_prop_reason) prop_loc)
          in
          let upper =
            maybe_chain
              lhs_reason
              (SetPrivatePropT (use_op, reason, name, mode, class_entries, false, t, Some prop_t))
          in
          Flow.flow cx (o, upper);
          post_assignment_havoc cx ~private_:true name (lhs_loc, lhs_expr) prop_t t;
          prop_t
      in
      ((lhs_loc, prop_t), reconstruct_ast { Member._object; property; comments })
    (* _object.name = e *)
    | {
     Member._object;
     property = Member.PropertyIdentifier (prop_loc, ({ Ast.Identifier.name; comments = _ } as id));
     comments;
    } ->
      let wr_ctx =
        match (_object, Env.var_scope_kind ()) with
        | ((_, This _), Scope.Ctor) -> ThisInCtor
        | _ -> Normal
      in
      let lhs_reason = mk_expression_reason _object in
      let (o, _object, _) = typecheck_object _object in
      let prop_t =
        (* if we fire this hook, it means the assignment is a sham. *)
        if Type_inference_hooks_js.dispatch_member_hook cx name prop_loc o then
          Unsoundness.at InferenceHooks prop_loc
        else
          let reason = mk_reason (RPropertyAssignment (Some name)) lhs_loc in
          let prop_reason = mk_reason (RProperty (Some (OrdinaryName name))) prop_loc in
          (* flow type to object property itself *)
          let prop_t = Tvar.mk cx prop_reason in
          let use_op =
            make_op ~lhs:reason ~prop:(mk_reason (desc_of_reason lhs_prop_reason) prop_loc)
          in
          let upper =
            maybe_chain
              lhs_reason
              (SetPropT
                 ( use_op,
                   reason,
                   Named (prop_reason, OrdinaryName name),
                   mode,
                   wr_ctx,
                   t,
                   Some prop_t
                 )
              )
          in
          Flow.flow cx (o, upper);
          post_assignment_havoc cx ~private_:false name (lhs_loc, lhs_expr) prop_t t;
          prop_t
      in
      let property = Member.PropertyIdentifier ((prop_loc, prop_t), id) in
      ((lhs_loc, prop_t), reconstruct_ast { Member._object; property; comments })
    (* _object[index] = e *)
    | { Member._object; property = Member.PropertyExpression ((iloc, _) as index); comments } ->
      let reason = mk_reason (RPropertyAssignment None) lhs_loc in
      let lhs_reason = mk_expression_reason _object in
      let (o, _object, preds) = typecheck_object _object in
      let (((_, i), _) as index) =
        match preds with
        | None -> expression cx ~hint:None index
        | Some (preds, _, xtypes) ->
          Env.in_refined_env cx lhs_loc preds xtypes (fun () -> expression cx ~hint:None index)
      in
      let use_op = make_op ~lhs:reason ~prop:(mk_reason (desc_of_reason lhs_prop_reason) iloc) in
      let upper = maybe_chain lhs_reason (SetElemT (use_op, reason, i, mode, t, None)) in
      Flow.flow cx (o, upper);

      (* types involved in the assignment itself are computed
         in pre-havoc environment. it's the assignment itself
         which clears refis *)
      Env.havoc_heap_refinements ();
      ( (lhs_loc, t),
        reconstruct_ast { Member._object; property = Member.PropertyExpression index; comments }
      )

  (* traverse simple assignment expressions (`lhs = rhs`) *)
  and simple_assignment cx _loc lhs rhs =
    (* Use annotations from variable declarations if the lhs contains only non-providers.
     * Consider this example:
     *
     * var a: t1, var b: t2;
     * [a, [b]] = [e1, [e2, e3]]. In this example, we would push down t1 and t2
     * to e1 and e2 (which will require work to make happen). e3 does not escape the rhs,
     * so we do not require an annotation. If either a or b were providers, then
     * we would require annotations on all of e1, e2, and e3.
     *
     * TODO: To relax that constraint, we need to be able to figure out how to
     * match the lhs to specific expressions on the rhs before we visit the rhs
     * to ask for annotations.
     *)
    let is_provider =
      Flow_ast_utils.fold_bindings_of_pattern
        (fun acc (loc, _) -> acc || Env.is_provider cx loc)
        false
        lhs
    in
    let hint =
      if is_provider then
        None
      else
        hint_of_loc_todo (fst lhs)
    in
    let (((_, t), _) as typed_rhs) = expression cx ~hint rhs in
    (* update env, add constraints arising from LHS structure,
       handle special cases, etc. *)
    let lhs =
      match lhs with
      | (lhs_loc, Ast.Pattern.Expression (pat_loc, Ast.Expression.Member mem)) ->
        let lhs_prop_reason = mk_pattern_reason lhs in
        let make_op ~lhs ~prop = Op (SetProperty { lhs; prop; value = mk_expression_reason rhs }) in
        let reconstruct_ast mem = Ast.Expression.Member mem in
        let ((lhs_loc, t), lhs) =
          assign_member
            cx
            ~make_op
            ~t
            ~lhs_loc
            ~lhs_expr:(Ast.Expression.Member mem)
            ~lhs_prop_reason
            ~reconstruct_ast
            ~mode:Assign
            mem
        in
        ((lhs_loc, t), Ast.Pattern.Expression ((pat_loc, t), lhs))
      (* other r structures are handled as destructuring assignments *)
      | _ -> Destructuring.assignment cx t rhs lhs
    in
    (t, lhs, typed_rhs)

  and plus_assign cx ~reason ~lhs_reason ~rhs_reason lhs_t rhs_t =
    let result_t = Tvar.mk cx reason in
    (* lhs = lhs + rhs *)
    let () =
      let use_op = Op (Addition { op = reason; left = lhs_reason; right = rhs_reason }) in
      Flow.flow cx (lhs_t, AdderT (use_op, reason, false, rhs_t, result_t))
    in
    result_t

  and arith_assign cx loc lhs_t rhs_t =
    let reason = mk_reason (RCustom ""(numop)="") loc in
    (* lhs = lhs (numop) rhs *)
    Flow.flow cx (lhs_t, AssertArithmeticOperandT reason);
    Flow.flow cx (rhs_t, AssertArithmeticOperandT reason);
    NumT.at loc |> with_trust literal_trust

  (* traverse assignment expressions with operators (`lhs += rhs`, `lhs *= rhs`, etc) *)
  and op_assignment cx loc lhs op rhs =
    let open Ast.Expression in
    match op with
    | Assignment.PlusAssign ->
      (* lhs += rhs *)
      let reason = mk_reason (RCustom ""+="") loc in
      let (((_, lhs_t), _) as lhs_ast) = assignment_lhs cx lhs in
      let (((_, rhs_t), _) as rhs_ast) = expression cx ~hint:None rhs in
      let result_t =
        plus_assign
          cx
          ~reason
          ~lhs_reason:(mk_pattern_reason lhs)
          ~rhs_reason:(mk_expression_reason rhs)
          lhs_t
          rhs_t
      in
      (* enforce state-based guards for binding update, e.g., const *)
      (match lhs with
      | ( _,
          Ast.Pattern.Identifier
            { Ast.Pattern.Identifier.name = (id_loc, { Ast.Identifier.name; comments = _ }); _ }
        ) ->
        let use_op =
          Op
            (AssignVar
               { var = Some (mk_reason (RIdentifier (OrdinaryName name)) id_loc); init = reason }
            )
        in
        Env.set_var cx ~use_op name result_t id_loc
      | (lhs_loc, Ast.Pattern.Expression (_, Ast.Expression.Member mem)) ->
        let lhs_prop_reason = mk_pattern_reason lhs in
        let make_op ~lhs ~prop = Op (UpdateProperty { lhs; prop }) in
        let reconstruct_ast mem = Ast.Expression.Member mem in
        ignore
        @@ assign_member
             cx
             ~make_op
             ~t:result_t
             ~lhs_loc
             ~lhs_expr:(Ast.Expression.Member mem)
             ~lhs_prop_reason
             ~reconstruct_ast
             ~mode:Assign
             mem
      | _ -> ());
      (lhs_t, lhs_ast, rhs_ast)
    | Assignment.MinusAssign
    | Assignment.MultAssign
    | Assignment.ExpAssign
    | Assignment.DivAssign
    | Assignment.ModAssign
    | Assignment.LShiftAssign
    | Assignment.RShiftAssign
    | Assignment.RShift3Assign
    | Assignment.BitOrAssign
    | Assignment.BitXorAssign
    | Assignment.BitAndAssign ->
      (* lhs (numop)= rhs *)
      let (((_, lhs_t), _) as lhs_ast) = assignment_lhs cx lhs in
      let (((_, rhs_t), _) as rhs_ast) = expression cx ~hint:None rhs in
      let result_t = arith_assign cx loc lhs_t rhs_t in
      (* enforce state-based guards for binding update, e.g., const *)
      (match lhs with
      | ( _,
          Ast.Pattern.Identifier
            { Ast.Pattern.Identifier.name = (id_loc, { Ast.Identifier.name; comments = _ }); _ }
        ) ->
        let use_op =
          Op
            (AssignVar
               {
                 var = Some (mk_reason (RIdentifier (OrdinaryName name)) id_loc);
                 init = reason_of_t result_t;
               }
            )
        in
        Env.set_var cx ~use_op name result_t id_loc
      | (lhs_loc, Ast.Pattern.Expression (_, Ast.Expression.Member mem)) ->
        let lhs_prop_reason = mk_pattern_reason lhs in
        let make_op ~lhs ~prop = Op (UpdateProperty { lhs; prop }) in
        let reconstruct_ast mem = Ast.Expression.Member mem in
        ignore
        @@ assign_member
             cx
             ~make_op
             ~t:result_t
             ~lhs_loc
             ~lhs_expr:(Ast.Expression.Member mem)
             ~lhs_prop_reason
             ~reconstruct_ast
             ~mode:Assign
             mem
      | _ -> ());
      (lhs_t, lhs_ast, rhs_ast)
    | Assignment.NullishAssign
    | Assignment.AndAssign
    | Assignment.OrAssign ->
      let reason = mk_reason (RCustom (Flow_ast_utils.string_of_assignment_operator op)) loc in
      let (((_, lhs_t), _) as lhs_pattern_ast) = assignment_lhs cx lhs in
      let left_expr =
        match lhs with
        | (lhs_loc, Ast.Pattern.Identifier { Ast.Pattern.Identifier.name; _ }) ->
          Some (lhs_loc, Ast.Expression.Identifier name)
        | (lhs_loc, Ast.Pattern.Expression (_, Ast.Expression.Member mem)) ->
          Some (lhs_loc, Ast.Expression.Member mem)
        | _ -> None
      in
      let update_env result_t =
        match lhs with
        | ( _,
            Ast.Pattern.Identifier
              { Ast.Pattern.Identifier.name = (id_loc, { Ast.Identifier.name; comments = _ }); _ }
          ) ->
          let use_op =
            Op
              (AssignVar
                 {
                   var = Some (mk_reason (RIdentifier (OrdinaryName name)) id_loc);
                   init = reason_of_t result_t;
                 }
              )
          in
          Env.set_var cx ~use_op name result_t id_loc
        | (lhs_loc, Ast.Pattern.Expression (_, Ast.Expression.Member mem)) ->
          let lhs_prop_reason = mk_pattern_reason lhs in
          let make_op ~lhs ~prop = Op (UpdateProperty { lhs; prop }) in
          let reconstruct_ast mem = Ast.Expression.Member mem in
          ignore
          @@ assign_member
               cx
               ~make_op
               ~t:result_t
               ~lhs_loc
               ~lhs_expr:(Ast.Expression.Member mem)
               ~lhs_prop_reason
               ~reconstruct_ast
               ~mode:Assign
               mem
        | _ -> ()
      in
      (match left_expr with
      | None ->
        ( AnyT.error reason,
          lhs_pattern_ast,
          (fun () -> expression cx ~hint:None rhs)
          |> Abnormal.catch_expr_control_flow_exception
          |> fst
        )
      | Some left_expr ->
        (match op with
        | Assignment.NullishAssign ->
          let ((((_, rhs_t), _) as rhs_ast), right_abnormal) =
            Abnormal.catch_expr_control_flow_exception (fun () ->
                expression cx ~hint:(hint_of_loc_todo (fst rhs)) rhs
            )
          in
          let rhs_t =
            match right_abnormal with
            | Some Abnormal.Throw -> EmptyT.at loc |> with_trust bogus_trust
            | None -> rhs_t
            | Some _ -> assert_false ""Unexpected abnormal control flow from within expression""
          in
          let result_t =
            Tvar.mk_no_wrap_where cx reason (fun t ->
                Flow.flow cx (lhs_t, NullishCoalesceT (reason, rhs_t, t))
            )
          in
          let () = update_env result_t in
          (lhs_t, lhs_pattern_ast, rhs_ast)
        | Assignment.AndAssign ->
          let (((_, lhs_t), _), map, _, xtypes) =
            predicates_of_condition ~cond:OtherTest cx left_expr
          in
          let ((((_, rhs_t), _) as rhs_ast), right_abnormal) =
            Abnormal.catch_expr_control_flow_exception (fun () ->
                Env.in_refined_env cx loc map xtypes (fun () -> expression cx ~hint:None rhs)
            )
          in
          let rhs_t =
            match right_abnormal with
            | Some Abnormal.Throw -> EmptyT.at loc |> with_trust bogus_trust
            | None -> rhs_t
            | Some _ -> assert_false ""Unexpected abnormal control flow from within expression""
          in
          let result_t =
            Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (lhs_t, AndT (reason, rhs_t, t)))
          in
          let () = update_env result_t in
          (lhs_t, lhs_pattern_ast, rhs_ast)
        | Assignment.OrAssign ->
          let () = check_default_pattern cx left_expr rhs in
          let (((_, lhs_t), _), _, not_map, xtypes) =
            predicates_of_condition ~cond:OtherTest cx left_expr
          in
          let ((((_, rhs_t), _) as rhs_ast), right_abnormal) =
            Abnormal.catch_expr_control_flow_exception (fun () ->
                Env.in_refined_env cx loc not_map xtypes (fun () -> expression cx ~hint:None rhs)
            )
          in
          let rhs_t =
            match right_abnormal with
            | Some Abnormal.Throw -> EmptyT.at loc |> with_trust bogus_trust
            | None -> rhs_t
            | Some _ -> assert_false ""Unexpected abnormal control flow from within expression""
          in
          let result_t =
            Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (lhs_t, OrT (reason, rhs_t, t)))
          in
          let () = update_env result_t in
          (lhs_t, lhs_pattern_ast, rhs_ast)
        | _ -> assert_false ""Unexpected operator""))

  (* traverse assignment expressions *)
  and assignment cx loc (lhs, op, rhs) =
    match op with
    | None -> simple_assignment cx loc lhs rhs
    | Some op -> op_assignment cx loc lhs op rhs

  (* delete variables and properties *)
  and delete cx loc target =
    let open Ast.Expression in
    let void = VoidT.at loc |> with_trust literal_trust in
    let (lhs_loc, targ_exp) = target in
    match targ_exp with
    | Member mem ->
      let lhs_prop_reason = mk_expression_reason target in
      let make_op ~lhs ~prop = Op (DeleteProperty { lhs; prop }) in
      let reconstruct_ast mem = Member mem in
      assign_member
        cx
        ~make_op
        ~t:void
        ~lhs_loc
        ~lhs_expr:targ_exp
        ~lhs_prop_reason
        ~reconstruct_ast
        ~mode:Type.Delete
        mem
    | OptionalMember { OptionalMember.member = mem; optional } ->
      let lhs_prop_reason = mk_expression_reason target in
      let make_op ~lhs ~prop = Op (DeleteProperty { lhs; prop }) in
      let reconstruct_ast mem = OptionalMember { OptionalMember.member = mem; optional } in
      let opt_state =
        if optional then
          NewChain
        else
          ContinueChain
      in
      assign_member
        cx
        ~optional:opt_state
        ~make_op
        ~t:void
        ~lhs_loc
        ~lhs_expr:targ_exp
        ~lhs_prop_reason
        ~reconstruct_ast
        ~mode:Type.Delete
        mem
    | Identifier (loc, { Ast.Identifier.name; _ }) ->
      let use_op = Op (DeleteVar { var = mk_expression_reason target }) in
      Env.set_var cx ~use_op name void loc;
      expression cx ~hint:None target
    | _ ->
      let (((_, t), _) as target) = expression cx ~hint:None target in
      Flow.add_output cx Error_message.(ECannotDelete (loc, reason_of_t t));
      target

  and collapse_children cx (children_loc, children) :
      Type.unresolved_param list * (ALoc.t * (ALoc.t, ALoc.t * Type.t) Ast.JSX.child list) =
    let (unresolved_params, children') =
      children
      |> List.fold_left
           (fun (unres_params, children) child ->
             let (unres_param_opt, child) = jsx_body cx child in
             ( Base.Option.value_map unres_param_opt ~default:unres_params ~f:(fun x ->
                   x :: unres_params
               ),
               child :: children
             ))
           ([], [])
      |> map_pair List.rev List.rev
    in
    (unresolved_params, (children_loc, children'))

  and jsx cx expr_loc e : Type.t * (ALoc.t, ALoc.t * Type.t) Ast.JSX.element =
    let open Ast.JSX in
    let { opening_element; children; closing_element; comments } = e in
    let (children_loc, _) = children in
    let locs =
      let (open_, _) = opening_element in
      match closing_element with
      | Some _ -> (expr_loc, open_, children_loc)
      | _ -> (open_, open_, open_)
    in
    let (t, opening_element, children, closing_element) =
      jsx_title cx opening_element children closing_element locs
    in
    (t, { opening_element; children; closing_element; comments })

  and jsx_fragment cx expr_loc fragment : Type.t * (ALoc.t, ALoc.t * Type.t) Ast.JSX.fragment =
    let open Ast.JSX in
    let { frag_opening_element; frag_children; frag_closing_element; frag_comments } = fragment in
    let (children_loc, _) = frag_children in
    let fragment_t =
      match Context.react_runtime cx with
      | Options.ReactRuntimeAutomatic ->
        let reason = mk_reason (RIdentifier (OrdinaryName ""Fragment"")) expr_loc in
        Flow.get_builtin_type cx reason (OrdinaryName ""React$FragmentType"")
      | Options.ReactRuntimeClassic ->
        let reason = mk_reason (RIdentifier (OrdinaryName ""React.Fragment"")) expr_loc in
        let react = Env.var_ref ~lookup_mode:ForValue cx (OrdinaryName ""React"") expr_loc in
        let use_op = Op (GetProperty reason) in
        get_prop ~cond:None cx reason ~use_op react (reason, ""Fragment"")
    in
    let (unresolved_params, frag_children) = collapse_children cx frag_children in
    let locs = (expr_loc, frag_opening_element, children_loc) in
    let t =
      jsx_desugar
        cx
        ""React.Fragment""
        fragment_t
        (NullT.at expr_loc |> with_trust bogus_trust)
        []
        unresolved_params
        locs
    in
    (t, { frag_opening_element; frag_children; frag_closing_element; frag_comments })

  and jsx_title cx opening_element children closing_element locs =
    let open Ast.JSX in
    let make_trust = Context.trust_constructor cx in
    let (loc_element, _, _) = locs in
    let (loc, { Opening.name; attributes; self_closing }) = opening_element in
    let facebook_fbs = Context.facebook_fbs cx in
    let facebook_fbt = Context.facebook_fbt cx in
    let jsx_mode = Context.jsx cx in
    let (t, name, attributes, children) =
      match (name, jsx_mode, (facebook_fbs, facebook_fbt)) with
      | ( Identifier (loc_id, ({ Identifier.name = ""fbs"" as name; comments = _ } as id)),
          _,
          (Some custom_jsx_type, _)
        )
      | ( Identifier (loc_id, ({ Identifier.name = ""fbt"" as name; comments = _ } as id)),
          _,
          (_, Some custom_jsx_type)
        ) ->
        let fbt_reason = mk_reason RFbt loc_element in
        let t = Flow.get_builtin_type cx fbt_reason (OrdinaryName custom_jsx_type) in
        (* TODO check attribute types against an fbt API *)
        let (_, attributes, _, children) = jsx_mk_props cx fbt_reason name attributes children in
        let name = Identifier ((loc_id, t), id) in
        (t, name, attributes, children)
      | (Identifier (loc, { Identifier.name; comments }), _, _) ->
        if Type_inference_hooks_js.dispatch_id_hook cx name loc then
          let t = Unsoundness.at InferenceHooks loc_element in
          let name = Identifier ((loc, t), { Identifier.name; comments }) in
          let attributes =
            Base.List.map ~f:Tast_utils.error_mapper#jsx_opening_attribute attributes
          in
          let (_, children) = collapse_children cx children in
          (t, name, attributes, children)
        else
          let reason =
            match jsx_mode with
            | Options.Jsx_react -> mk_reason (RReactElement (Some (OrdinaryName name))) loc_element
            | Options.Jsx_pragma _ -> mk_reason (RJSXElement (Some name)) loc_element
          in
          let c =
            if name = String.capitalize_ascii name then
              identifier cx (mk_ident ~comments:None name) loc
            else
              let strt =
                (* TODO: why are these different? *)
                match jsx_mode with
                | Options.Jsx_react -> SingletonStrT (OrdinaryName name)
                | Options.Jsx_pragma _ -> StrT (Literal (None, OrdinaryName name))
              in
              DefT (mk_reason (RIdentifier (OrdinaryName name)) loc, make_trust (), strt)
          in
          let (o, attributes', unresolved_params, children) =
            jsx_mk_props cx reason name attributes children
          in
          let t = jsx_desugar cx name c o attributes unresolved_params locs in
          let name = Identifier ((loc, c), { Identifier.name; comments }) in
          (t, name, attributes', children)
      | (MemberExpression member, Options.Jsx_react, _) ->
        let name = jsx_title_member_to_string member in
        let el = RReactElement (Some (OrdinaryName name)) in
        let reason = mk_reason el loc_element in
        let m_expr = jsx_title_member_to_expression member in
        let ((m_loc, t), m_expr') = expression cx ~hint:None m_expr in
        let c = mod_reason_of_t (replace_desc_reason (RIdentifier (OrdinaryName name))) t in
        let (o, attributes', unresolved_params, children) =
          jsx_mk_props cx reason name attributes children
        in
        let t = jsx_desugar cx name c o attributes unresolved_params locs in
        let member' =
          match expression_to_jsx_title_member m_loc m_expr' with
          | Some member -> member
          | None -> Tast_utils.error_mapper#jsx_member_expression member
        in
        (t, MemberExpression member', attributes', children)
      | (MemberExpression member, Options.Jsx_pragma _, _) ->
        let t = Unsoundness.at InferenceHooks loc_element in
        let name' = Tast_utils.error_mapper#jsx_element_name name in
        let el_name = jsx_title_member_to_string member in
        let reason = mk_reason (RJSXElement (Some el_name)) loc_element in
        let (_o, attributes', _, children) = jsx_mk_props cx reason el_name attributes children in
        (t, name', attributes', children)
      | (NamespacedName namespace, _, _) ->
        (* TODO? covers namespaced names as element names *)
        let t = Unsoundness.at InferenceHooks loc_element in
        let name' = Tast_utils.error_mapper#jsx_element_name name in
        let el_name = jsx_title_namespaced_name_to_string namespace in
        let reason = mk_reason (RJSXElement (Some el_name)) loc_element in
        let (_o, attributes', _, children) = jsx_mk_props cx reason el_name attributes children in
        (t, name', attributes', children)
    in
    let closing_element =
      match closing_element with
      | Some (c_loc, { Closing.name = cname }) ->
        Some (c_loc, { Closing.name = jsx_match_closing_element name cname })
      | None -> None
    in
    (t, (loc, { Opening.name; self_closing; attributes }), children, closing_element)

  and jsx_match_closing_element =
    let match_identifiers o_id c_id =
      let ((_, t), _) = o_id in
      let (loc, name) = c_id in
      ((loc, t), name)
    in
    let rec match_member_expressions o_mexp c_mexp =
      let open Ast.JSX.MemberExpression in
      let (_, { _object = o_obj; property = o_prop }) = o_mexp in
      let (loc, { _object = c_obj; property = c_prop }) = c_mexp in
      let _object = match_objects o_obj c_obj in
      let property = match_identifiers o_prop c_prop in
      (loc, { _object; property })
    and match_objects o_obj c_obj =
      match (o_obj, c_obj) with
      | (Ast.JSX.MemberExpression.Identifier o_id, Ast.JSX.MemberExpression.Identifier c_id) ->
        Ast.JSX.MemberExpression.Identifier (match_identifiers o_id c_id)
      | ( Ast.JSX.MemberExpression.MemberExpression o_exp,
          Ast.JSX.MemberExpression.MemberExpression c_exp
        ) ->
        Ast.JSX.MemberExpression.MemberExpression (match_member_expressions o_exp c_exp)
      | (_, _) -> Tast_utils.error_mapper#jsx_member_expression_object c_obj
    in
    let match_namespaced_names o_id c_id =
      let (_, { Ast.JSX.NamespacedName.namespace = o_ns; name = o_name }) = o_id in
      let (loc, { Ast.JSX.NamespacedName.namespace = c_ns; name = c_name }) = c_id in
      let namespace = match_identifiers o_ns c_ns in
      let name = match_identifiers o_name c_name in
      (loc, { Ast.JSX.NamespacedName.namespace; name })
    in
    (* Transfer open types to close types *)
    fun o_name c_name ->
      let open Ast.JSX in
      match (o_name, c_name) with
      | (Identifier o_id, Identifier c_id) -> Identifier (match_identifiers o_id c_id)
      | (NamespacedName o_nname, NamespacedName c_nname) ->
        NamespacedName (match_namespaced_names o_nname c_nname)
      | (MemberExpression o_mexp, MemberExpression c_mexp) ->
        MemberExpression (match_member_expressions o_mexp c_mexp)
      | (_, _) -> Tast_utils.error_mapper#jsx_element_name c_name

  and jsx_mk_props cx reason name attributes children =
    let open Ast.JSX in
    let is_react = Context.jsx cx = Options.Jsx_react in
    let reason_props =
      replace_desc_reason
        ( if is_react then
          RReactProps
        else
          RJSXElementProps name
        )
        reason
    in
    (* Use the same reason for proto and the ObjT so we can walk the proto chain
       and use the root proto reason to build an error. *)
    let proto = ObjProtoT reason_props in
    let (acc, atts) =
      List.fold_left
        (fun (acc, atts) att ->
          match att with
          (* All attributes with a non-namespaced name that are not a react ignored
           * attribute. *)
          | Opening.Attribute
              ( attr_loc,
                {
                  Attribute.name =
                    Attribute.Identifier (id_loc, { Identifier.name = aname; comments = acomments });
                  value;
                }
              ) ->
            (* Get the type for the attribute's value. *)
            let (atype, value) =
              match value with
              (* <element name=""literal"" /> *)
              | Some (Attribute.Literal (loc, lit)) ->
                let t = literal cx loc lit in
                (t, Some (Attribute.Literal ((loc, t), lit)))
              (* <element name={expression} /> *)
              | Some
                  (Attribute.ExpressionContainer
                    ( ec_loc,
                      {
                        ExpressionContainer.expression = ExpressionContainer.Expression (loc, e);
                        comments;
                      }
                    )
                    ) ->
                let (((_, t), _) as e) = expression cx ~hint:(hint_of_loc_todo loc) (loc, e) in
                ( t,
                  Some
                    (Attribute.ExpressionContainer
                       ( (ec_loc, t),
                         {
                           ExpressionContainer.expression = ExpressionContainer.Expression e;
                           comments;
                         }
                       )
                    )
                )
              (* <element name={} /> *)
              | Some (Attribute.ExpressionContainer _ as ec) ->
                let t = EmptyT.at attr_loc |> with_trust bogus_trust in
                (t, Some (Tast_utils.unchecked_mapper#jsx_attribute_value ec))
              (* <element name /> *)
              | None -> (DefT (mk_reason RBoolean attr_loc, bogus_trust (), BoolT (Some true)), None)
            in
            let acc =
              if Type_inference_hooks_js.dispatch_jsx_hook cx aname id_loc then
                (* don't add `aname` to the prop map because it is the autocomplete token *)
                acc
              else
                ObjectExpressionAcc.add_prop
                  (Properties.add_field (OrdinaryName aname) Polarity.Neutral (Some id_loc) atype)
                  acc
            in
            let att =
              Opening.Attribute
                ( attr_loc,
                  {
                    Attribute.name =
                      Attribute.Identifier
                        ((id_loc, atype), { Identifier.name = aname; comments = acomments });
                    value;
                  }
                )
            in
            (acc, att :: atts)
          (* Do nothing for namespaced attributes or ignored React attributes. *)
          | Opening.Attribute _ ->
            (* TODO: attributes with namespaced names *)
            (acc, atts)
          (* <element {...spread} /> *)
          | Opening.SpreadAttribute (spread_loc, { SpreadAttribute.argument; comments }) ->
            let (((_, spread), _) as argument) =
              expression cx ~hint:(hint_of_loc_todo (fst argument)) argument
            in
            let acc = ObjectExpressionAcc.add_spread spread acc in
            let att =
              Opening.SpreadAttribute (spread_loc, { SpreadAttribute.argument; comments })
            in
            (acc, att :: atts))
        (ObjectExpressionAcc.empty ~allow_sealed:true, [])
        attributes
    in
    let attributes = List.rev atts in
    let (unresolved_params, children) = collapse_children cx children in
    let acc =
      match unresolved_params with
      | [] -> acc
      (* We add children to the React.createElement() call for React. Not to the
       * props as other JSX users may support. *)
      | _ when is_react -> acc
      | _ ->
        let arr =
          Tvar.mk_where cx reason (fun tout ->
              let reason_op = reason in
              let element_reason =
                replace_desc_reason Reason.inferred_union_elem_array_desc reason_op
              in
              let elem_t = Tvar.mk cx element_reason in
              Flow.resolve_spread_list
                cx
                ~use_op:unknown_use
                ~reason_op:reason
                unresolved_params
                (ResolveSpreadsToArrayLiteral (mk_id (), elem_t, tout))
          )
        in
        ObjectExpressionAcc.add_prop
          (Properties.add_field (OrdinaryName ""children"") Polarity.Neutral None arr)
          acc
    in
    let t =
      ObjectExpressionAcc.mk_object_from_spread_acc
        cx
        acc
        reason_props
        ~frozen:false
        ~default_proto:proto
        ~empty_unsealed:false
    in
    (t, attributes, unresolved_params, children)

  and jsx_desugar cx name component_t props attributes children locs =
    let (loc_element, loc_opening, loc_children) = locs in
    match Context.jsx cx with
    | Options.Jsx_react ->
      let reason = mk_reason (RReactElement (Some (OrdinaryName name))) loc_element in
      let children =
        Base.List.map
          ~f:(function
            | UnresolvedArg (a, _) -> a
            | UnresolvedSpreadArg a ->
              Flow.add_output cx Error_message.(EUnsupportedSyntax (loc_children, SpreadArgument));
              reason_of_t a |> AnyT.error)
          children
      in
      let tvar = (reason, Tvar.mk_no_wrap cx reason) in
      let args = [Arg component_t; Arg props] @ Base.List.map ~f:(fun c -> Arg c) children in
      (match Context.react_runtime cx with
      | Options.ReactRuntimeAutomatic ->
        (* TODO(jmbrown): Model jsx more faithfully. children are now passed in as part of the props
         * object. See https://github.com/reactjs/rfcs/blob/createlement-rfc/text/0000-create-element-changes.md
         * for more details. *)
        let reason_jsx = mk_reason (RFunction RNormal) loc_element in
        let use_op =
          Op
            (ReactCreateElementCall
               { op = reason_jsx; component = reason_of_t component_t; children = loc_children }
            )
        in
        let jsx_fun = CustomFunT (reason_jsx, ReactCreateElement) in
        let calltype = mk_functioncalltype reason_jsx None args tvar in
        Flow.flow cx (jsx_fun, CallT (use_op, reason, calltype))
      | Options.ReactRuntimeClassic ->
        let reason_createElement =
          mk_reason (RProperty (Some (OrdinaryName ""createElement""))) loc_element
        in
        let use_op =
          Op
            (ReactCreateElementCall
               {
                 op = reason_createElement;
                 component = reason_of_t component_t;
                 children = loc_children;
               }
            )
        in
        let react = Env.var_ref ~lookup_mode:ForValue cx (OrdinaryName ""React"") loc_element in
        Flow.flow
          cx
          ( react,
            MethodT
              ( use_op,
                reason,
                reason_createElement,
                Named (reason_createElement, OrdinaryName ""createElement""),
                CallM
                  (mk_methodcalltype
                     None
                     ([Arg component_t; Arg props] @ Base.List.map ~f:(fun c -> Arg c) children)
                     tvar
                  ),
                None
              )
          ));
      OpenT tvar
    | Options.Jsx_pragma (raw_jsx_expr, jsx_expr) ->
      let reason = mk_reason (RJSXFunctionCall raw_jsx_expr) loc_element in
      (* A JSX element with no attributes should pass in null as the second
       * arg *)
      let props =
        match attributes with
        | [] -> NullT.at loc_opening |> with_trust bogus_trust
        | _ -> props
      in
      let argts =
        [Arg component_t; Arg props]
        @ Base.List.map
            ~f:(function
              | UnresolvedArg (c, _) -> Arg c
              | UnresolvedSpreadArg c -> SpreadArg c)
            children
      in
      let use_op = Op (JSXCreateElement { op = reason; component = reason_of_t component_t }) in
      let open Ast.Expression in
      (match jsx_expr with
      | ( _,
          Member
            {
              Member._object;
              property = Member.PropertyIdentifier (prop_loc, { Ast.Identifier.name; comments = _ });
              _;
            }
        ) ->
        let ot = jsx_pragma_expression cx raw_jsx_expr loc_element _object in
        snd
          (method_call
             cx
             reason
             ~use_op
             ~call_strict_arity:false
             ~havoc:false
             prop_loc
             (jsx_expr, ot, name)
             None
             argts
          )
      | _ ->
        let f = jsx_pragma_expression cx raw_jsx_expr loc_element jsx_expr in
        func_call cx reason ~use_op ~call_strict_arity:false ~havoc:false f None argts)

  (* The @jsx pragma specifies a left hand side expression EXPR such that
   *
   * <Foo />
   *
   * is transformed into
   *
   * EXPR(Foo, props, child1, child2, etc)
   *
   * This means we need to process EXPR. However, EXPR is not inline in the code,
   * it's up in a comment at the top of the file. This means if we run into an
   * error, we're going to point at the comment at the top.
   *
   * We can cover almost all the cases by just explicitly handling identifiers,
   * since the common error is that the identifier is not in scope.
   *)
  and jsx_pragma_expression cx raw_jsx_expr loc =
    let open Ast.Expression in
    function
    | (_, Identifier (_, { Ast.Identifier.name; comments = _ })) ->
      let desc = RJSXIdentifier (raw_jsx_expr, name) in
      Env.var_ref ~lookup_mode:ForValue cx (OrdinaryName name) loc ~desc
    | expr ->
      (* Oh well, we tried *)
      let ((_, t), _) = expression cx ~hint:None expr in
      t

  and jsx_body cx (loc, child) =
    let open Ast.JSX in
    let make_trust = Context.trust_constructor cx in
    match child with
    | Element e ->
      let (t, e) = jsx cx loc e in
      (Some (UnresolvedArg (t, None)), (loc, Element e))
    | Fragment f ->
      let (t, f) = jsx_fragment cx loc f in
      (Some (UnresolvedArg (t, None)), (loc, Fragment f))
    | ExpressionContainer ec ->
      ExpressionContainer.(
        let { expression = ex; ExpressionContainer.comments } = ec in
        let (unresolved_param, ex) =
          match ex with
          | Expression ((loc, _) as e) ->
            let (((_, t), _) as e) = expression cx ~hint:(hint_of_loc_todo loc) e in
            (Some (UnresolvedArg (t, None)), Expression e)
          | EmptyExpression -> (None, EmptyExpression)
        in
        ( unresolved_param,
          (loc, ExpressionContainer { expression = ex; ExpressionContainer.comments })
        )
      )
    | SpreadChild { SpreadChild.expression = expr; comments } ->
      let (((_, t), _) as e) = expression cx ~hint:None expr in
      (Some (UnresolvedSpreadArg t), (loc, SpreadChild { SpreadChild.expression = e; comments }))
    | Text { Text.value; raw } ->
      let unresolved_param_opt =
        match jsx_trim_text make_trust loc value with
        | Some c -> Some (UnresolvedArg (c, None))
        | None -> None
      in
      (unresolved_param_opt, (loc, Text { Text.value; raw }))

  and jsx_trim_text make_trust loc value =
    match Utils_jsx.trim_jsx_text (ALoc.to_loc_exn loc) value with
    | Some (loc, trimmed) ->
      Some
        (DefT
           ( mk_reason RJSXText (loc |> ALoc.of_loc),
             make_trust (),
             StrT (Type.Literal (None, OrdinaryName trimmed))
           )
        )
    | None -> None

  and jsx_title_member_to_string (_, member) =
    let open Ast.JSX.MemberExpression in
    let (_, { Ast.JSX.Identifier.name; comments = _ }) = member.property in
    match member._object with
    | MemberExpression member -> jsx_title_member_to_string member ^ ""."" ^ name
    | Identifier (_, { Ast.JSX.Identifier.name = obj; comments = _ }) -> obj ^ ""."" ^ name

  and jsx_title_namespaced_name_to_string namespaced_name =
    let (_, { Ast.JSX.NamespacedName.namespace = (_, namespace); name = (_, name) }) =
      namespaced_name
    in
    namespace.Ast.JSX.Identifier.name ^ name.Ast.JSX.Identifier.name

  and jsx_title_member_to_expression member =
    let (mloc, member) = member in
    let _object =
      let open Ast.JSX.MemberExpression in
      match member._object with
      | MemberExpression member -> jsx_title_member_to_expression member
      | Identifier (loc, { Ast.JSX.Identifier.name = ""this""; comments }) ->
        (loc, Ast.Expression.This { Ast.Expression.This.comments })
      | Identifier (loc, { Ast.JSX.Identifier.name; comments }) ->
        (loc, Ast.Expression.Identifier (loc, mk_ident ~comments name))
    in
    let property =
      let open Ast.JSX.MemberExpression in
      let (loc, { Ast.JSX.Identifier.name; comments }) = member.property in
      (loc, mk_ident ~comments name)
    in
    let open Ast.Expression.Member in
    ( mloc,
      Ast.Expression.Member { _object; property = PropertyIdentifier property; comments = None }
    )

  (* reverses jsx_title_member_to_expression *)
  and expression_to_jsx_title_member loc member =
    match member with
    | Ast.Expression.Member.(
        Ast.Expression.Member
          {
            _object = ((mloc, tobj), obj_expr);
            property = PropertyIdentifier (pannot, { Ast.Identifier.name; comments });
            comments = _;
          }) ->
      let _object =
        match obj_expr with
        | Ast.Expression.This { Ast.Expression.This.comments } ->
          Some
            (Ast.JSX.MemberExpression.Identifier
               ((mloc, tobj), { Ast.JSX.Identifier.name = ""this""; comments })
            )
        | Ast.Expression.Identifier ((id_loc, t), { Ast.Identifier.name; comments }) ->
          Some
            (Ast.JSX.MemberExpression.Identifier ((id_loc, t), { Ast.JSX.Identifier.name; comments })
            )
        | _ ->
          expression_to_jsx_title_member mloc obj_expr
          |> Base.Option.map ~f:(fun e -> Ast.JSX.MemberExpression.MemberExpression e)
      in
      let property = (pannot, { Ast.JSX.Identifier.name; comments }) in
      Base.Option.map _object ~f:(fun _object ->
          (loc, Ast.JSX.MemberExpression.{ _object; property })
      )
    | _ -> None

  and mk_and map1 map2 =
    Key_map.merge
      (fun _ p1 p2 ->
        match (p1, p2) with
        | (None, None) -> None
        | (Some p, None)
        | (None, Some p) ->
          Some p
        | (Some p1, Some p2) -> Some (AndP (p1, p2)))
      map1
      map2

  and mk_or map1 map2 =
    Key_map.merge
      (fun _ p1 p2 ->
        match (p1, p2) with
        | (None, None) -> None
        | (Some _, None)
        | (None, Some _) ->
          None
        | (Some p1, Some p2) -> Some (OrP (p1, p2)))
      map1
      map2

  (* Given an expression found in a test position, notices certain
     type refinements which follow from the test's success or failure,
     and returns a 5-tuple:
     - result type of the test (not always bool)
     - map (lookup key -> type) of refinements which hold if
     the test is true
     - map of refinements which hold if the test is false
     - map of unrefined types for lvalues found in refinement maps
     - typed AST of the test expression
  *)
  and predicates_of_condition cx ~cond e =
    let open Ast in
    let open Expression in
    (* package empty result (no refinements derived) from test type *)
    let empty_result test_tast = (test_tast, Key_map.empty, Key_map.empty, Key_map.empty) in
    let add_predicate key unrefined_t pred sense (test_tast, ps, notps, tmap) =
      (* if two predicates are applied to the same key, in the positive branch (which depends on
         sense) the predicates are conjuncted, and in the negative branch they are disjuncted *)
      let and_ p1 p2 = AndP (p1, p2) in
      let or_ p1 p2 = OrP (p1, p2) in
      let (p, notp, combine, not_combine) =
        if sense then
          (pred, NotP pred, and_, or_)
        else
          (NotP pred, pred, or_, and_)
      in
      ( test_tast,
        Key_map.add ~combine key p ps,
        Key_map.add ~combine:not_combine key notp notps,
        Key_map.add key unrefined_t tmap
      )
    in
    let flow_eqt ~strict loc (t1, t2) =
      if strict then
        let reason = mk_reason (RCustom ""strict equality comparison"") loc in
        Flow.flow cx (t1, StrictEqT { reason; cond_context = Some cond; flip = false; arg = t2 })
      else
        let reason = mk_reason (RCustom ""non-strict equality comparison"") loc in
        Flow.flow cx (t1, EqT { reason; flip = false; arg = t2 })
    in
    (* package result quad from test typed ast, refi key, unrefined type,
       predicate, and predicate's truth sense *)
    let result test_tast key unrefined_t pred sense =
      empty_result test_tast |> add_predicate key unrefined_t pred sense
    in

    (* a wrapper around `condition` (which is a wrapper around `expression`) that
       evaluates `expr`. if this is a sentinel property check (determined by
       a strict equality check against a member expression `_object.prop_name`),
       then also returns the refinement of `_object`.

       this is used by other tests such as `bool_test` such that if given
       `foo.bar === false`, `foo.bar` is refined to be `false` (by `bool_test`)
       and `foo` is refined to eliminate branches that don't have a `false` bar
       property (by this function). *)
    let condition_of_maybe_sentinel cx ~allow_optional ~sense ~strict expr val_t =
      let expr' =
        match expr with
        | (loc, OptionalMember { OptionalMember.member; _ }) -> (loc, Member member)
        | _ -> expr
      in
      match (Refinement.key ~allow_optional expr, expr') with
      | ( Some _,
          ( _,
            Member
              {
                Member._object;
                property =
                  ( Member.PropertyIdentifier (_, { Ast.Identifier.name = prop_name; comments = _ })
                  | Member.PropertyExpression
                      ( _,
                        Ast.Expression.Literal
                          { Ast.Literal.value = Ast.Literal.String prop_name; _ }
                      ) );
                comments = _;
              }
          )
        ) ->
        let sentinel_refine obj_t =
          (* Generate a refinement on the object that contains a sentinel property.
             We need to pass this into optional_chain, rather than locally generating a
             refinement on the type of _object, because the type getting refined is
             the non-short-circuited, non-nullable branch of any optional chains. *)
          match (strict, Refinement.key ~allow_optional:true _object) with
          | (false, _)
          | (_, None) ->
            None
          | (true, Some ((name, projections) as refinement_key)) ->
            Env.record_expression_type_if_needed cx (aloc_of_reason (reason_of_t val_t)) val_t;
            let pred = LeftP (SentinelProp prop_name, val_t) in
            ( if projections = [] then
              let general_type = Env.query_var_non_specific cx name (fst expr) in
              (* Store any potential sentinel type. Later on, when the check is fired (in
                 merge_js.ml), we only focus on primitive literal types. *)
              Context.add_matching_props cx (reason_of_t val_t, prop_name, val_t, general_type)
            );
            Some (refinement_key, obj_t, pred, sense)
        in
        (* Note here we're calling optional_chain on the whole expression, not on _object.
           We could ""look down"" one level and call it on _object and wouldn't need the
           sentinel_refine function above, but then we'd need to duplicate a lot of the
           functionality of optional_chain here. *)
        let (_, _, ast, preds, sentinel_refinement) =
          optional_chain
            ~cond:(Some cond) (* We do want to allow possibly absent properties... *)
            ~is_existence_check:
              false
              (* ...but we don't generate predicates about
                 their existence at the top level: ""a.b === undefined"" must not generate the
                 predicate ""a.b exists"". *)
            ~sentinel_refine
            cx
            expr
        in
        (ast, preds, sentinel_refinement)
      | _ -> (condition cx ~cond expr, None, None)
    in
    let extend_with_chain_preds ((ast, preds, not_preds, xts1) as out) chain_preds sense =
      let out =
        match chain_preds with
        | None -> out
        | Some (chain_preds, chain_not_preds, xts2) ->
          let xts = Key_map.union xts1 xts2 in
          if sense then
            (ast, mk_and preds chain_preds, mk_or not_preds chain_not_preds, xts)
          else
            (ast, mk_or preds chain_not_preds, mk_and not_preds chain_preds, xts)
      in
      out
    in
    (* inspect a null equality test *)
    let null_test loc ~sense ~strict e null_t reconstruct_ast =
      let ((((_, t), _) as e_ast), chain_preds, sentinel_refinement) =
        condition_of_maybe_sentinel cx ~allow_optional:true ~sense ~strict e null_t
      in
      let ast = reconstruct_ast e_ast in
      flow_eqt ~strict loc (t, null_t);
      let t_out = BoolT.at loc |> with_trust literal_trust in
      let out =
        match Refinement.key ~allow_optional:true e with
        | None -> empty_result ((loc, t_out), ast)
        | Some name ->
          let pred =
            if strict then
              NullP
            else
              MaybeP
          in
          result ((loc, t_out), ast) name t pred sense
      in
      let out =
        match sentinel_refinement with
        | Some (name, obj_t, p, sense) -> out |> add_predicate name obj_t p sense
        | None -> out
      in

      (*
       This is a little tricky in the presence of optional chains, because
       non-strict ""== null"" is true if the LHS is undefined, and a short-circuting
       optional chain always returns ""undefined"". OTOH, strict ""=== null"" is false
       if the LHS is a short-circuiting optional chain, so in the truthy
       branch of an if we can refine the LHS with the knowledge that all
       optional chain operators did not short circuit.

       For example,
       declare var a: ?{b: (null | number)}
       if (a?.b === null) {
         // here ""a"" must not be null or undefined, because the optional chain
         // operator would have short circuited and produced undefined, which !== null
       } else {
         // ""a"" could be null or undefined, or ""a.b"" could be number.
       }
       but on the other hand,
       if (a?.b == null) {
         // here ""a"" might be null or undefined, because the optional chain short-
         // circuiting would produce undefined, which == null
       } else {
         // and here, ""a"" must not be null or undefined, *and* ""a.b"" must be a number
       }
    *)
      let chain_sense = (sense && strict) || ((not sense) && not strict) in
      extend_with_chain_preds out chain_preds chain_sense
    in
    let void_test loc ~sense ~strict e void_t reconstruct_ast =
      (* if `void_t` is not a VoidT, make it one so that the sentinel test has a
         literal type to test against. It's not appropriate to call `void_test`
         with a `void_t` that you don't want to treat like an actual `void`! *)
      let void_t =
        match void_t with
        | DefT (_, _, VoidT) -> void_t
        | _ -> VoidT.why (reason_of_t void_t) |> with_trust bogus_trust
      in
      let ((((_, t), _) as e_ast), chain_preds, sentinel_refinement) =
        condition_of_maybe_sentinel cx ~allow_optional:true ~sense ~strict e void_t
      in
      let ast = reconstruct_ast e_ast in
      flow_eqt ~strict loc (t, void_t);
      let out =
        match Refinement.key ~allow_optional:true e with
        | None ->
          let t_out = BoolT.at loc |> with_trust bogus_trust in
          empty_result ((loc, t_out), ast)
        | Some name ->
          let pred =
            if strict then
              VoidP
            else
              MaybeP
          in
          let t_out = BoolT.at loc |> with_trust bogus_trust in
          result ((loc, t_out), ast) name t pred sense
      in
      let out =
        match sentinel_refinement with
        | Some (name, obj_t, p, sense) -> out |> add_predicate name obj_t p sense
        | None -> out
      in
      (* We flip the sense here for reasons similar to the discussion in null_test,
         except that optional chain short-circuiting *always* reaches the true case,
         since it produces undefined. *)
      extend_with_chain_preds out chain_preds (not sense)
    in
    (* inspect an undefined equality test *)
    let undef_test loc ~undefined_loc ~sense ~strict e void_t reconstruct_ast =
      (* if `undefined` isn't redefined in scope, then we assume it is `void` *)
      if Env.is_global_var cx ""undefined"" undefined_loc then
        void_test loc ~sense ~strict e void_t reconstruct_ast
      else
        let e_ast = expression cx ~hint:None e in
        empty_result ((loc, BoolT.at loc |> with_trust bogus_trust), reconstruct_ast e_ast)
    in
    let literal_test loc ~strict ~sense expr val_t pred reconstruct_ast =
      let ((((_, t), _) as expr_ast), chain_preds, sentinel_refinement) =
        condition_of_maybe_sentinel cx ~allow_optional:true ~sense ~strict expr val_t
      in
      let ast = reconstruct_ast expr_ast in
      flow_eqt ~strict loc (t, val_t);
      let refinement =
        if strict then (
          let key = Refinement.key ~allow_optional:true expr in
          (match (Env.new_env, key) with
          | (false, Some ((OrdinaryName _ as name), [])) ->
            let general_type = Env.query_var_non_specific cx name (fst expr) in
            (match pred with
            | SingletonBoolP (loc, b) ->
              let reason = loc |> mk_reason (RBooleanLit b) in
              let l = DefT (reason, bogus_trust (), BoolT (Some b)) in
              let u = UseT (Op (Internal Refinement), general_type) in
              Context.add_literal_subtypes cx (l, u)
            | SingletonStrP (loc, b, str) ->
              let reason = loc |> mk_reason (RStringLit (OrdinaryName str)) in
              let l = DefT (reason, bogus_trust (), StrT (Literal (Some b, OrdinaryName str))) in
              let u = UseT (Op (Internal Refinement), general_type) in
              Context.add_literal_subtypes cx (l, u)
            | SingletonNumP (loc, b, ((_, str) as num)) ->
              let reason = loc |> mk_reason (RNumberLit str) in
              let l = DefT (reason, bogus_trust (), NumT (Literal (Some b, num))) in
              let u = UseT (Op (Internal Refinement), general_type) in
              Context.add_literal_subtypes cx (l, u)
            | _ -> ())
          | _ -> ());
          key
        ) else
          None
      in
      let out =
        match refinement with
        | Some name ->
          let t_out = BoolT.at loc |> with_trust bogus_trust in
          result ((loc, t_out), ast) name t pred sense
        | None ->
          let t = BoolT.at loc |> with_trust bogus_trust in
          empty_result ((loc, t), ast)
      in
      let out =
        match sentinel_refinement with
        | Some (name, obj_t, p, sense) -> out |> add_predicate name obj_t p sense
        | None -> out
      in
      extend_with_chain_preds out chain_preds sense
    in
    (* generalizes typeof, instanceof, and Array.isArray() *)
    let instance_test loc target make_ast_and_pred sense chain_sense =
      let bool = BoolT.at loc |> with_trust bogus_trust in
      match Refinement.key ~allow_optional:true target with
      | Some name ->
        let (filtered_out, _, targ_ast, chain_preds, _) =
          optional_chain ~cond:(Some cond) ~is_existence_check:false cx target
        in
        let (ast, pred) = make_ast_and_pred targ_ast bool in
        let out = result ast name filtered_out pred sense in
        extend_with_chain_preds out chain_preds chain_sense
      | None ->
        let targ_ast = condition cx ~cond target in
        let (ast, _) = make_ast_and_pred targ_ast bool in
        empty_result ast
    in
    (* inspect a typeof equality test *)
    let typeof_test loc sense arg typename str_loc reconstruct_ast =
      let bool = BoolT.at loc |> with_trust bogus_trust in
      let pred_and_chain_sense sense =
        match typename with
        | ""boolean"" -> Some (BoolP loc, sense)
        | ""function"" -> Some (FunP, sense)
        | ""number"" -> Some (NumP loc, sense)
        | ""object"" -> Some (ObjP, sense)
        | ""string"" -> Some (StrP loc, sense)
        | ""symbol"" -> Some (SymbolP loc, sense)
        | ""undefined"" -> Some (VoidP, not sense)
        | _ -> None
      in
      match pred_and_chain_sense sense with
      | Some (pred, chain_sense) ->
        let make_ast_and_pred ast _ = (((loc, bool), reconstruct_ast ast), pred) in
        instance_test loc arg make_ast_and_pred sense chain_sense
      | None ->
        let arg = condition cx ~cond arg in
        Flow.add_output cx Error_message.(EInvalidTypeof (str_loc, typename));
        empty_result ((loc, bool), reconstruct_ast arg)
    in
    let sentinel_prop_test loc ~sense ~strict expr val_t reconstruct_ast =
      let ((((_, t), _) as expr_ast), _, sentinel_refinement) =
        condition_of_maybe_sentinel cx ~allow_optional:false ~sense ~strict expr val_t
      in
      let ast = reconstruct_ast expr_ast in
      flow_eqt ~strict loc (t, val_t);
      let t_out = BoolT.at loc |> with_trust bogus_trust in
      let out = empty_result ((loc, t_out), ast) in
      match sentinel_refinement with
      | Some (name, obj_t, p, sense) -> out |> add_predicate name obj_t p sense
      | None -> out
    in
    let eq_test loc ~sense ~strict left right reconstruct_ast =
      let is_number_literal node =
        match node with
        | Expression.Literal { Literal.value = Literal.Number _; _ }
        | Expression.Unary
            {
              Unary.operator = Unary.Minus;
              argument = (_, Expression.Literal { Literal.value = Literal.Number _; _ });
              comments = _;
            } ->
          true
        | _ -> false
      in
      let extract_number_literal node =
        match node with
        | Expression.Literal { Literal.value = Literal.Number lit; raw; comments = _ } -> (lit, raw)
        | Expression.Unary
            {
              Unary.operator = Unary.Minus;
              argument = (_, Expression.Literal { Literal.value = Literal.Number lit; raw; _ });
              comments = _;
            } ->
          (-.lit, ""-"" ^ raw)
        | _ -> Utils_js.assert_false ""not a number literal""
      in
      match (left, right) with
      (* typeof expr ==/=== string *)
      (* this must happen before the case below involving Literal.String in order
         to match anything. *)
      | ( (typeof_loc, Expression.Unary { Unary.operator = Unary.Typeof; argument; comments }),
          (str_loc, (Expression.Literal { Literal.value = Literal.String s; _ } as lit_exp))
        ) ->
        typeof_test loc sense argument s str_loc (fun argument ->
            let left_t = StrT.at typeof_loc |> with_trust bogus_trust in
            let left =
              ( (typeof_loc, left_t),
                Expression.Unary { Unary.operator = Unary.Typeof; argument; comments }
              )
            in
            let right_t = StrT.at str_loc |> with_trust bogus_trust in
            let right = ((str_loc, right_t), lit_exp) in
            reconstruct_ast left right
        )
      | ( (str_loc, (Expression.Literal { Literal.value = Literal.String s; _ } as lit_exp)),
          (typeof_loc, Expression.Unary { Unary.operator = Unary.Typeof; argument; comments })
        ) ->
        typeof_test loc sense argument s str_loc (fun argument ->
            let left_t = StrT.at str_loc |> with_trust bogus_trust in
            let left = ((str_loc, left_t), lit_exp) in
            let right_t = StrT.at typeof_loc |> with_trust bogus_trust in
            let right =
              ( (typeof_loc, right_t),
                Expression.Unary { Unary.operator = Unary.Typeof; argument; comments }
              )
            in
            reconstruct_ast left right
        )
      | ( (typeof_loc, Expression.Unary { Unary.operator = Unary.Typeof; argument; comments }),
          ( str_loc,
            ( Expression.TemplateLiteral
                {
                  TemplateLiteral.quasis =
                    [
                      ( _,
                        {
                          TemplateLiteral.Element.value = { TemplateLiteral.Element.cooked = s; _ };
                          _;
                        }
                      );
                    ];
                  expressions = [];
                  comments = _;
                } as lit_exp
            )
          )
        ) ->
        typeof_test loc sense argument s str_loc (fun argument ->
            let left_t = StrT.at typeof_loc |> with_trust bogus_trust in
            let left =
              ( (typeof_loc, left_t),
                Expression.Unary { Unary.operator = Unary.Typeof; argument; comments }
              )
            in
            let right_t = StrT.at str_loc |> with_trust bogus_trust in
            let right = ((str_loc, right_t), lit_exp) in
            reconstruct_ast left right
        )
      | ( ( str_loc,
            ( Expression.TemplateLiteral
                {
                  TemplateLiteral.quasis =
                    [
                      ( _,
                        {
                          TemplateLiteral.Element.value = { TemplateLiteral.Element.cooked = s; _ };
                          _;
                        }
                      );
                    ];
                  expressions = [];
                  comments = _;
                } as lit_exp
            )
          ),
          (typeof_loc, Expression.Unary { Unary.operator = Unary.Typeof; argument; comments })
        ) ->
        typeof_test loc sense argument s str_loc (fun argument ->
            let left_t = StrT.at str_loc |> with_trust bogus_trust in
            let left = ((str_loc, left_t), lit_exp) in
            let right_t = StrT.at typeof_loc |> with_trust bogus_trust in
            let right =
              ( (typeof_loc, right_t),
                Expression.Unary { Unary.operator = Unary.Typeof; argument; comments }
              )
            in
            reconstruct_ast left right
        )
      (* special case equality relations involving booleans *)
      | (((lit_loc, Expression.Literal { Literal.value = Literal.Boolean lit; _ }) as value), expr)
        ->
        let (((_, val_t), _) as val_ast) = expression cx ~hint:None value in
        literal_test
          loc
          ~sense
          ~strict
          expr
          val_t
          (SingletonBoolP (lit_loc, lit))
          (fun expr -> reconstruct_ast val_ast expr)
      | (expr, ((lit_loc, Expression.Literal { Literal.value = Literal.Boolean lit; _ }) as value))
        ->
        let (((_, val_t), _) as val_ast) = expression cx ~hint:None value in
        literal_test
          loc
          ~sense
          ~strict
          expr
          val_t
          (SingletonBoolP (lit_loc, lit))
          (fun expr -> reconstruct_ast expr val_ast)
      (* special case equality relations involving strings *)
      | (((lit_loc, Expression.Literal { Literal.value = Literal.String lit; _ }) as value), expr)
      | ( ( ( _,
              Expression.TemplateLiteral
                {
                  TemplateLiteral.quasis =
                    [
                      ( lit_loc,
                        {
                          TemplateLiteral.Element.value =
                            { TemplateLiteral.Element.cooked = lit; _ };
                          _;
                        }
                      );
                    ];
                  _;
                }
            ) as value
          ),
          expr
        ) ->
        let (((_, val_t), _) as val_ast) = expression cx ~hint:None value in
        literal_test
          loc
          ~sense
          ~strict
          expr
          val_t
          (SingletonStrP (lit_loc, sense, lit))
          (fun expr -> reconstruct_ast val_ast expr)
      | (expr, ((lit_loc, Expression.Literal { Literal.value = Literal.String lit; _ }) as value))
      | ( expr,
          ( ( _,
              Expression.TemplateLiteral
                {
                  TemplateLiteral.quasis =
                    [
                      ( lit_loc,
                        {
                          TemplateLiteral.Element.value =
                            { TemplateLiteral.Element.cooked = lit; _ };
                          _;
                        }
                      );
                    ];
                  _;
                }
            ) as value
          )
        ) ->
        let (((_, val_t), _) as val_ast) = expression cx ~hint:None value in
        literal_test
          loc
          ~sense
          ~strict
          expr
          val_t
          (SingletonStrP (lit_loc, sense, lit))
          (fun expr -> reconstruct_ast expr val_ast)
      (* special case equality relations involving numbers *)
      | (((lit_loc, number_literal) as value), expr) when is_number_literal number_literal ->
        let (lit, raw) = extract_number_literal number_literal in
        let (((_, val_t), _) as val_ast) = expression cx ~hint:None value in
        literal_test
          loc
          ~sense
          ~strict
          expr
          val_t
          (SingletonNumP (lit_loc, sense, (lit, raw)))
          (fun expr -> reconstruct_ast val_ast expr)
      | (expr, ((lit_loc, number_literal) as value)) when is_number_literal number_literal ->
        let (lit, raw) = extract_number_literal number_literal in
        let (((_, val_t), _) as val_ast) = expression cx ~hint:None value in
        literal_test
          loc
          ~sense
          ~strict
          expr
          val_t
          (SingletonNumP (lit_loc, sense, (lit, raw)))
          (fun expr -> reconstruct_ast expr val_ast)
      (* TODO: add Type.predicate variant that tests number equality *)
      (* expr op null *)
      | (((_, Expression.Literal { Literal.value = Literal.Null; _ }) as null), expr) ->
        let (((_, null_t), _) as null_ast) = expression cx ~hint:None null in
        null_test loc ~sense ~strict expr null_t (fun expr -> reconstruct_ast null_ast expr)
      | (expr, ((_, Expression.Literal { Literal.value = Literal.Null; _ }) as null)) ->
        let (((_, null_t), _) as null_ast) = expression cx ~hint:None null in
        null_test loc ~sense ~strict expr null_t (fun expr -> reconstruct_ast expr null_ast)
      (* expr op undefined *)
      | ( ( (_, Identifier (undefined_loc, { Ast.Identifier.name = ""undefined""; comments = _ })) as
          void
          ),
          expr
        ) ->
        let (((_, void_t), _) as void_ast) = expression cx ~hint:None void in
        undef_test loc ~undefined_loc ~sense ~strict expr void_t (fun expr ->
            reconstruct_ast void_ast expr
        )
      | ( expr,
          ( (_, Identifier (undefined_loc, { Ast.Identifier.name = ""undefined""; comments = _ })) as
          void
          )
        ) ->
        let (((_, void_t), _) as void_ast) = expression cx ~hint:None void in
        undef_test loc ~undefined_loc ~sense ~strict expr void_t (fun expr ->
            reconstruct_ast expr void_ast
        )
      (* expr op void(...) *)
      | (((_, Unary { Unary.operator = Unary.Void; _ }) as void), expr) ->
        let (((_, void_t), _) as void_ast) = expression cx ~hint:None void in
        void_test loc ~sense ~strict expr void_t (fun expr -> reconstruct_ast void_ast expr)
      | (expr, ((_, Unary { Unary.operator = Unary.Void; _ }) as void)) ->
        let (((_, void_t), _) as void_ast) = expression cx ~hint:None void in
        void_test loc ~sense ~strict expr void_t (fun expr -> reconstruct_ast expr void_ast)
      (* fallback case for equality relations involving sentinels (this should be
         lower priority since it refines the object but not the property) *)
      | (((_, Expression.Member _) as expr), value) ->
        let (((_, value_t), _) as value_ast) = expression cx ~hint:None value in
        sentinel_prop_test loc ~sense ~strict expr value_t (fun expr ->
            reconstruct_ast expr value_ast
        )
      | (value, ((_, Expression.Member _) as expr))
        when match cond with
             | SwitchTest _ ->
               (* Do not treat `switch (val) { case o.p: ... }` as a sentinel prop test on `o`. *)
               false
             | OtherTest -> true ->
        let (((_, value_t), _) as value_ast) = expression cx ~hint:None value in
        sentinel_prop_test loc ~sense ~strict expr value_t (fun expr ->
            reconstruct_ast value_ast expr
        )
      (* for all other cases, walk the AST but always return bool *)
      | (expr, value) ->
        let (((_, t1), _) as expr) = expression cx ~hint:None expr in
        let (((_, t2), _) as value) = expression cx ~hint:None value in
        flow_eqt ~strict loc (t1, t2);
        let ast = reconstruct_ast expr value in
        let t_out = BoolT.at loc |> with_trust bogus_trust in
        empty_result ((loc, t_out), ast)
    in
    (* main *)
    match e with
    (* member expressions *)
    | (_, Member _)
    | (_, OptionalMember _) ->
      let (_, _, ast, preds, _) = optional_chain ~cond:(Some cond) ~is_existence_check:true cx e in
      begin
        match preds with
        | None -> empty_result ast
        | Some (preds, not_preds, xts) -> (ast, preds, not_preds, xts)
      end
    (* assignments *)
    | (_, Assignment { Assignment.left = (loc, Ast.Pattern.Identifier id); _ }) ->
      let (((_, expr), _) as tast) = expression cx ~hint:None e in
      let id = id.Ast.Pattern.Identifier.name in
      Context.add_exists_check cx loc expr;
      (match Refinement.key ~allow_optional:true (loc, Ast.Expression.Identifier id) with
      | Some name -> result tast name expr ExistsP true
      | None -> empty_result tast)
    (* expr instanceof t *)
    | (loc, Binary { Binary.operator = Binary.Instanceof; left; right; comments }) ->
      let make_ast_and_pred left_ast bool =
        let (((rloc, right_t), _) as right_ast) = expression cx ~hint:None right in
        let reason_rhs = mk_reason (RCustom ""RHS of `instanceof` operator"") rloc in
        Flow.flow cx (right_t, AssertInstanceofRHST reason_rhs);
        ( ( (loc, bool),
            Binary
              { Binary.operator = Binary.Instanceof; left = left_ast; right = right_ast; comments }
          ),
          LeftP (InstanceofTest, right_t)
        )
      in
      instance_test loc left make_ast_and_pred true true
    (* expr op expr *)
    | (loc, Binary { Binary.operator = Binary.Equal; left; right; comments }) ->
      eq_test loc ~sense:true ~strict:false left right (fun left right ->
          Binary { Binary.operator = Binary.Equal; left; right; comments }
      )
    | (loc, Binary { Binary.operator = Binary.StrictEqual; left; right; comments }) ->
      eq_test loc ~sense:true ~strict:true left right (fun left right ->
          Binary { Binary.operator = Binary.StrictEqual; left; right; comments }
      )
    | (loc, Binary { Binary.operator = Binary.NotEqual; left; right; comments }) ->
      eq_test loc ~sense:false ~strict:false left right (fun left right ->
          Binary { Binary.operator = Binary.NotEqual; left; right; comments }
      )
    | (loc, Binary { Binary.operator = Binary.StrictNotEqual; left; right; comments }) ->
      eq_test loc ~sense:false ~strict:true left right (fun left right ->
          Binary { Binary.operator = Binary.StrictNotEqual; left; right; comments }
      )
    (* Array.isArray(expr) *)
    | ( loc,
        Call
          {
            Call.callee =
              ( callee_loc,
                Member
                  {
                    Member._object =
                      (_, Identifier (_, { Ast.Identifier.name = ""Array""; comments = _ })) as o;
                    property =
                      Member.PropertyIdentifier
                        (prop_loc, ({ Ast.Identifier.name = ""isArray""; comments = _ } as id));
                    comments = member_comments;
                  }
              );
            targs;
            arguments =
              (args_loc, { ArgList.arguments = [Expression arg]; comments = args_comments });
            comments;
          }
      ) ->
      Base.Option.iter targs ~f:(fun _ ->
          Flow.add_output
            cx
            Error_message.(
              ECallTypeArity
                {
                  call_loc = loc;
                  is_new = false;
                  reason_arity = Reason.(locationless_reason (RFunction RNormal));
                  expected_arity = 0;
                }
            )
      );

      (* get Array.isArray in order to populate the type tables, but we don't
         care about the result. *)
      (* TODO: one day we can replace this with a call to `method_call`, and
         then discard the result. currently MethodT does not update type_table
         properly. *)
      let (((_, obj_t), _) as _object) = expression cx ~hint:None o in
      let reason = mk_reason (RCustom ""`Array.isArray(...)`"") callee_loc in
      let fn_t =
        Tvar.mk_no_wrap_where cx reason (fun t ->
            let prop_reason = mk_reason (RProperty (Some (OrdinaryName ""isArray""))) prop_loc in
            let use_op = Op (GetProperty (mk_expression_reason e)) in
            Flow.flow
              cx
              ( obj_t,
                GetPropT (use_op, reason, None, Named (prop_reason, OrdinaryName ""isArray""), t)
              )
        )
      in
      let make_ast_and_pred arg bool =
        let property = Member.PropertyIdentifier ((prop_loc, fn_t), id) in
        ( ( (loc, bool),
            Call
              {
                Call.callee =
                  ( (callee_loc, fn_t),
                    Member { Member._object; property; comments = member_comments }
                  );
                targs = None;
                arguments =
                  (args_loc, { ArgList.arguments = [Expression arg]; comments = args_comments });
                comments;
              }
          ),
          ArrP
        )
      in
      instance_test loc arg make_ast_and_pred true true
    (* test1 && test2 *)
    | (loc, Logical { Logical.operator = Logical.And; left; right; comments }) ->
      let ((((_, t1), _) as left_ast), map1, not_map1, xts1) =
        predicates_of_condition cx ~cond left
      in
      let ((((_, t2), _) as right_ast), map2, not_map2, xts2) =
        Env.in_refined_env cx loc map1 xts1 (fun () -> predicates_of_condition cx ~cond right)
      in
      let reason = mk_reason (RLogical (""&&"", desc_of_t t1, desc_of_t t2)) loc in
      let t_out =
        Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (t1, AndT (reason, t2, t)))
      in
      ( ( (loc, t_out),
          Logical { Logical.operator = Logical.And; left = left_ast; right = right_ast; comments }
        ),
        mk_and map1 map2,
        mk_or not_map1 not_map2,
        Key_map.union xts1 xts2
      )
    (* test1 || test2 *)
    | (loc, Logical { Logical.operator = Logical.Or; left; right; comments }) ->
      let () = check_default_pattern cx left right in
      let ((((_, t1), _) as left_ast), map1, not_map1, xts1) =
        predicates_of_condition cx ~cond left
      in
      let ((((_, t2), _) as right_ast), map2, not_map2, xts2) =
        Env.in_refined_env cx loc not_map1 xts1 (fun () -> predicates_of_condition cx ~cond right)
      in
      let reason = mk_reason (RLogical (""||"", desc_of_t t1, desc_of_t t2)) loc in
      let t_out =
        Tvar.mk_no_wrap_where cx reason (fun t -> Flow.flow cx (t1, OrT (reason, t2, t)))
      in
      ( ( (loc, t_out),
          Logical { Logical.operator = Logical.Or; left = left_ast; right = right_ast; comments }
        ),
        mk_or map1 map2,
        mk_and not_map1 not_map2,
        Key_map.union xts1 xts2
      )
    (* !test *)
    | (loc, Unary { Unary.operator = Unary.Not; argument; comments }) ->
      let (arg, map, not_map, xts) = predicates_of_condition cx ~cond argument in
      let ast' = Unary { Unary.operator = Unary.Not; argument = arg; comments } in
      let t_out = BoolT.at loc |> with_trust bogus_trust in
      let ast = ((loc, t_out), ast') in
      (ast, not_map, map, xts)
    (* ids *)
    | (loc, This _)
    | (loc, Identifier _) ->
      let (((_, t), _) as e) = condition ~cond cx e in
      Context.add_exists_check cx loc t;
      (match Refinement.key ~allow_optional:true e with
      | Some name -> result e name t ExistsP true
      | None -> empty_result e)
    (* e.m(...) *)
    (* TODO: Don't trap method calls for now *)
    | (_, Call { Call.callee = (_, (Member _ | OptionalMember _)); _ }) ->
      empty_result (expression cx ~hint:None e)
    (* f(...) *)
    (* The concrete predicate is not known at this point. We attach a ""latent""
       predicate pointing to the type of the function that will supply this
       predicated when it is resolved. *)
    | (loc, Call ({ Call.callee; arguments = (_, { ArgList.arguments; comments = _ }); _ } as call))
      ->
      let is_spread = function
        | Spread _ -> true
        | _ -> false
      in
      if List.exists is_spread arguments || is_call_to_invariant callee then
        empty_result (expression cx ~hint:None e)
      else
        let (fun_t, keys, arg_ts, ret_t, call_ast) = predicated_call_expression cx loc call in
        let ast = ((loc, ret_t), Call call_ast) in
        let args_with_offset = ListUtils.zipi keys arg_ts in
        let emp_pred_map = empty_result ast in
        List.fold_left
          (fun pred_map arg_info ->
            match arg_info with
            | (idx, Some key, unrefined_t) ->
              let pred = LatentP (fun_t, idx + 1) in
              add_predicate key unrefined_t pred true pred_map
            | _ -> pred_map)
          emp_pred_map
          args_with_offset
    (* fallthrough case: evaluate test expr, no refinements *)
    | e -> empty_result (expression cx ~hint:None e)

  (* Conditional expressions are checked like expressions, except that property
     accesses are provisionally allowed even when such properties do not exist.
     This accommodates the common JavaScript idiom of testing for the existence
     of a property before using that property. *)
  and condition cx ~cond e : (ALoc.t, ALoc.t * Type.t) Ast.Expression.t =
    expression ~cond ~hint:None cx e

  and get_private_field_opt_use reason ~use_op name =
    let class_entries = Env.get_class_entries () in
    OptGetPrivatePropT (use_op, reason, name, class_entries, false)

  (* Property lookups become non-strict when processing conditional expressions
     (see above).

     TODO: It should be possible to factor the processing of LHS / reference
     expressions out of `expression`, somewhat like what assignment_lhs does. That
     would make everything involving Refinement be in the same place.
  *)
  and get_prop_opt_use ~cond reason ~use_op (prop_reason, name) =
    let id = mk_id () in
    if Base.Option.is_some cond then
      OptTestPropT (use_op, reason, id, Named (prop_reason, OrdinaryName name))
    else
      OptGetPropT (use_op, reason, Some id, Named (prop_reason, OrdinaryName name))

  and get_prop ~cond cx reason ~use_op tobj (prop_reason, name) =
    let opt_use = get_prop_opt_use ~cond reason ~use_op (prop_reason, name) in
    Tvar.mk_no_wrap_where cx reason (fun t ->
        let get_prop_u = apply_opt_use opt_use t in
        Flow.flow cx (tobj, get_prop_u)
    )

  and static_method_call_Object cx loc callee_loc prop_loc expr obj_t m targs args =
    let open Ast.Expression in
    let reason = mk_reason (RCustom (spf ""`Object.%s`"" m)) loc in
    let use_op =
      Op
        (FunCallMethod
           {
             op = reason;
             fn = mk_reason (RMethod (Some m)) callee_loc;
             prop = mk_reason (RProperty (Some (OrdinaryName m))) prop_loc;
             args = mk_initial_arguments_reason args;
             local = true;
           }
        )
    in
    match (m, targs, args) with
    | (""create"", None, (args_loc, { ArgList.arguments = [Expression e]; comments })) ->
      let (((_, e_t), _) as e_ast) = expression cx ~hint:None e in
      let proto =
        let reason = mk_reason RPrototype (fst e) in
        Tvar.mk_where cx reason (fun t -> Flow.flow cx (e_t, ObjTestProtoT (reason, t)))
      in
      ( Obj_type.mk_unsealed cx reason ~proto,
        None,
        (args_loc, { ArgList.arguments = [Expression e_ast]; comments })
      )
    | ( ""create"",
        None,
        ( args_loc,
          {
            ArgList.arguments =
              [
                Expression e;
                Expression (obj_loc, Object { Object.properties; comments = obj_comments });
              ];
            comments;
          }
        )
      ) ->
      let (((_, e_t), _) as e_ast) = expression cx ~hint:None e in
      let proto =
        let reason = mk_reason RPrototype (fst e) in
        Tvar.mk_where cx reason (fun t -> Flow.flow cx (e_t, ObjTestProtoT (reason, t)))
      in
      let (pmap, properties) = prop_map_of_object cx properties in
      let propdesc_type = Flow.get_builtin cx (OrdinaryName ""PropertyDescriptor"") reason in
      let props =
        NameUtils.Map.fold
          (fun x p acc ->
            let loc = Property.read_loc p in
            match Property.read_t p with
            | None ->
              (* Since the properties object must be a literal, and literal objects
                 can only ever contain neutral fields, this should not happen. *)
              Flow.add_output
                cx
                Error_message.(EInternal (prop_loc, PropertyDescriptorPropertyCannotBeRead));
              acc
            | Some spec ->
              let reason =
                update_desc_reason
                  (fun desc ->
                    RCustom (spf "".%s of %s"" (display_string_of_name x) (string_of_desc desc)))
                  reason
              in
              let t =
                Tvar.mk_where cx reason (fun tvar ->
                    let loc = aloc_of_reason reason in
                    let propdesc = implicit_typeapp ~annot_loc:loc propdesc_type [tvar] in
                    Flow.flow cx (spec, UseT (use_op, propdesc))
                )
              in
              let p = Field (loc, t, Polarity.Neutral) in
              NameUtils.Map.add x p acc)
          pmap
          NameUtils.Map.empty
      in
      ( Obj_type.mk_unsealed cx reason ~props ~proto,
        None,
        ( args_loc,
          {
            ArgList.arguments =
              [
                Expression e_ast;
                (* TODO(vijayramamurthy) construct object type *)
                Expression
                  ( (obj_loc, AnyT.at Untyped obj_loc),
                    Object { Object.properties; comments = obj_comments }
                  );
              ];
            comments;
          }
        )
      )
    | ( (""getOwnPropertyNames"" | ""keys""),
        None,
        (args_loc, { ArgList.arguments = [Expression e]; comments })
      ) ->
      let arr_reason = mk_reason RArrayType loc in
      let (((_, o), _) as e_ast) = expression cx ~hint:None e in
      ( DefT
          ( arr_reason,
            bogus_trust (),
            ArrT
              (ArrayAT
                 ( Tvar.mk_where cx arr_reason (fun tvar ->
                       let keys_reason =
                         update_desc_reason
                           (fun desc -> RCustom (spf ""element of %s"" (string_of_desc desc)))
                           reason
                       in
                       Flow.flow cx (o, GetKeysT (keys_reason, UseT (use_op, tvar)))
                   ),
                   None
                 )
              )
          ),
        None,
        (args_loc, { ArgList.arguments = [Expression e_ast]; comments })
      )
    | ( ""defineProperty"",
        ( None
        | Some
            (_, { CallTypeArgs.arguments = [Ast.Expression.CallTypeArg.Explicit _]; comments = _ })
          ),
        ( args_loc,
          {
            ArgList.arguments =
              [
                Expression e;
                Expression
                  ( (ploc, Ast.Expression.Literal { Ast.Literal.value = Ast.Literal.String x; _ })
                  as key
                  );
                Expression config;
              ];
            comments;
          }
        )
      ) ->
      let (ty, targs) =
        match targs with
        | None -> (Tvar.mk cx reason, None)
        | Some
            ( targs_loc,
              { CallTypeArgs.arguments = [Ast.Expression.CallTypeArg.Explicit targ]; comments }
            ) ->
          let (((_, ty), _) as targ) = Anno.convert cx Subst_name.Map.empty targ in
          ( ty,
            Some
              ( targs_loc,
                { CallTypeArgs.arguments = [Ast.Expression.CallTypeArg.Explicit targ]; comments }
              )
          )
        | _ -> assert_false ""unexpected type argument to Object.defineProperty, match guard failed""
      in
      let loc = aloc_of_reason reason in
      let propdesc_type = Flow.get_builtin cx (OrdinaryName ""PropertyDescriptor"") reason in
      let propdesc = implicit_typeapp ~annot_loc:loc propdesc_type [ty] in
      let (((_, o), _) as e_ast) = expression cx ~hint:None e in
      let key_ast = expression cx ~hint:None key in
      let (((_, spec), _) as config_ast) = expression cx ~hint:None config in
      let prop_reason = mk_reason (RProperty (Some (OrdinaryName x))) ploc in
      Flow.flow cx (spec, UseT (use_op, propdesc));
      let prop_t = Tvar.mk cx prop_reason in
      Flow.flow
        cx
        ( o,
          SetPropT
            (use_op, reason, Named (prop_reason, OrdinaryName x), Assign, Normal, ty, Some prop_t)
        );
      ( o,
        targs,
        ( args_loc,
          {
            ArgList.arguments = [Expression e_ast; Expression key_ast; Expression config_ast];
            comments;
          }
        )
      )
    | ( ""defineProperties"",
        None,
        ( args_loc,
          {
            ArgList.arguments =
              [
                Expression e;
                Expression (obj_loc, Object { Object.properties; comments = obj_comments });
              ];
            comments;
          }
        )
      ) ->
      let (((_, o), _) as e_ast) = expression cx ~hint:None e in
      let (pmap, properties) = prop_map_of_object cx properties in
      let propdesc_type = Flow.get_builtin cx (OrdinaryName ""PropertyDescriptor"") reason in
      pmap
      |> NameUtils.Map.iter (fun x p ->
             match Property.read_t p with
             | None ->
               (* Since the properties object must be a literal, and literal objects
                  can only ever contain neutral fields, this should not happen. *)
               Flow.add_output
                 cx
                 Error_message.(EInternal (prop_loc, PropertyDescriptorPropertyCannotBeRead))
             | Some spec ->
               let reason =
                 update_desc_reason
                   (fun desc ->
                     RCustom (spf "".%s of %s"" (display_string_of_name x) (string_of_desc desc)))
                   reason
               in
               let tvar = Tvar.mk cx reason in
               let loc = aloc_of_reason reason in
               let propdesc = implicit_typeapp ~annot_loc:loc propdesc_type [tvar] in
               Flow.flow cx (spec, UseT (use_op, propdesc));
               Flow.flow
                 cx
                 (o, SetPropT (use_op, reason, Named (reason, x), Assign, Normal, tvar, None))
         );
      ( o,
        None,
        ( args_loc,
          {
            ArgList.arguments =
              [
                Expression e_ast;
                (* TODO(vijayramamurthy) construct object type *)
                Expression
                  ( (obj_loc, AnyT.at Untyped obj_loc),
                    Object { Object.properties; comments = obj_comments }
                  );
              ];
            comments;
          }
        )
      )
    (* Freezing an object literal is supported since there's no way it could
       have been mutated elsewhere *)
    | ( ""freeze"",
        ((None | Some (_, { CallTypeArgs.arguments = [_]; comments = _ })) as targs),
        (args_loc, { ArgList.arguments = [Expression (arg_loc, Object o)]; comments })
      ) ->
      let targs =
        Base.Option.map
          ~f:(fun (loc, targs) -> (loc, convert_call_targs cx Subst_name.Map.empty targs))
          targs
      in
      let (((_, arg_t), _) as e_ast) =
        let { Object.properties; comments } = o in
        let reason = mk_reason (RFrozen RObjectLit) arg_loc in
        let (t, properties) = object_ ~hint:None ~frozen:true cx reason properties in
        ((arg_loc, t), Object { Object.properties; comments })
      in
      let reason = mk_reason (RMethodCall (Some m)) loc in
      ( snd
          (method_call
             cx
             reason
             prop_loc
             ~use_op
             (expr, obj_t, m)
             (Base.Option.map ~f:(snd %> fst) targs)
             [Arg arg_t]
          ),
        Base.Option.map ~f:(fun (loc, targs) -> (loc, snd targs)) targs,
        (args_loc, { ArgList.arguments = [Expression e_ast]; comments })
      )
    | ( ( ""create"" | ""getOwnPropertyNames"" | ""keys"" | ""defineProperty"" | ""defineProperties""
        | ""freeze"" ),
        Some (targs_loc, targs),
        _
      ) ->
      let targs = snd (convert_call_targs cx Subst_name.Map.empty targs) in
      let (_argts, args) = arg_list cx args in
      let arity =
        if m = ""freeze"" || m = ""defineProperty"" then
          1
        else
          0
      in
      Flow.add_output
        cx
        Error_message.(
          ECallTypeArity
            {
              call_loc = loc;
              is_new = false;
              reason_arity = Reason.(locationless_reason (RFunction RNormal));
              expected_arity = arity;
            }
        );
      (AnyT.at (AnyError None) loc, Some (targs_loc, targs), args)
    (* TODO *)
    | _ ->
      let (targts, targ_asts) = convert_call_targs_opt cx targs in
      let (argts, arg_asts) = arg_list cx args in
      let reason = mk_reason (RMethodCall (Some m)) loc in
      let use_op =
        Op
          (FunCallMethod
             {
               op = reason;
               fn = mk_reason (RMethod (Some m)) callee_loc;
               prop = mk_reason (RProperty (Some (OrdinaryName m))) prop_loc;
               args = mk_initial_arguments_reason args;
               local = true;
             }
          )
      in
      ( snd (method_call cx reason ~use_op ~havoc:false prop_loc (expr, obj_t, m) targts argts),
        targ_asts,
        arg_asts
      )

  and mk_class cx class_loc ~name_loc ~general reason c =
    let def_reason = repos_reason class_loc reason in
    let this_in_class = Class_stmt_sig.This.in_class c in
    let self = Tvar.mk cx reason in
    let (class_sig, class_ast_f) = mk_class_sig cx name_loc reason self c in
    let instance_this_type = Class_stmt_sig.this_or_mixed_of_t ~static:false class_sig in
    let static_this_type = Class_stmt_sig.this_or_mixed_of_t ~static:true class_sig in
    let public_property_map =
      Class_stmt_sig.fields_to_prop_map cx
      @@ Class_stmt_sig.public_fields_of_signature ~static:false class_sig
    in
    let private_property_map =
      Class_stmt_sig.fields_to_prop_map cx
      @@ Class_stmt_sig.private_fields_of_signature ~static:false class_sig
    in
    Class_stmt_sig.check_super cx def_reason class_sig;
    Class_stmt_sig.check_implements cx def_reason class_sig;
    Class_stmt_sig.check_methods cx def_reason class_sig;
    if this_in_class || not (Class_stmt_sig.This.is_bound_to_empty class_sig) then
      Class_stmt_sig.toplevels
        cx
        class_sig
        ~private_property_map
        ~instance_this_type
        ~static_this_type;

    let class_body = Ast.Class.((snd c.body).Body.body) in
    Context.add_voidable_check
      cx
      {
        Context.public_property_map;
        private_property_map;
        errors = Property_assignment.eval_property_assignment class_body;
      };
    let (class_t_internal, class_t) = Class_stmt_sig.classtype cx class_sig in
    Flow.unify cx self class_t_internal;
    (class_t, class_ast_f general)

  (* Process a class definition, returning a (polymorphic) class type. A class
     type is a wrapper around an instance type, which contains types of instance
     members, a pointer to the super instance type, and a container for types of
     static members. The static members can be thought of as instance members of a
     ""metaclass"": thus, the static type is itself implemented as an instance
     type. *)
  and mk_class_sig =
    Class_stmt_sig.(
      (* Given information about a field, returns:
         - Class_sig.field representation of this field
         - typed AST of the field's type annotation
         - a function which will return a typed AST of the field's initializer expression.
           Function should only be called after Class_sig.toplevels has been called on a
           Class_sig.t containing this field, as that is when the initializer expression
           gets checked.
      *)
      let mk_field cx tparams_map reason annot init =
        let (annot_or_inferred, annot_ast) = Anno.mk_type_annotation cx tparams_map reason annot in
        let annot_t = type_t_of_annotated_or_inferred annot_or_inferred in
        let (field, get_init) =
          match init with
          | Ast.Class.Property.Declared -> (Annot annot_t, Fn.const Ast.Class.Property.Declared)
          | Ast.Class.Property.Uninitialized ->
            (Annot annot_t, Fn.const Ast.Class.Property.Uninitialized)
          | Ast.Class.Property.Initialized expr ->
            let value_ref : (ALoc.t, ALoc.t * Type.t) Ast.Expression.t option ref = ref None in
            ( Infer
                ( Func_stmt_sig.field_initializer tparams_map reason expr annot_or_inferred,
                  (fun (_, _, value_opt) -> value_ref := Some (Base.Option.value_exn value_opt))
                ),
              fun () ->
                Ast.Class.Property.Initialized
                  (Base.Option.value !value_ref ~default:(Tast_utils.error_mapper#expression expr))
            )
        in
        (field, annot_t, annot_ast, get_init)
      in
      let mk_method = mk_func_sig ~hint:None ~needs_this_param:false in
      let mk_extends cx tparams_map = function
        | None -> (Implicit { null = false }, None)
        | Some (loc, { Ast.Class.Extends.expr; targs; comments }) ->
          let (((_, c), _) as expr) = expression cx ~hint:None expr in
          let (t, targs) = Anno.mk_super cx tparams_map loc c targs in
          (Explicit t, Some (loc, { Ast.Class.Extends.expr; targs; comments }))
      in
      fun cx name_loc reason self cls ->
        let {
          Ast.Class.id;
          body = (body_loc, { Ast.Class.Body.body = elements; comments = body_comments });
          tparams;
          extends;
          implements;
          class_decorators;
          comments;
        } =
          cls
        in
        let class_decorators_ast =
          Base.List.map ~f:Tast_utils.error_mapper#class_decorator class_decorators
        in
        let (tparams, tparams_map, tparams_ast) = Anno.mk_type_param_declarations cx tparams in
        let (this_tparam, this_t) = mk_this self cx reason tparams in
        let tparams_map_with_this =
          Subst_name.Map.add (Subst_name.Name ""this"") this_t tparams_map
        in
        let (class_sig, extends_ast, implements_ast) =
          let id = Context.make_aloc_id cx name_loc in
          let (extends, extends_ast) = mk_extends cx tparams_map_with_this extends in
          let (implements, implements_ast) =
            match implements with
            | None -> ([], None)
            | Some (implements_loc, { Ast.Class.Implements.interfaces; comments }) ->
              let (implements, interfaces_ast) =
                interfaces
                |> Base.List.map ~f:(fun (loc, i) ->
                       let {
                         Ast.Class.Implements.Interface.id =
                           (id_loc, ({ Ast.Identifier.name; comments = _ } as id));
                         targs;
                       } =
                         i
                       in
                       let c = Env.get_var ~lookup_mode:Env_sig.LookupMode.ForType cx name id_loc in
                       let (typeapp, targs) =
                         match targs with
                         | None -> ((loc, c, None), None)
                         | Some (targs_loc, { Ast.Type.TypeArgs.arguments = targs; comments }) ->
                           let (ts, targs_ast) = Anno.convert_list cx tparams_map_with_this targs in
                           ( (loc, c, Some ts),
                             Some (targs_loc, { Ast.Type.TypeArgs.arguments = targs_ast; comments })
                           )
                       in
                       ( typeapp,
                         (loc, { Ast.Class.Implements.Interface.id = ((id_loc, c), id); targs })
                       )
                   )
                |> List.split
              in
              ( implements,
                Some (implements_loc, { Ast.Class.Implements.interfaces = interfaces_ast; comments })
              )
          in
          let super =
            Class { Class_stmt_sig.extends; mixins = []; implements; this_t; this_tparam }
          in
          (empty id reason tparams tparams_map super, extends_ast, implements_ast)
        in
        (* In case there is no constructor, pick up a default one. *)
        let class_sig =
          if extends <> None then
            (* Subclass default constructors are technically of the form (...args) =>
               { super(...args) }, but we can approximate that using flow's existing
               inheritance machinery. *)
            (* TODO: Does this distinction matter for the type checker? *)
            class_sig
          else
            let reason = replace_desc_reason RDefaultConstructor reason in
            add_default_constructor reason class_sig
        in
        (* All classes have a static ""name"" property. *)
        let class_sig = add_name_field class_sig in

        let check_duplicate_name public_seen_names member_loc name ~static ~private_ kind =
          if private_ then
            (* duplicate private names are a parser error - so we don't need to check them *)
            public_seen_names
          else
            let names_map =
              if static then
                public_seen_names.static_names
              else
                public_seen_names.instance_names
            in
            let names_map' =
              match SMap.find_opt name names_map with
              | Some seen ->
                (match (kind, seen) with
                | (Class_Member_Getter, Class_Member_Setter)
                | (Class_Member_Setter, Class_Member_Getter) ->
                  (* One getter and one setter are allowed as long as it's not used as a field
                     We use the special type here to indicate we've seen both a getter and a
                     setter for the name so that future getters/setters can have an error raised. *)
                  SMap.add name Class_Member_GetterSetter names_map
                | _ ->
                  Flow.add_output
                    cx
                    Error_message.(EDuplicateClassMember { loc = member_loc; name; static });
                  names_map)
              | None -> SMap.add name kind names_map
            in
            if static then
              { public_seen_names with static_names = names_map' }
            else
              { public_seen_names with instance_names = names_map' }
        in

        (* NOTE: We used to mine field declarations from field assignments in a
           constructor as a convenience, but it was not worth it: often, all that did
           was exchange a complaint about a missing field for a complaint about a
           missing annotation. Moreover, it caused fields declared in the super class
           to be redeclared if they were assigned in the constructor. So we don't do
           it. In the future, we could do it again, but only for private fields. *)

        (* NOTE: field initializer expressions and method bodies don't get checked
           until Class_sig.toplevels is called on class_sig. For this reason rather
           than returning a typed AST, we'll return a function which returns a typed
           AST, and this function shouldn't be called until after Class_sig.toplevels
           has been called.

           If a field/method ever gets shadowed later in the class, then its
           initializer/body (respectively) will not get checked, and the corresponding
           nodes of the typed AST will be filled in with error nodes.
        *)
        let (class_sig, rev_elements, _) =
          List.fold_left
            (let open Ast.Class in
            fun (c, rev_elements, public_seen_names) ->
              let add_method_sig_and_element
                  ~method_loc
                  ~name
                  ~id_loc
                  ~func_loc
                  ~func
                  ~kind
                  ~private_
                  ~static
                  ~decorators
                  ~comments
                  ~get_typed_method_key =
                Type_inference_hooks_js.dispatch_class_member_decl_hook cx self static name id_loc;
                let decorators =
                  Base.List.map ~f:Tast_utils.error_mapper#class_decorator decorators
                in
                (match kind with
                | Method.Get
                | Method.Set ->
                  Flow_js.add_output cx (Error_message.EUnsafeGettersSetters method_loc)
                | _ -> ());
                let reason =
                  Ast.Function.(func_reason ~async:func.async ~generator:func.generator method_loc)
                in
                let (method_sig, reconstruct_func) =
                  mk_method cx tparams_map_with_this reason func
                in
                (* The body of a class method doesn't get checked until Class_sig.toplevels
                   is called on the class sig (in this case c). The order of how the methods
                   were arranged in the class is lost by the time this happens, so rather
                   than attempting to return a list of method bodies from the Class_sig.toplevels
                   function, we have it place the function bodies into a list via side effects.
                   We use a similar approach for method types *)
                let params_ref : (ALoc.t, ALoc.t * Type.t) Ast.Function.Params.t option ref =
                  ref None
                in
                let body_ref : (ALoc.t, ALoc.t * Type.t) Ast.Function.body option ref = ref None in
                let set_asts (params_opt, body_opt, _) =
                  params_ref := Some (Base.Option.value_exn params_opt);
                  body_ref := Some (Base.Option.value_exn body_opt)
                in
                let func_t_ref : Type.t option ref = ref None in
                let set_type t = func_t_ref := Some t in
                let get_element () =
                  let params =
                    Base.Option.value
                      !params_ref
                      ~default:(Tast_utils.error_mapper#function_params func.Ast.Function.params)
                  in
                  let body =
                    Base.Option.value
                      !body_ref
                      ~default:(Tast_utils.error_mapper#function_body func.Ast.Function.body)
                  in
                  let func_t =
                    Base.Option.value
                      !func_t_ref
                      ~default:(EmptyT.at id_loc |> with_trust bogus_trust)
                  in
                  let func = reconstruct_func params body func_t in
                  Body.Method
                    ( (method_loc, func_t),
                      {
                        Method.key = get_typed_method_key func_t;
                        value = (func_loc, func);
                        kind;
                        static;
                        decorators;
                        comments;
                      }
                    )
                in
                let (add, class_member_kind) =
                  match kind with
                  | Method.Constructor ->
                    let add = add_constructor (Some id_loc) ~set_asts ~set_type in
                    (add, None)
                  | Method.Method ->
                    let add =
                      if private_ then
                        add_private_method ~static name id_loc ~set_asts ~set_type
                      else
                        add_method ~static name id_loc ~set_asts ~set_type
                    in
                    (add, Some Class_Member_Method)
                  | Method.Get ->
                    let add = add_getter ~static name id_loc ~set_asts ~set_type in
                    (add, Some Class_Member_Getter)
                  | Method.Set ->
                    let add = add_setter ~static name id_loc ~set_asts ~set_type in
                    (add, Some Class_Member_Setter)
                in
                let public_seen_names' =
                  match class_member_kind with
                  | Some k -> check_duplicate_name public_seen_names id_loc name ~static ~private_ k
                  | None -> public_seen_names
                in
                (add method_sig c, get_element :: rev_elements, public_seen_names')
              in
              function
              (* instance and static methods *)
              | Body.Property (_, { Property.key = Ast.Expression.Object.Property.PrivateName _; _ })
                ->
                failwith ""Internal Error: Found non-private field with private name""
              | Body.Method
                  ( method_loc,
                    {
                      Method.key =
                        Ast.Expression.Object.Property.PrivateName
                          (id_loc, ({ Ast.PrivateName.name; comments = _ } as id));
                      value = (func_loc, func);
                      kind;
                      static;
                      decorators;
                      comments;
                    }
                  ) ->
                add_method_sig_and_element
                  ~method_loc
                  ~name
                  ~id_loc
                  ~func_loc
                  ~func
                  ~kind
                  ~private_:true
                  ~static
                  ~decorators
                  ~comments
                  ~get_typed_method_key:(fun _ ->
                    Ast.Expression.Object.Property.PrivateName (id_loc, id)
                )
              | Body.Method
                  ( method_loc,
                    {
                      Method.key =
                        Ast.Expression.Object.Property.Identifier
                          (id_loc, ({ Ast.Identifier.name; comments = _ } as id));
                      value = (func_loc, func);
                      kind;
                      static;
                      decorators;
                      comments;
                    }
                  ) ->
                add_method_sig_and_element
                  ~method_loc
                  ~name
                  ~id_loc
                  ~func_loc
                  ~func
                  ~kind
                  ~private_:false
                  ~static
                  ~decorators
                  ~comments
                  ~get_typed_method_key:(fun func_t ->
                    Ast.Expression.Object.Property.Identifier ((id_loc, func_t), id)
                )
              (* fields *)
              | Body.PrivateField
                  ( loc,
                    {
                      PrivateField.key = (id_loc, { Ast.PrivateName.name; comments = _ }) as key;
                      annot;
                      value;
                      static;
                      variance;
                      comments;
                    }
                  ) ->
                Type_inference_hooks_js.dispatch_class_member_decl_hook cx self static name id_loc;
                let reason = mk_reason (RProperty (Some (OrdinaryName name))) loc in
                let polarity = Anno.polarity variance in
                let (field, annot_t, annot_ast, get_value) =
                  mk_field cx tparams_map_with_this reason annot value
                in
                let get_element () =
                  Body.PrivateField
                    ( (loc, annot_t),
                      {
                        PrivateField.key;
                        annot = annot_ast;
                        value = get_value ();
                        static;
                        variance;
                        comments;
                      }
                    )
                in
                let public_seen_names' =
                  check_duplicate_name
                    public_seen_names
                    id_loc
                    name
                    ~static
                    ~private_:true
                    Class_Member_Field
                in
                ( add_private_field ~static name id_loc polarity field c,
                  get_element :: rev_elements,
                  public_seen_names'
                )
              | Body.Property
                  ( loc,
                    {
                      Property.key =
                        Ast.Expression.Object.Property.Identifier
                          (id_loc, ({ Ast.Identifier.name; comments = _ } as id));
                      annot;
                      value;
                      static;
                      variance;
                      comments;
                    }
                  ) ->
                Type_inference_hooks_js.dispatch_class_member_decl_hook cx self static name id_loc;
                let reason = mk_reason (RProperty (Some (OrdinaryName name))) loc in
                let polarity = Anno.polarity variance in
                let (field, annot_t, annot, get_value) =
                  mk_field cx tparams_map_with_this reason annot value
                in
                let get_element () =
                  Body.Property
                    ( (loc, annot_t),
                      {
                        Property.key =
                          Ast.Expression.Object.Property.Identifier ((id_loc, annot_t), id);
                        annot;
                        value = get_value ();
                        static;
                        variance;
                        comments;
                      }
                    )
                in
                let public_seen_names' =
                  check_duplicate_name
                    public_seen_names
                    id_loc
                    name
                    ~static
                    ~private_:false
                    Class_Member_Field
                in
                ( add_field ~static name id_loc polarity field c,
                  get_element :: rev_elements,
                  public_seen_names'
                )
              (* literal LHS *)
              | ( Body.Method (loc, { Method.key = Ast.Expression.Object.Property.Literal _; _ })
                | Body.Property (loc, { Property.key = Ast.Expression.Object.Property.Literal _; _ })
                  ) as elem ->
                Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, ClassPropertyLiteral));
                ( c,
                  (fun () -> Tast_utils.error_mapper#class_element elem) :: rev_elements,
                  public_seen_names
                )
              (* computed LHS *)
              | ( Body.Method (loc, { Method.key = Ast.Expression.Object.Property.Computed _; _ })
                | Body.Property
                    (loc, { Property.key = Ast.Expression.Object.Property.Computed _; _ }) ) as elem
                ->
                Flow.add_output cx Error_message.(EUnsupportedSyntax (loc, ClassPropertyComputed));
                ( c,
                  (fun () -> Tast_utils.error_mapper#class_element elem) :: rev_elements,
                  public_seen_names
                )
            )
            (class_sig, [], empty_seen_names)
            elements
        in
        let elements = List.rev rev_elements in
        ( class_sig,
          fun class_t ->
            {
              Ast.Class.id = Base.Option.map ~f:(fun (loc, name) -> ((loc, class_t), name)) id;
              body =
                ( body_loc,
                  {
                    Ast.Class.Body.body = Base.List.map ~f:(fun f -> f ()) elements;
                    comments = body_comments;
                  }
                );
              tparams = tparams_ast;
              extends = extends_ast;
              implements = implements_ast;
              class_decorators = class_decorators_ast;
              comments;
            }
        )
    )

  and mk_func_sig =
    let predicate_function_kind cx loc params =
      let open Error_message in
      let (_, { Ast.Function.Params.params; rest; this_ = _; comments = _ }) = params in
      let kind = Func_sig.Predicate in
      let kind =
        List.fold_left
          (fun kind (_, param) ->
            let open Flow_ast.Function.Param in
            match param.argument with
            | (ploc, Flow_ast.Pattern.Object _)
            | (ploc, Flow_ast.Pattern.Array _)
            | (ploc, Flow_ast.Pattern.Expression _) ->
              let reason = mk_reason RDestructuring ploc in
              Flow_js.add_output cx (EUnsupportedSyntax (loc, PredicateInvalidParameter reason));
              Func_sig.Ordinary
            | (_, Flow_ast.Pattern.Identifier _) -> kind)
          kind
          params
      in
      match rest with
      | Some (rloc, { Flow_ast.Function.RestParam.argument; comments = _ }) ->
        let desc = Reason.code_desc_of_pattern argument in
        let reason = mk_reason (RRestParameter (Some desc)) rloc in
        Flow_js.add_output cx (EUnsupportedSyntax (loc, PredicateInvalidParameter reason));
        Func_sig.Ordinary
      | None -> kind
    in
    let function_kind cx ~async ~generator ~predicate ~params =
      let open Func_sig in
      let open Ast.Type.Predicate in
      match (async, generator, predicate) with
      | (true, true, None) -> AsyncGenerator
      | (true, false, None) -> Async
      | (false, true, None) -> Generator
      | (false, false, None) -> Ordinary
      | (false, false, Some (loc, { kind = Ast.Type.Predicate.Inferred | Declared _; comments = _ }))
        ->
        predicate_function_kind cx loc params
      | (_, _, _) -> Utils_js.assert_false ""(async || generator) && pred""
    in
    let id_param cx tparams_map id mk_reason =
      let { Ast.Pattern.Identifier.name; annot; optional } = id in
      let (id_loc, ({ Ast.Identifier.name; comments = _ } as id)) = name in
      let reason = mk_reason name in
      let (annotated_or_inferred, annot) = Anno.mk_type_annotation cx tparams_map reason annot in
      let t = type_t_of_annotated_or_inferred annotated_or_inferred in
      let name = ((id_loc, t), id) in
      (t, { Ast.Pattern.Identifier.name; annot; optional })
    in
    let mk_param cx ~hint tparams_map param =
      let (loc, { Ast.Function.Param.argument = (ploc, patt); default }) = param in
      let has_param_anno =
        match Destructuring.type_of_pattern (ploc, patt) with
        | Ast.Type.Missing _ -> false
        | Ast.Type.Available _ -> true
      in
      let (t, pattern) =
        match patt with
        | Ast.Pattern.Identifier id ->
          let (t, id) =
            id_param cx tparams_map id (fun name -> mk_reason (RParameter (Some name)) ploc)
          in
          (t, Func_stmt_config.Id id)
        | Ast.Pattern.Object { Ast.Pattern.Object.annot; properties; comments } ->
          let reason = mk_reason RDestructuring ploc in
          let (annotated_or_inferred, annot) =
            Anno.mk_type_annotation cx tparams_map reason annot
          in
          let t = type_t_of_annotated_or_inferred annotated_or_inferred in
          (t, Func_stmt_config.Object { annot; properties; comments })
        | Ast.Pattern.Array { Ast.Pattern.Array.annot; elements; comments } ->
          let reason = mk_reason RDestructuring ploc in
          let (annotated_or_inferred, annot) =
            Anno.mk_type_annotation cx tparams_map reason annot
          in
          let t = type_t_of_annotated_or_inferred annotated_or_inferred in
          (t, Func_stmt_config.Array { annot; elements; comments })
        | Ast.Pattern.Expression _ -> failwith ""unexpected expression pattern in param""
      in
      RequireAnnot.require_annot_on_pattern cx ~hint (reason_of_t t) patt;
      Func_stmt_config.Param { t; loc; ploc; pattern; default; has_anno = has_param_anno }
    in
    let mk_rest cx ~hint tparams_map rest =
      let (loc, { Ast.Function.RestParam.argument = (ploc, patt); comments = _ }) = rest in
      let has_param_anno =
        match Destructuring.type_of_pattern (ploc, patt) with
        | Ast.Type.Missing _ -> false
        | Ast.Type.Available _ -> true
      in
      match patt with
      | Ast.Pattern.Identifier id ->
        let (t, id) =
          id_param cx tparams_map id (fun name -> mk_reason (RRestParameter (Some name)) ploc)
        in
        RequireAnnot.require_annot_on_pattern cx ~hint (reason_of_t t) patt;
        Ok (Func_stmt_config.Rest { t; loc; ploc; id; has_anno = has_param_anno })
      | Ast.Pattern.Object _
      | Ast.Pattern.Array _
      | Ast.Pattern.Expression _ ->
        (* TODO: this should be a parse error, unrepresentable AST *)
        Error Error_message.(EInternal (ploc, RestParameterNotIdentifierPattern))
    in
    let mk_this
        cx tparams_map (loc, { Ast.Function.ThisParam.annot = (annot_loc, annot); comments = _ }) =
      let (((_, t), _) as annot) = Anno.convert cx tparams_map annot in
      Func_stmt_config.This { t; loc; annot = (annot_loc, annot) }
    in
    let require_this_annot cx func param_loc = function
      | None when Context.enforce_this_annotations cx ->
        if
          Signature_utils.This_finder.found_this_in_body_or_params
            func.Ast.Function.body
            func.Ast.Function.params
        then
          RequireAnnot.add_missing_annotation_error
            cx
            (mk_reason (RImplicitThis (RFunction RNormal)) param_loc)
      | _ -> ()
    in
    let mk_params cx ~hint tparams_map (loc, { Ast.Function.Params.params; rest; this_; comments })
        =
      let fparams =
        Func_stmt_params.empty (fun params rest this_ ->
            Some (loc, { Ast.Function.Params.params; rest; this_; comments })
        )
      in
      let fparams =
        List.fold_left
          (fun acc param ->
            Func_stmt_params.add_param
              (mk_param cx ~hint:(hint_decompose_opt_todo hint) tparams_map param)
              acc)
          fparams
          params
      in
      let fparams =
        Base.Option.fold
          ~f:(fun acc rest ->
            match mk_rest cx ~hint:(hint_decompose_opt_todo hint) tparams_map rest with
            | Ok rest -> Func_stmt_params.add_rest rest acc
            | Error err ->
              Flow_js.add_output cx err;
              acc)
          ~init:fparams
          rest
      in
      let fparams =
        Base.Option.fold
          ~f:(fun acc this -> Func_stmt_params.add_this (mk_this cx tparams_map this) acc)
          ~init:fparams
          this_
      in
      fparams
    in
    let free_bound_ts cx t =
      let finder =
        object (_self)
          inherit [Loc_collections.ALocSet.t] Type_visitor.t as super

          val mutable tparams : Subst_name.t list = []

          method! type_ cx pole acc t =
            match t with
            | DefT (_, _, PolyT { tparams = tps; _ }) ->
              let old_tparams = tparams in
              Nel.iter (fun tp -> tparams <- tp.name :: tparams) tps;
              let acc = super#type_ cx pole acc t in
              tparams <- old_tparams;
              acc
            | GenericT { name; _ } when not (List.exists (fun x -> x = name) tparams) ->
              Loc_collections.ALocSet.add (TypeUtil.loc_of_t t) acc
            | _ -> super#type_ cx pole acc t
        end
      in
      finder#type_ cx Polarity.Neutral Loc_collections.ALocSet.empty t
    in
    fun cx ~hint ~needs_this_param tparams_map reason func ->
      let {
        Ast.Function.tparams;
        return;
        body;
        predicate;
        params;
        id;
        async;
        generator;
        sig_loc = _;
        comments = _;
      } =
        func
      in
      let loc = aloc_of_reason reason in
      let kind = function_kind cx ~async ~generator ~predicate ~params in
      let (tparams, tparams_map, tparams_ast) =
        Anno.mk_type_param_declarations cx ~tparams_map tparams
      in
      let fparams = mk_params cx ~hint tparams_map params in
      if needs_this_param then
        require_this_annot cx func (fst params) Ast.Function.Params.((snd params).this_);
      let body = Some body in
      let ret_reason = mk_reason RReturn (Func_sig.return_loc func) in
      let (return_annotated_or_inferred, return) =
        let has_nonvoid_return = might_have_nonvoid_return loc func in
        let definitely_returns_void = kind = Func_sig.Ordinary && not has_nonvoid_return in
        Anno.mk_return_type_annotation cx tparams_map ret_reason ~definitely_returns_void return
      in
      let (return_annotated_or_inferred, predicate) =
        let open Ast.Type.Predicate in
        match predicate with
        | None -> (return_annotated_or_inferred, None)
        | Some ((_, { kind = Ast.Type.Predicate.Inferred; comments = _ }) as pred) ->
          (* Predicate Functions
           *
           * function f(x: S): [T] %checks { return e; }
           *
           * The return type we assign to this function will be used for refining the
           * input x. The type annotation T may not have this ability (if it's an
           * annotation). Instead we introduce a fresh type T'. T' will receive lower
           * bounds from the return expression e, but is also checked against the
           * return type (annotation) T:
           *
           *   OpenPred(typeof e, preds) ~> T'
           *   T' ~> T
           *
           * The function signature will be
           *
           *  (x: S) => T' (%checks)
           *)
          let bounds =
            free_bound_ts cx (type_t_of_annotated_or_inferred return_annotated_or_inferred)
          in
          if Loc_collections.ALocSet.is_empty bounds then
            let return_annotated_or_inferred' =
              map_annotated_or_inferred
                (fun return_t -> Tvar.mk_where cx reason (fun t -> Flow.flow_t cx (t, return_t)))
                return_annotated_or_inferred
            in
            (return_annotated_or_inferred', Some pred)
          else
            (* If T is a polymorphic type P<X>, this approach can lead to some
             * complications. The 2nd constraint from above would become
             *
             *   T' ~> P<X>
             *
             * which was previously ill-formed since it was outside a check_with_generics
             * call (led to Not_expect_bounds exception). We disallow this case
             * and instead propagate the original return type T; with the removal of
             * check_with_generics this may no longer be necessary.
             *)
            let () =
              Loc_collections.ALocSet.iter
                (fun loc ->
                  Flow_js.add_output
                    cx
                    Error_message.(EUnsupportedSyntax (loc, PredicateFunctionAbstractReturnType)))
                bounds
            in
            (return_annotated_or_inferred, Some (Tast_utils.error_mapper#type_predicate pred))
        | Some ((loc, { kind = Declared _; comments = _ }) as pred) ->
          let (annotated_or_inferred, _) =
            Anno.mk_type_annotation cx tparams_map ret_reason (Ast.Type.Missing loc)
          in
          Flow_js.add_output
            cx
            Error_message.(EUnsupportedSyntax (loc, PredicateDeclarationForImplementation));
          (annotated_or_inferred, Some (Tast_utils.error_mapper#type_predicate pred))
      in
      let return_t =
        mk_inference_target_with_annots return_annotated_or_inferred (hint_decompose_opt_todo hint)
      in
      ( { Func_stmt_sig.reason; kind; tparams; tparams_map; fparams; body; return_t },
        fun params body fun_type ->
          {
            func with
            Ast.Function.id =
              Base.Option.map ~f:(fun (id_loc, name) -> ((id_loc, fun_type), name)) id;
            params;
            body;
            predicate;
            return;
            tparams = tparams_ast;
          }
      )

  (* Given a function declaration and types for `this` and `super`, extract a
     signature consisting of type parameters, parameter types, parameter names,
     and return type, check the body against that signature by adding `this`
     and super` to the environment, and return the signature. *)
  and function_decl cx ~hint ~needs_this_param reason func this_recipe super =
    let (func_sig, reconstruct_func) =
      mk_func_sig cx ~hint ~needs_this_param Subst_name.Map.empty reason func
    in
    let save_return = Abnormal.clear_saved Abnormal.Return in
    let save_throw = Abnormal.clear_saved Abnormal.Throw in
    let (this_t, params_ast, body_ast, _) = Func_stmt_sig.toplevels cx this_recipe super func_sig in
    ignore (Abnormal.swap_saved Abnormal.Return save_return);
    ignore (Abnormal.swap_saved Abnormal.Throw save_throw);
    let fun_type = Func_stmt_sig.functiontype cx this_t func_sig in
    (fun_type, reconstruct_func (Base.Option.value_exn params_ast) (Base.Option.value_exn body_ast))

  (* Switch back to the declared type for an internal name. *)
  and define_internal cx reason x =
    let ix = internal_name x in
    let loc = aloc_of_reason reason in
    Env.declare_let cx ix loc;
    let t = Env.get_var_declared_type cx ix loc in
    Env.init_let cx ~use_op:unknown_use ix ~has_anno:false t loc

  (* Process a function declaration, returning a (polymorphic) function type. *)
  and mk_function_declaration cx ~general reason func =
    mk_function cx ~hint:None ~general ~needs_this_param:true reason func

  (* Process a function expression, returning a (polymorphic) function type. *)
  and mk_function_expression cx ~hint ~general ~needs_this_param reason func =
    mk_function cx ~hint ~needs_this_param ~general reason func

  (* Internal helper function. Use `mk_function_declaration` and `mk_function_expression` instead. *)
  and mk_function
      cx ~hint ~needs_this_param ~general reason ({ Ast.Function.id = func_id; _ } as func) =
    let node_cache = Context.node_cache cx in
    let cached =
      Base.Option.value_map
        ~default:None
        ~f:(fun (id_loc, _) -> Node_cache.get_function node_cache id_loc)
        func_id
    in
    match cached with
    | Some cached ->
      Debug_js.Verbose.print_if_verbose_lazy
        cx
        (lazy [spf ""Function cache hit at %s"" (ALoc.debug_to_string (aloc_of_reason reason))]);
      cached
    | None ->
      let loc = aloc_of_reason reason in

      (* Normally, functions do not have access to super. *)
      let super =
        let t = ObjProtoT (mk_reason RNoSuper loc) in
        Scope.Entry.new_let (Inferred t) ~provider:t ~loc ~state:Scope.State.Initialized
      in
      (* The default behavior of `this` still depends on how it
         was created, so we must provide the recipe based on where `function_decl`
         is invoked. *)
      let this_recipe fparams =
        let default =
          if
            Signature_utils.This_finder.found_this_in_body_or_params
              func.Ast.Function.body
              func.Ast.Function.params
          then
            Tvar.mk cx (mk_reason RThis loc)
          else
            Type.implicit_mixed_this reason
        in
        (* If `this` is a bound type variable, we cannot create the type here, and
           instead must wait until `check_with_generics` to instantiate the type.
           However, the default behavior of `this` still depends on how it
           was created, so we must provide the recipe based on where `function_decl`
           is invoked. *)
        let t =
          match Func_stmt_params.this fparams with
          | Some t -> Inferred t
          | None -> Annotated default
        in
        let this =
          Scope.Entry.new_let
            t
            ~provider:(type_t_of_annotated_or_inferred t)
            ~loc
            ~state:Scope.State.Initialized
        in
        (type_t_of_annotated_or_inferred t, this)
      in
      let (fun_type, reconstruct_ast) =
        function_decl cx ~needs_this_param ~hint reason func this_recipe super
      in
      (fun_type, reconstruct_ast general)

  (* Process an arrow function, returning a (polymorphic) function type. *)
  and mk_arrow cx ~hint reason func =
    let loc = aloc_of_reason reason in
    let (_, super) = Env.find_entry cx (internal_name ""super"") loc in
    let this_recipe _ =
      let (_, this) = Env.find_entry cx (internal_name ""this"") loc in
      (* Do not expose the type of `this` in the function's type. This call to
         function_decl has already done the necessary checking of `this` in
         the body of the function. Now we want to avoid re-binding `this` to
         objects through which the function may be called. *)
      (dummy_this loc, this)
    in
    let (fun_type, reconstruct_ast) =
      function_decl cx ~needs_this_param:false ~hint reason func this_recipe super
    in
    (fun_type, reconstruct_ast fun_type)

  and declare_function_to_function_declaration cx =
    let add_output l =
      Flow.add_output
        cx
        (match l with
        | Declare_function_utils.PredicateDeclarationWithoutExpression loc ->
          Error_message.(EUnsupportedSyntax (loc, PredicateDeclarationWithoutExpression))
        | Declare_function_utils.PredicateDeclarationAnonymousParameters loc ->
          Error_message.(EUnsupportedSyntax (loc, PredicateDeclarationAnonymousParameters)))
    in
    let copy_t (_, t) l = (l, t) in
    let loc_of_tloc = fst in
    Declare_function_utils.declare_function_to_function_declaration ~add_output ~copy_t ~loc_of_tloc

  and check_default_pattern cx left right =
    let left_loc = fst left in
    let right_loc = fst right in
    let update_excuses update_fun =
      let exists_excuses = Context.exists_excuses cx in
      let exists_excuse =
        Loc_collections.ALocMap.find_opt left_loc exists_excuses
        |> Base.Option.value ~default:ExistsCheck.empty
        |> update_fun
      in
      let exists_excuses = Loc_collections.ALocMap.add left_loc exists_excuse exists_excuses in
      Context.set_exists_excuses cx exists_excuses
    in
    match snd right with
    | Ast.Expression.Literal literal ->
      ExistsCheck.(
        begin
          match literal.Ast.Literal.value with
          | Ast.Literal.String """" ->
            update_excuses (fun excuse -> { excuse with string_loc = Some right_loc })
          | Ast.Literal.Boolean false ->
            update_excuses (fun excuse -> { excuse with bool_loc = Some right_loc })
          | Ast.Literal.Number 0. ->
            update_excuses (fun excuse -> { excuse with number_loc = Some right_loc })
          (* There's no valid default value for mixed to create an excuse. *)
          | _ -> ()
        end
      )
    | _ -> ()

  and post_assignment_havoc cx ~private_ name exp orig_t t =
    (* types involved in the assignment are computed
       in pre-havoc environment. it's the assignment itself
       which clears refis *)
    Env.havoc_heap_refinements_with_propname ~private_ name;

    (* add type refinement if LHS is a pattern we handle *)
    match Refinement.key ~allow_optional:false exp with
    | Some key ->
      (* NOTE: currently, we allow property refinements to propagate
         even if they may turn out to be invalid w.r.t. the
         underlying object type. If invalid, of course, they produce
         errors, but in the future we may want to prevent the
         invalid types from flowing downstream as well.
         Doing so would require that we defer any subsequent flow
         calls that are sensitive to the refined type until the
         object and refinement types - `o` and `t` here - are
         fully resolved.
      *)
      Env.(set_expr cx key (fst exp) ~refined:t ~original:orig_t)
    | None -> ()

  and mk_initial_arguments_reason =
    let open Ast.Expression in
    let rec helper = function
      | [] -> []
      | Expression x :: args -> mk_expression_reason x :: helper args
      | Spread _ :: _ -> []
    in
    (fun (_args_loc, { Ast.Expression.ArgList.arguments; comments = _ }) -> helper arguments)

  and is_valid_enum_member_name name =
    (not @@ Base.String.is_empty name) && (not @@ Base.Char.is_lowercase name.[0])

  and enum_exhaustive_check_of_switch_cases cases_ast =
    let open Flow_ast in
    let open Flow_ast.Statement.Switch in
    let exhaustive_check =
      List.fold_left
        (fun acc -> function
          | ( _,
              {
                Case.test =
                  Some
                    ( (case_test_loc, _),
                      Expression.Member
                        Expression.Member.
                          {
                            _object = ((_, obj_t), _);
                            property = PropertyIdentifier (_, { Identifier.name; _ });
                            _;
                          }
                    );
                _;
              }
            )
            when is_valid_enum_member_name name ->
            (match acc with
            | EnumExhaustiveCheckInvalid _ -> acc
            | EnumExhaustiveCheckPossiblyValid { tool; possible_checks; checks; default_case } ->
              let reason = mk_reason (RCustom ""case"") case_test_loc in
              let possible_check = (obj_t, EnumCheck { reason; member_name = name }) in
              EnumExhaustiveCheckPossiblyValid
                { tool; possible_checks = possible_check :: possible_checks; checks; default_case })
          | (default_case_loc, { Case.test = None; _ }) ->
            (match acc with
            | EnumExhaustiveCheckInvalid _ -> acc
            | EnumExhaustiveCheckPossiblyValid { tool; possible_checks; checks; default_case = _ }
              ->
              EnumExhaustiveCheckPossiblyValid
                {
                  tool;
                  possible_checks;
                  checks;
                  default_case = Some (mk_reason (RCustom ""default case"") default_case_loc);
                })
          | (_, { Case.test = Some ((case_test_loc, _), _); _ }) ->
            let case_reason = Reason.mk_reason (Reason.RCustom ""case"") case_test_loc in
            (match acc with
            | EnumExhaustiveCheckInvalid invalid_checks ->
              EnumExhaustiveCheckInvalid (case_reason :: invalid_checks)
            | EnumExhaustiveCheckPossiblyValid _ -> EnumExhaustiveCheckInvalid [case_reason]))
        (EnumExhaustiveCheckPossiblyValid
           {
             tool = EnumResolveDiscriminant;
             possible_checks = [];
             checks = [];
             default_case = None;
           }
        )
        cases_ast
    in
    match exhaustive_check with
    | EnumExhaustiveCheckInvalid invalid_checks ->
      EnumExhaustiveCheckInvalid (List.rev invalid_checks)
    | EnumExhaustiveCheckPossiblyValid _ ->
      (* As we process `possible_checks` into `checks`, we reverse the list back
       * into the correct order. *)
      exhaustive_check

  and mk_enum cx ~enum_reason name_loc body =
    let open Ast.Statement.EnumDeclaration in
    let defaulted_members =
      Base.List.fold
        ~init:SMap.empty
        ~f:(fun acc (member_loc, { DefaultedMember.id = (_, { Ast.Identifier.name; _ }) }) ->
          SMap.add name member_loc acc
      )
    in
    let enum_id = Context.make_aloc_id cx name_loc in
    let (representation_t, members, has_unknown_members) =
      match body with
      | (_, BooleanBody { BooleanBody.members; has_unknown_members; _ }) ->
        let reason = mk_reason (REnumRepresentation RBoolean) (aloc_of_reason enum_reason) in
        let (members, bool_type, _) =
          Base.List.fold_left
            ~f:
              (fun (members_map, bool_type, seen_values)
                   (member_loc, { InitializedMember.id = (_, { Ast.Identifier.name; _ }); init }) ->
              let (init_loc, { Ast.BooleanLiteral.value = init_value; _ }) = init in
              let bool_type =
                match bool_type with
                (* we have seen one value *)
                | None -> Some init_value
                (* we have now seen both values *)
                | Some _ -> None
              in
              let seen_values =
                match BoolMap.find_opt init_value seen_values with
                | Some prev_use_loc ->
                  Flow.add_output
                    cx
                    (Error_message.EEnumMemberDuplicateValue
                       { loc = init_loc; prev_use_loc; enum_reason }
                    );
                  seen_values
                | None -> BoolMap.add init_value member_loc seen_values
              in
              (SMap.add name member_loc members_map, bool_type, seen_values))
            ~init:(SMap.empty, None, BoolMap.empty)
            members
        in
        (DefT (reason, literal_trust (), BoolT bool_type), members, has_unknown_members)
      | (_, NumberBody { NumberBody.members; has_unknown_members; _ }) ->
        let reason = mk_reason (REnumRepresentation RNumber) (aloc_of_reason enum_reason) in
        let (members, num_type, _) =
          Base.List.fold_left
            ~f:
              (fun (members_map, num_type, seen_values)
                   (member_loc, { InitializedMember.id = (_, { Ast.Identifier.name; _ }); init }) ->
              let (init_loc, { Ast.NumberLiteral.value = init_value; _ }) = init in
              let num_type =
                if init_value = 0.0 then
                  AnyLiteral
                else
                  num_type
              in
              let seen_values =
                match NumberMap.find_opt init_value seen_values with
                | Some prev_use_loc ->
                  Flow.add_output
                    cx
                    (Error_message.EEnumMemberDuplicateValue
                       { loc = init_loc; prev_use_loc; enum_reason }
                    );
                  seen_values
                | None -> NumberMap.add init_value member_loc seen_values
              in
              (SMap.add name member_loc members_map, num_type, seen_values))
            ~init:(SMap.empty, Truthy, NumberMap.empty)
            members
        in
        (DefT (reason, literal_trust (), NumT num_type), members, has_unknown_members)
      | ( _,
          StringBody { StringBody.members = StringBody.Initialized members; has_unknown_members; _ }
        ) ->
        let reason = mk_reason (REnumRepresentation RString) (aloc_of_reason enum_reason) in
        let (members, str_type, _) =
          Base.List.fold_left
            ~f:
              (fun (members_map, str_type, seen_values)
                   (member_loc, { InitializedMember.id = (_, { Ast.Identifier.name; _ }); init }) ->
              let (init_loc, { Ast.StringLiteral.value = init_value; _ }) = init in
              let str_type =
                if init_value = """" then
                  AnyLiteral
                else
                  str_type
              in
              let seen_values =
                match SMap.find_opt init_value seen_values with
                | Some prev_use_loc ->
                  Flow.add_output
                    cx
                    (Error_message.EEnumMemberDuplicateValue
                       { loc = init_loc; prev_use_loc; enum_reason }
                    );
                  seen_values
                | None -> SMap.add init_value member_loc seen_values
              in
              (SMap.add name member_loc members_map, str_type, seen_values))
            ~init:(SMap.empty, Truthy, SMap.empty)
            members
        in
        (DefT (reason, literal_trust (), StrT str_type), members, has_unknown_members)
      | (_, StringBody { StringBody.members = StringBody.Defaulted members; has_unknown_members; _ })
        ->
        let reason = mk_reason (REnumRepresentation RString) (aloc_of_reason enum_reason) in
        ( DefT (reason, literal_trust (), StrT Truthy (* Member names can't be the empty string *)),
          defaulted_members members,
          has_unknown_members
        )
      | (_, SymbolBody { SymbolBody.members; has_unknown_members; comments = _ }) ->
        let reason = mk_reason (REnumRepresentation RSymbol) (aloc_of_reason enum_reason) in
        (DefT (reason, literal_trust (), SymbolT), defaulted_members members, has_unknown_members)
    in
    { enum_id; members; representation_t; has_unknown_members }
end
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(* This module describes the representation of lexical environments and defines
   various operations on them, including ""stack"" operations to push/pop scopes,
   and ""lookup"" operations to find, read, and write variables and their
   associated type information. *)

open Utils_js
open Loc_collections
open Type
open TypeUtil
open Reason
open Scope
module Flow = Flow_js

(* lookup modes:

   - ForValue is a lookup from a syntactic value location, i.e. standard
     JS code

   - ForType is a lookup from a syntactic type location, e.g. annotations,
     interface declarations etc.

   - ForTypeof is a lookup from a typeof expression (necessarily in a type
     location)

   Rules:

   1. ForValue lookups give errors if they retrieve type aliases (note: we
      have a single namespace, so any name resolves uniquely to either a
      value or type)

   2. ForValue lookups give errors if they forward reference non-hoisted
      things (lets or consts)

   3. ForType lookups may return values or type aliases, since some values
      also denote types - e.g. a generator function F also denotes the type
      of the objects it creates. Of course many values don't also have a type
      denotation and thus errors in type position. But we don't know the type
      of a symbol during local inference as a rule, so errors of this kind are
      not raised here.

   4. ForTypeof lookups are in fact ForValue lookups, but due to the order in
      which AST traversal takes place, these lookups may legitimately violate
      rule #2, hence the need for a special mode.
*)

module Env : Env_sig.S = struct
  open Env_sig.LookupMode

  (****************)
  (* Environment *)
  (****************)

  type scope = Scope.t

  type t = scope list

  (* the environment is a scope stack, which mutates as an AST is
     traversed. changesets are also managed here, but live in
     a separate Changeset module for dependency reasons.
  *)
  let scopes : t ref = ref []

  (* symbols whose bindings are forcibly prevented from being created,
     initialized, etc. This set is initialized in init_env, and is normally
     empty. It's used to implement library overrides: suppressing a local
     binding to definition D means that any local reference to D will
     register it as a deferred global lookup, which will then be linked
     to the override. See Init_js.load_lib_files.
  *)
  let exclude_symbols : NameUtils.Set.t ref = ref NameUtils.Set.empty

  let set_exclude_symbols syms = exclude_symbols := syms

  let is_excluded name = NameUtils.Set.mem name !exclude_symbols

  (* scopes *)

  (* return the current scope *)
  let peek_scope () = List.hd !scopes

  let in_toplevel_scope () = Scope.is_toplevel (peek_scope ())

  let in_global_scope () = Scope.is_global (peek_scope ())

  (* return current scope stack *)
  let peek_env () = !scopes

  let string_of_env cx env =
    spf ""[ %s ]"" (String.concat "";\n"" (Base.List.map ~f:(Debug_js.string_of_scope cx) env))

  (* return the value of f applied to topmost var scope in a scope list *)
  let rec top_var_scope = function
    | [] -> assert_false ""empty scope list""
    | scope :: scopes ->
      (match scope.kind with
      | VarScope _ -> scope
      | _ -> top_var_scope scopes)

  (* get top var scope of current env *)
  let peek_var_scope () = top_var_scope (peek_env ())

  (* use the passed f to iterate over all scopes *)
  let iter_scopes f = List.iter f !scopes

  (* apply function f to local scopes: the 0 or more
     lex scopes between us and the closest var scope,
     and also that var scope *)
  let iter_local_scopes f =
    let rec loop = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        f scope;
        (match scope.kind with
        | LexScope -> loop scopes
        | _ -> ())
    in
    loop !scopes

  (* clone the given scope stack (snapshots entry maps) *)
  let clone_env scopes = Base.List.map ~f:Scope.clone scopes

  let var_scope_kind () =
    let scope = peek_var_scope () in
    match scope.kind with
    | VarScope k -> k
    | _ -> assert_false ""peek_var_scope returns a VarScope""

  (* true iff scope is var scope with the given kind *)
  let is_func_kind k scope =
    match scope.kind with
    | VarScope func_kind -> func_kind = k
    | _ -> false

  let in_async_scope () =
    match var_scope_kind () with
    | Async
    | AsyncGenerator ->
      true
    | _ -> false

  let in_generator_scope () =
    match var_scope_kind () with
    | Generator
    | AsyncGenerator ->
      true
    | _ -> false

  let in_predicate_scope () = is_func_kind Predicate (peek_var_scope ())

  (* whole env *)

  (* clear environment *)
  let havoc_current_activation () =
    scopes := [];
    Changeset.Global.init ()

  (* push a new var scope into the environment.
     current env state is stored to cx under scope id *)
  (* TODO maintain changelist here too *)
  let push_var_scope scope =
    (match scope.kind with
    | VarScope _ -> ()
    | _ -> assert_false ""push_var_scope on non-var scope"");
    scopes := scope :: !scopes;
    Changeset.Global.push ()

  (* --- *)

  (* pop a var scope from the environment.
     note: may require popping accumulated lex scopes *)
  let pop_var_scope () =
    match !scopes with
    | { kind = VarScope _; _ } :: tail_scopes ->
      scopes := tail_scopes;
      Changeset.Global.pop ()
    | [] -> assert_false ""empty scope list""
    | _ -> assert_false ""top scope is non-var""

  (* push a lex scope but NOT a changeset
     (which is 1-1 with var scopes). *)
  let push_lex_scope () =
    let scope = Scope.fresh_lex () in
    scopes := scope :: !scopes

  let pop_lex_scope () =
    match !scopes with
    | { kind = LexScope; id; _ } :: tail_scopes ->
      (* cull any changelist entries for this scope *)
      ignore (Changeset.Global.filter_scope_changes id);

      (* pop *)
      scopes := tail_scopes
    | [] -> assert_false ""empty scope list""
    | _ -> assert_false ""top scope is non-lex""

  let in_lex_scope f =
    push_lex_scope ();
    let result = f () in
    pop_lex_scope ();
    result

  (* depth of current env *)
  let env_depth () = List.length !scopes

  (* strip the given number of scopes from top of env *)
  let trunc_env =
    let rec trunc = function
      | (0, scopes) -> scopes
      | (_, []) -> assert_false ""trunc_env: scopes underflow""
      | (n, scope :: scopes) ->
        ignore (Changeset.Global.filter_scope_changes scope.id);
        trunc (n - 1, scopes)
    in
    fun depth ->
      let cur = !scopes in
      scopes := trunc (List.length cur - depth, cur)

  (* initialize a new environment (once per module) *)
  let init_env ?(exclude_syms = NameUtils.Set.empty) cx module_scope =
    begin
      if Context.env_option_enabled cx Options.ConstrainWrites then
        let ({ Loc_env.var_info; _ } as env) = Context.environment cx in
        ALocMap.fold
          (fun loc env_entry env ->
            match env_entry with
            | Env_api.AssigningWrite reason
            | Env_api.GlobalWrite reason ->
              let t = Inferred (Tvar.mk cx reason) in
              (* Treat everything as inferred for now for the purposes of annotated vs inferred *)
              Loc_env.initialize env loc t
            | Env_api.NonAssigningWrite -> env)
          var_info.Env_api.env_entries
          env
        |> Context.set_environment cx
    end;

    set_exclude_symbols exclude_syms;
    havoc_current_activation ();
    let global_scope = Scope.fresh ~var_scope_kind:Global () in
    push_var_scope global_scope;
    push_var_scope module_scope

  let save_excluded_symbols () =
    let ex = !exclude_symbols in
    set_exclude_symbols NameUtils.Set.empty;
    ex

  let restore_excluded_symbols ex = set_exclude_symbols ex

  (* replace the current env with the passed one.
     envs must be congruent - we measure length as a quick check,
     with a more thorough check on env merge/copy *)
  let update_env loc new_scopes =
    if List.length new_scopes != List.length (peek_env ()) then
      assert_false
        (spf
           ""update_env %s: unequal length scope lists, old %d new %d ""
           (string_of_aloc loc)
           (List.length new_scopes)
           (List.length (peek_env ()))
        );

    scopes := new_scopes

  (* end of basic env API *)

  let global_any =
    [
      OrdinaryName ""eval"";
      OrdinaryName ""arguments"";
      (* For `switch` statements not in a function body, so we don't get an error. *)
      internal_name ""maybe_exhaustively_checked"";
    ]

  let global_lexicals = [internal_name ""super""; internal_name ""this""]

  (* any names that haven't been resolved in upper scopes
     wind up here. after handling special names, we add a Var
     binding to the local scope, and register a lookup with
     the global builtin type, to be resolved later.

     Of course, the globals being referred to may not be vars:
     they may instead be consts or type aliases. Currently we
     have no process for checking the use of a global binding
     against the kind of binding it turns out to be: this global
     scope is simply a proxy; resolution takes place as a result
     of the GetPropT types created in the call to Flow.get_builtin.

     This means that we have some false negatives, currently.
     Errors that go unreported currently include:
     - type aliases referred to from value positions
     - global consts assigned to locally
     The first is especially problematic, since it will actually
     cause a runtime error.

     The least complex solution to this will be to process libs
     eagerly, and save the actual scope to check against here
     when doing local checking of modules. Alternatively, we
     would have to record in the GetPropT (or an enrichment) enough
     information about what uses were made of the reference to
     flag such errors on the current deferred basis.
     tests/global_ref tracks this issue.
  *)
  let cache_global cx name ?desc loc global_scope =
    let t =
      if List.mem name global_any then
        AnyT.at AnnotatedAny loc
      else if List.mem name global_lexicals then
        ObjProtoT (mk_reason (RCustom ""global object"") loc)
      else
        let desc =
          match desc with
          | Some desc -> desc
          | None -> RIdentifier name
        in
        let reason = mk_reason desc loc in
        Flow.get_builtin cx name reason
    in
    let entry = Entry.new_var (Inferred t) ~loc ~provider:t ~state:State.Initialized in
    Scope.add_entry name entry global_scope;
    (global_scope, entry)

  let local_scope_entry_exists _ _ name =
    let name = OrdinaryName name in
    let rec loop = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        (match Scope.get_entry name scope with
        | Some _ -> true
        | None ->
          (match scopes with
          | [] -> false
          | _ -> loop scopes))
    in
    loop !scopes

  (* Look for scope that holds binding for a given name. If found,
     return scope and entry. Note that anything we don't resolve
     otherwise, we add to the global scope after generating a
     deferred lookup, which may fail later. *)
  let find_entry cx name ?desc loc =
    let rec loop = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        (match Scope.get_entry name scope with
        | Some entry -> (scope, entry)
        | None ->
          (* keep looking until we're at the global scope *)
          (match scopes with
          | [] -> cache_global cx name ?desc loc scope
          | _ -> loop scopes))
    in
    loop !scopes

  let get_class_entries () =
    let rec loop class_bindings = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        (match Scope.get_entry (internal_name ""class"") scope with
        | Some entry -> loop (entry :: class_bindings) scopes
        | None ->
          (* keep looking until we're at the global scope *)
          (match scopes with
          | [] -> class_bindings
          | _ -> loop class_bindings scopes))
    in
    let class_bindings = loop [] !scopes in
    let to_class_record = function
      | Entry.Class c -> c
      | _ -> assert_false ""Internal Error: Non-class binding stored with .class""
    in
    Base.List.map ~f:to_class_record class_bindings

  (* Search for the scope which binds the given name, through the
     topmost LexScopes and up to the first VarScope. If the entry
     is not found, return the VarScope where we terminated. *)
  let find_entry_in_var_scope name =
    let rec loop = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        (match (Scope.get_entry name scope, scope.kind) with
        | (Some entry, _) -> (scope, Some entry)
        | (None, VarScope _) -> (scope, None)
        | (None, LexScope) -> loop scopes)
    in
    loop !scopes

  (* Search for the scope which holds the given refinement, through
     the topmost LexScopes and up to the first VarScope. If the
     entry is not found, return None. *)
  let find_refi_in_var_scope key =
    let rec loop = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        (match (Scope.get_refi key scope, scope.kind) with
        | (Some refi, _) -> Some (scope, refi)
        | (None, VarScope _) -> None
        | (None, LexScope) -> loop scopes)
    in
    loop !scopes

  (* helpers *)

  let valid_declaration_check cx name loc =
    let { Loc_env.var_info = { Env_api.scopes = info; ssa_values = values; providers; _ }; _ } =
      Context.environment cx
    in
    let error null_write =
      let null_write =
        Base.Option.map
          ~f:(fun null_loc -> Error_message.{ null_loc; initialized = ALoc.equal loc null_loc })
          null_write
      in
      Flow.add_output
        cx
        Error_message.(
          EInvalidDeclaration { declaration = mk_reason (RIdentifier name) loc; null_write }
        )
    in
    match Invalidation_api.declaration_validity info values providers loc with
    | Invalidation_api.Valid -> ()
    | Invalidation_api.NotWritten -> error None
    | Invalidation_api.NullWritten null_loc -> error (Some null_loc)

  let promote_non_const cx name loc spec =
    if Reason.is_internal_name name then
      (None, spec)
    else
      let { Loc_env.var_info = { Env_api.scopes = info; ssa_values = values; _ }; _ } =
        Context.environment cx
      in
      valid_declaration_check cx name loc;
      if spec <> Entry.ConstLike && Invalidation_api.is_const_like info values loc then
        (None, Entry.ConstLike)
      else if spec <> Entry.NotWrittenByClosure then
        let writes_by_closure = Invalidation_api.written_by_closure info values loc in
        if ALocSet.is_empty writes_by_closure then
          (None, Entry.NotWrittenByClosure)
        else
          (Some writes_by_closure, spec)
      else
        (None, spec)

  let mk_havoc cx name loc general spec =
    let providers =
      if Context.env_option_enabled cx Options.ConstrainWrites then
        let ({ Loc_env.var_info = { Env_api.providers; _ }; _ } as env) = Context.environment cx in
        let providers =
          Env_api.Provider_api.providers_of_def providers loc
          |> Base.Option.value_map ~f:snd ~default:[]
          |> Base.List.map
               ~f:
                 (Fn.compose
                    (fun loc -> Base.Option.map ~f:(fun t -> (loc, t)) (Loc_env.find_write env loc))
                    Reason.aloc_of_reason
                 )
          |> Base.Option.all
        in
        match providers with
        | None -> []
        | Some providers -> providers
      else
        []
    in

    let (writes_by_closure_opt, spec') = promote_non_const cx name loc spec in
    let closure_writes =
      match writes_by_closure_opt with
      | Some writes_by_closure ->
        let writes_by_closure_t =
          Tvar.mk_where cx (mk_reason (RIdentifier name) loc) (fun tvar ->
              Flow.flow_t cx (tvar, general)
          )
        in
        let writes_by_closure_provider =
          if
            ALocSet.for_all
              (Base.List.mem ~equal:ALoc.equal (Base.List.map ~f:fst providers))
              writes_by_closure
          then
            let writes_by_closure_providers =
              Base.List.filter_map
                ~f:(fun (loc, t) ->
                  if ALocSet.mem loc writes_by_closure then
                    Some t
                  else
                    None)
                providers
            in
            match writes_by_closure_providers with
            | [] -> None
            | [t] -> Some t
            | t1 :: t2 :: ts -> Some (UnionT (mk_reason (RType name) loc, UnionRep.make t1 t2 ts))
          else
            None
        in

        Some (writes_by_closure, writes_by_closure_t, writes_by_closure_provider)
      | _ -> None
    in
    let provider =
      if Context.env_option_enabled cx Options.ConstrainWrites then
        match providers with
        | [] -> VoidT.at loc (bogus_trust ())
        | [(_, t)] -> t
        | (_, t1) :: (_, t2) :: ts ->
          UnionT (mk_reason (RType name) loc, UnionRep.make t1 t2 (Base.List.map ~f:snd ts))
      else
        general
    in
    (spec', closure_writes, provider)

  let binding_error msg cx name entry loc =
    Flow.add_output cx (Error_message.EBindingError (msg, loc, name, Entry.entry_loc entry))

  let already_bound_error = binding_error Error_message.ENameAlreadyBound

  let is_provider cx id_loc =
    let { Loc_env.var_info = { Env_api.providers; _ }; _ } = Context.environment cx in
    Env_api.Provider_api.is_provider providers id_loc

  let install_provider cx t name loc =
    match name with
    | OrdinaryName _name when Context.env_option_enabled cx Options.ConstrainWrites ->
      let ({ Loc_env.var_info = { Env_api.providers; _ }; _ } as env) = Context.environment cx in
      if Env_api.Provider_api.is_provider providers loc then
        let t' = Loc_env.find_write env loc in
        Base.Option.iter ~f:(fun t' -> Flow_js.flow_t cx (t, t')) t'
    | _ -> ()

  let get_provider cx name loc =
    let ({ Loc_env.var_info = { Env_api.providers; _ }; _ } as env) = Context.environment cx in
    let (provider_state, provider_locs) =
      Base.Option.value
        ~default:(Find_providers.UninitializedVar, [])
        (Env_api.Provider_api.providers_of_def providers loc)
    in
    let fully_initialized = Provider_api.is_provider_state_fully_initialized provider_state in
    let providers =
      Base.List.map ~f:(Fn.compose (Loc_env.find_write env) Reason.aloc_of_reason) provider_locs
      |> Base.Option.all
    in
    let provider =
      match providers with
      | None
        (* We can have no providers when the only writes to a variable are in unreachable code *)
      | Some [] ->
        (* If we find an entry for the providers, but none that actually exist, its because this variable
           was never assigned to. We treat this as undefined. We handle erroring on
           these cases using a different approach (the error should be at the declaration,
           not the assignment). *)
        None
      | Some [t] -> Some t
      | Some (t1 :: t2 :: ts) ->
        Some (UnionT (mk_reason (RIdentifier name) loc, UnionRep.make t1 t2 ts))
    in
    (fully_initialized, provider, provider_locs)

  let constrain_by_provider cx ~use_op t name loc =
    match name with
    | OrdinaryName ord_name when Context.env_option_enabled cx Options.ConstrainWrites ->
      let { Loc_env.var_info = { Env_api.providers; scopes; _ }; _ } = Context.environment cx in
      if not @@ Env_api.Provider_api.is_provider providers loc then
        let (fully_initialized, provider, provider_locs) = get_provider cx name loc in
        if fully_initialized then
          Base.Option.iter provider ~f:(fun provider ->
              match Scope_api.With_ALoc.(def_of_use_opt scopes loc) with
              | Some { Scope_api.With_ALoc.Def.locs = (declaration, _); _ } ->
                let use_op =
                  Frame
                    ( ConstrainedAssignment
                        { name = ord_name; declaration; providers = provider_locs },
                      use_op
                    )
                in
                Context.add_constrained_write cx (t, UseT (use_op, provider))
              | None ->
                (* If there isn't a declaration for the variable, then it's a global, and we don't need to constrain it *)
                ()
          )
    | _ -> ()

  let can_shadow cx name prev loc =
    Entry.(
      function
      (* vars can shadow other vars *)
      | (Var _, Var _) -> true
      (* nonpredicate declared functions can shadow each other, and any declared function can be shadowed by a function *)
      | (Let (FunctionBinding, _), Let (DeclaredFunctionBinding _, _))
      | ( Let (DeclaredFunctionBinding { predicate = false }, _),
          Let (DeclaredFunctionBinding { predicate = false }, _)
        ) ->
        true
      (* declared functions can't shadow other things *)
      | (Let (DeclaredFunctionBinding _, _), (Var _ | Let (FunctionBinding, _))) -> false
      (* In JS, funcs/vars can shadow other funcs/vars -- only in var scope. However, we want to
         ban this pattern in Flow, so we raise an already_bound_error BUT don't abort the binding
         so that we can still check downstream things. *)
      | ( (Var _ | Let ((FunctionBinding | DeclaredFunctionBinding _), _)),
          (Var _ | Let ((FunctionBinding | DeclaredFunctionBinding _), _))
        ) ->
        already_bound_error cx name prev loc;
        true
      (* vars can shadow function params, but we should raise an error if they are constlike params *)
      | (Var _, Let (ParamBinding, _)) -> true
      | (Var _, Const ConstParamBinding) ->
        already_bound_error cx name prev loc;
        true
      | _ -> false
    )

  (* initialization of entries happens during a preliminary pass through a
     scoped region of the AST (dynamic for hoisted things, lexical for
     lexical things). this leaves them in a germinal state which is
     then read and written during the main traversal of the AST *)

  (* helper: initialize entry for given key in top scope,
     dealing with various situations involving a preexisting entry
     (since multiple declarations - sometimes but not always erroneous -
     may appear in an AST)
  *)

  let bind_entry cx name entry loc =
    (* iterate top-down through scopes until the appropriate scope for this
       binding is found, or realize a binding error *)
    let rec loop = function
      | [] -> assert_false ""empty scope list""
      | scope :: scopes ->
        (match get_entry name scope with
        (* if no entry already exists, this might be our scope *)
        | None ->
          Entry.(
            (match (scope.Scope.kind, entry) with
            (* lex scopes can only hold let/const/class bindings *)
            (* var scope can hold all binding types *)
            | (LexScope, Value { Entry.kind = Let _; _ })
            | (LexScope, Value { Entry.kind = Const _; _ })
            | (LexScope, Class _)
            | (VarScope _, _) ->
              add_entry name entry scope
            (* otherwise, keep looking for our scope *)
            | _ -> loop scopes)
          )
        (* some rebindings are allowed, but usually an error *)
        | Some prev ->
          (match scope.kind with
          (* specifically a var scope allows some shadowing *)
          | VarScope _ ->
            Entry.(
              (match (entry, prev) with
              (* good shadowing leaves existing entry, unifies with new *)
              | (Value e, Value p)
                when can_shadow cx name prev loc (Entry.kind_of_value e, Entry.kind_of_value p) ->
                (* TODO currently we don't step on specific. shouldn't we? *)
                Flow.unify cx (Entry.general_of_value p) (Entry.general_of_value e)
              (* bad shadowing is a binding error *)
              | _ -> already_bound_error cx name prev loc)
            )
          (* shadowing in a lex scope is always an error *)
          | LexScope -> already_bound_error cx name prev loc))
    in
    if not (is_excluded name) then loop !scopes

  (* bind class entry *)
  let bind_class
      cx
      class_id
      class_private_fields
      class_private_static_fields
      class_private_methods
      class_private_static_methods =
    bind_entry
      cx
      (internal_name ""class"")
      (Entry.new_class
         class_id
         class_private_fields
         class_private_static_fields
         class_private_methods
         class_private_static_methods
      )
      ALoc.none

  (* bind var entry *)
  let bind_var_to_name ?(state = State.Declared) cx name t loc =
    let (spec, closure_writes, provider) =
      mk_havoc cx name loc (TypeUtil.type_t_of_annotated_or_inferred t) Entry.Havocable
    in
    bind_entry cx name (Entry.new_var t ~loc ~state ~spec ?closure_writes ~provider) loc

  let bind_var ?state cx name t loc = bind_var_to_name ?state cx (OrdinaryName name) t loc

  (* bind let entry *)
  let bind_let ?(state = State.Undeclared) cx name t loc =
    let (spec, closure_writes, provider) =
      mk_havoc
        cx
        (OrdinaryName name)
        loc
        (TypeUtil.type_t_of_annotated_or_inferred t)
        Entry.Havocable
    in
    bind_entry
      cx
      (OrdinaryName name)
      (Entry.new_let t ~loc ~state ~spec ?closure_writes ~provider)
      loc

  (* bind implicit let entry *)
  let bind_implicit_let ?(state = State.Undeclared) kind cx name t loc =
    let (spec, closure_writes, provider) =
      mk_havoc cx name loc (TypeUtil.type_t_of_annotated_or_inferred t) Entry.Havocable
    in
    begin
      match (state, kind) with
      | (State.Initialized, Entry.(ParamBinding | CatchParamBinding)) ->
        (* If this variable starts off initialized then init_entry does not need to be called later, which is where normally providers are installed. *)
        install_provider cx (TypeUtil.type_t_of_annotated_or_inferred t) name loc
      | _ -> ()
    end;
    bind_entry cx name (Entry.new_let t ~kind ~loc ~state ~spec ?closure_writes ~provider) loc

  let bind_fun ?(state = State.Declared) cx name t =
    bind_implicit_let ~state Entry.FunctionBinding cx name (Inferred t)

  (* bind const entry *)
  let bind_const ?(state = State.Undeclared) cx name t loc =
    bind_entry cx (OrdinaryName name) (Entry.new_const t ~loc ~state) loc

  let bind_import cx name t loc = bind_entry cx (OrdinaryName name) (Entry.new_import t ~loc) loc

  (* bind implicit const entry *)
  let bind_implicit_const ?(state = State.Undeclared) kind cx name t loc =
    bind_entry cx (OrdinaryName name) (Entry.new_const t ~kind ~loc ~state) loc

  (* bind type entry *)
  let bind_type ?(state = State.Declared) cx name t loc =
    bind_entry cx (OrdinaryName name) (Entry.new_type t ~loc ~state) loc

  let bind_this_tparam ~state cx t loc = bind_type ~state cx ""this"" t loc

  let bind_import_type cx name t loc =
    bind_entry cx (OrdinaryName name) (Entry.new_import_type t ~loc) loc

  (* vars coming from 'declare' statements are preinitialized *)
  let bind_declare_var cx name t = bind_var_to_name ~state:State.Initialized cx name (Annotated t)

  (* bind entry for declare function *)
  let bind_declare_fun =
    let update_type seen_t new_t =
      match seen_t with
      | IntersectionT (reason, rep) -> IntersectionT (reason, InterRep.append [new_t] rep)
      | _ ->
        let reason = replace_desc_reason RIntersectionType (reason_of_t seen_t) in
        IntersectionT (reason, InterRep.make seen_t new_t [])
    in
    let update_general_type general_t new_t =
      match general_t with
      | Inferred t -> Inferred (update_type t new_t)
      | Annotated t -> Annotated (update_type t new_t)
    in
    fun cx ~predicate name t loc ->
      if not (is_excluded name) then
        let scope = peek_scope () in
        match Scope.get_entry name scope with
        | None ->
          let (spec, closure_writes, provider) = mk_havoc cx name loc t Entry.Havocable in
          let entry =
            Entry.new_let
              (Annotated t)
              ~kind:(Entry.DeclaredFunctionBinding { predicate })
              ~loc
              ~state:State.Initialized
              ~spec
              ~provider
              ?closure_writes
          in
          Scope.add_entry name entry scope
        | Some prev ->
          Entry.(
            (match prev with
            | Value v
              when can_shadow
                     cx
                     name
                     prev
                     loc
                     ( Let (DeclaredFunctionBinding { predicate }, Havocable (*doesnt matter *)),
                       Entry.kind_of_value v
                     ) ->
              let entry =
                Value
                  {
                    v with
                    value_state = State.Initialized;
                    specific = update_type v.specific t;
                    general = update_general_type v.general t;
                    provider = update_type v.provider t;
                  }
              in
              Scope.add_entry name entry scope
            | _ ->
              Utils_js.prerr_endlinef ""already_bound-1"";
              (* declare function shadows some other kind of binding *)
              already_bound_error cx name prev loc)
          )

  let same_kind k1 k2 =
    let open Entry in
    match (k1, k2) with
    | (Var _, Var _) -> true
    | (Let (kind1, _), Let (kind2, _)) -> kind1 = kind2
    | (Const kind1, Const kind2) -> kind1 = kind2
    | _ -> false

  (* helper: move a Let/Const's entry's state from Undeclared to Declared.
     Only needed for let and const to push things into scope for potentially
     recursive internal refs: hoisted things (vars and types) become declared
     immediately on binding.
  *)
  let declare_value_entry kind cx name loc =
    if not (is_excluded name) then
      Entry.(
        let (scope, entry) = find_entry cx name loc in
        match entry with
        | Value v
          when same_kind (Entry.kind_of_value v) kind && Entry.state_of_value v = State.Undeclared
          ->
          let new_entry = Value { v with value_state = State.Declared } in
          Scope.add_entry name new_entry scope
        | _ -> already_bound_error cx name entry loc
      )

  let declare_let = declare_value_entry Entry.(Let (LetVarBinding, Havocable))

  let declare_implicit_let kind = declare_value_entry Entry.(Let (kind, Havocable))

  let declare_const = declare_value_entry Entry.(Const ConstVarBinding)

  let declare_implicit_const kind = declare_value_entry (Entry.Const kind)

  let initialized_value_entry specific v =
    Entry.Value { v with Entry.value_state = State.Initialized; specific }

  (* helper - update var entry to reflect assignment/initialization *)
  (* note: here is where we understand that a name can be multiply var-bound
   * TODO: we started tracking annotations when variables are bound. Once we do
   * that at all binding sites this ~has_anno param can go away in favor of
   * looking up the annot in the environment *)
  let init_value_entry kind cx ~use_op name ~has_anno specific loc =
    if not (is_excluded name) then
      Entry.(
        let (scope, entry) = find_entry cx name loc in
        match (kind, entry) with
        | (Var _, Value ({ Entry.kind = Var _; _ } as v))
        | ( Let _,
            Value ({ Entry.kind = Let _; value_state = State.Undeclared | State.Declared; _ } as v)
          )
        | ( Const _,
            Value ({ Entry.kind = Const _; value_state = State.Undeclared | State.Declared; _ } as v)
          ) ->
          Changeset.Global.change_var (scope.id, name, Changeset.Write);
          let general = TypeUtil.type_t_of_annotated_or_inferred v.general in
          if specific != general then Flow.flow cx (specific, UseT (use_op, general));

          (* note that annotation supercedes specific initializer type *)
          begin
            match v.general with
            | Annotated _ -> ()
            | Inferred _ ->
              (* This is checked separately from has_anno because this variable
                 may have been previously declared with an annotation even if this
                 declaration lacks one; e.g. `var x: number; var x = ""hello""` *)
              constrain_by_provider cx ~use_op specific name loc
          end;

          let specific =
            if has_anno then
              general
            else
              specific
          in
          install_provider cx specific name loc;

          let new_entry = initialized_value_entry specific v in
          Scope.add_entry name new_entry scope
        | _ ->
          (* Incompatible or non-redeclarable new and previous entries.
             We will have already issued an error in `bind_value_entry`,
             so we can prune this case here. *)
          ()
      )

  let init_var = init_value_entry Entry.(Var Havocable)

  let init_let = init_value_entry Entry.(Let (LetVarBinding, Havocable))

  let init_implicit_let kind = init_value_entry Entry.(Let (kind, Havocable))

  let init_fun = init_implicit_let ~has_anno:false Entry.FunctionBinding

  let init_const = init_value_entry Entry.(Const ConstVarBinding)

  let init_implicit_const kind = init_value_entry Entry.(Const kind)

  (* update type alias to reflect initialization in code *)
  let init_type cx name type_ loc =
    let name = OrdinaryName name in
    if not (is_excluded name) then
      Entry.(
        let (scope, entry) = find_entry cx name loc in
        match entry with
        | Type ({ type_state = State.Declared; _ } as t) ->
          Flow.flow_t cx (type_, t.type_);
          let new_entry = Type { t with type_state = State.Initialized; type_ } in
          Scope.add_entry name new_entry scope
        | _ ->
          (* Incompatible or non-redeclarable new and previous entries.
             We will have already issued an error in `bind_value_entry`,
             so we can prune this case here. *)
          ()
      )

  (* treat a var's declared (annotated) type as an initializer *)
  let pseudo_init_declared_type cx name loc =
    let name = OrdinaryName name in
    if not (is_excluded name) then
      Entry.(
        let (scope, entry) = find_entry cx name loc in
        match entry with
        | Value ({ Entry.kind = Var _; _ } as v)
        | Value
            ({ Entry.kind = Let _ | Const _; value_state = State.(Undeclared | Declared); _ } as v)
          ->
          Changeset.Global.change_var (scope.id, name, Changeset.Write);
          install_provider cx (TypeUtil.type_t_of_annotated_or_inferred v.general) name loc;
          let entry =
            initialized_value_entry (TypeUtil.type_t_of_annotated_or_inferred v.general) v
          in
          Scope.add_entry name entry scope
        | _ ->
          (* Incompatible or non-redeclarable new and previous entries.
             We will have already issued an error in `bind_value_entry`,
             so we can prune this case here. *)
          ()
      )

  (* helper for read/write tdz checks *)
  (* for now, we only enforce TDZ within the same activation.
     return true if the given target scope is in the same
     activation as the current scope.
  *)
  let same_activation target =
    let rec loop target = function
      | [] -> assert_false ""target scope not found""
      | scope :: _ when scope.id = target.id ->
        (* target is nearer than (or actually is) nearest VarScope *)
        true
      | scope :: scopes ->
        (match scope.kind with
        | VarScope _ ->
          (* found var scope before target *)
          false
        | LexScope ->
          (* still in inner lex scopes, keep looking *)
          loop target scopes)
    in
    (* search outward for target scope *)
    loop target (peek_env ())

  (* get types from value entry, does uninitialized -> undefined behavior *)
  let value_entry_types ?(lookup_mode = ForValue) scope =
    Entry.(
      function
      (* from value positions, a same-activation ref to var or an explicit let
         before initialization yields undefined. *)
      | {
          Entry.kind = Var _ | Let (LetVarBinding, _);
          value_state = (State.Declared | State.MaybeInitialized) as state;
          value_declare_loc;
          specific;
          general;
          _;
        }
        when lookup_mode = ForValue && same_activation scope ->
        let uninit desc = VoidT.make (mk_reason desc value_declare_loc) |> with_trust bogus_trust in
        let specific =
          if state = State.Declared then
            uninit (RCustom ""uninitialized variable"")
          else
            (* State.MaybeInitialized *)
            let desc = RCustom ""possibly uninitialized variable"" in
            let rep = UnionRep.make (uninit desc) specific [] in
            UnionT (mk_reason desc value_declare_loc, rep)
        in
        (specific, general)
      | { specific; general; _ } -> (specific, general)
    )

  (* emit tdz error for value entry *)
  let tdz_error cx name loc v =
    Entry.(
      (* second clause of error message is due to switch scopes *)
      let msg = Error_message.EReferencedBeforeDeclaration in
      binding_error msg cx name (Value v) loc
    )

  (* helper for read/write tdz checks *)
  (* functions are block-scoped, but also hoisted. forward ref ok *)
  let allow_forward_ref =
    Scope.Entry.(
      function
      | Var _
      | Let ((FunctionBinding | DeclaredFunctionBinding _), _) ->
        true
      | _ -> false
    )

  (* helper - does semantic checking and returns entry type *)
  let read_entry ~lookup_mode ~specific cx name ?desc loc =
    let (scope, entry) = find_entry cx name ?desc loc in
    Entry.(
      match entry with
      | Type { type_binding_kind; _ } when lookup_mode != ForType ->
        let imported =
          match type_binding_kind with
          | ImportTypeBinding -> true
          | TypeBinding -> false
        in
        let msg =
          Error_message.ETypeInValuePosition { imported; name = display_string_of_name name }
        in
        binding_error msg cx name entry loc;
        AnyT.at (AnyError None) (entry_loc entry)
      | Type t -> t.type_
      | Class _ ->
        assert_false ""Internal Error: Classes should only be read using get_class_entries""
      | Value v ->
        (match v with
        | { Entry.kind; value_state = State.Undeclared; value_declare_loc; _ }
          when lookup_mode = ForValue && (not (allow_forward_ref kind)) && same_activation scope ->
          tdz_error cx name loc v;
          AnyT.at (AnyError None) value_declare_loc
        | _ ->
          Changeset.Global.change_var (scope.id, name, Changeset.Read);
          let (s, g) = value_entry_types ~lookup_mode scope v in
          if specific then
            s
          else
            TypeUtil.type_t_of_annotated_or_inferred g)
    )

  let rec seek_env f = function
    | [] -> None
    | scope :: scopes ->
      (match f scope with
      | Some x -> Some x
      | None -> seek_env f scopes)

  (* get env entry for name, if it exists *)
  let get_env_entry name = seek_env (Scope.get_entry name)

  (* get current env entry for name, if it exists *)
  let get_current_env_entry name = get_env_entry name !scopes

  (* get env refi for key, if it exists *)
  let get_env_refi key = seek_env (Scope.get_refi key)

  (* get current env refi for name, if it exists *)
  let get_current_env_refi key = get_env_refi key !scopes

  (* get var's specific type (and track the reference) *)
  let get_var ?(lookup_mode = ForValue) cx name loc =
    read_entry ~lookup_mode ~specific:true ?desc:None cx (OrdinaryName name) loc

  (* query var's specific type *)
  let query_var ?(lookup_mode = ForValue) = read_entry ~lookup_mode ~specific:true

  let query_var_non_specific = read_entry ~lookup_mode:ForValue ?desc:None ~specific:false

  let get_internal_var cx name loc = query_var cx (internal_name name) loc

  let get_var_annotation cx name loc =
    let (_, entry) = find_entry cx name loc in
    match entry with
    | Entry.Value { Entry.general = Annotated t; _ } -> Some t
    | _ -> None

  (* get var's general type - for annotated vars, this is the
     annotated type, and for others it's the union of all
     types assigned to the var throughout its lifetime.
  *)
  let get_var_declared_type ?(lookup_mode = ForValue) cx name loc =
    read_entry ~lookup_mode ~specific:false ?desc:None cx name loc

  let constraining_type ~default cx name loc =
    match name with
    | OrdinaryName _
      when Context.env_option_enabled cx Options.ConstrainWrites
           && not (Context.env_option_enabled cx Options.ClassicTypeAtPos) ->
      let (_, provider, _) = get_provider cx name loc in
      begin
        match provider with
        | Some provider -> provider
        | _ -> default
      end
    | _ -> default

  (* Unify declared type with another type. This is useful for allowing forward
     references in declared types to other types declared later in scope. *)
  let unify_declared_type ?(lookup_mode = ForValue) ?(is_func = false) cx name loc t =
    Entry.(
      (* If name_already_bound is true, then this is already a [name-already-bound]
       * error. In that case we don't need to unify with the general type. *)
      let name_already_bound v =
        match v.Entry.kind with
        | Let ((ClassNameBinding | FunctionBinding), _) -> v.value_assign_loc <> loc
        | Let (DeclaredFunctionBinding _, _) when not is_func ->
          (* Multiple declare functions followed by a function declaration is okay. *)
          v.value_assign_loc <> loc
        | _ -> false
      in
      match get_current_env_entry name with
      | Some (Value v) when lookup_mode = ForValue ->
        if not (name_already_bound v) then Flow.unify cx t (general_of_value v)
      | Some entry when lookup_mode <> ForValue -> Flow.unify cx t (Entry.declared_type entry)
      | _ -> ()
    )

  (* Unify declared function type with another type. This is similarly motivated as above, except that
     we also need to take overloading into account. See `bind_declare_fun` for similar logic. *)
  let unify_declared_fun_type =
    let find_type aloc = function
      | IntersectionT (_, rep) ->
        let match_type t = aloc_of_reason (reason_of_t t) = aloc in
        begin
          match List.find_opt match_type (InterRep.members rep) with
          | Some t -> t
          | None -> assert_false ""Internal Error: Improper overloaded declare function entries.""
        end
      | v -> v
    in
    fun cx name aloc t ->
      Entry.(
        match get_current_env_entry name with
        | Some (Value { Entry.kind = Let (FunctionBinding, _); _ }) ->
          (* This is already a 'name-already-bound' error. No need to unify types. *)
          ()
        | Some (Value v) -> Flow.unify cx t (find_type aloc (general_of_value v))
        | _ -> ()
      )

  let is_global_var _cx name _ =
    let rec loop = function
      | [] -> true
      | scope :: scopes ->
        (match Scope.get_entry (OrdinaryName name) scope with
        | Some _ -> Scope.is_global scope
        | None -> loop scopes)
    in
    loop !scopes

  (* get var type, with given location used in type's reason *)
  let var_ref ?(lookup_mode = ForValue) cx ?desc name loc =
    let t = query_var ~lookup_mode cx name ?desc loc in
    Flow.reposition cx loc t

  let init_import ~lookup_mode cx name loc t =
    let t_generic = get_var_declared_type ~lookup_mode cx name loc in
    Flow.unify cx t t_generic

  (* get refinement entry *)
  let get_refinement cx key loc =
    match find_refi_in_var_scope key with
    | Some (_, { refined; _ }) -> Some (Flow.reposition cx loc refined)
    | _ -> None

  (* Types-First signature extraction only inspects the initial binding for let-like
     definitions. Any subsequent assignment is ignored. This would cause a discrepancy
     between what classic mode views as the exported value, and what types-first does.
     To avoid this, we disallow updates on classes and functions. Let-bound variables
     would follow the same rule, but Types-First requires an annotation on their
     definition. This mitigates the problem, since in case of a reassigment the updated
     value needs to respect the annotation type, so we would only miss a potential
     refinement rather a strong type update.

     We also ban such reassignments in non-exported functions and classes in order to
     allow their types to be eagerly resolved.
  *)
  let has_illegal_let_bound_reassignment op cx name entry loc =
    let open Entry in
    match (op, entry) with
    | ( Changeset.Write,
        Value
          {
            Entry.kind =
              Let
                Entry.
                  ( ( (ClassNameBinding | FunctionBinding | DeclaredFunctionBinding _) as
                    binding_kind
                    ),
                    _
                  );
            value_declare_loc;
            _;
          }
      ) ->
      let reason = mk_reason (RType name) value_declare_loc in
      Flow.add_output
        cx
        Error_message.(EAssignConstLikeBinding { loc; definition = reason; binding_kind });
      true
    | _ -> false

  (* helper: update let or var entry *)
  let update_var op cx ~use_op name specific loc =
    let (scope, entry) = find_entry cx name loc in
    if has_illegal_let_bound_reassignment op cx name entry loc then
      None
    else
      Entry.(
        match entry with
        | Value ({ Entry.kind = Let _ as kind; value_state = State.Undeclared; _ } as v)
          when (not (allow_forward_ref kind)) && same_activation scope ->
          tdz_error cx name loc v;
          None
        | Value ({ Entry.kind = Let _ | Var _; closure_writes; general; _ } as v) ->
          let change = (scope.id, name, op) in
          Changeset.Global.change_var change;
          begin
            match (closure_writes, op) with
            | (_, Changeset.Refine) -> ()
            | (_, Changeset.Read) -> assert_false ""read op during variable update""
            | (Some (writes_by_closure, t, _), Changeset.Write)
              when ALocSet.mem loc writes_by_closure ->
              Flow.flow cx (specific, UseT (use_op, t))
            | (_, Changeset.Write) ->
              Flow.flow cx (specific, UseT (use_op, Entry.general_of_value v))
          end;

          install_provider cx specific name loc;

          begin
            match (general, op) with
            | (Inferred _, Changeset.Write) -> constrain_by_provider cx ~use_op specific name loc
            | _ -> ()
          end;

          (* add updated entry *)
          let update =
            Entry.Value
              { v with Entry.value_state = State.Initialized; specific; value_assign_loc = loc }
          in
          Scope.add_entry name update scope;
          Some change
        | Value { Entry.kind = Const ConstVarBinding; _ } ->
          let msg = Error_message.EConstReassigned in
          binding_error msg cx name entry loc;
          None
        | Value { Entry.kind = Const EnumNameBinding; _ } ->
          let msg = Error_message.EEnumReassigned in
          binding_error msg cx name entry loc;
          None
        | Value { Entry.kind = Const ConstImportBinding; _ } ->
          let msg = Error_message.EImportReassigned in
          binding_error msg cx name entry loc;
          None
        | Value { Entry.kind = Const ConstParamBinding; _ } ->
          (* TODO: remove extra info when surface syntax is added *)
          let msg = Error_message.EConstParamReassigned in
          binding_error msg cx name entry loc;
          None
        | Type _ ->
          let msg = Error_message.ETypeAliasInValuePosition in
          binding_error msg cx name entry loc;
          None
        | Class _ -> assert_false ""Internal error: update_var called on Class""
      )

  (* update var by direct assignment *)
  let set_var cx ~use_op name t loc =
    update_var Changeset.Write cx ~use_op (OrdinaryName name) t loc |> ignore

  let set_internal_var cx name t loc =
    update_var Changeset.Write cx ~use_op:unknown_use (internal_name name) t loc |> ignore

  (* update var by refinement test *)
  let refine_var = update_var Changeset.Refine ~use_op:(Op (Internal Refinement))

  (* set const's specific type to reflect a refinement test (internal) *)
  let refine_const cx name specific loc =
    let (scope, entry) = find_entry cx name loc in
    Entry.(
      match entry with
      | Value ({ Entry.kind = Const _; value_state = State.Undeclared; _ } as v)
        when same_activation scope ->
        tdz_error cx name loc v;
        None
      | Value ({ Entry.kind = Const _; _ } as v) ->
        let change = (scope.id, name, Changeset.Refine) in
        Changeset.Global.change_var change;
        let update = Value { v with value_state = State.Initialized; specific } in
        Scope.add_entry name update scope;
        Some change
      | _ ->
        assert_false
          (spf
             ""refine_const called on %s %s""
             (Entry.string_of_kind entry)
             (display_string_of_name name)
          )
    )

  (* given a list of envs (scope lists), return true iff all envs are
     the same length and all scope ids and kinds match *)
  let envs_congruent envs =
    let rec check_scopes envs =
      let env0 = List.hd envs in
      env0 = []
      ||
      let scope0 = List.hd env0 in
      let check_scope env =
        let scope = List.hd env in
        scope.id = scope0.id && scope.kind = scope0.kind
      in
      List.for_all check_scope (List.tl envs) && check_scopes (Base.List.map ~f:List.tl envs)
    in
    let envs = Base.List.remove_consecutive_duplicates ~equal:( == ) envs in
    List.length envs <= 1
    ||
    let len = List.length (List.hd envs) in
    List.for_all (fun env -> List.length env = len) (List.tl envs) && check_scopes envs

  (* find scopes with a given id in a list of envs.
     envs are assumed congruent amd assumed to contain scope id *)
  let rec find_scope cx loc envs scope_id =
    match envs with
    | (scope0 :: _) :: _ ->
      if scope0.id = scope_id then
        List.(map hd envs)
      else
        find_scope cx loc List.(map tl envs) scope_id
    | _ ->
      assert_false
        (spf
           ""find_scopes %s: scope %d not found. head env %s""
           (string_of_aloc loc)
           scope_id
           (string_of_env cx (List.hd envs))
        )

  (* The following function takes a changset and a triple of environments -
       original and two derivations - and merges the bindings indicated by
     changeset keys from the derivations into the original. *)
  let merge_env =
    (* find scope triple in env triple *)
    let find_scope_triple cx loc (env0, env1, env2) id =
      let lst = find_scope cx loc [env0; env1; env2] id in
      List.(nth lst 0, nth lst 1, nth lst 2)
    in
    let create_union cx loc name l1 l2 =
      let reason = mk_reason name loc in
      Tvar.mk_where cx reason (fun tvar ->
          Flow.flow cx (l1, UseT (Op (Internal MergeEnv), tvar));
          Flow.flow cx (l2, UseT (Op (Internal MergeEnv), tvar))
      )
    in
    (* merge_entry helper - calculate new specific type *)
    let merge_specific cx loc name (specific0, general0) specific1 specific2 =
      (* if both children are unchanged, or 1 child is unchanged and the other
         is bottom (EmptyT), then we can avoid creating a merged specific *)
      if
        (specific0 = specific1 && (specific0 = specific2 || is_bot specific2))
        || (specific0 = specific2 && is_bot specific1)
      then
        specific0
      (* child has reverted to original - shortcut *)
      else if specific1 = general0 || specific2 = general0 then
        general0
      (* general case *)
      else
        create_union cx loc name specific1 specific2
    in
    (* propagate var state updates from child entries *)
    let merge_states orig child1 child2 =
      Entry.(
        match orig.Entry.kind with
        | Var _
        | Let _
          when child1.value_state = State.Initialized && child2.value_state = State.Initialized ->
          (* if both branches have initialized, we can set parent state *)
          State.Initialized
        | Var _
        | Let _
          when child1.value_state >= State.Declared
               && child2.value_state >= State.Declared
               && (child1.value_state >= State.MaybeInitialized
                  || child2.value_state >= State.MaybeInitialized
                  ) ->
          (* if either branch has initialized, we can set parent state *)
          State.MaybeInitialized
        | _ -> orig.value_state
      )
    in
    let merge_entry cx loc envs ((scope_id, name, _) as entry_ref) =
      let (scope0, scope1, scope2) = find_scope_triple cx loc envs scope_id in
      let get = get_entry name in
      Entry.(
        match (get scope0, get scope1, get scope2) with
        (* merge child var and let types back to original *)
        | (Some (Value orig), Some (Value child1), Some (Value child2)) ->
          let { specific = s0; general = g0; _ } = orig in
          let { specific = s1; _ } = child1 in
          let { specific = s2; _ } = child2 in
          let specific =
            merge_specific
              cx
              loc
              (RIdentifier name)
              (s0, TypeUtil.type_t_of_annotated_or_inferred g0)
              s1
              s2
          in
          let value_state = merge_states orig child1 child2 in
          (* replace entry if anything changed *)
          if specific == s0 && value_state = orig.value_state then
            ()
          else
            let e = Entry.Value { orig with Entry.specific; value_state } in
            add_entry name e scope0
        (* type aliases can't be refined or reassigned, shouldn't be here *)
        | (Some (Type _), Some (Type _), Some (Type _)) ->
          assert_false
            (spf
               ""merge_env %s: type alias %s found in changelist""
               (string_of_aloc loc)
               (display_string_of_name name)
            )
        (* global lookups may leave uneven new entries, which we can forget *)
        | (_, _, _) when is_global scope0 -> ()
        (* missing completely from non-global scope *)
        | (None, None, None) ->
          assert_false
            (spf
               ""%smerge_entry %s %s: missing from scopes:\n%s\n%s\n%s""
               (Context.pid_prefix cx)
               (string_of_aloc loc)
               (Changeset.string_of_entry_ref entry_ref)
               (Debug_js.string_of_scope cx scope0)
               (Debug_js.string_of_scope cx scope1)
               (Debug_js.string_of_scope cx scope2)
            )
        (* a newly created entry may exist in one lex child -
           this pattern is due to our current switch handling *)
        | (None, Some (Value _ as entry), None) when Scope.is_lex scope1 ->
          add_entry name entry scope0
        | (None, None, Some (Value _ as entry)) when Scope.is_lex scope2 ->
          add_entry name entry scope0
        (* otherwise, non-refinement uneven distributions are asserts. *)
        | (orig, child1, child2) ->
          let print_entry_kind_opt = function
            | None -> ""None""
            | Some e -> spf ""Some %s"" Entry.(string_of_kind e)
          in
          assert_false
            (spf
               ""merge_env %s: non-uniform distribution of entry %s: %s, %s, %s""
               (string_of_aloc loc)
               (display_string_of_name name)
               (print_entry_kind_opt orig)
               (print_entry_kind_opt child1)
               (print_entry_kind_opt child2)
            )
      )
    in
    let merge_refi cx loc envs (scope_id, key, _) =
      let (scope0, scope1, scope2) = find_scope_triple cx loc envs scope_id in
      let get = get_refi key in
      match (get scope0, get scope1, get scope2) with
      (* evenly distributed refinements are merged *)
      | (Some base, Some child1, Some child2) ->
        let name = Key.reason_desc key in
        let refined =
          merge_specific cx loc name (base.refined, base.original) child1.refined child2.refined
        in
        if refined == base.refined then
          ()
        else
          add_refi key { base with refined } scope0
      (* refi was introduced in both children *)
      | (None, Some child1, Some child2) ->
        let name = Key.reason_desc key in
        let refined = create_union cx loc name child1.refined child2.refined in
        let original = create_union cx loc name child1.original child2.original in
        let refi = { refi_loc = loc; refined; original } in
        add_refi key refi scope0
      (* refi was cleared in a child env. clear from original *)
      | (Some _, _, _) -> remove_refi key scope0
      (* refi was introduced - and possibly also removed by havoc -
         after envs diverged *)
      | (None, _, _) -> ()
    in
    (* merge entries and refis found in changeset *)
    fun cx loc (env0, env1, env2) changeset ->
      if not (envs_congruent [env0; env1; env2]) then
        assert_false
          (spf
             ""merge_env %s: envs not congruent: %d %d %d""
             (string_of_aloc loc)
             (List.length env0)
             (List.length env1)
             (List.length env2)
          );
      changeset
      |> Changeset.iter_type_updates
           (merge_entry cx loc (env0, env1, env2))
           (merge_refi cx loc (env0, env1, env2))

  (* copy changes from env2 into env1 *)
  let copy_env =
    (* find sscope pair in env pair *)
    let find_scope_pair cx loc (env0, env1) id =
      let lst = find_scope cx loc [env0; env1] id in
      List.(nth lst 0, nth lst 1)
    in
    (* look for and copy entry, starting in topmost scope *)
    let copy_entry cx loc envs (scope_id, name, _) =
      let (scope1, scope2) = find_scope_pair cx loc envs scope_id in
      let get = get_entry name in
      Entry.(
        match (get scope1, get scope2) with
        (* for values, flow env2's specific type into env1's specific type *)
        | (Some (Value v1), Some (Value v2)) ->
          (* flow child2's specific type to child1 in place *)
          Flow.flow cx (v2.specific, UseT (Op (Internal CopyEnv), v1.specific));

          (* update state *)
          if v1.value_state < State.Initialized && v2.value_state >= State.MaybeInitialized then
            let new_entry = Value { v1 with value_state = State.MaybeInitialized } in
            add_entry name new_entry scope1
        (* type aliases shouldn't be here *)
        | (Some (Type _), Some (Type _)) ->
          assert_false
            (spf
               ""copy_env %s: type alias %s found in changelist""
               (string_of_aloc loc)
               (display_string_of_name name)
            )
        (* global lookups may leave new entries in env2, or orphan changes *)
        (* ...which we can forget *)
        | (None, _) when is_global scope1 -> ()
        (* changeset entry exists only in lex scope *)
        | (Some (Value _), None) when Scope.is_lex scope1 -> ()
        | (None, Some (Value _ as entry)) when Scope.is_lex scope2 -> add_entry name entry scope1
        (* uneven distributions *)
        | (entry1, entry2) ->
          let print_entry_kind_opt = function
            | None -> ""None""
            | Some e -> spf ""Some %s"" (Entry.string_of_kind e)
          in
          assert_false
            (spf
               ""copy_env %s: non-uniform distribution of entry %s: %s, %s""
               (string_of_aloc loc)
               (display_string_of_name name)
               (print_entry_kind_opt entry1)
               (print_entry_kind_opt entry2)
            )
      )
    in
    (* look for and copy refinement in top scope only *)
    let copy_refi cx loc envs (scope_id, key, _) =
      let (scope0, scope1) = find_scope_pair cx loc envs scope_id in
      let get = get_refi key in
      match (get scope0, get scope1) with
      (* flow child refi's type back to parent *)
      | (Some { refined = t1; _ }, Some { refined = t2; _ }) ->
        Flow.flow cx (t2, UseT (Op (Internal CopyEnv), t1))
      (* uneven cases imply refi was added after splitting: remove *)
      | _ -> ()
    in
    (* copy entries and refis bound to names and keys, respectively *)
    fun cx loc (env1, env2) changeset ->
      if envs_congruent [env1; env2] then
        ()
      else
        assert_false (spf ""copy_env %s: envs not congruent"" (string_of_aloc loc));
      changeset
      |> Changeset.iter_type_updates (copy_entry cx loc (env1, env2)) (copy_refi cx loc (env1, env2))

  (* in the top scope, convert specific types to tvars with former
     specific type as incoming lower bound, and general type as
     upper bound. This prepares the specific type for later merging
     during path-dependent analysis.
  *)
  let widen_env =
    let widened cx loc name specific general =
      if specific = general then
        None
      else
        let reason = mk_reason name loc in
        let tvar = Tvar.mk cx reason in
        Flow.flow cx (specific, UseT (Op (Internal WidenEnv), tvar));
        Flow.flow cx (tvar, UseT (Op (Internal WidenEnv), general));
        Some tvar
    in
    let widen_var
        cx loc name ({ Entry.specific; general = Annotated general | Inferred general; _ } as var) =
      match widened cx loc name specific general with
      | None -> var
      | Some specific -> { var with Entry.specific }
    in
    let widen_refi cx loc name ({ refined; original; _ } as refi) =
      match widened cx loc name refined original with
      | None -> refi
      | Some refined -> { refi with refined }
    in
    fun cx loc ->
      iter_local_scopes (fun scope ->
          scope
          |> Scope.update_entries
               Entry.(
                 fun name -> function
                   | Value var -> Value (widen_var cx loc (RIdentifier name) var)
                   | entry -> entry
               );
          scope |> Scope.update_refis (fun key refi -> widen_refi cx loc (Key.reason_desc key) refi)
      )

  (* The protocol around havoc has changed a few times.
     The following function used to do most of the work, but is now subsumed by
     havoc_ctx, and is now used only to clear the environment when looking at
     a function body. Also see below. *)

  (* clear refinement informnation for all binding entries in env *)
  let havoc_all () = iter_scopes Scope.havoc

  (* set specific type of every non-internal var *and const*
     in top activation to undefined, and clear heap refinements.
     Note: this operation is needed by our control flow handling, which is
     left over from the earlier, looser model. To properly simulate early exits,
     all entries including consts must have their specific entries set to EmptyT.
     TODO rework the early-exit stuff to not break invariants. Until then it'll
     remain a source of bugs.
  *)
  let reset_current_activation loc = iter_local_scopes (Scope.reset loc)

  (* clear refinement info for (topmost bindings of) given names in env *)
  let havoc_vars =
    Scope.(
      (* clear specific info for (topmost binding of) given var in env *)
      let havoc_entry (_, name, _) =
        let rec loop = function
          | [] -> ()
          | scope :: scopes ->
            (match get_entry name scope with
            | Some entry ->
              let entry = Entry.havoc name entry in
              add_entry name entry scope
            | None -> loop scopes)
        in
        loop !scopes
      in
      (* clear refinement for (topmost binding of) given key in env *)
      let havoc_refi (_, key, _) =
        let rec loop = function
          | [] -> ()
          | scope :: scopes ->
            (match get_refi key scope with
            | Some _ -> remove_refi key scope
            | None -> loop scopes)
        in
        loop !scopes
      in
      Changeset.iter_type_updates havoc_entry havoc_refi
    )

  (* Clear all heap refinements (refis) in env.

     Refinements on names bound directly in a scope are left
     untouched; for those, see [havoc_local_refinements]. *)
  let havoc_heap_refinements () =
    iter_scopes (fun scope ->
        if Changeset.Global.is_active () then
          scope
          |> Scope.iter_refis (fun key _ ->
                 Changeset.Global.change_refi (scope.id, key, Changeset.Write)
             );
        Scope.havoc_all_refis scope
    )

  let havoc_local_refinements ?(all = false) cx =
    iter_scopes (fun scope ->
        Scope.update_entries
          (fun name entry ->
            let entry' =
              if all then
                Entry.havoc name entry
              else
                Entry.havoc
                  ~on_call:(fun specific t general ->
                    if
                      specific == general
                      (* We already know t ~> general, so specific | t = general *)
                    then
                      general
                    else if Context.env_option_enabled cx Options.ConstrainWrites then (
                      let tvar = Tvar.mk cx (reason_of_t t) in
                      Flow.flow cx (specific, UseT (Op (Internal WidenEnv), tvar));
                      Flow.flow cx (general, UseT (Op (Internal WidenEnv), tvar));
                      tvar
                    ) else
                      let (_, tvar_t) = open_tvar t in
                      let constraints_t = Context.find_graph cx tvar_t in
                      match (specific, constraints_t) with
                      | (OpenT (_, tvar_specific), Constraint.Unresolved bounds_t)
                        when IMap.mem tvar_specific bounds_t.Constraint.uppertvars ->
                        (* If t ~> specific, then specific | t = specific *)
                        specific
                      | _ ->
                        (* Compute specific | t = tvar where specific, t ~> tvar ~> general *)
                        let tvar = Tvar.mk cx (reason_of_t t) in
                        Flow.flow cx (specific, UseT (Op (Internal WidenEnv), tvar));
                        Flow.flow cx (t, UseT (Op (Internal WidenEnv), tvar));
                        Flow.flow cx (tvar, UseT (Op (Internal WidenEnv), general));
                        tvar)
                  name
                  entry
            in
            ( if entry' != entry then
              let entry_ref = (scope.id, name, Changeset.Write) in
              Changeset.(if Global.is_active () then Global.change_var entry_ref)
            );
            entry')
          scope
    )

  let havoc_heap_refinements_with_propname ~private_ name =
    iter_scopes (Scope.havoc_refis ~private_ ~name)

  (* The following functions are used to narrow the type of variables
     based on dynamic checks. *)

  (* Directly refine an expression's type to t. The refinement is
     installed into the same scope where the object is bound. A
     refinement may already be present in this scope - if so, we
     overwrite it.

     However note that we do so at a low level, rather than by using the
     standard set_var mechanism. This is to avoid unwanted reentrancy:
     set_var calls flow (specific, general) to model the effect of a
     variable assignment in user code, and this in certain cases
     (broadly, assignment of function values) may provoke havoc_ctx
     into clearing the refinement we're in the process of installing.
  *)
  let add_heap_refinement op key refi_loc refined original =
    let refi = { refi_loc; refined; original } in
    let (base, _) = key in
    let (scope, _) = find_entry_in_var_scope base in
    let change = (scope.id, key, op) in
    Changeset.Global.change_refi change;
    Scope.add_refi key refi scope;
    change

  let set_expr _cx k l ~refined:t1 ~original:t2 =
    add_heap_refinement Changeset.Write k l t1 t2 |> ignore

  let refine_expr = add_heap_refinement Changeset.Refine

  (* add predicate refinements from given preds map to environment.
     returns changeset containing all refinements added to env.
     note: orig_types maps names to unrefined types. this param is
     only necessary for fresh pseudovars like heap refinements -
     others can be obtained via query_var.
  *)
  let refine_with_preds cx loc preds orig_types =
    let check_instanceof_subtypes ~general_type pred t =
      match pred with
      | LeftP (InstanceofTest, _) ->
        let u = UseT (Op (Internal Refinement), general_type) in
        Context.add_literal_subtypes cx (t, u)
      | _ -> ()
    in
    let refine_type orig_type pred refined_type =
      Flow.flow cx (orig_type, PredicateT (pred, refined_type))
    in
    let mk_refi_type orig_type pred refi_reason =
      refine_type orig_type pred |> Tvar.mk_no_wrap_where cx refi_reason
    in
    let refine_with_pred key pred acc =
      let refi_reason = mk_reason (RRefined (Key.reason_desc key)) loc in
      match key with
      (* for real consts/lets/vars, we model assignment/initialization *)
      | ((OrdinaryName _ as name), []) ->
        Entry.(
          (match find_entry cx name loc with
          | (_, Value v) ->
            let orig_type = query_var cx name loc in
            let general_type = query_var_non_specific cx name loc in
            let refi_type = mk_refi_type orig_type pred refi_reason in
            check_instanceof_subtypes ~general_type pred refi_type;
            let refine =
              match Entry.kind_of_value v with
              | Const _ -> refine_const
              | _ -> refine_var
            in
            begin
              match refine cx name refi_type loc with
              | Some change -> Changeset.add_var change acc
              | None -> acc
            end
          | (_, _) ->
            Flow.add_output cx (Error_message.ERefineAsValue (refi_reason, name));
            acc)
        )
      (* for heap refinements, we just add new entries *)
      | _ ->
        let orig_type = Key_map.find key orig_types in
        let refi_type = mk_refi_type orig_type pred refi_reason in
        let change = refine_expr key loc refi_type orig_type in
        Changeset.add_refi change acc
    in
    Key_map.fold refine_with_pred preds Changeset.empty

  (* run the given function in a clone of the current environment
     augmented by the given refinement map, then merge the final
     state of the cloned environment back into the reinstated
     original *)
  let in_refined_env cx loc preds orig_types f =
    let oldset = Changeset.Global.clear () in
    let orig_env = peek_env () in
    let new_env = clone_env orig_env in
    update_env loc new_env;
    let _ = refine_with_preds cx loc preds orig_types in
    let result = f () in
    let newset = Changeset.Global.merge oldset in
    merge_env cx loc (orig_env, orig_env, new_env) newset;
    update_env loc orig_env;

    result

  let new_env = false

  let record_expression_type_if_needed _ _ _ = ()

  let discriminant_after_negated_cases cx _switch_loc refinement_key_opt discriminant =
    match discriminant with
    | (loc, Flow_ast.Expression.Identifier (_, { Flow_ast.Identifier.name; _ })) ->
      Some (query_var cx (OrdinaryName name) loc)
    | _ ->
      refinement_key_opt
      |> Base.Option.bind ~f:get_current_env_refi
      |> Base.Option.map ~f:(fun refi -> refi.Scope.refined)
end
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

module Ast = Flow_ast

module type S = sig
  module Env : Env_sig.S

  module Abnormal : Abnormal_sig.S with module Env := Env

  module Import_export : module type of Import_export.Make (Env)

  module Toplevels : module type of Toplevels.DependencyToplevels (Env) (Abnormal)

  module Anno : Type_annotation_sig.S with module Env := Env

  module Func_stmt_params : Func_params_intf.S

  module Func_stmt_sig : Func_sig_intf.S with type func_params := Func_stmt_params.t

  val expression :
    ?cond:Type.cond_context ->
    Context.t ->
    hint:Type.t option ->
    (ALoc.t, ALoc.t) Flow_ast.Expression.t ->
    (ALoc.t, ALoc.t * Type.t) Flow_ast.Expression.t

  val statement :
    Context.t -> (ALoc.t, ALoc.t) Ast.Statement.t -> (ALoc.t, ALoc.t * Type.t) Ast.Statement.t

  val toplevel_decls : Context.t -> (ALoc.t, ALoc.t) Ast.Statement.t list -> unit

  val for_of_elemt : Context.t -> Type.t -> Reason.reason -> bool -> Type.t

  val mk_function :
    Context.t ->
    hint:Type.t option ->
    needs_this_param:bool ->
    general:Type.t ->
    Reason.reason ->
    (ALoc.t, ALoc.t) Ast.Function.t ->
    Type.t * (ALoc.t, ALoc.t * Type.t) Ast.Function.t

  val mk_func_sig :
    Context.t ->
    hint:Type.t option ->
    needs_this_param:bool ->
    Type.t Subst_name.Map.t ->
    Reason.reason ->
    (ALoc.t, ALoc.t) Ast.Function.t ->
    Func_stmt_sig.t
    * ((ALoc.t, ALoc.t * Type.t) Ast.Function.Params.t ->
      (ALoc.t, ALoc.t * Type.t) Ast.Function.body ->
      Type.t ->
      (ALoc.t, ALoc.t * Type.t) Ast.Function.t
      )

  val plus_assign :
    Context.t ->
    reason:Reason.reason ->
    lhs_reason:Reason.reason ->
    rhs_reason:Reason.reason ->
    Type.t ->
    Type.t ->
    Type.t

  val arith_assign : Context.t -> ALoc.t -> Type.t -> Type.t -> Type.t

  val type_alias :
    Context.t ->
    ALoc.t ->
    (ALoc.t, ALoc.t) Ast.Statement.TypeAlias.t ->
    Type.t * (ALoc.t, ALoc.t * Type.t) Ast.Statement.TypeAlias.t

  val opaque_type :
    Context.t ->
    ALoc.t ->
    (ALoc.t, ALoc.t) Ast.Statement.OpaqueType.t ->
    Type.t * (ALoc.t, ALoc.t * Type.t) Ast.Statement.OpaqueType.t

  val import_named_specifier_type :
    Context.t ->
    Reason.t ->
    Ast.Statement.ImportDeclaration.import_kind ->
    source_loc:ALoc.t ->
    module_name:string ->
    remote_name_loc:ALoc.t ->
    remote_name:string ->
    local_name:string ->
    Type.t

  val import_namespace_specifier_type :
    Context.t ->
    Reason.t ->
    Ast.Statement.ImportDeclaration.import_kind ->
    source_loc:ALoc.t ->
    module_name:string ->
    local_loc:ALoc.t ->
    Type.t

  val import_default_specifier_type :
    Context.t ->
    Reason.t ->
    Ast.Statement.ImportDeclaration.import_kind ->
    source_loc:ALoc.t ->
    module_name:string ->
    local_loc:ALoc.t ->
    local_name:string ->
    Type.t

  val interface :
    Context.t ->
    ALoc.t ->
    (ALoc.t, ALoc.t) Ast.Statement.Interface.t ->
    Type.t * (ALoc.t, ALoc.t * Type.t) Ast.Statement.Interface.t

  val declare_class :
    Context.t ->
    ALoc.t ->
    (ALoc.t, ALoc.t) Ast.Statement.DeclareClass.t ->
    Type.t * (ALoc.t, ALoc.t * Type.t) Ast.Statement.DeclareClass.t

  val mk_enum :
    Context.t ->
    enum_reason:Reason.t ->
    ALoc.t ->
    ALoc.t Ast.Statement.EnumDeclaration.body ->
    Type.enum_t
end
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

(***********************************************************************)
(* flow init command *)
(***********************************************************************)

let spec =
  {
    CommandSpec.name = ""init"";
    doc = ""Initializes a directory to be used as a flow root directory"";
    usage =
      Printf.sprintf
        ""Usage: %s init [ROOT]\nInitializes a directory to be used as a flow root directory\n\ne.g. %s init /path/to/root\nor %s init\nor %s init --options \""optionA=123;optionB=456\""\nor %s init --lints \""lintA=on,lintB=off\""\n\nIf the root is not specified it is assumed to be the current working directory\n\nThis command will create and initialize /path/to/root/.flowconfig\n""
        CommandUtils.exe_name
        CommandUtils.exe_name
        CommandUtils.exe_name
        CommandUtils.exe_name
        CommandUtils.exe_name;
    args =
      CommandSpec.ArgSpec.(
        empty
        |> CommandUtils.base_flags
        |> CommandUtils.from_flag
        |> CommandUtils.flowconfig_flags
        |> flag ""--options"" (optional string) ~doc:""Semicolon-delimited list of key=value pairs""
        |> anon ""root"" (optional string)
      );
  }

let error (errs : (int * string) list) =
  let msg =
    errs
    |> Base.List.map ~f:(fun (ln, msg) -> Utils_js.spf "".flowconfig:%d %s"" ln msg)
    |> String.concat ""\n""
  in
  Exit.(exit ~msg Invalid_flowconfig)

let main base_flags flowconfig_flags options root () =
  let root =
    match root with
    | None -> Sys.getcwd () |> Path.make
    | Some root -> Path.make root
  in
  FlowEventLogger.set_root (Some (Path.to_string root));
  let options =
    match options with
    | None -> []
    | Some str -> Str.split (Str.regexp "";"") str
  in
  let ignores = flowconfig_flags.CommandUtils.ignores in
  let untyped = flowconfig_flags.CommandUtils.untyped in
  let declarations = flowconfig_flags.CommandUtils.declarations in
  let includes = flowconfig_flags.CommandUtils.includes in
  let libs = flowconfig_flags.CommandUtils.libs in
  let lints = flowconfig_flags.CommandUtils.raw_lint_severities in
  let file = Server_files_js.config_file base_flags.CommandUtils.Base_flags.flowconfig_name root in
  ( if Sys.file_exists file then
    let msg = Utils_js.spf ""Error: \""%s\"" already exists!\n%!"" file in
    Exit.(exit ~msg Invalid_flowconfig)
  );

  let config = FlowConfig.init ~ignores ~untyped ~declarations ~includes ~libs ~options ~lints in
  let config =
    match config with
    | Ok (config, []) -> config
    | Ok (_, warnings) -> error warnings (* TODO: write warnings to stderr instead of exiting *)
    | Error err -> error [err]
  in
  let out = Stdlib.open_out file in
  FlowConfig.write config out;
  Stdlib.close_out out

let command = CommandSpec.command spec main
",ocaml
"open Ast_helper
open Parsetree

module Ext = struct
  let mk () = (Location.mkloc ""merlin.hole"" !default_loc, PStr [])
end

module Exp = struct
  let mk () = Exp.extension (Ext.mk ())
end

module Cl = struct
  let mk () = Cl.extension (Ext.mk ())
end

module Cty = struct
  let mk () = Cty.extension (Ext.mk ())
end

module Pat = struct
  let mk () = Pat.extension (Ext.mk ())
end

module Mty = struct
  let mk () = Mty.extension (Ext.mk ())
end

module Mod = struct
  let mk () = Mod.extension (Ext.mk ())
end
",ocaml
"class c =
",ocaml
"(*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 *)

module type CONNECTION_PROCESSOR = sig
  type in_message

  type out_message
end

module type CONNECTION = sig
  type t

  type in_message

  type out_message

  val create :
    name:string ->
    in_fd:Lwt_unix.file_descr ->
    out_fd:Lwt_unix.file_descr ->
    close:(unit -> unit Lwt.t) ->
    on_read:(msg:in_message -> connection:t -> unit Lwt.t) ->
    ((unit -> unit) * t) Lwt.t

  val write : msg:out_message -> t -> bool

  val write_and_close : msg:out_message -> t -> bool

  val close_immediately : t -> unit Lwt.t

  val try_flush_and_close : t -> unit Lwt.t

  val is_closed : t -> bool

  val wait_for_closed : t -> unit Lwt.t
end

module Make (ConnectionProcessor : CONNECTION_PROCESSOR) :
  CONNECTION
    with type in_message := ConnectionProcessor.in_message
     and type out_message := ConnectionProcessor.out_message
",ocaml
"let x = if k then
",ocaml
"module Pre = struct
  (* 和集合 *)
  let union (xs: 'a list) (ys: 'a list):'a list =
    List.filter begin fun x ->
      not (List.mem x ys)
    end xs @ ys

  (* 積集合 *)
  let intersect (xs: 'a list) (ys: 'a list): 'a list =
    List.filter begin fun x ->
      List.mem x ys
    end xs

  (* リストをセットにする。要素が１つずつにまとめる *)
  let nub (xs : 'a list): 'a list =
    List.fold_left begin fun ys y ->
      if List.mem y ys
      then ys
      else y :: ys
    end [] xs

  let show_list show sep xs =
    begin
      let rec loop xs =
        begin match xs with
          | [] -> """"
          | [x] -> show x
          | x::xs -> show x ^ sep ^ loop xs
        end
    in
      Printf.sprintf ""[%s]"" (loop xs)
    end
  let show_int_list xs =
    show_list string_of_int ""; "" xs
end

module Id = struct
  type id = string

  (* 数値に対するidを取得する *)
  let enumId (n:int) : id =
    ""v"" ^ string_of_int n
end

(* 3 Kinds *)
module Kind = struct
  type kind =
    | Star
    | Kfun of kind * kind

  let rec show (k:kind):string =
    begin match k with
      | Star -> ""*""
      | Kfun(Kfun _ as k1,k2) -> Printf.sprintf ""(%s) -> %s"" (show k1) (show k2) 
      | Kfun(k1,k2) -> Printf.sprintf ""%s -> %s"" (show k1) (show k2) 
    end

  let rec show_list (ks:kind list):string =
    Pre.show_list show "";"" ks

end

(* 4 Types *)
module Type = struct
  open Kind
  (* 型変数 *)
  type tyvar = Tyvar of Id.id * kind
  (* 型コンストラクタ *)
  type tycon = Tycon of Id.id * kind
  (* 型 *)
  type type_ =
    | TVar of tyvar
    | TCon of tycon
    | TAp of type_ * type_
    | TGen of int

  let tUnit :type_ = TCon(Tycon(""()"", Star))
  let tChar :type_ = TCon(Tycon(""Char"", Star))
  let tInt :type_ = TCon(Tycon(""Int"", Star))
  let tInteger :type_ = TCon(Tycon(""Integer"", Star))
  let tFloat :type_ = TCon(Tycon(""Float"", Star))
  let tDouble :type_ = TCon(Tycon(""Double"", Star))

  let tList :type_ = TCon(Tycon(""[]"", Kfun(Star, Star)))
  let tArrow :type_ = TCon(Tycon(""(->)"", Kfun(Star, Kfun(Star, Star))))
  let tTuple2 :type_ = TCon(Tycon(""(,)"", Kfun(Star, Kfun(Star, Star))))

  let fn (a:type_) (b:type_) :type_ = TAp(TAp(tArrow, a), b)

  let list t :type_ = TAp(tList, t)

  let tString :type_ = list tChar

  let pair a b :type_ = TAp(TAp(tTuple2, a), b)

  let tyvarKind (Tyvar(_, k)) :kind = k
  let tyconKind (Tycon(_, k)) :kind = k
  let rec typeKind t:kind =
    match t with
    | TCon tc -> tyconKind tc
    | TVar u -> tyvarKind u
    | TAp(t, _) ->
      begin match typeKind t with
        | Kfun(_, k) -> k
        | _ -> failwith ""inconsistent type""
      end
    | TGen _ -> failwith ""generic type variables have no kind""

  let rec show (t:type_): string =
    begin match t with
      | TVar(Tyvar(id,kind)) -> Printf.sprintf ""TVar(Tyvar(%s,%s))"" id (Kind.show kind)
      | TCon(Tycon(id,kind)) -> Printf.sprintf ""TCon(Tycon(%s,%s))"" id (Kind.show kind)
      | TAp(t1,t2)           -> Printf.sprintf ""TAp(%s,%s)"" (show t1) (show t2)
      | TGen(i)              -> Printf.sprintf ""TGen(%d)"" i
    end
end

(* 5 Substitutions *)
module Subst = struct
  open Type

  type subst = (tyvar * type_) list

  let nullSubst : subst = []

  let (+->) u t : subst = [(u, t)]

  (* 型変数を展開する *)
  let rec typeApply (s : subst) (t:type_):type_ = 
    begin match t with
      | TVar u as t ->
        begin try
          List.assoc u s
        with
          Not_found -> t
        end
      | TAp(l, r) -> TAp(typeApply s l, typeApply s r)
      | t -> t
    end

  let rec typeTv (t:type_):tyvar list =
    begin match t with
      | TVar u -> [u]
      | TAp(l, r) -> Pre.union (typeTv l) (typeTv r)
      | _ -> []
    end

  let listApply (apply : subst -> 'a -> 'b) (s : subst) (xs:'a list):'b list =
    List.map (apply s) xs

  let listTv (tv:'a -> tyvar list) (xs:'a list) : tyvar list =
    Pre.nub (List.concat (List.map tv xs))

  let (@@) (s1:subst) (s2 : subst) : subst =
    List.map begin fun (u, t) ->
      (u, typeApply s1 t)
    end s2 @ s1

  let merge s1 s2 : subst =
    let agree =
      let agreeOnVar v =
        typeApply s1 (TVar v) = typeApply s2 (TVar v)
      in
      List.for_all agreeOnVar (Pre.intersect (List.map fst s1) (List.map fst s2))
    in
    if agree
    then s1 @ s2
    else failwith ""substitutions do not agree""

  let show (subst:subst):string =
    Pre.show_list begin fun (Tyvar(id,kind),type_) ->
      Printf.sprintf ""Tyvar(%s,%s),%s"" id (Kind.show kind) (Type.show type_)
    end ""; "" subst

  let rec show_tyvar(tv:tyvar): string = 
    begin match tv with
      | Tyvar(id,kind) -> Printf.sprintf ""Tyvar(%s,%s)"" id (Kind.show kind)
    end

  let show_tyvar_list xs :string =
    Pre.show_list begin fun (Tyvar(id,kind)) ->
      Printf.sprintf ""Tyvar(%s,%s)"" id (Kind.show kind)
    end ""; "" xs
end

(* 6 Unification and Matching *)
module Unify = struct
  open List
  open Kind
  open Type
  open Subst
  
  let rec mgu (t1:type_) (t2:type_):subst =
    match t1, t2 with
    | TAp(l, r), TAp(l', r') ->
      let s1 = mgu l l' in
      let s2 = mgu (typeApply s1 r) (typeApply s1 r') in
      s2 @@ s1
    | TVar u, t | t, TVar u -> varBind u t
    | TCon tc1, TCon tc2 when tc1 = tc2 -> nullSubst
    | _ -> failwith ""types do not unify""

  and varBind (u:tyvar) (t:type_):subst =
    match t with
    | _ when t = TVar u                -> nullSubst
    | _ when mem u (typeTv t)          -> failwith ""occurs check fails""
    | _ when tyvarKind u <> typeKind t -> failwith ""kinds do not match""
    | _                                -> u +-> t

  let rec match_ (t1:type_) (t2:type_):subst =
    match t1, t2 with
    | TAp(l, r), TAp(l', r') ->
      let sl = match_ l l' in
      let sr = match_ r r' in
      merge sl sr
    | TVar u, t when tyvarKind u = typeKind t -> u +-> t
    | TCon tc1, TCon tc2 when tc1 = tc2 -> nullSubst
    | _ -> failwith ""types do not match""
end

(* 7 Type Classes, Predicates and Qualified Types *)
module Pred = struct
  open List
  open Kind
  open Type
  open Subst


  (* 7.1 Basic definitions *)
  type pred = IsIn of Id.id * type_

  let p (IsIn(s, t)) =
    s  ^ "" "" ^ (Type.show t)

  let ps pred =
    Pre.show_list p "", "" pred

  type 't qual = Qual of pred list * 't

  let p_qual q =
    begin match q with
      | Qual(preds,ty) -> ps preds ^ "" => "" ^ Type.show ty
    end

  let predApply (s:subst) (pred:pred):pred =
    match pred with
    | IsIn(i, t) -> IsIn(i, Subst.typeApply s t)

  let predTv (pred:pred):tyvar list =
    match pred with
    | IsIn(_, t) -> Subst.typeTv t

  let predsApply (s:subst) (xs:pred list):pred list =
    Subst.listApply predApply s xs

  let predsTv (xs:'a list) : tyvar list =
    Subst.listTv predTv xs

  let qualTypeApply (s:subst) (qual:type_ qual):type_ qual =
    match qual with
    | Qual(ps, t) -> Qual(predsApply s ps, Subst.typeApply s t)

  let qualTypeTv qual =
    match qual with
    | Qual(ps, t) ->
      Pre.union (predsTv ps) (Subst.typeTv t)

  let lift (m:type_->type_->'a) (p:pred) (p':pred):'a =
    match (p, p') with
    | IsIn(i, t), IsIn(i', t') ->
      if i = i' then m t t'
      else failwith ""classes differ""

  let mguPred = lift Unify.mgu

  let matchPred = lift Unify.match_

  type inst = pred qual

  let p_inst i =
    begin match i with
    | Qual(preds,pred) -> Printf.sprintf ""Qual(%s,%s)"" (ps preds) (p pred)
    end

  type class_ = Id.id list * inst list

  let (==>) ps p = Qual(ps, p)

  (* 7.2 Class Environments *)

  type classEnv = {
    classes : (Id.id -> class_);
    defaults : type_ list;
  }

  let initialEnv :classEnv = {
    classes = (fun i -> raise Not_found);
    defaults = [tInteger; tDouble]
  }

  let modify (ce:classEnv) i c =
    { ce with classes = fun j -> if i = j then c else ce.classes j; }

  let super (ce:classEnv) i = fst (ce.classes i)

  let insts (ce:classEnv) i = snd (ce.classes i)

  let defined (ce:classEnv) i =
    try
      ignore (ce.classes i);
      true
    with Not_found -> false

  type envTransformer = classEnv -> classEnv

  let addClass i is : envTransformer =
    fun (ce:classEnv) ->
      if defined ce i then failwith ""class already defined""
      else if exists (fun i -> not (defined ce i)) is then
        failwith ""superclass not defined""
      else modify ce i (is, [])

  let (<:>) (f : envTransformer) (g : envTransformer) : envTransformer =
    fun (ce:classEnv) -> g (f ce)

  let addCoreClasses :envTransformer =
        addClass ""Eq"" []
    <:> addClass ""Ord"" [""Eq""]
    <:> addClass ""Show"" []
    <:> addClass ""Read"" []
    <:> addClass ""Bounded"" []
    <:> addClass ""Enum"" []
    <:> addClass ""Functor"" []
    <:> addClass ""Monad"" []

  let addNumClasses :envTransformer =
        addClass ""Num"" [""Eq""; ""Show""]
    <:> addClass ""Real"" [""Num""; ""Ord""]
    <:> addClass ""Fractional"" [""Num""]
    <:> addClass ""Integral"" [""Real""; ""Enum""]
    <:> addClass ""RealFrac"" [""Real""; ""Fractional""]
    <:> addClass ""Floating"" [""Fractional""]
    <:> addClass ""RealFloat"" [""RealFrac""; ""Floating""]

  let addPreludeClasses :envTransformer =
    addCoreClasses <:> addNumClasses

  let overlap (p:pred) (q:pred) : bool =
    try
      ignore (mguPred p q);
      true
    with _ -> false

  let addInst ps (IsIn(i, _) as p) : envTransformer =
    fun (ce:classEnv) ->
      if not (defined ce i) then failwith ""no class for instance"";
      let its = insts ce i in
      let qs = map (fun (Qual(_, q)) -> q) its in
      if exists (overlap p) qs then failwith ""overlapping instance"";      
      let c = super ce i, Qual(ps, p) :: its in
      modify ce i c

  let exampleInsts : envTransformer =
        addPreludeClasses
    <:> addInst [] (IsIn(""Ord"", tUnit))
    <:> addInst [] (IsIn(""Ord"", tChar))
    <:> addInst [] (IsIn(""Ord"", tInt))
    <:> addInst [IsIn(""Ord"", TVar(Tyvar(""a"", Star)));
                 IsIn(""Ord"", TVar(Tyvar(""b"", Star)))]
                (IsIn(""Ord"", pair (TVar(Tyvar(""a"", Star)))
                                  (TVar(Tyvar(""b"", Star)))))

  (* 7.3 Entailment *)

  let rec bySuper (ce:classEnv) (IsIn(i, t) as p) =
    p :: concat (map (fun i' -> bySuper ce (IsIn(i', t))) (super ce i))

  let byInst (ce:classEnv) (IsIn(i, t) as p) =
    let tryInst (Qual(ps, h)) =
      try
       let u = matchPred h p in
       Some (map (predApply u) ps)
      with _ -> None in
    let rec msum = function
      | [] -> None
      | None :: xs -> msum xs
      | x :: _ -> x in
    msum (map tryInst (insts ce i))

  let rec entail (ce:classEnv) ps p =
    exists (mem p) (map (bySuper ce) ps) ||
    match byInst ce p with
    | None -> false
    | Some qs -> for_all (entail ce ps) qs

  (* 7.4 Context Reduction *)

  let inHnf (p:pred):bool =
    match p with
    | IsIn(_, t) ->
      let rec hnf = function
        | TVar _ -> true
        | TCon _ -> false
        | TAp(t, _) -> hnf t
        | TGen _ -> failwith ""context reduction on generic variable""
      in
      hnf t

  let rec toHnfs (ce:classEnv) ps = concat (map (toHnf ce) ps)
  and toHnf (ce:classEnv) p =
    if inHnf p then [p]
    else
      match byInst ce p with
      | None -> failwith ""context reduction""
      | Some ps -> toHnfs ce ps

  let simplify (ce:classEnv) ps =
    let rec loop rs = function
      | [] -> rs
      | p :: ps ->
        if entail ce (rs @ ps) p then loop rs ps
        else loop (p :: rs) ps in
    loop [] ps

  let reduce (ce:classEnv) ps =
    simplify ce (toHnfs ce ps)

  let scEntail (ce:classEnv) ps p =
    exists (mem p) (map (bySuper ce) ps)

end

(* 8 Type Schemes *)
module Scheme = struct

  open List
  open Kind
  open Type
  open Pred

  type scheme = Forall of kind list * type_ qual

  let show (Forall(ks, qt):scheme) =
    Printf.sprintf ""Forall(%s, %s)"" (Kind.show_list ks) (Pred.p_qual qt)

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    let sc = Forall([],Qual([pred],ty)) in
    Printf.printf ""scheme = %s\n"" (show sc)

  let schemeApply (s:Subst.subst) (Forall(ks, qt):scheme):scheme =
    Forall(ks, qualTypeApply s qt)

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    let sc = Forall([],Qual([pred],ty)) in
    let subst = [Tyvar(""a"", Star), tInt] in
    let sc = schemeApply subst sc in
    Printf.printf ""scheme = %s\n"" (show sc)

  let schemeTv (Forall(_, qt):scheme):tyvar list = qualTypeTv qt

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    let sc = Forall([],Qual([pred],ty)) in
    let tvs = schemeTv sc in
    Printf.printf ""tvs = %s\n"" (Subst.show_tyvar_list tvs)

  let quantify(vs:tyvar list) (qt:type_ qual):scheme =
    let vs' = filter (fun v -> mem v vs) (qualTypeTv qt) in
    let ks = map tyvarKind vs' in
    let newGen v =
      let count = ref 0 in
      let t = TGen !count in
      incr count;
      (v, t) in
    let s = map newGen vs' in
    Forall(ks, qualTypeApply s qt)

  let _ =
    let tyvar = Tyvar(""a"", Star) in
    let ty = TVar(Tyvar(""a"", Star)) in
    let pred = IsIn(""Num"", ty) in
    let qual = Qual([pred], fn ty tInt) in
    let sc = quantify [tyvar] qual in
    Printf.printf ""scheme = %s\n"" (show sc)


  let toScheme (t:type_) :scheme = Forall([], (Qual([], t)))

  let _ =
    let ty = TVar(Tyvar(""a"", Star)) in
    let sc = toScheme ty in
    Printf.printf ""scheme = %s\n"" (show sc)
end
",ocaml
"let x = if k then x else
",ocaml
"/*
 * Problem Statement: https://www.hackerrank.com/challenges/piling-up/copy-from/181700435
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <assert.h>
#include <ctype.h>
#include <limits.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <time.h>

/*START OF CODE-TEMPLATE*/

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

// Constant Macros.
#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Calculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

// Error-Handling Macros.
#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, (expected_return_val)); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0)

// Initialisation Macros.
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '\0', (bytes))

// Mathematical Macros.
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) / 2) + (start)

// Bit-Manipulation Macros.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

/*END OF CODE-TEMPLATE*/

static bool check_decreasing_order(int*, const int);
static bool check_stack_possible(const int*, const int);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        int n;
        if(1 != scanf(""%d"", &n)) {
            SCANF_READ_ERROR(1);
        }
        assert(n > 0);
        int *const cube_side_lengths = calloc((size_t) n, sizeof*cube_side_lengths);
        if(!cube_side_lengths) {
            MEMORY_ALLOCATION_FAILED_ERROR(cube_side_lengths, (size_t) n * sizeof*cube_side_lengths);
            exit(0);
        }
        for(int i = 0; i < n; ++i) {
            if(1 != scanf(""%d"", cube_side_lengths + i)) {
                SCANF_READ_ERROR(1);
            }
        }
        printf(""%s\n"", check_stack_possible(cube_side_lengths, n) ? ""Yes"" : ""No"");
        free(cube_side_lengths);
    }
    return EXIT_SUCCESS;
}

static bool check_decreasing_order(int *sequence, const int n) {
    bool is_decreasing_order = true;
    for(int i = 1; i < n; ++i) {
        if(sequence[i - 1] < sequence[i]) {
            is_decreasing_order = false;
            break;
        }
    }
    free(sequence);
    return is_decreasing_order;
}

static bool check_stack_possible(const int *cube_side_lengths, const int n) {
    int *const stacked_cubes = calloc((size_t) n, sizeof*stacked_cubes);
    if(!stacked_cubes) {
        MEMORY_ALLOCATION_FAILED_ERROR(stacked_cubes, (size_t) n * sizeof*stacked_cubes);
        exit(0);
    }
    for(int i = 0, start = 0, end = n - 1; start <= end; ) {
        if(cube_side_lengths[start] > cube_side_lengths[end]) {
            stacked_cubes[i++] = cube_side_lengths[start++];
            continue;
        }
        stacked_cubes[i++] = cube_side_lengths[end--];
    }
    return check_decreasing_order(stacked_cubes, n);
}
",c++
"/*
 *  Problem Statement: Program to compute the GCD of two numbers using only one statement.
 *  Author: striker
*/

#include <stdio.h>
#include <stdlib.h>
#include <assert.h>

typedef long long ll_t;
typedef unsigned long long ull_t;

#define SCANF_READ_ERROR(exp_return) fprintf(stderr, ""Line Number: %u: scanf() read error. Expected return value: %d\n"", __LINE__, (exp_return)); exit(1)

static ll_t compute_gcd(ll_t, ll_t);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    assert(test > 0);
    while(test--) {
        ll_t a, b;
        if(2 != scanf(""%lld%lld"", &a, &b)) {
            SCANF_READ_ERROR(2);
        }
        printf(""%lld\n"", compute_gcd(a, b));
    }
    return EXIT_SUCCESS;
}

static ll_t compute_gcd(ll_t a, ll_t b) {
    return !b ? a : b == 1LL ? b : compute_gcd(b, a % b);
}
",c++
"#include <stdio.h>
#include <stdlib.h>

struct node{
    int data;
    struct node *left;
    struct node *right;
};

struct node *newrec, *root, *a, *b;

void insert(int x){
    newrec = (struct node *)malloc(sizeof(struct node));
    newrec -> data = x;
    newrec -> left = NULL;
    newrec -> right = NULL;
    
    if(root == NULL){
        root = newrec;
    }
    else{
        a = b = root;
        while(a!=NULL){
            b = a;
            if(x <= a->data){
                a = a->left;
            }else{
                a = a->right;
            }
        }
        if(x<=b->data){
            b->left = newrec;
        }else{
            b->right = newrec;
        }
    }
}

void delete(int x){
    a = b = root;
    while(a!=NULL || a->data != x){
        b = a;
        if(x <= a->data){
            a = a->left;
        }else{
            a = a->right;
        }
    }
    if(a==NULL){
        printf(""\n Element not found!"");
    }
    // element to be delete is pointed by a
    // parent of element to be delete is pointed by b
    else if(a->left != NULL && a->right == NULL){
        // if it is root node
        if(x == root->data){
            root = a->left;
        }else{
            if(b->left == a){
                b->left = a->left;
            }else{
                b->right = a->left;
            }
        }
    }
    else if(a->left == NULL && a->right != NULL){
       if(root->data == x){
           root = a->right;
       }else{
           if(b->left == a){
               b -> left = a->right;
           }else{
               b -> right = a->right;
           }
       }
    }
    else if(a->left == NULL && a->right == NULL){
        if(root->data == x){
            root = NULL;
        }else{
            if(b->left == a){
                b->left = NULL;
            }else{
                b->right = NULL;
            }
        }
    }
    else if(a->left !=NULL && a->right != NULL){
        struct node *c;
        c = a->right;
        while(c->left != NULL){
            c = c -> left;
        }
        c->left = a->left;
        if(root == a){
            root = root-> right;
        }else{
            if(b->left == a){
                b->left = a->right;
            }else{
                b->right = a->right;
            }
        }
    }
}

void inorder(struct node *p){
    if(p!=NULL){
        inorder(p->left);
        printf(""%d, "", p->data);
        inorder(p->right);
    }
}

void preorder(struct node *p){
    if(p!=NULL){
        printf(""%d, "", p->data);
        preorder(p->left);
        preorder(p->right);
    }
}

void postorder(struct node *p){
    if(p!=NULL){
        postorder(p->left);
        postorder(p->right);
        printf(""%d, "", p->data);
    }
}

void distroy(){
    root = NULL;
    printf(""\n Tree is destroyed!"");
}

void main(void) {
    insert(100);
    insert(50);
    insert(150);
    insert(25);
    insert(75);
    insert(125);
    insert(175);
    printf(""\n Inorder traversal: "");
    inorder(root);
    printf(""\n Preorder traversal: "");
    preorder(root);
    delete(75);
    printf(""\n Postorder traversal: "");
    postorder(root);
    distroy();
}
",c++
"#include <stdio.h>
#include <string.h>

int main () {
    char ch1[101],ch3;
    char ch2[101];

    int i=0,j;

    gets(ch1);
    gets(ch2);

    j = strlen(ch1) - 1;

    for( ; i<j ; i++,j--){
        ch3 = ch1[j];
        ch1[j] = ch1[i];
        ch1[i] = ch3;
    }

    if(!(strcmp(ch1,ch2))) printf(""YES"");
    else printf(""NO"");

    return 0;
}
",c++
"#include <stdio.h>

int partition(int a[], int l, int r){
    int i =l, j= r, x=a[l], temp;
    while(i<j){
        while(a[i]<=x && i<=r){
            i++;
        }
        while(a[j]>x){
            j--;
        }
        if(i<j){
            temp = a[i];
            a[i] = a[j];
            a[j] = temp;
        }
    }
    temp = a[l];
    a[l] = a[j];
    a[j] = temp;
    return j;
}

int quick_sort(int a[], int l, int r){
    if(l!=r){
        int p = partition(a, l, r);
        quick_sort(a, l, p-1);
        quick_sort(a, p+1, r);
    }
    
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call quick sort
    // 0, l, r
    quick_sort(a, 0, 5);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c++
"/*
 * Problem Statement: Refer to the readme.md file.
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d\n"", __LINE__, return_val); exit(0)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

static void display_list(int[], const int, const char *const);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    if(1 == scanf(""%d"", &test)) {
        if(test < 1) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(test, test value cannot be 0 or -ve);
            exit(0);
        }
        while(test--) {
            int n, k;
            if(2 == scanf(""%d%d"", &n, &k)) {
                int sequence[n];
                for(register int i = 0; i < n; ++i) {
                    scanf(""%d"", &sequence[(i + k) % n]);
                }
                display_list(sequence, n, "" "");
                printf(""\n"");
            } else {
                SCANF_READ_ERROR(2);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static void display_list(int sequence[], const int n, const char *const delimeter) {
    printf(""%d"", sequence[0]);
    for(register int i = 1; i < n; ++i) {
        printf(""%s%d"", delimeter, sequence[i]);
    }
}
",c++
"/*  Problem Statement: https://www.spoj.com/problems/BINSTIRL/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<string.h>
#include<assert.h>

const uint32_t compute_stirling_number_of_second_kind(uint32_t,uint32_t);

int main(void) {
    uint32_t test;
    scanf(""%""SCNu32, &test);
    assert(test > 0 && test < 201);
    while(test--) {
        uint32_t n,m;
        scanf(""%""SCNu32""%""SCNu32, &n,&m);
        assert((n > 0 && n < 1000000001) && (m > 0 && m < 1000000001));
        printf(""%""PRIu32""\n"", compute_stirling_number_of_second_kind((n + 1),(m + 1)));
    }
    return EXIT_SUCCESS;
}

const uint32_t compute_stirling_number_of_second_kind(uint32_t n,uint32_t m) {
    uint8_t *const data_storage = calloc((m + 1),sizeof(uint8_t));
    data_storage[0] = 1;
    for(uint32_t i = 0; i < n; ++i) {
        for(int32_t j = (m - 1); j >= 0; --j) {
            if(j > i) {
                data_storage[j] = 0;
            } else if(i > 0 && j == 0) {
                data_storage[j] = 0;
            }
            else if(j == i) {
                data_storage[j] = 1;
            } else {
                data_storage[j] = (((j % 2) * (data_storage[j] % 2)) + (data_storage[j - 1] % 2)) % 2;
            }
        }
    }
    uint32_t ans = data_storage[m - 1];
    free(data_storage);
    return ans;
}",c++
"/*
 * Problem Statement: https://onlinejudge.org/index.php?option=com_onlinejudge&Itemid=8&category=3&page=show_problem&problem=36
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

/* ANSI C 5.3.0 - GNU C Compiler doesn't have following GCC functions defined.
// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).
*/

#define MAX_SIZE 10000

static ll_t compute_maximum_cycle_length(ll_t, ll_t);
static void swap_data(ll_t *const, ll_t *const);
static ll_t compute_cycle_length(ll_t);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    ll_t start, end;
    while(EOF != scanf(""%lld%lld"", &start, &end)) {
        printf(""%lld %lld %lld\n"", start, end, compute_maximum_cycle_length(start, end));
    }
    return EXIT_SUCCESS;
}

static ll_t compute_maximum_cycle_length(ll_t start, ll_t end) {
    static ll_t cache[MAX_SIZE];
    if(start > end) {
        swap_data(&start, &end);
    }
    ll_t max_cycle_length = 0;
    for(; start <= end; ++start) {
        if(!cache[start - 1]) {
            cache[start - 1] = compute_cycle_length(start);
        }
        if(max_cycle_length < cache[start - 1]) {
            max_cycle_length = cache[start - 1];
        }
    }
    return max_cycle_length;
}

static void swap_data(ll_t *const a, ll_t *const b) {
    if(a != b) {
        *a = (*a) ^ (*b);
        *b = (*a) ^ (*b);
        *a = (*a) ^ (*b);
    }
}

static ll_t compute_cycle_length(ll_t n) {
    ll_t cycle_length = 1;
    while(1 != n) {
        ++cycle_length;
        if(n % 2) {
            n = (3 * n) + 1;
            continue;
        }
        n >>= 1;
    }
    return cycle_length;
}
",c++
"// Copyright 2015 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef COMMON_SHADERS_FOR_TESTS_H_
#define COMMON_SHADERS_FOR_TESTS_H_

#ifdef __cplusplus
extern ""C"" {
#endif

// The minimal shader, without a version directive.
const char kMinimalShaderWithoutVersion[] = ""void main(){}"";
// The minimal shader, with a version directive.
const char kMinimalShader[] =
    ""#version 140\n""
    ""void main(){}"";
const char kMinimalHlslShader[] =
    ""float4 EntryPoint(uint index : SV_VERTEXID) : SV_POSITION\n""
    ""{ return float4(1.0, 2.0, 3.0, 4.0); }"";
const char kMinimalShaderWithMacro[] =
    ""#version 140\n""
    ""#define E main\n""
    ""void E(){}\n"";

// The minimal shader that needs valueless predefinition of 'E' to compile.
const char kValuelessPredefinitionShader[] =
    ""#version 140\n""
    ""#ifdef E\n""
    ""void main(){}\n""
    ""#else\n""
    ""#error\n""
    ""#endif"";

// By default the compiler will emit a warning on line 2 complaining
// that 'float' is a deprecated attribute in version 130.  Use verison 140
// because some versions of glslang will error out for a too-low version
// when generating SPIR-V.
const char kDeprecatedAttributeShader[] =
    ""#version 400\n""
    ""layout(location = 0) attribute float x;\n""
    ""void main() {}\n"";

// By default the compiler will emit a warning as version 550 is an unknown
// version.
const char kMinimalUnknownVersionShader[] =
    ""#version 550\n""
    ""void main() {}\n"";

// gl_ClipDistance doesn't exist in es profile (at least until 3.10).
const char kCoreVertShaderWithoutVersion[] =
    ""void main() {\n""
    ""gl_ClipDistance[0] = 5.;\n""
    ""}\n"";

// Generated debug information should contain the name of the vector:
// debug_info_sample.
const char kMinimalDebugInfoShader[] =
    ""#version 140\n""
    ""void main(){\n""
    ""vec2 debug_info_sample = vec2(1.0,1.0);\n""
    ""}\n"";

// Compiler should generate two errors.
const char kTwoErrorsShader[] =
    ""#version 150\n""
    ""#error\n""
    ""#error\n""
    ""void main(){}\n"";

// Compiler should generate two warnings.
const char kTwoWarningsShader[] =
    ""#version 400\n""
    ""layout(location = 0) attribute float x;\n""
    ""layout(location = 1) attribute float y;\n""
    ""void main(){}\n"";

// A shader that compiles under OpenGL compatibility profile rules,
// but not OpenGL core profile rules.
const char kOpenGLCompatibilityFragmentShader[] =
    R""(#version 100
     uniform highp sampler2D tex;
     void main() {
       gl_FragColor = texture2D(tex, vec2(0.0,0.0));
     })"";

// A shader that compiles under OpenGL core profile rules.
const char kOpenGLVertexShader[] =
    R""(#version 330
       void main() { int t = gl_VertexID; })"";

// Empty 310 es shader. It is valid for vertex, fragment, compute shader kind.
const char kEmpty310ESShader[] =
    ""#version 310 es\n""
    ""void main() {}\n"";

// Vertex only shader.
const char kVertexOnlyShader[] =
    ""#version 310 es\n""
    ""void main() {\n""
    ""    gl_Position = vec4(1.);\n""
    ""}"";

// TessControl only shader.
const char kTessControlOnlyShader[] =
    ""#version 440 core\n""
    ""layout(vertices = 3) out;\n""
    ""void main() { }"";

// TessEvaluation only shader.
const char kTessEvaluationOnlyShader[] =
    ""#version 440 core\n""
    ""layout(triangles) in;\n""
    ""void main() { }"";

// Geometry only shader.
const char kGeometryOnlyShader[] =
    ""#version 150 core\n""
    ""layout (triangles) in;\n""
    ""layout (line_strip, max_vertices = 4) out;\n""
    ""void main() { }"";

// Vertex only shader with #pragma annotation.
const char kVertexOnlyShaderWithPragma[] =
    ""#version 310 es\n""
    ""#pragma shader_stage(vertex)\n""
    ""void main() {\n""
    ""    gl_Position = vec4(1.);\n""
    ""}"";

// Fragment only shader with #pragma annotation.
const char kFragmentOnlyShaderWithPragma[] =
    ""#version 310 es\n""
    ""#pragma shader_stage(fragment)\n""
    ""void main() {\n""
    ""    gl_FragDepth = 10.;\n""
    ""}"";

// TessControl only shader with #pragma annotation.
const char kTessControlOnlyShaderWithPragma[] =
    ""#version 440 core\n""
    ""#pragma shader_stage(tesscontrol)\n""
    ""layout(vertices = 3) out;\n""
    ""void main() { }"";

// TessEvaluation only shader with #pragma annotation.
const char kTessEvaluationOnlyShaderWithPragma[] =
    ""#version 440 core\n""
    ""#pragma shader_stage(tesseval)\n""
    ""layout(triangles) in;\n""
    ""void main() { }"";

// Geometry only shader with #pragma annotation.
const char kGeometryOnlyShaderWithPragma[] =
    ""#version 150 core\n""
    ""#pragma shader_stage(geometry)\n""
    ""layout (triangles) in;\n""
    ""layout (line_strip, max_vertices = 4) out;\n""
    ""void main() { }"";

// Compute only shader with #pragma annotation.
const char kComputeOnlyShaderWithPragma[] =
    ""#version 310 es\n""
    ""#pragma shader_stage(compute)\n""
    ""void main() {\n""
    ""    uvec3 temp = gl_WorkGroupID;\n""
    ""}"";

// NV mesh shader without #pragma.
const char kNVMeshShader[] =
    ""#version 450\n""
    ""#extension GL_NV_mesh_shader : enable\n""
    ""layout(local_size_x=8) in;\n""
    ""layout(max_vertices=5) out;\n""
    ""layout(max_primitives=10) out;\n""
    ""layout(triangles) out;\n""
    ""void main() {\n""
    ""  gl_MeshVerticesNV[gl_LocalInvocationID.x].gl_Position = vec4(0.0);\n""
    ""}\n"";

// NV mesh shader with #pragma annotation.
const char kNVMeshShaderWithPragma[] =
    ""#version 450\n""
    ""#extension GL_NV_mesh_shader : enable\n""
    ""#pragma shader_stage(mesh)\n""
    ""layout(local_size_x=8) in;\n""
    ""layout(max_vertices=5) out;\n""
    ""layout(max_primitives=10) out;\n""
    ""layout(triangles) out;\n""
    ""void main() {\n""
    ""  gl_MeshVerticesNV[gl_LocalInvocationID.x].gl_Position = vec4(0.0);\n""
    ""}\n"";

// NV task shader without #pragma annotation.
const char kNVTaskShader[] =
    ""#version 450\n""
    ""#extension GL_NV_mesh_shader : enable\n""
    ""layout(local_size_x=8) in;\n""
    ""void main() {\n""
    ""  gl_TaskCountNV = 2;\n""
    ""}\n"";

// NV task shader with #pragma annotation.
const char kNVTaskShaderWithPragma[] =
    ""#version 450\n""
    ""#extension GL_NV_mesh_shader : enable\n""
    ""#pragma shader_stage(task)\n""
    ""layout(local_size_x=8) in;\n""
    ""void main() {\n""
    ""  gl_TaskCountNV = 2;\n""
    ""}\n"";

// Vertex only shader with invalid #pragma annotation.
const char kVertexOnlyShaderWithInvalidPragma[] =
    ""#version 310 es\n""
    ""#pragma shader_stage(fragment)\n""
    ""void main() {\n""
    ""    gl_Position = vec4(1.);\n""
    ""}"";

// Parts of a valid disassembly of a minimal shader.  We only check certain
// parts since Glslang code generation changes in incidental ways.
const char* kMinimalShaderDisassemblySubstrings[] = {
    ""; SPIR-V\n""
    ""; Version: 1.0\n""
    ""; Generator: Google Shaderc over Glslang; 10\n""
    ""; Bound:"",

    ""               OpCapability Shader\n"",
    ""          %1 = OpExtInstImport \""GLSL.std.450\""\n"",
    ""               OpMemoryModel Logical GLSL450\n"",
    ""               OpReturn\n"",
    ""               OpFunctionEnd\n""};

const char* kMinimalShaderDebugInfoDisassemblySubstrings[] = {
    ""; SPIR-V\n""
    ""; Version: 1.0\n""
    ""; Generator: Google Shaderc over Glslang; 10\n""
    ""; Bound:"",

    ""               OpCapability Shader\n"",
    ""          %2 = OpExtInstImport \""GLSL.std.450\""\n"",
    ""               OpMemoryModel Logical GLSL450\n"",
    ""               OpReturn\n"",
    ""               OpFunctionEnd\n""};

const char kMinimalShaderAssembly[] = R""(
    ; SPIR-V
    ; Version: 1.0
    ; Generator: Google Shaderc over Glslang; 10
    ; Bound: 6
    ; Schema: 0

         OpCapability Shader
    %1 = OpExtInstImport ""GLSL.std.450""
         OpMemoryModel Logical GLSL450
         OpEntryPoint Vertex %4 ""main""
         OpSource ESSL 310
         OpName %4 ""main""
    %2 = OpTypeVoid
    %3 = OpTypeFunction %2
    %4 = OpFunction %2 None %3
    %5 = OpLabel
         OpReturn
         OpFunctionEnd)"";

const char kShaderWithUniformsWithoutBindings[] =
    R""(#version 450
       #extension GL_ARB_sparse_texture2 : enable
       uniform texture2D my_tex;
       uniform sampler my_sam;
       layout(rgba32f) uniform image2D my_img;
       layout(rgba32f) uniform imageBuffer my_imbuf;
       uniform block { float x; float y; } my_ubo;
       void main() {
         texture(sampler2D(my_tex,my_sam),vec2(1.0));
         vec4 t;
         sparseImageLoadARB(my_img,ivec2(0),t);
         imageLoad(my_imbuf,42);
         float x = my_ubo.x;
       })"";

// A GLSL vertex shader with a weirdly packed block.
const char kGlslShaderWeirdPacking[] =
    R""(#version 450
       layout(set=0, binding=0)
       buffer B { float x; vec3 foo; } my_ssbo;
       void main() { my_ssbo.x = 1.0; })"";

// A HLSL fragment shader with a weirdly packed block.
const char kHlslFragShaderWithRegisters[] =
    R""(Buffer<float> t4 : register(t4);
       Buffer<float> t5 : register(t5);
       float4 main() : SV_Target0 {
         return float4(t4.Load(0) + t5.Load(1));
       })"";

// A GLSL compute shader using a regular barrier.
const char kGlslShaderComputeBarrier[] =
    R""(#version 450
       void main() { barrier(); })"";

// A GLSL compute shader using the Subgroups feature.
const char kGlslShaderComputeSubgroupBarrier[] =
    R""(#version 450
       #extension GL_KHR_shader_subgroup_basic : enable
       void main() { subgroupBarrier(); })"";

// A GLSL task shader using a regular barrier.
const char kGlslShaderTaskBarrier[] =
    R""(#version 450
       #extension GL_NV_mesh_shader : enable
       layout(local_size_x = 32) in;
       void main() { barrier(); })"";

// A GLSL task shader using the Subgroups feature.
const char kGlslShaderTaskSubgroupBarrier[] =
    R""(#version 450
       #extension GL_NV_mesh_shader : enable
       #extension GL_KHR_shader_subgroup_basic : enable
       layout(local_size_x = 32) in;
       void main() { subgroupBarrier(); })"";

// A GLSL mesh shader using a regular barrier.
const char kGlslShaderMeshBarrier[] =
    R""(#version 450
       #extension GL_NV_mesh_shader : enable
       layout(local_size_x = 32) in;
       layout(max_vertices=81) out;
       layout(max_primitives=32) out;
       layout(triangles) out;
       void main() { barrier(); })"";

// A GLSL mesh shader using the Subgroups feature.
const char kGlslShaderMeshSubgroupBarrier[] =
    R""(#version 450
       #extension GL_NV_mesh_shader : enable
       #extension GL_KHR_shader_subgroup_basic : enable
       layout(local_size_x = 32) in;
       layout(max_vertices=81) out;
       layout(max_primitives=32) out;
       layout(triangles) out;
       void main() { subgroupBarrier(); })"";

const char kGlslMultipleFnShader[] =
    R""(#version 450
       layout(location=0) flat in  int inVal;
       layout(location=0)      out int outVal;
       int foo(int a) { return a; }
       void main() { outVal = foo(inVal); })"";

const char kHlslShaderWithCounterBuffer[] =
    R""(RWStructuredBuffer<uint> Ainc;
       float4 main() : SV_Target0 {
         return float4(Ainc.IncrementCounter(), 0, 0, 0);
       })"";

const char kHlslWaveActiveSumeComputeShader[] =
  R""(struct S { uint val; uint result; };

     [[vk::binding(0,0)]]
     RWStructuredBuffer<S> MyBuffer;

     [numthreads(32, 1, 1)]
     void main(uint3 id : SV_DispatchThreadID) {
       MyBuffer[id.x].result = WaveActiveSum(MyBuffer[id.x].val);
     })"";

const char kHlslMemLayoutResourceSelect[] =
    R""(cbuffer Foo { float a; float3 b; }

       [[vk::binding(0,0)]]
       Texture2D Tex;
       [[vk::binding(1,0)]]
       SamplerState Sampler1;
       [[vk::binding(2,0)]]
       SamplerState Sampler2;

       static const int val = 42;

       float4 main() : SV_Target {
         SamplerState samp;

         if (val > 5)
           samp = Sampler1;
         else
           samp = Sampler2;

         return Tex.Sample(samp, float2(0.5, 0.5)) + float4(a, b);
       })"";

const char kGlslShaderWithClamp[] =
    R""(#version 450
    layout(location=0) in vec4 i;
    layout(location=0) out vec4 o;
    void main() { o = clamp(i, vec4(0.5), vec4(1.0)); }
    )"";

#ifdef __cplusplus
}
#endif  // __cplusplus

#endif  // COMMON_SHADERS_FOR_TESTS_H_
",c++
"#include <stdio.h>

int main () {
    int a,b,c;
    char atto1[10][10]= {""zero"",""one"",""two"",""three"",""four"",""five"",""six"",""seven"",""eight"",""nine""};
    char atto2[10][10]= {""ten"",""eleven"",""twelve"",""thirteen"",""fourteen"",""fifteen"",""sixteen"",""seventeen"",""eighteen"",""nineteen""};
    char atto3[ 8][10]= {""twenty"", ""thirty"", ""forty"", ""fifty"", ""sixty"", ""seventy"", ""eighty"", ""ninety""};

    scanf(""%d"", &a);
    b=a/10;

    if (b==0) printf(""%s"", atto1[a]);
    else if(b==1) printf(""%s"", atto2[a-10]);
    else {
        c = a%10;
        if(!c) printf(""%s"", atto3[b-2]);
        else {
            printf(""%s"", atto3[b-2]);
            printf(""-"");
            printf(""%s"", atto1[c]);
        }
    }


    return 0;
}

",c++
"/*  Problem Statement: https://www.spoj.com/problems/ACODE/
 *  Author: striker
*/

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

#define MAX_STRING_LENGTH 50001
#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr. ""Line number: %u: Constraints not satisfied for the <%s> variable i.e. %s\n"", __LINE__, #variable, #constraints)

enum alphabet_mapping {A = 1, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z};

static ull_t compute_number_of_decodings(char[]);

int main(void) {
    /*
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    */
    while(true) {
        char encoded_data[MAX_STRING_LENGTH];
        scanf(""%s"", encoded_data);
        if(!strcmp(encoded_data, ""0"")) {
            break;
        }
        printf(""%llu\n"", compute_number_of_decodings(encoded_data));
    }
    return EXIT_SUCCESS;
}

static ull_t compute_number_of_decodings(char encoded_data[]) {
    int data_len = strlen(encoded_data);
    ull_t cache_solutions[data_len];
    memset(cache_solutions, 0, data_len * sizeof(ull_t));
    for(int end = data_len - 1, i = 0; end >= 0; --end, ++i) {
        if(end == data_len - 1) {
            if('0' == encoded_data[end]) {
                cache_solutions[i] = 0;
            } else {
                cache_solutions[i] = 1;
            }
        } else {
            int valid_num = ((encoded_data[end] - '0') * 10) + encoded_data[end + 1] - '0';
            if('0' != encoded_data[end]) {
                cache_solutions[i] = cache_solutions[i - 1];
                if(valid_num >= J  && valid_num <= Z) {
                    if(end == data_len - 2) {
                        cache_solutions[i]++;
                    } else {
                        cache_solutions[i] += cache_solutions[i - 2];
                    }
                }
            }
        }
    }
    return cache_solutions[data_len - 1];
}

",c++
"#include <stdio.h>

int main (void) {
    int atto[4],i,j,k,l=0,m=0,n=0;

    scanf(""%d %d %d %d"", &atto[0],&atto[1],&atto[2],&atto[3]);

    // bubble sort
    for(i=0; i<4; i++) {
        for(j=i+1; j<4; j++) {
            if(atto[i]<atto[j]) {
                k=atto[i];
                atto[i]=atto[j];
                atto[j]=k;
            }
        }
    }

    for(i=0; i<2; i++) {
        if(atto[i] < atto[i+1]+atto[i+2]) l++;
        else if(atto[i] == atto[i+1]+atto[i+2]) m++;
        else n++;
    }

    if(l>0) printf(""TRIANGLE"");
    else if(m>0) printf(""SEGMENT"");
    else printf(""IMPOSSIBLE"");

    return 0;
}
",c++
"/*  Problem Statement: Refer to the readme.md in this directory.
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<stdbool.h>
#include<string.h>
#include<assert.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

static const bool check_sorted(const int *const,unsigned int);
static void merge_sort_int_sequence(int *const,unsigned int,unsigned int);
static void merge_int_sequence(int *const,unsigned int,unsigned int,unsigned int);
static void rearrange_int_sequence(int *const,unsigned int);
static void display_sequence(const int *const,unsigned int);

int main(void) {
    unsigned int n;
    // printf(""Enter the length of the sequence\n"");
    scanf(""%u"", &n);
    assert(n > 0);
    int sequence[n];
    // printf(""Enter the sequence\n"");
    for(unsigned int i = 0; i < n; ++i) {
        scanf(""%d"", &sequence[i]);
    }
    if(!check_sorted(sequence,n)) {
        merge_sort_int_sequence(sequence,0,(n - 1));
    }
    rearrange_int_sequence(sequence,n);
    // printf(""Sequence after re-arrangement\n"");
    display_sequence(sequence,n);
    return EXIT_SUCCESS;
}

static const bool check_sorted(const int *const data,unsigned int n) {
    bool is_sorted = true;
    for(unsigned int i = 0; i < (n - 1); ++i) {
        if(data[i] > data[i + 1]) {
            is_sorted = false;
            break;
        }
    }
    return is_sorted;
}

static void merge_sort_int_sequence(int *const data,unsigned int start,unsigned int end) {
    if(start < end) {
        unsigned int mid = ((end - start) >> 1) + start;
        merge_sort_int_sequence(data,start,mid);
        merge_sort_int_sequence(data,(mid + 1),end);
        merge_int_sequence(data,start,mid,end);
    }
}

static void merge_int_sequence(int *const data,unsigned int start,unsigned int mid,unsigned int end) {
    unsigned left_size = (mid - start) + 1;
    int left_data[left_size];
    memmove(left_data,&data[start],(sizeof(int) * left_size));
    unsigned right_size = end - mid;
    int right_data[right_size];
    memmove(right_data,&data[mid + 1],(sizeof(int) * right_size));
    for(unsigned int k = start, i = 0, j = 0; k <= end; ++k) {
        if(i == left_size) {
            data[k] = right_data[j++];
        } else if(j == right_size) {
            data[k] = left_data[i++];
        } else if(left_data[i] < right_data[j]) {
            data[k] = left_data[i++];
        } else {
            data[k] = right_data[j++];
        }
    }
}

static void rearrange_int_sequence(int *const data,unsigned int n) {
    unsigned int even_count,odd_count;
    even_count = odd_count = 0;
    for(unsigned int i = 0; i < n; ++i) {
        if(data[i] & 1) {
            ++odd_count;
        } else {
            ++even_count;
        }
    }
    int even_number_sequence[even_count],odd_number_sequence[odd_count];
    for(unsigned int i = 0, j = 0, k = 0; (i < n && j <= odd_count && k <= even_count); ++i) {
        if(data[i] & 1) {
            odd_number_sequence[j++] = data[i];
        } else {
            even_number_sequence[k++] = data[i];
        }
    }
    bool even_odd = false;
    for(unsigned int i = 0, j = 0, k = 0; k < n; ++k) {
        if(i == even_count) {
            data[k] = odd_number_sequence[j++];
        } else if(j == odd_count) {
            data[k] = even_number_sequence[i++];
        } else if(!k) {
            if(even_number_sequence[i] < odd_number_sequence[j]) {
                data[k] = even_number_sequence[i++];
                even_odd = true; 
            } else {
                data[k] = odd_number_sequence[j++];
            }
        } else if(!even_odd) {
            if(k & 1) {
                data[k] = even_number_sequence[i++];
            } else {
                data[k] = odd_number_sequence[j++];
            }
        } else {
            if(k & 1) {
                data[k] = odd_number_sequence[j++];
            } else {
                data[k] = even_number_sequence[i++];
            }
        }
    }
}

static void display_sequence(const int *const data,unsigned int n) {
    for(unsigned int i = 0; i < n; ++i) {
        printf(""%d "", data[i]);
    }
    printf(""\n"");
}",c++
"/**
    This code is based on the glslang_c_interface implementation by Viktor Latypov
**/

/**
BSD 2-Clause License

Copyright (c) 2019, Viktor Latypov
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
**/

#ifndef C_SHADER_TYPES_H_INCLUDED
#define C_SHADER_TYPES_H_INCLUDED

#define LAST_ELEMENT_MARKER(x) x

/* EShLanguage counterpart */
typedef enum {
    GLSLANG_STAGE_VERTEX,
    GLSLANG_STAGE_TESSCONTROL,
    GLSLANG_STAGE_TESSEVALUATION,
    GLSLANG_STAGE_GEOMETRY,
    GLSLANG_STAGE_FRAGMENT,
    GLSLANG_STAGE_COMPUTE,
    GLSLANG_STAGE_RAYGEN_NV,
    GLSLANG_STAGE_INTERSECT_NV,
    GLSLANG_STAGE_ANYHIT_NV,
    GLSLANG_STAGE_CLOSESTHIT_NV,
    GLSLANG_STAGE_MISS_NV,
    GLSLANG_STAGE_CALLABLE_NV,
    GLSLANG_STAGE_TASK_NV,
    GLSLANG_STAGE_MESH_NV,
    LAST_ELEMENT_MARKER(GLSLANG_STAGE_COUNT),
} glslang_stage_t; // would be better as stage, but this is ancient now

/* EShLanguageMask counterpart */
typedef enum {
    GLSLANG_STAGE_VERTEX_MASK = (1 << GLSLANG_STAGE_VERTEX),
    GLSLANG_STAGE_TESSCONTROL_MASK = (1 << GLSLANG_STAGE_TESSCONTROL),
    GLSLANG_STAGE_TESSEVALUATION_MASK = (1 << GLSLANG_STAGE_TESSEVALUATION),
    GLSLANG_STAGE_GEOMETRY_MASK = (1 << GLSLANG_STAGE_GEOMETRY),
    GLSLANG_STAGE_FRAGMENT_MASK = (1 << GLSLANG_STAGE_FRAGMENT),
    GLSLANG_STAGE_COMPUTE_MASK = (1 << GLSLANG_STAGE_COMPUTE),
    GLSLANG_STAGE_RAYGEN_NV_MASK = (1 << GLSLANG_STAGE_RAYGEN_NV),
    GLSLANG_STAGE_INTERSECT_NV_MASK = (1 << GLSLANG_STAGE_INTERSECT_NV),
    GLSLANG_STAGE_ANYHIT_NV_MASK = (1 << GLSLANG_STAGE_ANYHIT_NV),
    GLSLANG_STAGE_CLOSESTHIT_NV_MASK = (1 << GLSLANG_STAGE_CLOSESTHIT_NV),
    GLSLANG_STAGE_MISS_NV_MASK = (1 << GLSLANG_STAGE_MISS_NV),
    GLSLANG_STAGE_CALLABLE_NV_MASK = (1 << GLSLANG_STAGE_CALLABLE_NV),
    GLSLANG_STAGE_TASK_NV_MASK = (1 << GLSLANG_STAGE_TASK_NV),
    GLSLANG_STAGE_MESH_NV_MASK = (1 << GLSLANG_STAGE_MESH_NV),
    LAST_ELEMENT_MARKER(GLSLANG_STAGE_MASK_COUNT),
} glslang_stage_mask_t;

/* EShSource counterpart */
typedef enum {
    GLSLANG_SOURCE_NONE,
    GLSLANG_SOURCE_GLSL,
    GLSLANG_SOURCE_HLSL,
    LAST_ELEMENT_MARKER(GLSLANG_SOURCE_COUNT),
} glslang_source_t;

/* EShClient counterpart */
typedef enum {
    GLSLANG_CLIENT_NONE,
    GLSLANG_CLIENT_VULKAN,
    GLSLANG_CLIENT_OPENGL,
    LAST_ELEMENT_MARKER(GLSLANG_CLIENT_COUNT),
} glslang_client_t;

/* EShTargetLanguage counterpart */
typedef enum {
    GLSLANG_TARGET_NONE,
    GLSLANG_TARGET_SPV,
    LAST_ELEMENT_MARKER(GLSLANG_TARGET_COUNT),
} glslang_target_language_t;

/* SH_TARGET_ClientVersion counterpart */
typedef enum {
    GLSLANG_TARGET_VULKAN_1_0 = (1 << 22),
    GLSLANG_TARGET_VULKAN_1_1 = (1 << 22) | (1 << 12),
    GLSLANG_TARGET_VULKAN_1_2 = (1 << 22) | (2 << 12),
    GLSLANG_TARGET_VULKAN_1_3 = (1 << 22) | (3 << 12),
    GLSLANG_TARGET_OPENGL_450 = 450,
    LAST_ELEMENT_MARKER(GLSLANG_TARGET_CLIENT_VERSION_COUNT = 5),
} glslang_target_client_version_t;

/* SH_TARGET_LanguageVersion counterpart */
typedef enum {
    GLSLANG_TARGET_SPV_1_0 = (1 << 16),
    GLSLANG_TARGET_SPV_1_1 = (1 << 16) | (1 << 8),
    GLSLANG_TARGET_SPV_1_2 = (1 << 16) | (2 << 8),
    GLSLANG_TARGET_SPV_1_3 = (1 << 16) | (3 << 8),
    GLSLANG_TARGET_SPV_1_4 = (1 << 16) | (4 << 8),
    GLSLANG_TARGET_SPV_1_5 = (1 << 16) | (5 << 8),
    GLSLANG_TARGET_SPV_1_6 = (1 << 16) | (6 << 8),
    LAST_ELEMENT_MARKER(GLSLANG_TARGET_LANGUAGE_VERSION_COUNT = 7),
} glslang_target_language_version_t;

/* EShExecutable counterpart */
typedef enum { GLSLANG_EX_VERTEX_FRAGMENT, GLSLANG_EX_FRAGMENT } glslang_executable_t;

// EShOptimizationLevel counterpart
// This enum is not used in the current C interface, but could be added at a later date.
// GLSLANG_OPT_NONE is the current default.
typedef enum {
    GLSLANG_OPT_NO_GENERATION,
    GLSLANG_OPT_NONE,
    GLSLANG_OPT_SIMPLE,
    GLSLANG_OPT_FULL,
    LAST_ELEMENT_MARKER(GLSLANG_OPT_LEVEL_COUNT),
} glslang_optimization_level_t;

/* EShTextureSamplerTransformMode counterpart */
typedef enum {
    GLSLANG_TEX_SAMP_TRANS_KEEP,
    GLSLANG_TEX_SAMP_TRANS_UPGRADE_TEXTURE_REMOVE_SAMPLER,
    LAST_ELEMENT_MARKER(GLSLANG_TEX_SAMP_TRANS_COUNT),
} glslang_texture_sampler_transform_mode_t;

/* EShMessages counterpart */
typedef enum {
    GLSLANG_MSG_DEFAULT_BIT = 0,
    GLSLANG_MSG_RELAXED_ERRORS_BIT = (1 << 0),
    GLSLANG_MSG_SUPPRESS_WARNINGS_BIT = (1 << 1),
    GLSLANG_MSG_AST_BIT = (1 << 2),
    GLSLANG_MSG_SPV_RULES_BIT = (1 << 3),
    GLSLANG_MSG_VULKAN_RULES_BIT = (1 << 4),
    GLSLANG_MSG_ONLY_PREPROCESSOR_BIT = (1 << 5),
    GLSLANG_MSG_READ_HLSL_BIT = (1 << 6),
    GLSLANG_MSG_CASCADING_ERRORS_BIT = (1 << 7),
    GLSLANG_MSG_KEEP_UNCALLED_BIT = (1 << 8),
    GLSLANG_MSG_HLSL_OFFSETS_BIT = (1 << 9),
    GLSLANG_MSG_DEBUG_INFO_BIT = (1 << 10),
    GLSLANG_MSG_HLSL_ENABLE_16BIT_TYPES_BIT = (1 << 11),
    GLSLANG_MSG_HLSL_LEGALIZATION_BIT = (1 << 12),
    GLSLANG_MSG_HLSL_DX9_COMPATIBLE_BIT = (1 << 13),
    GLSLANG_MSG_BUILTIN_SYMBOL_TABLE_BIT = (1 << 14),
    GLSLANG_MSG_ENHANCED = (1 << 15),
    LAST_ELEMENT_MARKER(GLSLANG_MSG_COUNT),
} glslang_messages_t;

/* EShReflectionOptions counterpart */
typedef enum {
    GLSLANG_REFLECTION_DEFAULT_BIT = 0,
    GLSLANG_REFLECTION_STRICT_ARRAY_SUFFIX_BIT = (1 << 0),
    GLSLANG_REFLECTION_BASIC_ARRAY_SUFFIX_BIT = (1 << 1),
    GLSLANG_REFLECTION_INTERMEDIATE_IOO_BIT = (1 << 2),
    GLSLANG_REFLECTION_SEPARATE_BUFFERS_BIT = (1 << 3),
    GLSLANG_REFLECTION_ALL_BLOCK_VARIABLES_BIT = (1 << 4),
    GLSLANG_REFLECTION_UNWRAP_IO_BLOCKS_BIT = (1 << 5),
    GLSLANG_REFLECTION_ALL_IO_VARIABLES_BIT = (1 << 6),
    GLSLANG_REFLECTION_SHARED_STD140_SSBO_BIT = (1 << 7),
    GLSLANG_REFLECTION_SHARED_STD140_UBO_BIT = (1 << 8),
    LAST_ELEMENT_MARKER(GLSLANG_REFLECTION_COUNT),
} glslang_reflection_options_t;

/* EProfile counterpart (from Versions.h) */
typedef enum {
    GLSLANG_BAD_PROFILE = 0,
    GLSLANG_NO_PROFILE = (1 << 0),
    GLSLANG_CORE_PROFILE = (1 << 1),
    GLSLANG_COMPATIBILITY_PROFILE = (1 << 2),
    GLSLANG_ES_PROFILE = (1 << 3),
    LAST_ELEMENT_MARKER(GLSLANG_PROFILE_COUNT),
} glslang_profile_t;

/* Shader options */
typedef enum {
    GLSLANG_SHADER_DEFAULT_BIT = 0,
    GLSLANG_SHADER_AUTO_MAP_BINDINGS = (1 << 0),
    GLSLANG_SHADER_AUTO_MAP_LOCATIONS = (1 << 1),
    GLSLANG_SHADER_VULKAN_RULES_RELAXED = (1 << 2),
    LAST_ELEMENT_MARKER(GLSLANG_SHADER_COUNT),
} glslang_shader_options_t;

/* TResourceType counterpart */
typedef enum {
    GLSLANG_RESOURCE_TYPE_SAMPLER,
    GLSLANG_RESOURCE_TYPE_TEXTURE,
    GLSLANG_RESOURCE_TYPE_IMAGE,
    GLSLANG_RESOURCE_TYPE_UBO,
    GLSLANG_RESOURCE_TYPE_SSBO,
    GLSLANG_RESOURCE_TYPE_UAV,
    LAST_ELEMENT_MARKER(GLSLANG_RESOURCE_TYPE_COUNT),
} glslang_resource_type_t;

#undef LAST_ELEMENT_MARKER

#endif
",c++
"#include <stdio.h>

int main () {
    long long int i,j,m,l[1000];
    int k,n,o;

    scanf(""%I64d"", &i);
    j=i;

    for(n=0,o=0; i ;n++) {
        for(k=0 ; j ; j=j/10) k++;
        for(m=0; k ; k-- ) {
            m = (m*10)+1;
            printf(""%d\n"",m);
        }

        if (i>m) {
            i= i-m;
            l[n]=m;
            o++;
        }
    }

    printf(""%d\n"",m);
    for(n=0 ; l[n]; n++) {
        printf(""%d "", l[n]);
    }


    return 0;
}
",c++
"#include <stdio.h>

int main (void) {

    long long int n,m,a,i,j;
    scanf(""%I64d %I64d %I64d"",&n, &m ,&a);

    if(n%a==0)i=n/a;
    else i=(n/a)+1;

    if(m%a==0)j=m/a;
    else j=(m/a)+1;


    printf(""%I64d"", i*j);

    return 0;
}
",c++
"#include<stdio.h>

int selection_sort(int a[], int n){
    int i, j, temp, min, p;
    for(i=0; i<=n-2; i++){
        min = a[i], p=i;
        for(j=i+1; j<=n-1; j++){
            if(a[j]<min){
                min = a[j];
                p = j;
            }
        }
        temp = a[i];
        a[i] = a[p];
        a[p] = temp;
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    selection_sort(a, 6);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c++
"/*
** Copyright (c) 2013 The Khronos Group Inc.
**
** Permission is hereby granted, free of charge, to any person obtaining a
** copy of this software and/or associated documentation files (the
** ""Materials""), to deal in the Materials without restriction, including
** without limitation the rights to use, copy, modify, merge, publish,
** distribute, sublicense, and/or sell copies of the Materials, and to
** permit persons to whom the Materials are furnished to do so, subject to
** the following conditions:
**
** The above copyright notice and this permission notice shall be included
** in all copies or substantial portions of the Materials.
**
** THE MATERIALS ARE PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
** EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
** MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
** IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
** CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
** TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
** MATERIALS OR THE USE OR OTHER DEALINGS IN THE MATERIALS.
*/

#pragma once

#define GL_FLOAT                          0x1406
#define GL_FLOAT_VEC2                     0x8B50
#define GL_FLOAT_VEC3                     0x8B51
#define GL_FLOAT_VEC4                     0x8B52

#define GL_DOUBLE                         0x140A
#define GL_DOUBLE_VEC2                    0x8FFC
#define GL_DOUBLE_VEC3                    0x8FFD
#define GL_DOUBLE_VEC4                    0x8FFE

#define GL_INT                            0x1404
#define GL_INT_VEC2                       0x8B53
#define GL_INT_VEC3                       0x8B54
#define GL_INT_VEC4                       0x8B55

#define GL_UNSIGNED_INT                   0x1405
#define GL_UNSIGNED_INT_VEC2              0x8DC6
#define GL_UNSIGNED_INT_VEC3              0x8DC7
#define GL_UNSIGNED_INT_VEC4              0x8DC8

#define GL_INT64_ARB                      0x140E
#define GL_INT64_VEC2_ARB                 0x8FE9
#define GL_INT64_VEC3_ARB                 0x8FEA
#define GL_INT64_VEC4_ARB                 0x8FEB

#define GL_UNSIGNED_INT64_ARB             0x140F
#define GL_UNSIGNED_INT64_VEC2_ARB        0x8FF5
#define GL_UNSIGNED_INT64_VEC3_ARB        0x8FF6
#define GL_UNSIGNED_INT64_VEC4_ARB        0x8FF7
#define GL_UNSIGNED_INT16_VEC2_NV         0x8FF1
#define GL_UNSIGNED_INT16_VEC3_NV         0x8FF2
#define GL_UNSIGNED_INT16_VEC4_NV         0x8FF3

#define GL_INT16_NV                       0x8FE4
#define GL_INT16_VEC2_NV                  0x8FE5
#define GL_INT16_VEC3_NV                  0x8FE6
#define GL_INT16_VEC4_NV                  0x8FE7

#define GL_BOOL                           0x8B56
#define GL_BOOL_VEC2                      0x8B57
#define GL_BOOL_VEC3                      0x8B58
#define GL_BOOL_VEC4                      0x8B59

#define GL_FLOAT_MAT2                     0x8B5A
#define GL_FLOAT_MAT3                     0x8B5B
#define GL_FLOAT_MAT4                     0x8B5C
#define GL_FLOAT_MAT2x3                   0x8B65
#define GL_FLOAT_MAT2x4                   0x8B66
#define GL_FLOAT_MAT3x2                   0x8B67
#define GL_FLOAT_MAT3x4                   0x8B68
#define GL_FLOAT_MAT4x2                   0x8B69
#define GL_FLOAT_MAT4x3                   0x8B6A

#define GL_DOUBLE_MAT2                    0x8F46
#define GL_DOUBLE_MAT3                    0x8F47
#define GL_DOUBLE_MAT4                    0x8F48
#define GL_DOUBLE_MAT2x3                  0x8F49
#define GL_DOUBLE_MAT2x4                  0x8F4A
#define GL_DOUBLE_MAT3x2                  0x8F4B
#define GL_DOUBLE_MAT3x4                  0x8F4C
#define GL_DOUBLE_MAT4x2                  0x8F4D
#define GL_DOUBLE_MAT4x3                  0x8F4E

// Those constants are borrowed from extension NV_gpu_shader5
#define GL_FLOAT16_NV                     0x8FF8
#define GL_FLOAT16_VEC2_NV                0x8FF9
#define GL_FLOAT16_VEC3_NV                0x8FFA
#define GL_FLOAT16_VEC4_NV                0x8FFB

#define GL_FLOAT16_MAT2_AMD               0x91C5
#define GL_FLOAT16_MAT3_AMD               0x91C6
#define GL_FLOAT16_MAT4_AMD               0x91C7
#define GL_FLOAT16_MAT2x3_AMD             0x91C8
#define GL_FLOAT16_MAT2x4_AMD             0x91C9
#define GL_FLOAT16_MAT3x2_AMD             0x91CA
#define GL_FLOAT16_MAT3x4_AMD             0x91CB
#define GL_FLOAT16_MAT4x2_AMD             0x91CC
#define GL_FLOAT16_MAT4x3_AMD             0x91CD

#define GL_SAMPLER_1D                     0x8B5D
#define GL_SAMPLER_2D                     0x8B5E
#define GL_SAMPLER_3D                     0x8B5F
#define GL_SAMPLER_CUBE                   0x8B60
#define GL_SAMPLER_BUFFER                 0x8DC2
#define GL_SAMPLER_1D_ARRAY               0x8DC0
#define GL_SAMPLER_2D_ARRAY               0x8DC1
#define GL_SAMPLER_1D_ARRAY_SHADOW        0x8DC3
#define GL_SAMPLER_2D_ARRAY_SHADOW        0x8DC4
#define GL_SAMPLER_CUBE_SHADOW            0x8DC5
#define GL_SAMPLER_1D_SHADOW              0x8B61
#define GL_SAMPLER_2D_SHADOW              0x8B62
#define GL_SAMPLER_2D_RECT                0x8B63
#define GL_SAMPLER_2D_RECT_SHADOW         0x8B64
#define GL_SAMPLER_2D_MULTISAMPLE         0x9108
#define GL_SAMPLER_2D_MULTISAMPLE_ARRAY   0x910B
#define GL_SAMPLER_CUBE_MAP_ARRAY         0x900C
#define GL_SAMPLER_CUBE_MAP_ARRAY_SHADOW  0x900D
#define GL_SAMPLER_CUBE_MAP_ARRAY_ARB     0x900C
#define GL_SAMPLER_CUBE_MAP_ARRAY_SHADOW_ARB 0x900D

#define GL_FLOAT16_SAMPLER_1D_AMD                       0x91CE
#define GL_FLOAT16_SAMPLER_2D_AMD                       0x91CF
#define GL_FLOAT16_SAMPLER_3D_AMD                       0x91D0
#define GL_FLOAT16_SAMPLER_CUBE_AMD                     0x91D1
#define GL_FLOAT16_SAMPLER_2D_RECT_AMD                  0x91D2
#define GL_FLOAT16_SAMPLER_1D_ARRAY_AMD                 0x91D3
#define GL_FLOAT16_SAMPLER_2D_ARRAY_AMD                 0x91D4
#define GL_FLOAT16_SAMPLER_CUBE_MAP_ARRAY_AMD           0x91D5
#define GL_FLOAT16_SAMPLER_BUFFER_AMD                   0x91D6
#define GL_FLOAT16_SAMPLER_2D_MULTISAMPLE_AMD           0x91D7
#define GL_FLOAT16_SAMPLER_2D_MULTISAMPLE_ARRAY_AMD     0x91D8

#define GL_FLOAT16_SAMPLER_1D_SHADOW_AMD                0x91D9
#define GL_FLOAT16_SAMPLER_2D_SHADOW_AMD                0x91DA
#define GL_FLOAT16_SAMPLER_2D_RECT_SHADOW_AMD           0x91DB
#define GL_FLOAT16_SAMPLER_1D_ARRAY_SHADOW_AMD          0x91DC
#define GL_FLOAT16_SAMPLER_2D_ARRAY_SHADOW_AMD          0x91DD
#define GL_FLOAT16_SAMPLER_CUBE_SHADOW_AMD              0x91DE
#define GL_FLOAT16_SAMPLER_CUBE_MAP_ARRAY_SHADOW_AMD    0x91DF

#define GL_FLOAT16_IMAGE_1D_AMD                         0x91E0
#define GL_FLOAT16_IMAGE_2D_AMD                         0x91E1
#define GL_FLOAT16_IMAGE_3D_AMD                         0x91E2
#define GL_FLOAT16_IMAGE_2D_RECT_AMD                    0x91E3
#define GL_FLOAT16_IMAGE_CUBE_AMD                       0x91E4
#define GL_FLOAT16_IMAGE_1D_ARRAY_AMD                   0x91E5
#define GL_FLOAT16_IMAGE_2D_ARRAY_AMD                   0x91E6
#define GL_FLOAT16_IMAGE_CUBE_MAP_ARRAY_AMD             0x91E7
#define GL_FLOAT16_IMAGE_BUFFER_AMD                     0x91E8
#define GL_FLOAT16_IMAGE_2D_MULTISAMPLE_AMD             0x91E9
#define GL_FLOAT16_IMAGE_2D_MULTISAMPLE_ARRAY_AMD       0x91EA

#define GL_INT_SAMPLER_1D                 0x8DC9
#define GL_INT_SAMPLER_2D                 0x8DCA
#define GL_INT_SAMPLER_3D                 0x8DCB
#define GL_INT_SAMPLER_CUBE               0x8DCC
#define GL_INT_SAMPLER_1D_ARRAY           0x8DCE
#define GL_INT_SAMPLER_2D_ARRAY           0x8DCF
#define GL_INT_SAMPLER_2D_RECT            0x8DCD
#define GL_INT_SAMPLER_BUFFER             0x8DD0
#define GL_INT_SAMPLER_2D_MULTISAMPLE     0x9109
#define GL_INT_SAMPLER_2D_MULTISAMPLE_ARRAY 0x910C
#define GL_INT_SAMPLER_CUBE_MAP_ARRAY     0x900E
#define GL_INT_SAMPLER_CUBE_MAP_ARRAY_ARB 0x900E

#define GL_UNSIGNED_INT_SAMPLER_1D        0x8DD1
#define GL_UNSIGNED_INT_SAMPLER_2D        0x8DD2
#define GL_UNSIGNED_INT_SAMPLER_3D        0x8DD3
#define GL_UNSIGNED_INT_SAMPLER_CUBE      0x8DD4
#define GL_UNSIGNED_INT_SAMPLER_1D_ARRAY  0x8DD6
#define GL_UNSIGNED_INT_SAMPLER_2D_ARRAY  0x8DD7
#define GL_UNSIGNED_INT_SAMPLER_2D_RECT   0x8DD5
#define GL_UNSIGNED_INT_SAMPLER_BUFFER    0x8DD8
#define GL_UNSIGNED_INT_SAMPLER_2D_MULTISAMPLE_ARRAY 0x910D
#define GL_UNSIGNED_INT_SAMPLER_CUBE_MAP_ARRAY 0x900F
#define GL_UNSIGNED_INT_SAMPLER_CUBE_MAP_ARRAY_ARB 0x900F
#define GL_UNSIGNED_INT_SAMPLER_2D_MULTISAMPLE 0x910A

#define GL_IMAGE_1D                       0x904C
#define GL_IMAGE_2D                       0x904D
#define GL_IMAGE_3D                       0x904E
#define GL_IMAGE_2D_RECT                  0x904F
#define GL_IMAGE_CUBE                     0x9050
#define GL_IMAGE_BUFFER                   0x9051
#define GL_IMAGE_1D_ARRAY                 0x9052
#define GL_IMAGE_2D_ARRAY                 0x9053
#define GL_IMAGE_CUBE_MAP_ARRAY           0x9054
#define GL_IMAGE_2D_MULTISAMPLE           0x9055
#define GL_IMAGE_2D_MULTISAMPLE_ARRAY     0x9056
#define GL_INT_IMAGE_1D                   0x9057
#define GL_INT_IMAGE_2D                   0x9058
#define GL_INT_IMAGE_3D                   0x9059
#define GL_INT_IMAGE_2D_RECT              0x905A
#define GL_INT_IMAGE_CUBE                 0x905B
#define GL_INT_IMAGE_BUFFER               0x905C
#define GL_INT_IMAGE_1D_ARRAY             0x905D
#define GL_INT_IMAGE_2D_ARRAY             0x905E
#define GL_INT_IMAGE_CUBE_MAP_ARRAY       0x905F
#define GL_INT_IMAGE_2D_MULTISAMPLE       0x9060
#define GL_INT_IMAGE_2D_MULTISAMPLE_ARRAY 0x9061
#define GL_UNSIGNED_INT_IMAGE_1D          0x9062
#define GL_UNSIGNED_INT_IMAGE_2D          0x9063
#define GL_UNSIGNED_INT_IMAGE_3D          0x9064
#define GL_UNSIGNED_INT_IMAGE_2D_RECT     0x9065
#define GL_UNSIGNED_INT_IMAGE_CUBE        0x9066
#define GL_UNSIGNED_INT_IMAGE_BUFFER      0x9067
#define GL_UNSIGNED_INT_IMAGE_1D_ARRAY    0x9068
#define GL_UNSIGNED_INT_IMAGE_2D_ARRAY    0x9069
#define GL_UNSIGNED_INT_IMAGE_CUBE_MAP_ARRAY 0x906A
#define GL_UNSIGNED_INT_IMAGE_2D_MULTISAMPLE 0x906B
#define GL_UNSIGNED_INT_IMAGE_2D_MULTISAMPLE_ARRAY 0x906C

#define GL_UNSIGNED_INT_ATOMIC_COUNTER    0x92DB
",c++
"/*
 * Problem Statement: https://www.spoj.com/problems/FENCE1/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

int main(void) {
    while(true) {
        int l;
        if(1 != scanf(""%d"", &l)) {
            SCANF_READ_ERROR(1);
        }
        if(!l) {
            break;
        }
        printf(""%0.2f\n"", (l * l) / (2 * PI));
    }
    return EXIT_SUCCESS;
}
",c++
"#include <stdio.h>

int main (void) {
    char str[200001];

    long long int a, b, c=0, d=0, e;

    scanf(""%I64d"", &a);
    gets(str);
    gets(str);

    for(b=0; b<a; b++) {
        if(str[b]=='1') c++;
        else d++;
    }


    if(c>d) printf(""%I64d\n"",c-d);
    else printf(""%I64d\n"",d-c);

    return 0;
}
",c++
"/*
** Copyright (c) 2014-2016 The Khronos Group Inc.
**
** Permission is hereby granted, free of charge, to any person obtaining a copy
** of this software and/or associated documentation files (the ""Materials""),
** to deal in the Materials without restriction, including without limitation
** the rights to use, copy, modify, merge, publish, distribute, sublicense,
** and/or sell copies of the Materials, and to permit persons to whom the
** Materials are furnished to do so, subject to the following conditions:
**
** The above copyright notice and this permission notice shall be included in
** all copies or substantial portions of the Materials.
**
** MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
** STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
** HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/
**
** THE MATERIALS ARE PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS
** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
** THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
** FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
** IN THE MATERIALS.
*/

#ifndef GLSLextEXT_H
#define GLSLextEXT_H

static const int GLSLextEXTVersion = 100;
static const int GLSLextEXTRevision = 2;

static const char* const E_SPV_EXT_shader_stencil_export        = ""SPV_EXT_shader_stencil_export"";
static const char* const E_SPV_EXT_shader_viewport_index_layer  = ""SPV_EXT_shader_viewport_index_layer"";
static const char* const E_SPV_EXT_fragment_fully_covered = ""SPV_EXT_fragment_fully_covered"";
static const char* const E_SPV_EXT_fragment_invocation_density = ""SPV_EXT_fragment_invocation_density"";
static const char* const E_SPV_EXT_demote_to_helper_invocation = ""SPV_EXT_demote_to_helper_invocation"";
static const char* const E_SPV_EXT_shader_atomic_float_add = ""SPV_EXT_shader_atomic_float_add"";
static const char* const E_SPV_EXT_shader_atomic_float16_add = ""SPV_EXT_shader_atomic_float16_add"";
static const char* const E_SPV_EXT_shader_atomic_float_min_max = ""SPV_EXT_shader_atomic_float_min_max"";
static const char* const E_SPV_EXT_shader_image_int64 = ""SPV_EXT_shader_image_int64"";

#endif  // #ifndef GLSLextEXT_H
",c++
"#include <stdio.h>
#include <string.h>

int main () {
    char str1[10] = ""CODEFORCES"";
    char str2[100];

    int i=0,j=0,k=0;

    scanf(""%s"", str2);

    if(strcmp(str1,str2)) {
        for( ; i<10; i++) {
            for( ; j<101 ; j++) {
                if(str1[i] == str2[j]) {
                    k++;
                    break;
                }
            }
        }
        if(k == 10) printf(""YES"");
        else printf(""NO"");
    }

    else printf(""NO"");

    return 0;
}
",c++
"#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#define MAX 5

struct vertex{
    char lable;
    int visited;
};

int queue[MAX];
int front = 0;
int rear = -1;

struct vertex * vertices[MAX];
int adjmatrix[MAX][MAX];
int vertexcount = 0;

void insert(int data){
    queue[++rear] = data;
}

int delete(){
    return queue[front++];
}

bool isQueueEmpty(){
    return front == -1;
}

void addVertex(char data){
    struct vertex * v = (struct vertex *) malloc(sizeof(struct vertex));
    v->lable = data;
    v->visited = false;
    vertices[vertexcount++] = v;
}

void addEdge(int start, int end){
    adjmatrix[start][end] = 1;
    adjmatrix[end][start] = 1;
}

void displayVertex(int vertexIndex) {
   printf(""%c "",vertices[vertexIndex]->lable);
}

int getadjecentVertex(int vertexIndex){
    for(int i = 0; i<vertexcount; i++) {
      if(adjmatrix[vertexIndex][i] == 1 && vertices[i]->visited == false)
         return i;
    }
    return -1;
}

void breadthFirstSearch() {
   int i;

   vertices[0]->visited = true;

   displayVertex(0);   

   //insert vertex index in queue
   insert(0);
   int unvisitedVertex;

   while(!isQueueEmpty()) {
      int tempVertex = delete();   
      while((unvisitedVertex = getadjecentVertex(tempVertex)) != -1) {    
         vertices[unvisitedVertex]->visited = true;
         displayVertex(unvisitedVertex);
         insert(unvisitedVertex);               
      }
   }   

   //queue is empty, search is complete, reset the visited flag        
   for(i = 0;i<vertexcount;i++) {
      vertices[i]->visited = false;
   }    
}

int main() {
   int i, j;

   for(i = 0; i<MAX; i++){
        for(j = 0; j<MAX; j++){
           adjmatrix[i][j] = 0;
        }
   }

   addVertex('S');   // 0
   addVertex('A');   // 1
   addVertex('B');   // 2
   addVertex('C');   // 3
   addVertex('D');   // 4
 
   addEdge(0, 1);    // S - A
   addEdge(0, 2);    // S - B
   addEdge(0, 3);    // S - C
   addEdge(1, 4);    // A - D
   addEdge(2, 4);    // B - D
   addEdge(3, 4);    // C - D
	
   printf(""\nBreadth First Search: "");
   
   breadthFirstSearch();

   return 0;
}
",c++
"//
// Copyright (C) 2002-2005  3Dlabs Inc. Ltd.
// Copyright (C) 2013 LunarG, Inc.
//
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions
// are met:
//
//    Redistributions of source code must retain the above copyright
//    notice, this list of conditions and the following disclaimer.
//
//    Redistributions in binary form must reproduce the above
//    copyright notice, this list of conditions and the following
//    disclaimer in the documentation and/or other materials provided
//    with the distribution.
//
//    Neither the name of 3Dlabs Inc. Ltd. nor the names of its
//    contributors may be used to endorse or promote products derived
//    from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
// FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
// COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
// LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
// ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.
//

#ifndef _RESOURCE_LIMITS_INCLUDED_
#define _RESOURCE_LIMITS_INCLUDED_

struct TLimits {
    bool nonInductiveForLoops;
    bool whileLoops;
    bool doWhileLoops;
    bool generalUniformIndexing;
    bool generalAttributeMatrixVectorIndexing;
    bool generalVaryingIndexing;
    bool generalSamplerIndexing;
    bool generalVariableIndexing;
    bool generalConstantMatrixVectorIndexing;
};

struct TBuiltInResource {
    int maxLights;
    int maxClipPlanes;
    int maxTextureUnits;
    int maxTextureCoords;
    int maxVertexAttribs;
    int maxVertexUniformComponents;
    int maxVaryingFloats;
    int maxVertexTextureImageUnits;
    int maxCombinedTextureImageUnits;
    int maxTextureImageUnits;
    int maxFragmentUniformComponents;
    int maxDrawBuffers;
    int maxVertexUniformVectors;
    int maxVaryingVectors;
    int maxFragmentUniformVectors;
    int maxVertexOutputVectors;
    int maxFragmentInputVectors;
    int minProgramTexelOffset;
    int maxProgramTexelOffset;
    int maxClipDistances;
    int maxComputeWorkGroupCountX;
    int maxComputeWorkGroupCountY;
    int maxComputeWorkGroupCountZ;
    int maxComputeWorkGroupSizeX;
    int maxComputeWorkGroupSizeY;
    int maxComputeWorkGroupSizeZ;
    int maxComputeUniformComponents;
    int maxComputeTextureImageUnits;
    int maxComputeImageUniforms;
    int maxComputeAtomicCounters;
    int maxComputeAtomicCounterBuffers;
    int maxVaryingComponents;
    int maxVertexOutputComponents;
    int maxGeometryInputComponents;
    int maxGeometryOutputComponents;
    int maxFragmentInputComponents;
    int maxImageUnits;
    int maxCombinedImageUnitsAndFragmentOutputs;
    int maxCombinedShaderOutputResources;
    int maxImageSamples;
    int maxVertexImageUniforms;
    int maxTessControlImageUniforms;
    int maxTessEvaluationImageUniforms;
    int maxGeometryImageUniforms;
    int maxFragmentImageUniforms;
    int maxCombinedImageUniforms;
    int maxGeometryTextureImageUnits;
    int maxGeometryOutputVertices;
    int maxGeometryTotalOutputComponents;
    int maxGeometryUniformComponents;
    int maxGeometryVaryingComponents;
    int maxTessControlInputComponents;
    int maxTessControlOutputComponents;
    int maxTessControlTextureImageUnits;
    int maxTessControlUniformComponents;
    int maxTessControlTotalOutputComponents;
    int maxTessEvaluationInputComponents;
    int maxTessEvaluationOutputComponents;
    int maxTessEvaluationTextureImageUnits;
    int maxTessEvaluationUniformComponents;
    int maxTessPatchComponents;
    int maxPatchVertices;
    int maxTessGenLevel;
    int maxViewports;
    int maxVertexAtomicCounters;
    int maxTessControlAtomicCounters;
    int maxTessEvaluationAtomicCounters;
    int maxGeometryAtomicCounters;
    int maxFragmentAtomicCounters;
    int maxCombinedAtomicCounters;
    int maxAtomicCounterBindings;
    int maxVertexAtomicCounterBuffers;
    int maxTessControlAtomicCounterBuffers;
    int maxTessEvaluationAtomicCounterBuffers;
    int maxGeometryAtomicCounterBuffers;
    int maxFragmentAtomicCounterBuffers;
    int maxCombinedAtomicCounterBuffers;
    int maxAtomicCounterBufferSize;
    int maxTransformFeedbackBuffers;
    int maxTransformFeedbackInterleavedComponents;
    int maxCullDistances;
    int maxCombinedClipAndCullDistances;
    int maxSamples;
    int maxMeshOutputVerticesNV;
    int maxMeshOutputPrimitivesNV;
    int maxMeshWorkGroupSizeX_NV;
    int maxMeshWorkGroupSizeY_NV;
    int maxMeshWorkGroupSizeZ_NV;
    int maxTaskWorkGroupSizeX_NV;
    int maxTaskWorkGroupSizeY_NV;
    int maxTaskWorkGroupSizeZ_NV;
    int maxMeshViewCountNV;
    int maxDualSourceDrawBuffersEXT;

    TLimits limits;
};

#endif // _RESOURCE_LIMITS_INCLUDED_
",c++
"#include <stdio.h>

int main (void) {
    int i,j,k,l,m,n=0;
    int art[100],art2[100];

    scanf(""%d %d"", &i, &j);

    for(k=0; k<i ; k++){
        scanf(""%d"", &art[k]);
        art2[k]=art[k];
    }


    // sort
    for(k=0; k<i; k++) {
        for(l=k+1; l<i; l++) {
            if(art[k]>art[l]){
                m=art[k];
                art[k]=art[l];
                art[l]=m;
            }
        }
    }

    for(k=0,m=0,l=0; l<i ;k++, l++) {
        if(art[k]+ m <= j) {
            m = m+ art[k];
            n++;
        }
        else break;
    }

    printf(""%d\n"", n);


    for(k=0,m=0,l=0,n=0; l<i ;k++, l++) {
        if(art[k]+ m <= j) {
            for(n=0; n<i; n++){
                if(art2[n]== art[k]) {
                    printf(""%d "", n+1);
                    art2[n]=-1;
                    break;
                }
            }
            m = m+ art[k];
        }
        else break;
    }

    return 0;
}
",c++
"#include <stdio.h>

int bubble_sort(int a[], int l){
    for(int i=l-2; i>=0; i--){
        for(int j=0; j<=i; j++){
            if(a[j]>a[j+1]){
                int temp = a[j];
                a[j] = a[j+1];
                a[j+1] = temp;
            }
        }
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call bubble sort
    bubble_sort(a, 6);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c++
"// Copyright 2018 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef SHADERC_STATUS_H_
#define SHADERC_STATUS_H_

#ifdef __cplusplus
extern ""C"" {
#endif

// Indicate the status of a compilation.
typedef enum {
  shaderc_compilation_status_success = 0,
  shaderc_compilation_status_invalid_stage = 1,  // error stage deduction
  shaderc_compilation_status_compilation_error = 2,
  shaderc_compilation_status_internal_error = 3,  // unexpected failure
  shaderc_compilation_status_null_result_object = 4,
  shaderc_compilation_status_invalid_assembly = 5,
  shaderc_compilation_status_validation_error = 6,
  shaderc_compilation_status_transformation_error = 7,
  shaderc_compilation_status_configuration_error = 8,
} shaderc_compilation_status;

#ifdef __cplusplus
}
#endif  // __cplusplus

#endif  // SHADERC_STATUS_H_
",c++
"        u = g_nDataIdx;
",c++
"#include <stdio.h>

int main (void) {
    double c,b,d=0;
    int a;

    scanf(""%d"",&a);
    c=a*100.0;
    for(; a; a--) {
        scanf(""%lf"", &b);
        d=d+b;
    }

    printf(""%.12f"", d/c*100.0);

    return 0;
}
",c++
"// Copyright 2016 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include ""shaderc/shaderc.h""
#include <assert.h>
#include <string.h>

// Because we want to test this as a plain old C file, we cannot use
// gtest, so just run a simple smoke test.

int main() {
  const char* test_program =
      ""#version 310 es\n""
      ""layout(location = 0) in highp vec4 vtxColor;\n""
      ""layout(location = 0) out highp vec4 outColor;\n""
      ""void main() {\n""
      ""  outColor = vtxColor;""
      ""}\n"";
  shaderc_compiler_t compiler;
  shaderc_compilation_result_t result;
  shaderc_compile_options_t options;

  compiler = shaderc_compiler_initialize();
  options = shaderc_compile_options_initialize();
  shaderc_compile_options_add_macro_definition(options, ""FOO"", 3, ""1"", 1);
  result = shaderc_compile_into_spv(
      compiler, test_program, strlen(test_program),
      shaderc_glsl_fragment_shader, ""a.glsl"", ""main"", options);

  assert(result);

  if (shaderc_result_get_compilation_status(result) !=
      shaderc_compilation_status_success) {
    // Early exit on failure.
    return -1;
  }
  shaderc_result_release(result);
  shaderc_compile_options_release(options);
  shaderc_compiler_release(compiler);

  return 0;
}

",c++
"/*  Problem Statement: https://www.spoj.com/problems/HANGOVER/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<stdbool.h>
#include<assert.h>

uint16_t find_min_cards(double);

int main(void) {
    double card_len;
    while(true) {
        fscanf(stdin,""%lf"",&card_len);
        if(card_len == 0.00) break;
        assert(card_len > 0.00 && card_len < 5.21);
        fprintf(stdout,""%""PRIu16"" card(s)\n"",find_min_cards(card_len));
    }
    return 0;
}

uint16_t find_min_cards(double card_len) {
    double nthterm = 0.00;
    uint16_t no_of_cards = 0;
    for(uint16_t i=1;nthterm<card_len;++i) {
            nthterm += (1/(double)(i+1));
            ++no_of_cards;
    }
    return no_of_cards;
}
",c++
"#include <stdio.h>

int main (void) {
    int i;
    long long int cord1, cord2, axxh=-1000000000, axyh=-1000000000, axxl=1000000000, axyl=1000000000;

    scanf(""%d"", &i);

    for( ; i ; i--) {
        scanf(""%I64d %I64d"", &cord1, &cord2);
        if(cord1 > axxh) axxh=cord1;
        if(cord1 < axxl) axxl=cord1;
        if(cord2 > axyh) axyh=cord2;
        if(cord2 < axyl) axyl=cord2;
    }

    axxh = axxh - axxl;
    if(axxh<0) axxh = axxh*(-1);

    axyh = axyh - axyl;
    if(axyh<0) axyh = axyh*(-1);

    if(axxh<axyh) axxh=axyh;

    printf(""%I64d"", axxh*axxh);

    return 0;
}
",c++
"/*  Problem Statement: Program to compute matrix-multiplication of two matrices of different dimensions.
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)

#define CONSTRAINTS_NOT_SATISFIED(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the <%s>, i.e. %s\n"", __LINE__, #variable, constraints)

static int** take_input_matrix(const size_t, const size_t);
static void display_matrix(int* *const, const size_t, const size_t);
static int** matrix_multiplication(int* *const, const size_t, const size_t, int* *const, const size_t);
static void free_memory(int* *const, const size_t);

int main(void) {
    int matrix_A_rows, matrix_A_cols, matrix_B_rows ,matrix_B_cols; // Dimensions of the matrix
    scanf(""%d%d"", &matrix_A_rows, &matrix_A_cols);
    if(matrix_A_rows < 1 || matrix_A_cols < 1) {
        CONSTRAINTS_NOT_SATISFIED(matrix_A, ""Dimensions of matrix cannot be -ve"");
        exit(0);
    }
    int* *const matrix_A = take_input_matrix(matrix_A_rows, matrix_A_cols);
    if(!matrix_A) {
        MEMORY_ALLOCATION_FAILED_ERROR(matrix_A, matrix_A_rows * matrix_A_cols * sizeof(**matrix_A));
        exit(0);
    }
    scanf(""%d%d"", &matrix_B_rows, &matrix_B_cols);
    if(matrix_B_rows < 1 || matrix_B_cols < 1) {
        CONSTRAINTS_NOT_SATISFIED(matrix_B, ""Dimensions of matrix cannot be -ve"");
        exit(0);
    }
    int* *const matrix_B = take_input_matrix(matrix_B_rows, matrix_B_cols);
    if(!matrix_B) {
        MEMORY_ALLOCATION_FAILED_ERROR(matrix_B, matrix_B_rows * matrix_B_cols * sizeof(**matrix_B));
        exit(0);
    }
    printf(""Matrix-A:\n"");
    display_matrix(matrix_A, matrix_A_rows, matrix_A_cols);
    printf(""Matrix-B:\n"");
    display_matrix(matrix_B, matrix_B_rows, matrix_B_cols);
    if(matrix_A_cols == matrix_B_rows) {
        int* *const result_matrix = matrix_multiplication(matrix_A, matrix_A_rows, matrix_A_cols, matrix_B, matrix_B_cols);
        if(!result_matrix) {
            MEMORY_ALLOCATION_FAILED_ERROR(result_matrix, matrix_A_rows * matrix_B_cols * sizeof(**result_matrix));
            exit(0);
        }
        printf(""Result-Matrix:\n"");
        display_matrix(result_matrix, matrix_A_rows, matrix_B_cols);
        free_memory(matrix_A, matrix_A_rows);
        free_memory(matrix_B, matrix_B_rows);
        free_memory(result_matrix, matrix_A_rows);
    } else {
        fprintf(stderr, ""Line number: %u: Matrix multiplication cannot be performed beacause matrix_A_cols != matrix_B_rows.\n"", __LINE__);
        exit(0);
    }
    return EXIT_SUCCESS;
}

static int** take_input_matrix(const size_t nrows, const size_t ncols) {
    int* *const matrix = calloc(nrows, sizeof(*matrix));
    if(matrix) {
        for(unsigned int i = 0; i < nrows; ++i) {
            matrix[i] = calloc(ncols, sizeof(**matrix));
            if(matrix[i]) {
                for(unsigned int j = 0; j < ncols; ++j) {
                    scanf(""%d"", &matrix[i][j]);
                }
            } else {
                MEMORY_ALLOCATION_FAILED_ERROR(matrix[i], ncols * sizeof(**matrix));
                return NULL;
            }
        }
    }
    return matrix;
}

static void display_matrix(int* *const matrix, const size_t nrows, const size_t ncols) {
    for(unsigned int i = 0; i < nrows; ++i) {
        for(unsigned int j = 0; j < ncols; ++j) {
            printf(""%5d"", matrix[i][j]);
        }
        printf(""\n"");
    }
}

static int** matrix_multiplication(int* *const matrix_A, const size_t matrix_A_rows, const size_t matrix_A_cols, int* *const matrix_B, const size_t matrix_B_cols) {
    int* *const result_matrix = calloc(matrix_A_rows, sizeof(*result_matrix));
    if(result_matrix) {
        for(unsigned int i = 0; i < matrix_A_rows; ++i) {
            result_matrix[i] = calloc(matrix_B_cols, sizeof(**result_matrix));
            if(!result_matrix[i]) {
                MEMORY_ALLOCATION_FAILED_ERROR(result_matrix[i], matrix_B_cols * sizeof(**result_matrix));
                return NULL;
            }
        }

        for(unsigned int i = 0; i < matrix_A_rows; ++i) {
            for(unsigned int j = 0; j < matrix_B_cols; ++j) {
                for(unsigned int k = 0; k < matrix_A_cols; ++k) {
                    result_matrix[i][j] += (matrix_A[i][k] * matrix_B[k][j]);
                }
            }
        }
    }
    return result_matrix;
}

static void free_memory(int* *const matrix, const size_t nrows) {
    for(unsigned int i = 0; i < nrows; free(matrix[i]), ++i);
    free(matrix);
}
",c++
"#include <stdio.h>

int n = 7;
int stack[10];
int top = -1;

void push(int x){
    if(top==n){
        printf(""\n Stak is overflow!"");
    }
    else{
        top++;
        stack[top] = x;
    }
}

void pop(){
    if(top==-1){
        printf(""\n Stack is underflow"");
    }else{
        printf(""\n Element to be delete:%d"", stack[top]);
        top--;
    }
}

void distroy(){
    top= -1;
    printf(""\n Stack is destroyed!"");
}

void display(){
    if(top==-1){
        printf(""\n Stack is underflow"");
    }else{
        printf(""\n stack elements:"");
        for(int i=0; i<=top; i++){
            printf(""%d "", stack[i]);
        }
    }
}
void main(void) {
    display();
    push(1);
    push(2);
    push(3);
    push(4);
    display();
    pop();
    display();
    distroy();
}


// ===== OUTPUT =====
//  Stack is underflow
//  stack elements:1 2 3 4 
//  Element to be delete:4
//  stack elements:1 2 3 
//  Stack is destroyed!
",c++
"/*
 * Problem Statement: https://www.hackerrank.com/challenges/handshake/problem
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <ctype.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        ll_t n;
        if(1 != scanf(""%lld"", &n)) {
            SCANF_READ_ERROR(1);
        }
        printf(""%lld\n"", (n * (n - 1)) >> 1);
    }
    return EXIT_SUCCESS;
}
",c++
"/* A Bison parser, made by GNU Bison 3.7.4.  */

/* Bison interface for Yacc-like parsers in C

   Copyright (C) 1984, 1989-1990, 2000-2015, 2018-2020 Free Software Foundation,
   Inc.

   This program is free software: you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation, either version 3 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with this program.  If not, see <http://www.gnu.org/licenses/>.  */

/* As a special exception, you may create a larger work that contains
   part or all of the Bison parser skeleton and distribute that work
   under terms of your choice, so long as that work isn't itself a
   parser generator using the skeleton or a modified version thereof
   as a parser skeleton.  Alternatively, if you modify or redistribute
   the parser skeleton itself, you may (at your option) remove this
   special exception, which will cause the skeleton and the resulting
   Bison output files to be licensed under the GNU General Public
   License without this special exception.

   This special exception was added by the Free Software Foundation in
   version 2.2 of Bison.  */

/* DO NOT RELY ON FEATURES THAT ARE NOT DOCUMENTED in the manual,
   especially those whose name start with YY_ or yy_.  They are
   private implementation details that can be changed or removed.  */

#ifndef YY_YY_MACHINEINDEPENDENT_GLSLANG_TAB_CPP_H_INCLUDED
# define YY_YY_MACHINEINDEPENDENT_GLSLANG_TAB_CPP_H_INCLUDED
/* Debug traces.  */
#ifndef YYDEBUG
# define YYDEBUG 1
#endif
#if YYDEBUG
extern int yydebug;
#endif

/* Token kinds.  */
#ifndef YYTOKENTYPE
# define YYTOKENTYPE
  enum yytokentype
  {
    YYEMPTY = -2,
    YYEOF = 0,                     /* ""end of file""  */
    YYerror = 256,                 /* error  */
    YYUNDEF = 257,                 /* ""invalid token""  */
    CONST = 258,                   /* CONST  */
    BOOL = 259,                    /* BOOL  */
    INT = 260,                     /* INT  */
    UINT = 261,                    /* UINT  */
    FLOAT = 262,                   /* FLOAT  */
    BVEC2 = 263,                   /* BVEC2  */
    BVEC3 = 264,                   /* BVEC3  */
    BVEC4 = 265,                   /* BVEC4  */
    IVEC2 = 266,                   /* IVEC2  */
    IVEC3 = 267,                   /* IVEC3  */
    IVEC4 = 268,                   /* IVEC4  */
    UVEC2 = 269,                   /* UVEC2  */
    UVEC3 = 270,                   /* UVEC3  */
    UVEC4 = 271,                   /* UVEC4  */
    VEC2 = 272,                    /* VEC2  */
    VEC3 = 273,                    /* VEC3  */
    VEC4 = 274,                    /* VEC4  */
    MAT2 = 275,                    /* MAT2  */
    MAT3 = 276,                    /* MAT3  */
    MAT4 = 277,                    /* MAT4  */
    MAT2X2 = 278,                  /* MAT2X2  */
    MAT2X3 = 279,                  /* MAT2X3  */
    MAT2X4 = 280,                  /* MAT2X4  */
    MAT3X2 = 281,                  /* MAT3X2  */
    MAT3X3 = 282,                  /* MAT3X3  */
    MAT3X4 = 283,                  /* MAT3X4  */
    MAT4X2 = 284,                  /* MAT4X2  */
    MAT4X3 = 285,                  /* MAT4X3  */
    MAT4X4 = 286,                  /* MAT4X4  */
    SAMPLER2D = 287,               /* SAMPLER2D  */
    SAMPLER3D = 288,               /* SAMPLER3D  */
    SAMPLERCUBE = 289,             /* SAMPLERCUBE  */
    SAMPLER2DSHADOW = 290,         /* SAMPLER2DSHADOW  */
    SAMPLERCUBESHADOW = 291,       /* SAMPLERCUBESHADOW  */
    SAMPLER2DARRAY = 292,          /* SAMPLER2DARRAY  */
    SAMPLER2DARRAYSHADOW = 293,    /* SAMPLER2DARRAYSHADOW  */
    ISAMPLER2D = 294,              /* ISAMPLER2D  */
    ISAMPLER3D = 295,              /* ISAMPLER3D  */
    ISAMPLERCUBE = 296,            /* ISAMPLERCUBE  */
    ISAMPLER2DARRAY = 297,         /* ISAMPLER2DARRAY  */
    USAMPLER2D = 298,              /* USAMPLER2D  */
    USAMPLER3D = 299,              /* USAMPLER3D  */
    USAMPLERCUBE = 300,            /* USAMPLERCUBE  */
    USAMPLER2DARRAY = 301,         /* USAMPLER2DARRAY  */
    SAMPLER = 302,                 /* SAMPLER  */
    SAMPLERSHADOW = 303,           /* SAMPLERSHADOW  */
    TEXTURE2D = 304,               /* TEXTURE2D  */
    TEXTURE3D = 305,               /* TEXTURE3D  */
    TEXTURECUBE = 306,             /* TEXTURECUBE  */
    TEXTURE2DARRAY = 307,          /* TEXTURE2DARRAY  */
    ITEXTURE2D = 308,              /* ITEXTURE2D  */
    ITEXTURE3D = 309,              /* ITEXTURE3D  */
    ITEXTURECUBE = 310,            /* ITEXTURECUBE  */
    ITEXTURE2DARRAY = 311,         /* ITEXTURE2DARRAY  */
    UTEXTURE2D = 312,              /* UTEXTURE2D  */
    UTEXTURE3D = 313,              /* UTEXTURE3D  */
    UTEXTURECUBE = 314,            /* UTEXTURECUBE  */
    UTEXTURE2DARRAY = 315,         /* UTEXTURE2DARRAY  */
    ATTRIBUTE = 316,               /* ATTRIBUTE  */
    VARYING = 317,                 /* VARYING  */
    FLOAT16_T = 318,               /* FLOAT16_T  */
    FLOAT32_T = 319,               /* FLOAT32_T  */
    DOUBLE = 320,                  /* DOUBLE  */
    FLOAT64_T = 321,               /* FLOAT64_T  */
    INT64_T = 322,                 /* INT64_T  */
    UINT64_T = 323,                /* UINT64_T  */
    INT32_T = 324,                 /* INT32_T  */
    UINT32_T = 325,                /* UINT32_T  */
    INT16_T = 326,                 /* INT16_T  */
    UINT16_T = 327,                /* UINT16_T  */
    INT8_T = 328,                  /* INT8_T  */
    UINT8_T = 329,                 /* UINT8_T  */
    I64VEC2 = 330,                 /* I64VEC2  */
    I64VEC3 = 331,                 /* I64VEC3  */
    I64VEC4 = 332,                 /* I64VEC4  */
    U64VEC2 = 333,                 /* U64VEC2  */
    U64VEC3 = 334,                 /* U64VEC3  */
    U64VEC4 = 335,                 /* U64VEC4  */
    I32VEC2 = 336,                 /* I32VEC2  */
    I32VEC3 = 337,                 /* I32VEC3  */
    I32VEC4 = 338,                 /* I32VEC4  */
    U32VEC2 = 339,                 /* U32VEC2  */
    U32VEC3 = 340,                 /* U32VEC3  */
    U32VEC4 = 341,                 /* U32VEC4  */
    I16VEC2 = 342,                 /* I16VEC2  */
    I16VEC3 = 343,                 /* I16VEC3  */
    I16VEC4 = 344,                 /* I16VEC4  */
    U16VEC2 = 345,                 /* U16VEC2  */
    U16VEC3 = 346,                 /* U16VEC3  */
    U16VEC4 = 347,                 /* U16VEC4  */
    I8VEC2 = 348,                  /* I8VEC2  */
    I8VEC3 = 349,                  /* I8VEC3  */
    I8VEC4 = 350,                  /* I8VEC4  */
    U8VEC2 = 351,                  /* U8VEC2  */
    U8VEC3 = 352,                  /* U8VEC3  */
    U8VEC4 = 353,                  /* U8VEC4  */
    DVEC2 = 354,                   /* DVEC2  */
    DVEC3 = 355,                   /* DVEC3  */
    DVEC4 = 356,                   /* DVEC4  */
    DMAT2 = 357,                   /* DMAT2  */
    DMAT3 = 358,                   /* DMAT3  */
    DMAT4 = 359,                   /* DMAT4  */
    F16VEC2 = 360,                 /* F16VEC2  */
    F16VEC3 = 361,                 /* F16VEC3  */
    F16VEC4 = 362,                 /* F16VEC4  */
    F16MAT2 = 363,                 /* F16MAT2  */
    F16MAT3 = 364,                 /* F16MAT3  */
    F16MAT4 = 365,                 /* F16MAT4  */
    F32VEC2 = 366,                 /* F32VEC2  */
    F32VEC3 = 367,                 /* F32VEC3  */
    F32VEC4 = 368,                 /* F32VEC4  */
    F32MAT2 = 369,                 /* F32MAT2  */
    F32MAT3 = 370,                 /* F32MAT3  */
    F32MAT4 = 371,                 /* F32MAT4  */
    F64VEC2 = 372,                 /* F64VEC2  */
    F64VEC3 = 373,                 /* F64VEC3  */
    F64VEC4 = 374,                 /* F64VEC4  */
    F64MAT2 = 375,                 /* F64MAT2  */
    F64MAT3 = 376,                 /* F64MAT3  */
    F64MAT4 = 377,                 /* F64MAT4  */
    DMAT2X2 = 378,                 /* DMAT2X2  */
    DMAT2X3 = 379,                 /* DMAT2X3  */
    DMAT2X4 = 380,                 /* DMAT2X4  */
    DMAT3X2 = 381,                 /* DMAT3X2  */
    DMAT3X3 = 382,                 /* DMAT3X3  */
    DMAT3X4 = 383,                 /* DMAT3X4  */
    DMAT4X2 = 384,                 /* DMAT4X2  */
    DMAT4X3 = 385,                 /* DMAT4X3  */
    DMAT4X4 = 386,                 /* DMAT4X4  */
    F16MAT2X2 = 387,               /* F16MAT2X2  */
    F16MAT2X3 = 388,               /* F16MAT2X3  */
    F16MAT2X4 = 389,               /* F16MAT2X4  */
    F16MAT3X2 = 390,               /* F16MAT3X2  */
    F16MAT3X3 = 391,               /* F16MAT3X3  */
    F16MAT3X4 = 392,               /* F16MAT3X4  */
    F16MAT4X2 = 393,               /* F16MAT4X2  */
    F16MAT4X3 = 394,               /* F16MAT4X3  */
    F16MAT4X4 = 395,               /* F16MAT4X4  */
    F32MAT2X2 = 396,               /* F32MAT2X2  */
    F32MAT2X3 = 397,               /* F32MAT2X3  */
    F32MAT2X4 = 398,               /* F32MAT2X4  */
    F32MAT3X2 = 399,               /* F32MAT3X2  */
    F32MAT3X3 = 400,               /* F32MAT3X3  */
    F32MAT3X4 = 401,               /* F32MAT3X4  */
    F32MAT4X2 = 402,               /* F32MAT4X2  */
    F32MAT4X3 = 403,               /* F32MAT4X3  */
    F32MAT4X4 = 404,               /* F32MAT4X4  */
    F64MAT2X2 = 405,               /* F64MAT2X2  */
    F64MAT2X3 = 406,               /* F64MAT2X3  */
    F64MAT2X4 = 407,               /* F64MAT2X4  */
    F64MAT3X2 = 408,               /* F64MAT3X2  */
    F64MAT3X3 = 409,               /* F64MAT3X3  */
    F64MAT3X4 = 410,               /* F64MAT3X4  */
    F64MAT4X2 = 411,               /* F64MAT4X2  */
    F64MAT4X3 = 412,               /* F64MAT4X3  */
    F64MAT4X4 = 413,               /* F64MAT4X4  */
    ATOMIC_UINT = 414,             /* ATOMIC_UINT  */
    ACCSTRUCTNV = 415,             /* ACCSTRUCTNV  */
    ACCSTRUCTEXT = 416,            /* ACCSTRUCTEXT  */
    RAYQUERYEXT = 417,             /* RAYQUERYEXT  */
    FCOOPMATNV = 418,              /* FCOOPMATNV  */
    ICOOPMATNV = 419,              /* ICOOPMATNV  */
    UCOOPMATNV = 420,              /* UCOOPMATNV  */
    SAMPLERCUBEARRAY = 421,        /* SAMPLERCUBEARRAY  */
    SAMPLERCUBEARRAYSHADOW = 422,  /* SAMPLERCUBEARRAYSHADOW  */
    ISAMPLERCUBEARRAY = 423,       /* ISAMPLERCUBEARRAY  */
    USAMPLERCUBEARRAY = 424,       /* USAMPLERCUBEARRAY  */
    SAMPLER1D = 425,               /* SAMPLER1D  */
    SAMPLER1DARRAY = 426,          /* SAMPLER1DARRAY  */
    SAMPLER1DARRAYSHADOW = 427,    /* SAMPLER1DARRAYSHADOW  */
    ISAMPLER1D = 428,              /* ISAMPLER1D  */
    SAMPLER1DSHADOW = 429,         /* SAMPLER1DSHADOW  */
    SAMPLER2DRECT = 430,           /* SAMPLER2DRECT  */
    SAMPLER2DRECTSHADOW = 431,     /* SAMPLER2DRECTSHADOW  */
    ISAMPLER2DRECT = 432,          /* ISAMPLER2DRECT  */
    USAMPLER2DRECT = 433,          /* USAMPLER2DRECT  */
    SAMPLERBUFFER = 434,           /* SAMPLERBUFFER  */
    ISAMPLERBUFFER = 435,          /* ISAMPLERBUFFER  */
    USAMPLERBUFFER = 436,          /* USAMPLERBUFFER  */
    SAMPLER2DMS = 437,             /* SAMPLER2DMS  */
    ISAMPLER2DMS = 438,            /* ISAMPLER2DMS  */
    USAMPLER2DMS = 439,            /* USAMPLER2DMS  */
    SAMPLER2DMSARRAY = 440,        /* SAMPLER2DMSARRAY  */
    ISAMPLER2DMSARRAY = 441,       /* ISAMPLER2DMSARRAY  */
    USAMPLER2DMSARRAY = 442,       /* USAMPLER2DMSARRAY  */
    SAMPLEREXTERNALOES = 443,      /* SAMPLEREXTERNALOES  */
    SAMPLEREXTERNAL2DY2YEXT = 444, /* SAMPLEREXTERNAL2DY2YEXT  */
    ISAMPLER1DARRAY = 445,         /* ISAMPLER1DARRAY  */
    USAMPLER1D = 446,              /* USAMPLER1D  */
    USAMPLER1DARRAY = 447,         /* USAMPLER1DARRAY  */
    F16SAMPLER1D = 448,            /* F16SAMPLER1D  */
    F16SAMPLER2D = 449,            /* F16SAMPLER2D  */
    F16SAMPLER3D = 450,            /* F16SAMPLER3D  */
    F16SAMPLER2DRECT = 451,        /* F16SAMPLER2DRECT  */
    F16SAMPLERCUBE = 452,          /* F16SAMPLERCUBE  */
    F16SAMPLER1DARRAY = 453,       /* F16SAMPLER1DARRAY  */
    F16SAMPLER2DARRAY = 454,       /* F16SAMPLER2DARRAY  */
    F16SAMPLERCUBEARRAY = 455,     /* F16SAMPLERCUBEARRAY  */
    F16SAMPLERBUFFER = 456,        /* F16SAMPLERBUFFER  */
    F16SAMPLER2DMS = 457,          /* F16SAMPLER2DMS  */
    F16SAMPLER2DMSARRAY = 458,     /* F16SAMPLER2DMSARRAY  */
    F16SAMPLER1DSHADOW = 459,      /* F16SAMPLER1DSHADOW  */
    F16SAMPLER2DSHADOW = 460,      /* F16SAMPLER2DSHADOW  */
    F16SAMPLER1DARRAYSHADOW = 461, /* F16SAMPLER1DARRAYSHADOW  */
    F16SAMPLER2DARRAYSHADOW = 462, /* F16SAMPLER2DARRAYSHADOW  */
    F16SAMPLER2DRECTSHADOW = 463,  /* F16SAMPLER2DRECTSHADOW  */
    F16SAMPLERCUBESHADOW = 464,    /* F16SAMPLERCUBESHADOW  */
    F16SAMPLERCUBEARRAYSHADOW = 465, /* F16SAMPLERCUBEARRAYSHADOW  */
    IMAGE1D = 466,                 /* IMAGE1D  */
    IIMAGE1D = 467,                /* IIMAGE1D  */
    UIMAGE1D = 468,                /* UIMAGE1D  */
    IMAGE2D = 469,                 /* IMAGE2D  */
    IIMAGE2D = 470,                /* IIMAGE2D  */
    UIMAGE2D = 471,                /* UIMAGE2D  */
    IMAGE3D = 472,                 /* IMAGE3D  */
    IIMAGE3D = 473,                /* IIMAGE3D  */
    UIMAGE3D = 474,                /* UIMAGE3D  */
    IMAGE2DRECT = 475,             /* IMAGE2DRECT  */
    IIMAGE2DRECT = 476,            /* IIMAGE2DRECT  */
    UIMAGE2DRECT = 477,            /* UIMAGE2DRECT  */
    IMAGECUBE = 478,               /* IMAGECUBE  */
    IIMAGECUBE = 479,              /* IIMAGECUBE  */
    UIMAGECUBE = 480,              /* UIMAGECUBE  */
    IMAGEBUFFER = 481,             /* IMAGEBUFFER  */
    IIMAGEBUFFER = 482,            /* IIMAGEBUFFER  */
    UIMAGEBUFFER = 483,            /* UIMAGEBUFFER  */
    IMAGE1DARRAY = 484,            /* IMAGE1DARRAY  */
    IIMAGE1DARRAY = 485,           /* IIMAGE1DARRAY  */
    UIMAGE1DARRAY = 486,           /* UIMAGE1DARRAY  */
    IMAGE2DARRAY = 487,            /* IMAGE2DARRAY  */
    IIMAGE2DARRAY = 488,           /* IIMAGE2DARRAY  */
    UIMAGE2DARRAY = 489,           /* UIMAGE2DARRAY  */
    IMAGECUBEARRAY = 490,          /* IMAGECUBEARRAY  */
    IIMAGECUBEARRAY = 491,         /* IIMAGECUBEARRAY  */
    UIMAGECUBEARRAY = 492,         /* UIMAGECUBEARRAY  */
    IMAGE2DMS = 493,               /* IMAGE2DMS  */
    IIMAGE2DMS = 494,              /* IIMAGE2DMS  */
    UIMAGE2DMS = 495,              /* UIMAGE2DMS  */
    IMAGE2DMSARRAY = 496,          /* IMAGE2DMSARRAY  */
    IIMAGE2DMSARRAY = 497,         /* IIMAGE2DMSARRAY  */
    UIMAGE2DMSARRAY = 498,         /* UIMAGE2DMSARRAY  */
    F16IMAGE1D = 499,              /* F16IMAGE1D  */
    F16IMAGE2D = 500,              /* F16IMAGE2D  */
    F16IMAGE3D = 501,              /* F16IMAGE3D  */
    F16IMAGE2DRECT = 502,          /* F16IMAGE2DRECT  */
    F16IMAGECUBE = 503,            /* F16IMAGECUBE  */
    F16IMAGE1DARRAY = 504,         /* F16IMAGE1DARRAY  */
    F16IMAGE2DARRAY = 505,         /* F16IMAGE2DARRAY  */
    F16IMAGECUBEARRAY = 506,       /* F16IMAGECUBEARRAY  */
    F16IMAGEBUFFER = 507,          /* F16IMAGEBUFFER  */
    F16IMAGE2DMS = 508,            /* F16IMAGE2DMS  */
    F16IMAGE2DMSARRAY = 509,       /* F16IMAGE2DMSARRAY  */
    I64IMAGE1D = 510,              /* I64IMAGE1D  */
    U64IMAGE1D = 511,              /* U64IMAGE1D  */
    I64IMAGE2D = 512,              /* I64IMAGE2D  */
    U64IMAGE2D = 513,              /* U64IMAGE2D  */
    I64IMAGE3D = 514,              /* I64IMAGE3D  */
    U64IMAGE3D = 515,              /* U64IMAGE3D  */
    I64IMAGE2DRECT = 516,          /* I64IMAGE2DRECT  */
    U64IMAGE2DRECT = 517,          /* U64IMAGE2DRECT  */
    I64IMAGECUBE = 518,            /* I64IMAGECUBE  */
    U64IMAGECUBE = 519,            /* U64IMAGECUBE  */
    I64IMAGEBUFFER = 520,          /* I64IMAGEBUFFER  */
    U64IMAGEBUFFER = 521,          /* U64IMAGEBUFFER  */
    I64IMAGE1DARRAY = 522,         /* I64IMAGE1DARRAY  */
    U64IMAGE1DARRAY = 523,         /* U64IMAGE1DARRAY  */
    I64IMAGE2DARRAY = 524,         /* I64IMAGE2DARRAY  */
    U64IMAGE2DARRAY = 525,         /* U64IMAGE2DARRAY  */
    I64IMAGECUBEARRAY = 526,       /* I64IMAGECUBEARRAY  */
    U64IMAGECUBEARRAY = 527,       /* U64IMAGECUBEARRAY  */
    I64IMAGE2DMS = 528,            /* I64IMAGE2DMS  */
    U64IMAGE2DMS = 529,            /* U64IMAGE2DMS  */
    I64IMAGE2DMSARRAY = 530,       /* I64IMAGE2DMSARRAY  */
    U64IMAGE2DMSARRAY = 531,       /* U64IMAGE2DMSARRAY  */
    TEXTURECUBEARRAY = 532,        /* TEXTURECUBEARRAY  */
    ITEXTURECUBEARRAY = 533,       /* ITEXTURECUBEARRAY  */
    UTEXTURECUBEARRAY = 534,       /* UTEXTURECUBEARRAY  */
    TEXTURE1D = 535,               /* TEXTURE1D  */
    ITEXTURE1D = 536,              /* ITEXTURE1D  */
    UTEXTURE1D = 537,              /* UTEXTURE1D  */
    TEXTURE1DARRAY = 538,          /* TEXTURE1DARRAY  */
    ITEXTURE1DARRAY = 539,         /* ITEXTURE1DARRAY  */
    UTEXTURE1DARRAY = 540,         /* UTEXTURE1DARRAY  */
    TEXTURE2DRECT = 541,           /* TEXTURE2DRECT  */
    ITEXTURE2DRECT = 542,          /* ITEXTURE2DRECT  */
    UTEXTURE2DRECT = 543,          /* UTEXTURE2DRECT  */
    TEXTUREBUFFER = 544,           /* TEXTUREBUFFER  */
    ITEXTUREBUFFER = 545,          /* ITEXTUREBUFFER  */
    UTEXTUREBUFFER = 546,          /* UTEXTUREBUFFER  */
    TEXTURE2DMS = 547,             /* TEXTURE2DMS  */
    ITEXTURE2DMS = 548,            /* ITEXTURE2DMS  */
    UTEXTURE2DMS = 549,            /* UTEXTURE2DMS  */
    TEXTURE2DMSARRAY = 550,        /* TEXTURE2DMSARRAY  */
    ITEXTURE2DMSARRAY = 551,       /* ITEXTURE2DMSARRAY  */
    UTEXTURE2DMSARRAY = 552,       /* UTEXTURE2DMSARRAY  */
    F16TEXTURE1D = 553,            /* F16TEXTURE1D  */
    F16TEXTURE2D = 554,            /* F16TEXTURE2D  */
    F16TEXTURE3D = 555,            /* F16TEXTURE3D  */
    F16TEXTURE2DRECT = 556,        /* F16TEXTURE2DRECT  */
    F16TEXTURECUBE = 557,          /* F16TEXTURECUBE  */
    F16TEXTURE1DARRAY = 558,       /* F16TEXTURE1DARRAY  */
    F16TEXTURE2DARRAY = 559,       /* F16TEXTURE2DARRAY  */
    F16TEXTURECUBEARRAY = 560,     /* F16TEXTURECUBEARRAY  */
    F16TEXTUREBUFFER = 561,        /* F16TEXTUREBUFFER  */
    F16TEXTURE2DMS = 562,          /* F16TEXTURE2DMS  */
    F16TEXTURE2DMSARRAY = 563,     /* F16TEXTURE2DMSARRAY  */
    SUBPASSINPUT = 564,            /* SUBPASSINPUT  */
    SUBPASSINPUTMS = 565,          /* SUBPASSINPUTMS  */
    ISUBPASSINPUT = 566,           /* ISUBPASSINPUT  */
    ISUBPASSINPUTMS = 567,         /* ISUBPASSINPUTMS  */
    USUBPASSINPUT = 568,           /* USUBPASSINPUT  */
    USUBPASSINPUTMS = 569,         /* USUBPASSINPUTMS  */
    F16SUBPASSINPUT = 570,         /* F16SUBPASSINPUT  */
    F16SUBPASSINPUTMS = 571,       /* F16SUBPASSINPUTMS  */
    SPIRV_INSTRUCTION = 572,       /* SPIRV_INSTRUCTION  */
    SPIRV_EXECUTION_MODE = 573,    /* SPIRV_EXECUTION_MODE  */
    SPIRV_EXECUTION_MODE_ID = 574, /* SPIRV_EXECUTION_MODE_ID  */
    SPIRV_DECORATE = 575,          /* SPIRV_DECORATE  */
    SPIRV_DECORATE_ID = 576,       /* SPIRV_DECORATE_ID  */
    SPIRV_DECORATE_STRING = 577,   /* SPIRV_DECORATE_STRING  */
    SPIRV_TYPE = 578,              /* SPIRV_TYPE  */
    SPIRV_STORAGE_CLASS = 579,     /* SPIRV_STORAGE_CLASS  */
    SPIRV_BY_REFERENCE = 580,      /* SPIRV_BY_REFERENCE  */
    SPIRV_LITERAL = 581,           /* SPIRV_LITERAL  */
    LEFT_OP = 582,                 /* LEFT_OP  */
    RIGHT_OP = 583,                /* RIGHT_OP  */
    INC_OP = 584,                  /* INC_OP  */
    DEC_OP = 585,                  /* DEC_OP  */
    LE_OP = 586,                   /* LE_OP  */
    GE_OP = 587,                   /* GE_OP  */
    EQ_OP = 588,                   /* EQ_OP  */
    NE_OP = 589,                   /* NE_OP  */
    AND_OP = 590,                  /* AND_OP  */
    OR_OP = 591,                   /* OR_OP  */
    XOR_OP = 592,                  /* XOR_OP  */
    MUL_ASSIGN = 593,              /* MUL_ASSIGN  */
    DIV_ASSIGN = 594,              /* DIV_ASSIGN  */
    ADD_ASSIGN = 595,              /* ADD_ASSIGN  */
    MOD_ASSIGN = 596,              /* MOD_ASSIGN  */
    LEFT_ASSIGN = 597,             /* LEFT_ASSIGN  */
    RIGHT_ASSIGN = 598,            /* RIGHT_ASSIGN  */
    AND_ASSIGN = 599,              /* AND_ASSIGN  */
    XOR_ASSIGN = 600,              /* XOR_ASSIGN  */
    OR_ASSIGN = 601,               /* OR_ASSIGN  */
    SUB_ASSIGN = 602,              /* SUB_ASSIGN  */
    STRING_LITERAL = 603,          /* STRING_LITERAL  */
    LEFT_PAREN = 604,              /* LEFT_PAREN  */
    RIGHT_PAREN = 605,             /* RIGHT_PAREN  */
    LEFT_BRACKET = 606,            /* LEFT_BRACKET  */
    RIGHT_BRACKET = 607,           /* RIGHT_BRACKET  */
    LEFT_BRACE = 608,              /* LEFT_BRACE  */
    RIGHT_BRACE = 609,             /* RIGHT_BRACE  */
    DOT = 610,                     /* DOT  */
    COMMA = 611,                   /* COMMA  */
    COLON = 612,                   /* COLON  */
    EQUAL = 613,                   /* EQUAL  */
    SEMICOLON = 614,               /* SEMICOLON  */
    BANG = 615,                    /* BANG  */
    DASH = 616,                    /* DASH  */
    TILDE = 617,                   /* TILDE  */
    PLUS = 618,                    /* PLUS  */
    STAR = 619,                    /* STAR  */
    SLASH = 620,                   /* SLASH  */
    PERCENT = 621,                 /* PERCENT  */
    LEFT_ANGLE = 622,              /* LEFT_ANGLE  */
    RIGHT_ANGLE = 623,             /* RIGHT_ANGLE  */
    VERTICAL_BAR = 624,            /* VERTICAL_BAR  */
    CARET = 625,                   /* CARET  */
    AMPERSAND = 626,               /* AMPERSAND  */
    QUESTION = 627,                /* QUESTION  */
    INVARIANT = 628,               /* INVARIANT  */
    HIGH_PRECISION = 629,          /* HIGH_PRECISION  */
    MEDIUM_PRECISION = 630,        /* MEDIUM_PRECISION  */
    LOW_PRECISION = 631,           /* LOW_PRECISION  */
    PRECISION = 632,               /* PRECISION  */
    PACKED = 633,                  /* PACKED  */
    RESOURCE = 634,                /* RESOURCE  */
    SUPERP = 635,                  /* SUPERP  */
    FLOATCONSTANT = 636,           /* FLOATCONSTANT  */
    INTCONSTANT = 637,             /* INTCONSTANT  */
    UINTCONSTANT = 638,            /* UINTCONSTANT  */
    BOOLCONSTANT = 639,            /* BOOLCONSTANT  */
    IDENTIFIER = 640,              /* IDENTIFIER  */
    TYPE_NAME = 641,               /* TYPE_NAME  */
    CENTROID = 642,                /* CENTROID  */
    IN = 643,                      /* IN  */
    OUT = 644,                     /* OUT  */
    INOUT = 645,                   /* INOUT  */
    STRUCT = 646,                  /* STRUCT  */
    VOID = 647,                    /* VOID  */
    WHILE = 648,                   /* WHILE  */
    BREAK = 649,                   /* BREAK  */
    CONTINUE = 650,                /* CONTINUE  */
    DO = 651,                      /* DO  */
    ELSE = 652,                    /* ELSE  */
    FOR = 653,                     /* FOR  */
    IF = 654,                      /* IF  */
    DISCARD = 655,                 /* DISCARD  */
    RETURN = 656,                  /* RETURN  */
    SWITCH = 657,                  /* SWITCH  */
    CASE = 658,                    /* CASE  */
    DEFAULT = 659,                 /* DEFAULT  */
    TERMINATE_INVOCATION = 660,    /* TERMINATE_INVOCATION  */
    TERMINATE_RAY = 661,           /* TERMINATE_RAY  */
    IGNORE_INTERSECTION = 662,     /* IGNORE_INTERSECTION  */
    UNIFORM = 663,                 /* UNIFORM  */
    SHARED = 664,                  /* SHARED  */
    BUFFER = 665,                  /* BUFFER  */
    FLAT = 666,                    /* FLAT  */
    SMOOTH = 667,                  /* SMOOTH  */
    LAYOUT = 668,                  /* LAYOUT  */
    DOUBLECONSTANT = 669,          /* DOUBLECONSTANT  */
    INT16CONSTANT = 670,           /* INT16CONSTANT  */
    UINT16CONSTANT = 671,          /* UINT16CONSTANT  */
    FLOAT16CONSTANT = 672,         /* FLOAT16CONSTANT  */
    INT32CONSTANT = 673,           /* INT32CONSTANT  */
    UINT32CONSTANT = 674,          /* UINT32CONSTANT  */
    INT64CONSTANT = 675,           /* INT64CONSTANT  */
    UINT64CONSTANT = 676,          /* UINT64CONSTANT  */
    SUBROUTINE = 677,              /* SUBROUTINE  */
    DEMOTE = 678,                  /* DEMOTE  */
    PAYLOADNV = 679,               /* PAYLOADNV  */
    PAYLOADINNV = 680,             /* PAYLOADINNV  */
    HITATTRNV = 681,               /* HITATTRNV  */
    CALLDATANV = 682,              /* CALLDATANV  */
    CALLDATAINNV = 683,            /* CALLDATAINNV  */
    PAYLOADEXT = 684,              /* PAYLOADEXT  */
    PAYLOADINEXT = 685,            /* PAYLOADINEXT  */
    HITATTREXT = 686,              /* HITATTREXT  */
    CALLDATAEXT = 687,             /* CALLDATAEXT  */
    CALLDATAINEXT = 688,           /* CALLDATAINEXT  */
    PATCH = 689,                   /* PATCH  */
    SAMPLE = 690,                  /* SAMPLE  */
    NONUNIFORM = 691,              /* NONUNIFORM  */
    COHERENT = 692,                /* COHERENT  */
    VOLATILE = 693,                /* VOLATILE  */
    RESTRICT = 694,                /* RESTRICT  */
    READONLY = 695,                /* READONLY  */
    WRITEONLY = 696,               /* WRITEONLY  */
    DEVICECOHERENT = 697,          /* DEVICECOHERENT  */
    QUEUEFAMILYCOHERENT = 698,     /* QUEUEFAMILYCOHERENT  */
    WORKGROUPCOHERENT = 699,       /* WORKGROUPCOHERENT  */
    SUBGROUPCOHERENT = 700,        /* SUBGROUPCOHERENT  */
    NONPRIVATE = 701,              /* NONPRIVATE  */
    SHADERCALLCOHERENT = 702,      /* SHADERCALLCOHERENT  */
    NOPERSPECTIVE = 703,           /* NOPERSPECTIVE  */
    EXPLICITINTERPAMD = 704,       /* EXPLICITINTERPAMD  */
    PERVERTEXNV = 705,             /* PERVERTEXNV  */
    PERPRIMITIVENV = 706,          /* PERPRIMITIVENV  */
    PERVIEWNV = 707,               /* PERVIEWNV  */
    PERTASKNV = 708,               /* PERTASKNV  */
    PRECISE = 709                  /* PRECISE  */
  };
  typedef enum yytokentype yytoken_kind_t;
#endif

/* Value type.  */
#if ! defined YYSTYPE && ! defined YYSTYPE_IS_DECLARED
union YYSTYPE
{
#line 97 ""MachineIndependent/glslang.y""

    struct {
        glslang::TSourceLoc loc;
        union {
            glslang::TString *string;
            int i;
            unsigned int u;
            long long i64;
            unsigned long long u64;
            bool b;
            double d;
        };
        glslang::TSymbol* symbol;
    } lex;
    struct {
        glslang::TSourceLoc loc;
        glslang::TOperator op;
        union {
            TIntermNode* intermNode;
            glslang::TIntermNodePair nodePair;
            glslang::TIntermTyped* intermTypedNode;
            glslang::TAttributes* attributes;
            glslang::TSpirvRequirement* spirvReq;
            glslang::TSpirvInstruction* spirvInst;
            glslang::TSpirvTypeParameters* spirvTypeParams;
        };
        union {
            glslang::TPublicType type;
            glslang::TFunction* function;
            glslang::TParameter param;
            glslang::TTypeLoc typeLine;
            glslang::TTypeList* typeList;
            glslang::TArraySizes* arraySizes;
            glslang::TIdentifierList* identifierList;
        };
        glslang::TArraySizes* typeParameters;
    } interm;

#line 557 ""MachineIndependent/glslang_tab.cpp.h""

};
typedef union YYSTYPE YYSTYPE;
# define YYSTYPE_IS_TRIVIAL 1
# define YYSTYPE_IS_DECLARED 1
#endif



int yyparse (glslang::TParseContext* pParseContext);

#endif /* !YY_YY_MACHINEINDEPENDENT_GLSLANG_TAB_CPP_H_INCLUDED  */
",c++
"#include ""parent.h""

float4 i3;
",c++
"// Copyright 2015 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef LIBSHADERC_UTIL_UNIVERSAL_UNISTD_H_
#define LIBSHADERC_UTIL_UNIVERSAL_UNISTD_H_

#ifndef _MSC_VER
#include <unistd.h>
#else
// Minimal set of <unistd> needed to compile on windows.

#include <io.h>
#define access _access

// https://msdn.microsoft.com/en-us/library/1w06ktdy.aspx
// Defines these constants.
#define R_OK 4
#define W_OK 2
#endif //_MSC_VER

#endif // LIBSHADERC_UTIL_UNIVERSAL_UNISTD_H_
",c++
"#include <stdio.h>
int main (void) {
    char ch1;
    long long int nA=0, nI=0, nF=0, count;

    scanf(""%I64d"", &count);
    scanf(""%c"", &ch1);

    while( count ) {
        scanf(""%c"", &ch1);
        if(ch1=='A') nA++;
        else if(ch1== 'I') nI++;
        else nF++;

        count--;
    }

    if(nI > 1) printf(""0"");
    else if(nI==1) printf(""1"");
    else printf(""%d"", nA);

    return 0;
}
",c++
"/*  * Program to generate the test-cases for the problem: https://www.spoj.com/problems/COINS/
    * Program is based on command-line arguments which takes a filename as an argument.
    * Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<time.h>
#include<assert.h>

#ifdef _WIN32
    #include<Windows.h>
#else
    #include<unistd.h>
#endif

typedef unsigned long long ull_t;
ull_t MAX_LIMIT = 100;

int main(int argc,char *const argv[]) {
    srand(time(NULL));
    if(argc == 2) {
        FILE *test_file = fopen(argv[1],""w"");
        if(test_file) {
            sleep(1);
            srand(time(NULL));
            for(int i = 0; i < 10; ++i) {
                fprintf(test_file,""%llu\n"",(rand() % MAX_LIMIT));
            }
            fclose(test_file);
        } else {
            fprintf(stderr,""File not opened successfully\n"");
            return EXIT_FAILURE;
        }
    } else {
        fprintf(stderr,""Insufficient or More number of command line arguments\n"");
        return EXIT_FAILURE;
    }
    return EXIT_SUCCESS;
}",c++
"#include <stdio.h>
#include <stdlib.h>
#include ""ml.h""

int  iunique(int y[], int n, int **values)
     /*
       extract unique values from a vector y of n integers.
       
       Return value: the number of unique values on success, 0 otherwise.
     */
{
  int nvalues=1;
  int i,j;
  int addclass;
  int *indx;

  if(!(*values=ivector(1))){
    fprintf(stderr,""iunique: out of memory\n"");
    return 0;
  }
    
  (*values)[0]=y[0];
  for(i=1;i<n;i++){
    addclass=1;
    for(j=0;j<nvalues;j++)
      if((*values)[j]==y[i])
        addclass=0;
    if(addclass){
      if(!(*values=(int*)realloc(*values,(nvalues+1)*sizeof(int)))){
	fprintf(stderr,""iunique: out of memory\n"");
	return 0;
      }
      (*values)[nvalues++]=y[i];
    }
  }

  if(!(indx=ivector(nvalues))){
    fprintf(stderr,""iunique: out of memory\n"");
    return 0;
  }

  isort(*values,indx,nvalues,SORT_ASCENDING);

  if(free_ivector(indx)!=0){
    fprintf(stderr,""iunique: free_ivector error\n"");
    return 0;
  }

  return nvalues;
}


int  dunique(double y[], int n, double **values)
     /*
       extract unique values from a vector y of n doubles.
       
       Return value: the number of unique values on success, 0 otherwise.
     */
{
  int nvalues=1;
  int i,j;
  int addclass;
  int *indx;

  if(!(*values=dvector(1))){
    fprintf(stderr,""dunique: out of memory\n"");
    return 0;
  }
    
  (*values)[0]=y[0];
  for(i=1;i<n;i++){
    addclass=1;
    for(j=0;j<nvalues;j++)
      if((*values)[j]==y[i])
        addclass=0;
    if(addclass){
      if(!(*values=(double*)realloc(*values,(nvalues+1)*sizeof(double)))){
	fprintf(stderr,""dunique: out of memory\n"");
	return 0;
      }
      (*values)[nvalues++]=y[i];
    }
  }

  if(!(indx=ivector(nvalues))){
    fprintf(stderr,""iunique: out of memory\n"");
    return 0;
  }

  dsort(*values,indx,nvalues,SORT_ASCENDING);

  if(free_ivector(indx)!=0){
    fprintf(stderr,""iunique: free_ivector error\n"");
    return 0;
  }

  return nvalues;
}
",c++
"#include <stdio.h>

int n = 7;
int queue[10];
int front = -1;
int rear = -1;

void insert(int x){
    if(front==-1){
        front = rear = 0;
        queue[rear] = x;
    }else{
        rear++;
        queue[rear] = x;
    }
}

void delete(){
    if(front == -1){
        printf(""\n Queue is underflow"");
    }else{
        printf(""\n element to be delete: %d"", queue[front]);
        front++;
    }
}

void display(){
     if(rear == -1){
        printf(""\n Queue is underflow"");
    }else{
        printf(""\n element of queue are:"");
        for(int i=front; i<=rear; i++){
            printf(""%d "", queue[i]);
        }
    }
}

void destroy(){
    front = -1;
    rear = -1;
    printf(""\n Queue is destroyed"");
}
void main(void) {
    display();
    insert(1);
    insert(2);
    insert(3);
    insert(4);
    display();
    delete();
    display();
    destroy();
}

// ====OUTPUT====
//  Queue is underflow
//  element of queue are:1 2 3 4 
//  element to be delete: 1
//  element of queue are:2 3 4 
//  Queue is destroyed
",c++
"#include <stdio.h>

int main () {
    char ch[201];
    int i,j,k=0,l=0,m=0,n;

    scanf(""%s"", ch);

    for(i=0; ch[i]; i++ ) {
        if(ch[i]=='1') k++;
        else if(ch[i]=='2') l++;
        else if(ch[i]=='3') m++;
    }

    n=2*(k+l+m)-1;

    for (i=0; n; i=i+2,n-- ) {
        if(k) {
            ch[i]='1';
            k--;
        }
        else if(l) {
            ch[i]='2';
            l--;
        }
        else ch[i]='3';
    }

    printf(""%s"", ch);

    return 0;
}
",c++
"#include <stdio.h>
#include <stdlib.h>

struct node
{
    int data;
    struct node *next;
}; 

struct node *newrec, *first, *last, *temp; 

void insert_beg(int x){
    newrec = (struct node*)malloc(sizeof(struct node));
    newrec->data = x;
    if(first == NULL){
        first = last = newrec;
        newrec->next = NULL;
    }
    else{
        newrec->next = first;
        first = newrec;
    }
}

void insert_end(int x){
    newrec = (struct node*)malloc(sizeof(struct node));
    newrec -> data = x;
    if(first == NULL){
        first = last = newrec;
        newrec -> next = NULL;
    }else{
        last -> next = newrec;
        newrec ->next = NULL;
        last = newrec;
    }
}

void insert_pos(int x, int p){
    newrec = (struct node *)malloc(sizeof(struct node));
    newrec -> data = x;
    if(first==NULL){
        first = last = newrec;
        newrec -> next = NULL;
    }else{
        temp = first;
        for(int i=1; i<p-1; i++){
            temp = temp->next;
        }
        newrec->next = temp->next;
        temp->next = newrec;
    }
}

void del_beg(){
    if(first == NULL){
        printf(""linkedlist is underflow"");
    }else{
        printf(""Element to be delete: %d \n"", first->data);
        if(first == last){
            first = last = NULL;
        }else{
            first = first->next;
        }
    }
}

void del_end(){
    if(first == NULL){
        printf(""linkedlist is underflow"");
    }else{
        printf(""Element to be delete: %d \n"", last->data);
        if(first == last){
            first = last = NULL; 
        }else{
            temp = first;
            while(temp->next!=last){
                temp = temp->next;
            }
            last = temp;
            last -> next = NULL;
            
        }
    }
}

void del_pos(int p){
    if(first == NULL){
        printf(""linkedlist is underflow"");
    }else{
        if(first==last){
            printf(""Element to be delete: %d \n"", first->data);
            first = last = NULL;
        }else{
            temp = first;
            for(int i=1; i<p-1; i++){
                temp=temp->next;
            }
            printf(""Element to be delete: %d \n"", temp->next->data);
            temp->next = temp->next->next;
        }
    }
}

void display(){
    if(first==NULL){
        printf(""Linked list is underflow"");
    }else{
        temp = first;
        printf(""Content of linkedlist:"");
        while(temp!= NULL){
            printf(""%d "", temp->data);
            temp = temp -> next;
        }
    }
    printf(""\n"");
}

void destroy(){
    first = last = NULL;
    printf(""linkedlist is destroyed! \n"");
}

void main(void) {
    display();
    insert_beg(3);
    display();
    insert_beg(2);
    display();
    insert_beg(1);
    display();
    insert_end(4);
    display();
    insert_end(5);
    display();
    insert_beg(0);
    display();
    insert_pos(8,3);
    display();
    insert_pos(10,2);
    display();
    del_beg();
    display();
    del_end();
    display();
    del_pos(4);
    display();
    destroy();
    display();
}

// ===========OUTPUT=============
// Linked list is underflow
// Content of linkedlist:3 
// Content of linkedlist:2 3 
// Content of linkedlist:1 2 3 
// Content of linkedlist:1 2 3 4 
// Content of linkedlist:1 2 3 4 5 
// Content of linkedlist:0 1 2 3 4 5 
// Content of linkedlist:0 1 8 2 3 4 5 
// Content of linkedlist:0 10 1 8 2 3 4 5 
// Element to be delete: 0 
// Content of linkedlist:10 1 8 2 3 4 5 
// Element to be delete: 5 
// Content of linkedlist:10 1 8 2 3 4 
// Element to be delete: 2 
// Content of linkedlist:10 1 8 3 4 
// linkedlist is destroyed! 
// Linked list is underflow
",c++
"/*  Problem Statement: https://www.spoj.com/problems/FIBOSUM/
 *  Author: striker
*/

#include<stdio.h>
#include<stdlib.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

enum matrix_dimensions {nrows = 2, ncols = 2};

#define MOD (1000000000 + 7)
#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line nubmer: %u: Constraints not satisfied for <%s> variable i.e. %s\n"",  __LINE__, #variable, #constraints)

static ll_t nth_fibonacci(ll_t);
static void matrix_exponentiation(ll_t [][ncols], ll_t);
static void matrix_multiplication(ll_t [][ncols], ll_t [][ncols]);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    scanf(""%d"", &test);
    if(test < 1 || test > 1000) {
        CONSTRAINTS_OUT_OF_BOUND_ERROR(test, 1 <= test <= 1000);
        exit(0);
    }
    while(test--) {
        int n, m;
        scanf(""%d%d"", &n, &m);
        if(n < 0 || n > 1000000000) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n, 0 <= n <= 10^9);
            exit(0);
        }
        if(m < 0 || m > 1000000000) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(m, 0 <= m <= 10^9);
            exit(0);
        }
        if(n > m) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n < m, n should be less than m);
            exit(0);
        }
        if(!(n == m)) {
            ll_t fibo_sum = ((nth_fibonacci(m + 2) - 1) - (nth_fibonacci((n - 1) + 2) - 1)) % MOD;
            if(fibo_sum < 0) {
                fibo_sum += MOD;
            }
            printf(""%lld\n"", fibo_sum);
        } else {
            printf(""%lld\n"", nth_fibonacci(n) % MOD);
        }
    }
    return EXIT_SUCCESS;
}

static ll_t nth_fibonacci(ll_t n) {
    if(!n) {
        return 0;
    } else if(1 == n) {
        return 1;
    }
    ll_t result_matrix[][ncols] = {{1, 0}, {0, 1}}; //Identity Matrix.
    matrix_exponentiation(result_matrix, n - 1);
    return result_matrix[0][0];
}

static void matrix_exponentiation(ll_t result_matrix[][ncols], ll_t n) {
    ll_t transformation_matrix[][ncols] = {{1, 1}, {1, 0}}; // Transformation Matrix.
    while(n) {
        if(n & 1) {
            matrix_multiplication(result_matrix, transformation_matrix);
        }
        matrix_multiplication(transformation_matrix, transformation_matrix);
        n >>= 1;
    }
}

static void matrix_multiplication(ll_t matrix_A[][ncols], ll_t matrix_B[][ncols]) {
    ll_t a = ((matrix_A[0][0] * matrix_B[0][0]) % MOD + (matrix_A[0][1] * matrix_B[1][0]) % MOD) % MOD;
    ll_t b = ((matrix_A[0][0] * matrix_B[0][1]) % MOD + (matrix_A[0][1] * matrix_B[1][1]) % MOD) % MOD;
    ll_t c = ((matrix_A[1][0] * matrix_B[0][0]) % MOD + (matrix_A[1][1] * matrix_B[1][0]) % MOD) % MOD;
    ll_t d = ((matrix_A[1][0] * matrix_B[0][1]) % MOD + (matrix_A[1][1] * matrix_B[1][1]) % MOD) % MOD;
    matrix_A[0][0] = a;
    matrix_A[0][1] = b;
    matrix_A[1][0] = c;
    matrix_A[1][1] = d;
}
",c++
,c++
"/**
    This code is based on the glslang_c_interface implementation by Viktor Latypov
**/

/**
BSD 2-Clause License

Copyright (c) 2019, Viktor Latypov
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
**/

#ifndef GLSLANG_C_IFACE_H_INCLUDED
#define GLSLANG_C_IFACE_H_INCLUDED

#include <stdbool.h>
#include <stdlib.h>

#include ""glslang_c_shader_types.h""

typedef struct glslang_shader_s glslang_shader_t;
typedef struct glslang_program_s glslang_program_t;

/* TLimits counterpart */
typedef struct glslang_limits_s {
    bool non_inductive_for_loops;
    bool while_loops;
    bool do_while_loops;
    bool general_uniform_indexing;
    bool general_attribute_matrix_vector_indexing;
    bool general_varying_indexing;
    bool general_sampler_indexing;
    bool general_variable_indexing;
    bool general_constant_matrix_vector_indexing;
} glslang_limits_t;

/* TBuiltInResource counterpart */
typedef struct glslang_resource_s {
    int max_lights;
    int max_clip_planes;
    int max_texture_units;
    int max_texture_coords;
    int max_vertex_attribs;
    int max_vertex_uniform_components;
    int max_varying_floats;
    int max_vertex_texture_image_units;
    int max_combined_texture_image_units;
    int max_texture_image_units;
    int max_fragment_uniform_components;
    int max_draw_buffers;
    int max_vertex_uniform_vectors;
    int max_varying_vectors;
    int max_fragment_uniform_vectors;
    int max_vertex_output_vectors;
    int max_fragment_input_vectors;
    int min_program_texel_offset;
    int max_program_texel_offset;
    int max_clip_distances;
    int max_compute_work_group_count_x;
    int max_compute_work_group_count_y;
    int max_compute_work_group_count_z;
    int max_compute_work_group_size_x;
    int max_compute_work_group_size_y;
    int max_compute_work_group_size_z;
    int max_compute_uniform_components;
    int max_compute_texture_image_units;
    int max_compute_image_uniforms;
    int max_compute_atomic_counters;
    int max_compute_atomic_counter_buffers;
    int max_varying_components;
    int max_vertex_output_components;
    int max_geometry_input_components;
    int max_geometry_output_components;
    int max_fragment_input_components;
    int max_image_units;
    int max_combined_image_units_and_fragment_outputs;
    int max_combined_shader_output_resources;
    int max_image_samples;
    int max_vertex_image_uniforms;
    int max_tess_control_image_uniforms;
    int max_tess_evaluation_image_uniforms;
    int max_geometry_image_uniforms;
    int max_fragment_image_uniforms;
    int max_combined_image_uniforms;
    int max_geometry_texture_image_units;
    int max_geometry_output_vertices;
    int max_geometry_total_output_components;
    int max_geometry_uniform_components;
    int max_geometry_varying_components;
    int max_tess_control_input_components;
    int max_tess_control_output_components;
    int max_tess_control_texture_image_units;
    int max_tess_control_uniform_components;
    int max_tess_control_total_output_components;
    int max_tess_evaluation_input_components;
    int max_tess_evaluation_output_components;
    int max_tess_evaluation_texture_image_units;
    int max_tess_evaluation_uniform_components;
    int max_tess_patch_components;
    int max_patch_vertices;
    int max_tess_gen_level;
    int max_viewports;
    int max_vertex_atomic_counters;
    int max_tess_control_atomic_counters;
    int max_tess_evaluation_atomic_counters;
    int max_geometry_atomic_counters;
    int max_fragment_atomic_counters;
    int max_combined_atomic_counters;
    int max_atomic_counter_bindings;
    int max_vertex_atomic_counter_buffers;
    int max_tess_control_atomic_counter_buffers;
    int max_tess_evaluation_atomic_counter_buffers;
    int max_geometry_atomic_counter_buffers;
    int max_fragment_atomic_counter_buffers;
    int max_combined_atomic_counter_buffers;
    int max_atomic_counter_buffer_size;
    int max_transform_feedback_buffers;
    int max_transform_feedback_interleaved_components;
    int max_cull_distances;
    int max_combined_clip_and_cull_distances;
    int max_samples;
    int max_mesh_output_vertices_nv;
    int max_mesh_output_primitives_nv;
    int max_mesh_work_group_size_x_nv;
    int max_mesh_work_group_size_y_nv;
    int max_mesh_work_group_size_z_nv;
    int max_task_work_group_size_x_nv;
    int max_task_work_group_size_y_nv;
    int max_task_work_group_size_z_nv;
    int max_mesh_view_count_nv;
    int maxDualSourceDrawBuffersEXT;

    glslang_limits_t limits;
} glslang_resource_t;

typedef struct glslang_input_s {
    glslang_source_t language;
    glslang_stage_t stage;
    glslang_client_t client;
    glslang_target_client_version_t client_version;
    glslang_target_language_t target_language;
    glslang_target_language_version_t target_language_version;
    /** Shader source code */
    const char* code;
    int default_version;
    glslang_profile_t default_profile;
    int force_default_version_and_profile;
    int forward_compatible;
    glslang_messages_t messages;
    const glslang_resource_t* resource;
} glslang_input_t;

/* Inclusion result structure allocated by C include_local/include_system callbacks */
typedef struct glsl_include_result_s {
    /* Header file name or NULL if inclusion failed */
    const char* header_name;

    /* Header contents or NULL */
    const char* header_data;
    size_t header_length;

} glsl_include_result_t;

/* Callback for local file inclusion */
typedef glsl_include_result_t* (*glsl_include_local_func)(void* ctx, const char* header_name, const char* includer_name,
                                                          size_t include_depth);

/* Callback for system file inclusion */
typedef glsl_include_result_t* (*glsl_include_system_func)(void* ctx, const char* header_name,
                                                           const char* includer_name, size_t include_depth);

/* Callback for include result destruction */
typedef int (*glsl_free_include_result_func)(void* ctx, glsl_include_result_t* result);

/* Collection of callbacks for GLSL preprocessor */
typedef struct glsl_include_callbacks_s {
    glsl_include_system_func include_system;
    glsl_include_local_func include_local;
    glsl_free_include_result_func free_include_result;
} glsl_include_callbacks_t;

#ifdef __cplusplus
extern ""C"" {
#endif

#ifdef GLSLANG_IS_SHARED_LIBRARY
    #ifdef _WIN32
        #ifdef GLSLANG_EXPORTING
            #define GLSLANG_EXPORT __declspec(dllexport)
        #else
            #define GLSLANG_EXPORT __declspec(dllimport)
        #endif
    #elif __GNUC__ >= 4
        #define GLSLANG_EXPORT __attribute__((visibility(""default"")))
    #endif
#endif // GLSLANG_IS_SHARED_LIBRARY

#ifndef GLSLANG_EXPORT
#define GLSLANG_EXPORT
#endif

GLSLANG_EXPORT int glslang_initialize_process();
GLSLANG_EXPORT void glslang_finalize_process();

GLSLANG_EXPORT glslang_shader_t* glslang_shader_create(const glslang_input_t* input);
GLSLANG_EXPORT void glslang_shader_delete(glslang_shader_t* shader);
GLSLANG_EXPORT void glslang_shader_shift_binding(glslang_shader_t* shader, glslang_resource_type_t res, unsigned int base);
GLSLANG_EXPORT void glslang_shader_shift_binding_for_set(glslang_shader_t* shader, glslang_resource_type_t res, unsigned int base, unsigned int set);
GLSLANG_EXPORT void glslang_shader_set_options(glslang_shader_t* shader, int options); // glslang_shader_options_t
GLSLANG_EXPORT void glslang_shader_set_glsl_version(glslang_shader_t* shader, int version);
GLSLANG_EXPORT int glslang_shader_preprocess(glslang_shader_t* shader, const glslang_input_t* input);
GLSLANG_EXPORT int glslang_shader_parse(glslang_shader_t* shader, const glslang_input_t* input);
GLSLANG_EXPORT const char* glslang_shader_get_preprocessed_code(glslang_shader_t* shader);
GLSLANG_EXPORT const char* glslang_shader_get_info_log(glslang_shader_t* shader);
GLSLANG_EXPORT const char* glslang_shader_get_info_debug_log(glslang_shader_t* shader);

GLSLANG_EXPORT glslang_program_t* glslang_program_create();
GLSLANG_EXPORT void glslang_program_delete(glslang_program_t* program);
GLSLANG_EXPORT void glslang_program_add_shader(glslang_program_t* program, glslang_shader_t* shader);
GLSLANG_EXPORT int glslang_program_link(glslang_program_t* program, int messages); // glslang_messages_t
GLSLANG_EXPORT int glslang_program_map_io(glslang_program_t* program);
GLSLANG_EXPORT void glslang_program_SPIRV_generate(glslang_program_t* program, glslang_stage_t stage);
GLSLANG_EXPORT size_t glslang_program_SPIRV_get_size(glslang_program_t* program);
GLSLANG_EXPORT void glslang_program_SPIRV_get(glslang_program_t* program, unsigned int*);
GLSLANG_EXPORT unsigned int* glslang_program_SPIRV_get_ptr(glslang_program_t* program);
GLSLANG_EXPORT const char* glslang_program_SPIRV_get_messages(glslang_program_t* program);
GLSLANG_EXPORT const char* glslang_program_get_info_log(glslang_program_t* program);
GLSLANG_EXPORT const char* glslang_program_get_info_debug_log(glslang_program_t* program);

#ifdef __cplusplus
}
#endif

#endif /* #ifdef GLSLANG_C_IFACE_INCLUDED */
",c++
"/*  Problem Statement: https://www.hackerrank.com/contests/projecteuler/challenges/euler002/problem or https://projecteuler.net/problem=2
 *  Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<string.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the <%s> variable i.e. %s\n"", __LINE__, #variable, #constraints)
#define INITIALIZE_DATA(variable, bytes) memset(variable, 0, (bytes))

static ull_t compute_even_fibonacci_sum(const ull_t);

int main(void) {
    /*
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    */
    int test;
    scanf(""%d"", &test);
    if(test < 1 || test > 100000) {
        CONSTRAINTS_OUT_OF_BOUND_ERROR(test, 1 <= test <= 10^5);
        exit(0);
    }
    while(test--) {
        ull_t n;
        scanf(""%llu"", &n);
        if(n < 1 || n > 40000000000000000) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n, 10 <= n <= 4 * 10^16);
            exit(0);
        }
        printf(""%llu\n"", compute_even_fibonacci_sum(n));
    }
    return EXIT_SUCCESS;
}

static ull_t compute_even_fibonacci_sum(const ull_t n) {
    ull_t sub_problem_1_sol = 2, sub_problem_2_sol = 8;
    ull_t even_sum = sub_problem_1_sol;
    while(sub_problem_2_sol <= n) {
        even_sum += sub_problem_2_sol;
        ull_t temp = sub_problem_2_sol;
        sub_problem_2_sol = 4 * sub_problem_2_sol + sub_problem_1_sol;
        sub_problem_1_sol = temp;
    }
    return even_sum;
}
",c++
"#include <stdio.h>
#include <stdlib.h>

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        while(test--) {
            long long int n;
            if(1 == scanf(""%lld"", &n)) {
                long long int total_triangle = (n * (n + 2) * ((n << 1) + 1)) / 8;
                printf(""%lld\n"", total_triangle);
                continue;
            }
        }
    }
    return EXIT_SUCCESS;
}
",c++
"/*
 * Problem Statement: Refer to the readme.md file.
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

static void rearrange_zeroes(int *const, const int);
static void display_sequence(const int *const, const int, const char *const);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    scanf(""%d"", &test);
    while(test--) {
        int n;
        scanf(""%d"", &n);
        if(n < 1) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n, size of array cannot be 0 or -ve);
            exit(0);
        }
        int *const sequence = calloc(n, sizeof*sequence);
        if(sequence) {
            for(int i = 0; i < n; ++i) {
                scanf(""%d"", sequence + i);
            }
            rearrange_zeroes(sequence, n);
            display_sequence(sequence, n, "" "");
            free(sequence);
        } else {
            MEMORY_ALLOCATION_FAILED_ERROR(sequence, n * sizeof*sequence);
            exit(0);
        }
    }
    return EXIT_SUCCESS;
}

static void display_sequence(const int *const data, const int n, const char *const delimiter) {
    printf(""%d"", data[0]);
    for(int i = 1; i < n; ++i) {
        printf(""%s%d"", delimiter, data[i]);
    }
    printf(""\n"");
}

static void rearrange_zeroes(int *const data, const int n) {
    int index = 0;
    for(int i = 0; i < n; ++i) {
        if(data[i]) {
            data[index++] = data[i];
        }
    }
    while(index < n) {
        data[index++] = 0;
    }
}
",c++
"#include <stdio.h>

int main (void) {
    int atto[1000];
    int a, b, c=0;

    scanf(""%d"", &a);
    for(b=0; b<a; b++) scanf(""%d"", &atto[b]);

    while(atto[0] != 0) {
        for(b=0; b<a ; b++) {
            if(b%2 == 1 && atto[b]==0) atto[b]= a-1;
            else if (b%2==1) atto[b]--;
            else if (atto[b]== a-1) atto[b]=0;
            else atto[b]++;
        }
    }

    for(b=0; b<a; b++) {
        if(atto[b]==b) c=1;
        else {
            c=0;
            break;
        }
    }

    if(c==1) printf(""YES\n"");
    else printf(""No\n"");

    return 0;
}
",c++
"/*  Problem Statement: https://www.codechef.com/ZCOPRAC/problems/ZCO12001
    Author: striker
*/

#include <stdio.h>
#include <stdlib.h>
#include <inttypes.h>
#include <assert.h>

int main(void) {
    int32_t n;
    scanf(""%""SCNd32, &n);
    assert(n > 1 && n < 100001);
    uint8_t *const bracket_sequence = calloc((size_t) n, sizeof(uint8_t));
    if(bracket_sequence) {
        int32_t open_cnt, max_depth, number_of_symbols, max_number_of_symbols;
        int32_t index_depth, index_max_symbols;
        index_depth = index_max_symbols = -1;
        open_cnt = max_depth = number_of_symbols = max_number_of_symbols = 0;
        for(int32_t i = 0; i < n; ++i) {
            scanf(""%""SCNu8, &bracket_sequence[i]);
            assert(bracket_sequence[i] > 0 && bracket_sequence[i] < 3);
            ++number_of_symbols;
            if(bracket_sequence[i] == 1) {
                ++open_cnt;
                if(open_cnt > max_depth) {
                    max_depth = open_cnt;
                    index_depth = i;
                }
            } else {
                --open_cnt;
                if(!open_cnt) {
                    if(number_of_symbols > max_number_of_symbols) {
                        max_number_of_symbols = number_of_symbols;
                        index_max_symbols = (i - (max_number_of_symbols - 1));
                    }
                    number_of_symbols = 0;
                }
            }
        }
        printf(""%""PRIu32"" %""PRIu32"" %""PRIu32"" %""PRIu32""\n"", max_depth, (index_depth + 1), max_number_of_symbols, (index_max_symbols + 1));
        free(bracket_sequence);
    } else {
        fprintf(stderr,""Not able to allocate %lu bytes of memory\n"", (n * sizeof(uint8_t)));
    }
    return 0;
}
",c++
"// Max External: startup.c
// T.Place - 9/4/2001, 1/8/2002
// A simple Max object to put all tap.tools' objects into the new object list & post some info

#include ""ext.h""				// Required for all Max external objects

void *this_class;			// Required. Global pointing to this class 

typedef struct startup		// Data structure for this object 
{
	Object	p_ob;		// Must always be the first field; used by Max 
} Startup;

		
// Prototypes for methods: need a method for each incoming message
void	*startup_new(long value);			// object creation method  
void	startup_free(Startup *startup);	// free method

/*********************************************************/
//Main() Function

void main(void)			//main receives a copy of the Max function macros table 
{	
	// set up our class: create a class definition 
	setup((t_messlist **)&this_class, (method)startup_new, (method)startup_free, (short)sizeof(Startup), 0L, A_DEFLONG, 0);

	addmess((method)inspector_open, ""info"", A_CANT, 0);		// bind method for opening the license window

	finder_addclass(""SuperCollider Lib"", ""sc.CombN"");
	finder_addclass(""SuperCollider Lib"", ""sc.LFPulse"");
	finder_addclass(""SuperCollider Lib"", ""sc.LFSaw"");
	finder_addclass(""SuperCollider Lib"", ""sc.midicps"");
	finder_addclass(""SuperCollider Lib"", ""sc.SinOsc"");
	finder_addclass(""SuperCollider Lib"", ""sc.WhiteNoise"");
	finder_addclass(""SuperCollider Lib"", ""sc.Xline"");
	
//	finder_addclass(""Tap.Tools"", ""tap.metro"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.prime"");
	finder_addclass(""Tap.Tools"", ""tap.random"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.sieve"");					// add object to new-object list

	finder_addclass(""Tap.Tools"", ""tap.1pole-lp~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.allpole~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.anticlick~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.auto_thru~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.avg~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.bink~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.crossfade~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.decibels~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.diff~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.elixir~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.fft-list~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.fft-normalize~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.lp-comb~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.lpc~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.noise~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.pan~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.polar~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.quantize~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.radians~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.rms~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.scale~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.sift~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.split~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.typecheck~"");			// add object to new-object list

	finder_addclass(""Tap.Tools"", ""tap.5comb~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.adapt~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.decay_calc"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.deviate~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.fft~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.filterbank~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.gate~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.ifft~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.Lchange"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.limiter~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.loadbang"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.normalizer~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.nr~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.shift~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.sustain~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.thru~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.verb~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.vocoder~"");				// add object to new-object list	
	finder_addclass(""Tap.Tools"", ""tap.vocoderlite~"");			// add object to new-object list	
	
	post(""Tap.Tools MSP"");						// Print to the Max Window...
	post(""    Objects for Max/MSP by Tim Place"");
	post(""    Version 0.95"");
	post(""    Copyright � 1999-2002 by Silicon Prairie Intermedia"");
	post(""    http://www.sp-intermedia.com"");
	post(""    Use \""Get Info\"" on any object to view its license"");
}


/*********************************************************/
//Object Creation Function

void *startup_new(long value)
{
	Startup *startup;
	startup = (Startup *)newobject(this_class);	// create the new instance and return a pointer to it 
	return(startup);						// must return a pointer to the new instance 
}


/*********************************************************/
//Bound to input Functions

// free method
void startup_free(Startup *startup)
{
	notify_free((t_object *)startup);
}",c++
"float4 p2;
",c++
"float4 p1;

#include ""local.h""
#include ""remote.h""
",c++
"/*  Problem Statement: https://www.hackerrank.com/challenges/maximum-element/problem
    Author: striker.
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<assert.h>

struct link_list {
    uint32_t data;
    struct link_list *next;
};
typedef struct link_list link_list_t;

link_list_t* make_node(uint32_t d);
void push_data(link_list_t*,link_list_t**);
void pop_data(link_list_t**);
link_list_t* peek_data(link_list_t**);
void delete_stack(link_list_t**);

int main(void) {
    uint32_t n;
    link_list_t *stack_1_head,*stack_2_head;
    scanf(""%""SCNu32,&n);
    assert(n > 0 && n < 100001);
    stack_1_head = stack_2_head = NULL;
    while(n--) {
        uint32_t type;
        scanf(""%""SCNu32,&type);
        assert(type > 0 && type < 4);
        switch(type) {
            uint32_t x;
            case 1:
                scanf(""%""SCNu32,&x);
                assert(x > 0 && x < 1000000001);
                push_data(make_node(x),&stack_1_head);
                if((!stack_2_head) || ((peek_data(&stack_2_head))->data) <= x) {
                    push_data(make_node(x),&stack_2_head);
                }
                break;
            case 2:
                if(stack_1_head && stack_2_head) {
                    if((peek_data(&stack_1_head)->data) == (peek_data(&stack_2_head)->data)) {
                        pop_data(&stack_2_head);
                    }
                    pop_data(&stack_1_head);
                } else {
                    if(!stack_1_head) {
                        fprintf(stderr,""Fist-stack is empty!\n"");
                    }
                    if(!stack_2_head) {
                        fprintf(stderr,""Second-stack is empty!\n"");
                    }
                }
                break;
            case 3:
                if(stack_2_head) {
                    printf(""%""PRIu32""\n"",(peek_data(&stack_2_head)->data));
                } else {
                    fprintf(stderr,""Second-stack is empty!\n"");
                }
                break;
            default:
                fprintf(stderr,""Entered query-type is not valid!\n"");
                break;
        }
    }
    if(stack_1_head) {
        delete_stack(&stack_1_head);
    }
    if(stack_2_head) {
        delete_stack(&stack_2_head);
    }
    return 0;
}

link_list_t* make_node(uint32_t d) {
    link_list_t *node = malloc(sizeof(link_list_t));
    if(node) {
        (node->data) = d;
        (node->next) = NULL;
    } else {
        fprintf(stderr,""Node not created successfully!\n"");
    }
    return node;
}

void push_data(link_list_t *node,link_list_t **head) {
    if(*head) {
        (node->next) = (*head);
        (*head) = node;
    } else {
        (*head) = node;
    }
}

void pop_data(link_list_t **head) {
    if(*head) {
        link_list_t *temp = (*head);
        (*head) = (*head)->next;
        free(temp);
    } else {
        fprintf(stderr,""Stack is empty!\n"");
    }
}

link_list_t* peek_data(link_list_t **head) {
    if(*head) {
        return (*head);
    } else {
        fprintf(stderr,""Stack is empty!\n"");
        return NULL;
    }
}

void delete_stack(link_list_t **head) {
    if(*head) {
        link_list_t *temp = (*head);
        while(temp) {
            (*head) = (*head)->next;
            free(temp);
            temp = *head;
        }
    } else {
        fprintf(stderr,""Stack is already empty!\n"");
    }
}",c++
"#ifndef _PCH_H
#define _PCH_H
//
// Copyright (C) 2018 The Khronos Group Inc.
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions
// are met:
//
//    Redistributions of source code must retain the above copyright
//    notice, this list of conditions and the following disclaimer.
//
//    Redistributions in binary form must reproduce the above
//    copyright notice, this list of conditions and the following
//    disclaimer in the documentation and/or other materials provided
//    with the distribution.
//
//    Neither the name of 3Dlabs Inc. Ltd. nor the names of its
//    contributors may be used to endorse or promote products derived
//    from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
// FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
// COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
// LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
// ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.
//

#include ""TestFixture.h""

#endif /* _PCH_H */
",c++
"/*  Problem Statement: https://www.spoj.com/problems/AE00/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<math.h>
#include<assert.h>

uint32_t find_number_rectangles(uint16_t);

int main(void) {
    uint16_t n; // number of square of side-length 1.
    scanf(""%""SCNu16,&n);
    assert(n > 0 && n < 10001);
    printf(""%""PRIu32""\n"",find_number_rectangles(n));
    return 0;
}

uint32_t find_number_rectangles(uint16_t n) {
    uint32_t ans = n;
    uint32_t n_rows = floor(sqrt(n));
    for(uint16_t i=2;i<=n_rows;ans += (n/i),++i);
    ans -= ((n_rows * (n_rows-1)) >> 1);
    return ans;
}
",c++
"#include <stdio.h>
#include <ctype.h>

int main () {
    char str1[101],str2[202];
    int i,j;


    for(i=0; i<101 ; i++) str1[i]=0;
    for(j=0; j<202 ; j++) str2[j]=0;

    scanf(""%s"", str1);

    for(i=0; str1[i]; i++) str1[i]= tolower(str1[i]);

    for(i=0,j=0; str1[i] ; i++) {
        if(str1[i]=='a' || str1[i]=='o' || str1[i]=='y' || str1[i]=='e' || str1[i]=='u' || str1[i]=='i' );
        else {
            str2[j]='.';
            j++;
            str2[j]= str1[i];
            j++;
        }
    }

    printf(str2);



    return 0;
}
",c++
"#include <stdio.h>

int main (void) {
	int num;
	int sec[num];
	int i=0;
	int flag=0;
	
	scanf(""%d"", &num);
	
	for( ;i<num; i++) scanf(""%d"", &sec[i]);
	
	for(i=1; i<num; i++) {
		if(sec[0]==sec[i]) {
			flag++;
			sec[0]++;
		}
		else if(sec[0]<sec[i]) {
			int temp=sec[i]-sec[0];
			
			if(temp%2) flag+=((temp/2)+1);
			else flag+=(temp/2);
			
			sec[0]+=(flag-sec[0]);
		}
	}
	
	printf(""%d\n"", flag);

	return 0;
}
",c++
"#include<stdio.h>
#include<stdlib.h>

#define MODULUS 10

static int compute_last_digit(int, int);

int main(void) {
	int test;
	scanf(""%d"", &test);
	while(test--) {
		int a, b;
		scanf(""%d%d"", &a, &b);
		printf(""%d\n"", compute_last_digit(a, b));
	}
	return EXIT_SUCCESS;
}

static int compute_last_digit(int base, int exponent) {
	int result;
	if(!base) {
		result = 0;
	} else if(!exponent) {
		result = 1;
	} else {
		result = 1;
		while(exponent) {
			if(exponent & 1) {
				result = (result * (base)) % MODULUS;
			}
			base = (base * base) % MODULUS;
			exponent >>= 1;
		}
	}
	return result;
}
",c++
"#include <stdio.h>

int main (void)
{
    int dime;
    int i,j,k;
    char ch;

    scanf(""%d"", &dime);

    if(!(dime%2)) printf(""%d\n"", (dime*dime)/2 );
    else printf(""%d\n"", ((dime*dime)/2)+1);

    for(i=0, k=0; i<dime; i++) {
        for(j=0 ; j<dime; j++){
            if(!(k%2)) printf(""C"");
            else printf(""."");
            k++;
        }
        if(!(dime%2)) k--;
        printf(""\n"");
    }

    return 0;
}
",c++
"#include <stdio.h>

int main () {
    char str1[] = ""hello"";
    char str2[101];

    int i=0,j=0,k=0;

    gets(str2);

    while(str1[i] && str2[j]) {
        if(str1[i]==str2[j]) {
            i++;
            k++;
        }
        j++;
    }

    if(k==5) printf(""YES"");
    else printf(""NO"");

    return 0;
}
",c++
"// Copyright 2015 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef SHADERC_SHADERC_H_
#define SHADERC_SHADERC_H_

#ifdef __cplusplus
extern ""C"" {
#endif

#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>

#include ""shaderc/env.h""
#include ""shaderc/status.h""
#include ""shaderc/visibility.h""

// Source language kind.
typedef enum {
  shaderc_source_language_glsl,
  shaderc_source_language_hlsl,
} shaderc_source_language;

typedef enum {
  // Forced shader kinds. These shader kinds force the compiler to compile the
  // source code as the specified kind of shader.
  shaderc_vertex_shader,
  shaderc_fragment_shader,
  shaderc_compute_shader,
  shaderc_geometry_shader,
  shaderc_tess_control_shader,
  shaderc_tess_evaluation_shader,

  shaderc_glsl_vertex_shader = shaderc_vertex_shader,
  shaderc_glsl_fragment_shader = shaderc_fragment_shader,
  shaderc_glsl_compute_shader = shaderc_compute_shader,
  shaderc_glsl_geometry_shader = shaderc_geometry_shader,
  shaderc_glsl_tess_control_shader = shaderc_tess_control_shader,
  shaderc_glsl_tess_evaluation_shader = shaderc_tess_evaluation_shader,

  // Deduce the shader kind from #pragma annotation in the source code. Compiler
  // will emit error if #pragma annotation is not found.
  shaderc_glsl_infer_from_source,
  // Default shader kinds. Compiler will fall back to compile the source code as
  // the specified kind of shader when #pragma annotation is not found in the
  // source code.
  shaderc_glsl_default_vertex_shader,
  shaderc_glsl_default_fragment_shader,
  shaderc_glsl_default_compute_shader,
  shaderc_glsl_default_geometry_shader,
  shaderc_glsl_default_tess_control_shader,
  shaderc_glsl_default_tess_evaluation_shader,
  shaderc_spirv_assembly,
  shaderc_raygen_shader,
  shaderc_anyhit_shader,
  shaderc_closesthit_shader,
  shaderc_miss_shader,
  shaderc_intersection_shader,
  shaderc_callable_shader,
  shaderc_glsl_raygen_shader = shaderc_raygen_shader,
  shaderc_glsl_anyhit_shader = shaderc_anyhit_shader,
  shaderc_glsl_closesthit_shader = shaderc_closesthit_shader,
  shaderc_glsl_miss_shader = shaderc_miss_shader,
  shaderc_glsl_intersection_shader = shaderc_intersection_shader,
  shaderc_glsl_callable_shader = shaderc_callable_shader,
  shaderc_glsl_default_raygen_shader,
  shaderc_glsl_default_anyhit_shader,
  shaderc_glsl_default_closesthit_shader,
  shaderc_glsl_default_miss_shader,
  shaderc_glsl_default_intersection_shader,
  shaderc_glsl_default_callable_shader,
  shaderc_task_shader,
  shaderc_mesh_shader,
  shaderc_glsl_task_shader = shaderc_task_shader,
  shaderc_glsl_mesh_shader = shaderc_mesh_shader,
  shaderc_glsl_default_task_shader,
  shaderc_glsl_default_mesh_shader,
} shaderc_shader_kind;

typedef enum {
  shaderc_profile_none,  // Used if and only if GLSL version did not specify
                         // profiles.
  shaderc_profile_core,
  shaderc_profile_compatibility,  // Disabled. This generates an error
  shaderc_profile_es,
} shaderc_profile;

// Optimization level.
typedef enum {
  shaderc_optimization_level_zero,  // no optimization
  shaderc_optimization_level_size,  // optimize towards reducing code size
  shaderc_optimization_level_performance,  // optimize towards performance
} shaderc_optimization_level;

// Resource limits.
typedef enum {
  shaderc_limit_max_lights,
  shaderc_limit_max_clip_planes,
  shaderc_limit_max_texture_units,
  shaderc_limit_max_texture_coords,
  shaderc_limit_max_vertex_attribs,
  shaderc_limit_max_vertex_uniform_components,
  shaderc_limit_max_varying_floats,
  shaderc_limit_max_vertex_texture_image_units,
  shaderc_limit_max_combined_texture_image_units,
  shaderc_limit_max_texture_image_units,
  shaderc_limit_max_fragment_uniform_components,
  shaderc_limit_max_draw_buffers,
  shaderc_limit_max_vertex_uniform_vectors,
  shaderc_limit_max_varying_vectors,
  shaderc_limit_max_fragment_uniform_vectors,
  shaderc_limit_max_vertex_output_vectors,
  shaderc_limit_max_fragment_input_vectors,
  shaderc_limit_min_program_texel_offset,
  shaderc_limit_max_program_texel_offset,
  shaderc_limit_max_clip_distances,
  shaderc_limit_max_compute_work_group_count_x,
  shaderc_limit_max_compute_work_group_count_y,
  shaderc_limit_max_compute_work_group_count_z,
  shaderc_limit_max_compute_work_group_size_x,
  shaderc_limit_max_compute_work_group_size_y,
  shaderc_limit_max_compute_work_group_size_z,
  shaderc_limit_max_compute_uniform_components,
  shaderc_limit_max_compute_texture_image_units,
  shaderc_limit_max_compute_image_uniforms,
  shaderc_limit_max_compute_atomic_counters,
  shaderc_limit_max_compute_atomic_counter_buffers,
  shaderc_limit_max_varying_components,
  shaderc_limit_max_vertex_output_components,
  shaderc_limit_max_geometry_input_components,
  shaderc_limit_max_geometry_output_components,
  shaderc_limit_max_fragment_input_components,
  shaderc_limit_max_image_units,
  shaderc_limit_max_combined_image_units_and_fragment_outputs,
  shaderc_limit_max_combined_shader_output_resources,
  shaderc_limit_max_image_samples,
  shaderc_limit_max_vertex_image_uniforms,
  shaderc_limit_max_tess_control_image_uniforms,
  shaderc_limit_max_tess_evaluation_image_uniforms,
  shaderc_limit_max_geometry_image_uniforms,
  shaderc_limit_max_fragment_image_uniforms,
  shaderc_limit_max_combined_image_uniforms,
  shaderc_limit_max_geometry_texture_image_units,
  shaderc_limit_max_geometry_output_vertices,
  shaderc_limit_max_geometry_total_output_components,
  shaderc_limit_max_geometry_uniform_components,
  shaderc_limit_max_geometry_varying_components,
  shaderc_limit_max_tess_control_input_components,
  shaderc_limit_max_tess_control_output_components,
  shaderc_limit_max_tess_control_texture_image_units,
  shaderc_limit_max_tess_control_uniform_components,
  shaderc_limit_max_tess_control_total_output_components,
  shaderc_limit_max_tess_evaluation_input_components,
  shaderc_limit_max_tess_evaluation_output_components,
  shaderc_limit_max_tess_evaluation_texture_image_units,
  shaderc_limit_max_tess_evaluation_uniform_components,
  shaderc_limit_max_tess_patch_components,
  shaderc_limit_max_patch_vertices,
  shaderc_limit_max_tess_gen_level,
  shaderc_limit_max_viewports,
  shaderc_limit_max_vertex_atomic_counters,
  shaderc_limit_max_tess_control_atomic_counters,
  shaderc_limit_max_tess_evaluation_atomic_counters,
  shaderc_limit_max_geometry_atomic_counters,
  shaderc_limit_max_fragment_atomic_counters,
  shaderc_limit_max_combined_atomic_counters,
  shaderc_limit_max_atomic_counter_bindings,
  shaderc_limit_max_vertex_atomic_counter_buffers,
  shaderc_limit_max_tess_control_atomic_counter_buffers,
  shaderc_limit_max_tess_evaluation_atomic_counter_buffers,
  shaderc_limit_max_geometry_atomic_counter_buffers,
  shaderc_limit_max_fragment_atomic_counter_buffers,
  shaderc_limit_max_combined_atomic_counter_buffers,
  shaderc_limit_max_atomic_counter_buffer_size,
  shaderc_limit_max_transform_feedback_buffers,
  shaderc_limit_max_transform_feedback_interleaved_components,
  shaderc_limit_max_cull_distances,
  shaderc_limit_max_combined_clip_and_cull_distances,
  shaderc_limit_max_samples,
} shaderc_limit;

// Uniform resource kinds.
// In Vulkan, uniform resources are bound to the pipeline via descriptors
// with numbered bindings and sets.
typedef enum {
  // Image and image buffer.
  shaderc_uniform_kind_image,
  // Pure sampler.
  shaderc_uniform_kind_sampler,
  // Sampled texture in GLSL, and Shader Resource View in HLSL.
  shaderc_uniform_kind_texture,
  // Uniform Buffer Object (UBO) in GLSL.  Cbuffer in HLSL.
  shaderc_uniform_kind_buffer,
  // Shader Storage Buffer Object (SSBO) in GLSL.
  shaderc_uniform_kind_storage_buffer,
  // Unordered Access View, in HLSL.  (Writable storage image or storage
  // buffer.)
  shaderc_uniform_kind_unordered_access_view,
} shaderc_uniform_kind;

// Usage examples:
//
// Aggressively release compiler resources, but spend time in initialization
// for each new use.
//      shaderc_compiler_t compiler = shaderc_compiler_initialize();
//      shaderc_compilation_result_t result = shaderc_compile_into_spv(
//          compiler, ""#version 450\nvoid main() {}"", 27,
//          shaderc_glsl_vertex_shader, ""main.vert"", ""main"", nullptr);
//      // Do stuff with compilation results.
//      shaderc_result_release(result);
//      shaderc_compiler_release(compiler);
//
// Keep the compiler object around for a long time, but pay for extra space
// occupied.
//      shaderc_compiler_t compiler = shaderc_compiler_initialize();
//      // On the same, other or multiple simultaneous threads.
//      shaderc_compilation_result_t result = shaderc_compile_into_spv(
//          compiler, ""#version 450\nvoid main() {}"", 27,
//          shaderc_glsl_vertex_shader, ""main.vert"", ""main"", nullptr);
//      // Do stuff with compilation results.
//      shaderc_result_release(result);
//      // Once no more compilations are to happen.
//      shaderc_compiler_release(compiler);

// An opaque handle to an object that manages all compiler state.
typedef struct shaderc_compiler* shaderc_compiler_t;

// Returns a shaderc_compiler_t that can be used to compile modules.
// A return of NULL indicates that there was an error initializing the compiler.
// Any function operating on shaderc_compiler_t must offer the basic
// thread-safety guarantee.
// [http://herbsutter.com/2014/01/13/gotw-95-solution-thread-safety-and-synchronization/]
// That is: concurrent invocation of these functions on DIFFERENT objects needs
// no synchronization; concurrent invocation of these functions on the SAME
// object requires synchronization IF AND ONLY IF some of them take a non-const
// argument.
SHADERC_EXPORT shaderc_compiler_t shaderc_compiler_initialize(void);

// Releases the resources held by the shaderc_compiler_t.
// After this call it is invalid to make any future calls to functions
// involving this shaderc_compiler_t.
SHADERC_EXPORT void shaderc_compiler_release(shaderc_compiler_t);

// An opaque handle to an object that manages options to a single compilation
// result.
typedef struct shaderc_compile_options* shaderc_compile_options_t;

// Returns a default-initialized shaderc_compile_options_t that can be used
// to modify the functionality of a compiled module.
// A return of NULL indicates that there was an error initializing the options.
// Any function operating on shaderc_compile_options_t must offer the
// basic thread-safety guarantee.
SHADERC_EXPORT shaderc_compile_options_t
    shaderc_compile_options_initialize(void);

// Returns a copy of the given shaderc_compile_options_t.
// If NULL is passed as the parameter the call is the same as
// shaderc_compile_options_init.
SHADERC_EXPORT shaderc_compile_options_t shaderc_compile_options_clone(
    const shaderc_compile_options_t options);

// Releases the compilation options. It is invalid to use the given
// shaderc_compile_options_t object in any future calls. It is safe to pass
// NULL to this function, and doing such will have no effect.
SHADERC_EXPORT void shaderc_compile_options_release(
    shaderc_compile_options_t options);

// Adds a predefined macro to the compilation options. This has the same
// effect as passing -Dname=value to the command-line compiler.  If value
// is NULL, it has the same effect as passing -Dname to the command-line
// compiler. If a macro definition with the same name has previously been
// added, the value is replaced with the new value. The macro name and
// value are passed in with char pointers, which point to their data, and
// the lengths of their data. The strings that the name and value pointers
// point to must remain valid for the duration of the call, but can be
// modified or deleted after this function has returned. In case of adding
// a valueless macro, the value argument should be a null pointer or the
// value_length should be 0u.
SHADERC_EXPORT void shaderc_compile_options_add_macro_definition(
    shaderc_compile_options_t options, const char* name, size_t name_length,
    const char* value, size_t value_length);

// Sets the source language.  The default is GLSL.
SHADERC_EXPORT void shaderc_compile_options_set_source_language(
    shaderc_compile_options_t options, shaderc_source_language lang);

// Sets the compiler mode to generate debug information in the output.
SHADERC_EXPORT void shaderc_compile_options_set_generate_debug_info(
    shaderc_compile_options_t options);

// Sets the compiler optimization level to the given level. Only the last one
// takes effect if multiple calls of this function exist.
SHADERC_EXPORT void shaderc_compile_options_set_optimization_level(
    shaderc_compile_options_t options, shaderc_optimization_level level);

// Forces the GLSL language version and profile to a given pair. The version
// number is the same as would appear in the #version annotation in the source.
// Version and profile specified here overrides the #version annotation in the
// source. Use profile: 'shaderc_profile_none' for GLSL versions that do not
// define profiles, e.g. versions below 150.
SHADERC_EXPORT void shaderc_compile_options_set_forced_version_profile(
    shaderc_compile_options_t options, int version, shaderc_profile profile);

// Source text inclusion via #include is supported with a pair of callbacks
// to an ""includer"" on the client side.  The first callback processes an
// inclusion request, and returns an include result.  The includer owns
// the contents of the result, and those contents must remain valid until the
// second callback is invoked to release the result.  Both callbacks take a
// user_data argument to specify the client context.
// To return an error, set the source_name to an empty string and put your
// error message in content.

// An include result.
typedef struct shaderc_include_result {
  // The name of the source file.  The name should be fully resolved
  // in the sense that it should be a unique name in the context of the
  // includer.  For example, if the includer maps source names to files in
  // a filesystem, then this name should be the absolute path of the file.
  // For a failed inclusion, this string is empty.
  const char* source_name;
  size_t source_name_length;
  // The text contents of the source file in the normal case.
  // For a failed inclusion, this contains the error message.
  const char* content;
  size_t content_length;
  // User data to be passed along with this request.
  void* user_data;
} shaderc_include_result;

// The kinds of include requests.
enum shaderc_include_type {
  shaderc_include_type_relative,  // E.g. #include ""source""
  shaderc_include_type_standard   // E.g. #include <source>
};

// An includer callback type for mapping an #include request to an include
// result.  The user_data parameter specifies the client context.  The
// requested_source parameter specifies the name of the source being requested.
// The type parameter specifies the kind of inclusion request being made.
// The requesting_source parameter specifies the name of the source containing
// the #include request.  The includer owns the result object and its contents,
// and both must remain valid until the release callback is called on the result
// object.
typedef shaderc_include_result* (*shaderc_include_resolve_fn)(
    void* user_data, const char* requested_source, int type,
    const char* requesting_source, size_t include_depth);

// An includer callback type for destroying an include result.
typedef void (*shaderc_include_result_release_fn)(
    void* user_data, shaderc_include_result* include_result);

// Sets includer callback functions.
SHADERC_EXPORT void shaderc_compile_options_set_include_callbacks(
    shaderc_compile_options_t options, shaderc_include_resolve_fn resolver,
    shaderc_include_result_release_fn result_releaser, void* user_data);

// Sets the compiler mode to suppress warnings, overriding warnings-as-errors
// mode. When both suppress-warnings and warnings-as-errors modes are
// turned on, warning messages will be inhibited, and will not be emitted
// as error messages.
SHADERC_EXPORT void shaderc_compile_options_set_suppress_warnings(
    shaderc_compile_options_t options);

// Sets the target shader environment, affecting which warnings or errors will
// be issued.  The version will be for distinguishing between different versions
// of the target environment.  The version value should be either 0 or
// a value listed in shaderc_env_version.  The 0 value maps to Vulkan 1.0 if
// |target| is Vulkan, and it maps to OpenGL 4.5 if |target| is OpenGL.
SHADERC_EXPORT void shaderc_compile_options_set_target_env(
    shaderc_compile_options_t options,
    shaderc_target_env target,
    uint32_t version);

// Sets the target SPIR-V version. The generated module will use this version
// of SPIR-V.  Each target environment determines what versions of SPIR-V
// it can consume.  Defaults to the highest version of SPIR-V 1.0 which is
// required to be supported by the target environment.  E.g. Default to SPIR-V
// 1.0 for Vulkan 1.0 and SPIR-V 1.3 for Vulkan 1.1.
SHADERC_EXPORT void shaderc_compile_options_set_target_spirv(
    shaderc_compile_options_t options, shaderc_spirv_version version);

// Sets the compiler mode to treat all warnings as errors. Note the
// suppress-warnings mode overrides this option, i.e. if both
// warning-as-errors and suppress-warnings modes are set, warnings will not
// be emitted as error messages.
SHADERC_EXPORT void shaderc_compile_options_set_warnings_as_errors(
    shaderc_compile_options_t options);

// Sets a resource limit.
SHADERC_EXPORT void shaderc_compile_options_set_limit(
    shaderc_compile_options_t options, shaderc_limit limit, int value);

// Sets whether the compiler should automatically assign bindings to uniforms
// that aren't already explicitly bound in the shader source.
SHADERC_EXPORT void shaderc_compile_options_set_auto_bind_uniforms(
    shaderc_compile_options_t options, bool auto_bind);

// Sets whether the compiler should automatically remove sampler variables
// and convert image variables to combined image-sampler variables.
SHADERC_EXPORT void shaderc_compile_options_set_auto_combined_image_sampler(
    shaderc_compile_options_t options, bool upgrade);

// Sets whether the compiler should use HLSL IO mapping rules for bindings.
// Defaults to false.
SHADERC_EXPORT void shaderc_compile_options_set_hlsl_io_mapping(
    shaderc_compile_options_t options, bool hlsl_iomap);

// Sets whether the compiler should determine block member offsets using HLSL
// packing rules instead of standard GLSL rules.  Defaults to false.  Only
// affects GLSL compilation.  HLSL rules are always used when compiling HLSL.
SHADERC_EXPORT void shaderc_compile_options_set_hlsl_offsets(
    shaderc_compile_options_t options, bool hlsl_offsets);

// Sets the base binding number used for for a uniform resource type when
// automatically assigning bindings.  For GLSL compilation, sets the lowest
// automatically assigned number.  For HLSL compilation, the regsiter number
// assigned to the resource is added to this specified base.
SHADERC_EXPORT void shaderc_compile_options_set_binding_base(
    shaderc_compile_options_t options,
    shaderc_uniform_kind kind,
    uint32_t base);

// Like shaderc_compile_options_set_binding_base, but only takes effect when
// compiling a given shader stage.  The stage is assumed to be one of vertex,
// fragment, tessellation evaluation, tesselation control, geometry, or compute.
SHADERC_EXPORT void shaderc_compile_options_set_binding_base_for_stage(
    shaderc_compile_options_t options, shaderc_shader_kind shader_kind,
    shaderc_uniform_kind kind, uint32_t base);

// Sets whether the compiler should automatically assign locations to
// uniform variables that don't have explicit locations in the shader source.
SHADERC_EXPORT void shaderc_compile_options_set_auto_map_locations(
    shaderc_compile_options_t options, bool auto_map);

// Sets a descriptor set and binding for an HLSL register in the given stage.
// This method keeps a copy of the string data.
SHADERC_EXPORT void shaderc_compile_options_set_hlsl_register_set_and_binding_for_stage(
    shaderc_compile_options_t options, shaderc_shader_kind shader_kind,
    const char* reg, const char* set, const char* binding);

// Like shaderc_compile_options_set_hlsl_register_set_and_binding_for_stage,
// but affects all shader stages.
SHADERC_EXPORT void shaderc_compile_options_set_hlsl_register_set_and_binding(
    shaderc_compile_options_t options, const char* reg, const char* set,
    const char* binding);

// Sets whether the compiler should enable extension
// SPV_GOOGLE_hlsl_functionality1.
SHADERC_EXPORT void shaderc_compile_options_set_hlsl_functionality1(
    shaderc_compile_options_t options, bool enable);

// Sets whether the compiler should invert position.Y output in vertex shader.
SHADERC_EXPORT void shaderc_compile_options_set_invert_y(
    shaderc_compile_options_t options, bool enable);

// Sets whether the compiler generates code for max and min builtins which,
// if given a NaN operand, will return the other operand. Similarly, the clamp
// builtin will favour the non-NaN operands, as if clamp were implemented
// as a composition of max and min.
SHADERC_EXPORT void shaderc_compile_options_set_nan_clamp(
    shaderc_compile_options_t options, bool enable);

// An opaque handle to the results of a call to any shaderc_compile_into_*()
// function.
typedef struct shaderc_compilation_result* shaderc_compilation_result_t;

// Takes a GLSL source string and the associated shader kind, input file
// name, compiles it according to the given additional_options. If the shader
// kind is not set to a specified kind, but shaderc_glslc_infer_from_source,
// the compiler will try to deduce the shader kind from the source
// string and a failure in deducing will generate an error. Currently only
// #pragma annotation is supported. If the shader kind is set to one of the
// default shader kinds, the compiler will fall back to the default shader
// kind in case it failed to deduce the shader kind from source string.
// The input_file_name is a null-termintated string. It is used as a tag to
// identify the source string in cases like emitting error messages. It
// doesn't have to be a 'file name'.
// The source string will be compiled into SPIR-V binary and a
// shaderc_compilation_result will be returned to hold the results.
// The entry_point_name null-terminated string defines the name of the entry
// point to associate with this GLSL source. If the additional_options
// parameter is not null, then the compilation is modified by any options
// present.  May be safely called from multiple threads without explicit
// synchronization. If there was failure in allocating the compiler object,
// null will be returned.
SHADERC_EXPORT shaderc_compilation_result_t shaderc_compile_into_spv(
    const shaderc_compiler_t compiler, const char* source_text,
    size_t source_text_size, shaderc_shader_kind shader_kind,
    const char* input_file_name, const char* entry_point_name,
    const shaderc_compile_options_t additional_options);

// Like shaderc_compile_into_spv, but the result contains SPIR-V assembly text
// instead of a SPIR-V binary module.  The SPIR-V assembly syntax is as defined
// by the SPIRV-Tools open source project.
SHADERC_EXPORT shaderc_compilation_result_t shaderc_compile_into_spv_assembly(
    const shaderc_compiler_t compiler, const char* source_text,
    size_t source_text_size, shaderc_shader_kind shader_kind,
    const char* input_file_name, const char* entry_point_name,
    const shaderc_compile_options_t additional_options);

// Like shaderc_compile_into_spv, but the result contains preprocessed source
// code instead of a SPIR-V binary module
SHADERC_EXPORT shaderc_compilation_result_t shaderc_compile_into_preprocessed_text(
    const shaderc_compiler_t compiler, const char* source_text,
    size_t source_text_size, shaderc_shader_kind shader_kind,
    const char* input_file_name, const char* entry_point_name,
    const shaderc_compile_options_t additional_options);

// Takes an assembly string of the format defined in the SPIRV-Tools project
// (https://github.com/KhronosGroup/SPIRV-Tools/blob/master/syntax.md),
// assembles it into SPIR-V binary and a shaderc_compilation_result will be
// returned to hold the results.
// The assembling will pick options suitable for assembling specified in the
// additional_options parameter.
// May be safely called from multiple threads without explicit synchronization.
// If there was failure in allocating the compiler object, null will be
// returned.
SHADERC_EXPORT shaderc_compilation_result_t shaderc_assemble_into_spv(
    const shaderc_compiler_t compiler, const char* source_assembly,
    size_t source_assembly_size,
    const shaderc_compile_options_t additional_options);

// The following functions, operating on shaderc_compilation_result_t objects,
// offer only the basic thread-safety guarantee.

// Releases the resources held by the result object. It is invalid to use the
// result object for any further operations.
SHADERC_EXPORT void shaderc_result_release(shaderc_compilation_result_t result);

// Returns the number of bytes of the compilation output data in a result
// object.
SHADERC_EXPORT size_t shaderc_result_get_length(const shaderc_compilation_result_t result);

// Returns the number of warnings generated during the compilation.
SHADERC_EXPORT size_t shaderc_result_get_num_warnings(
    const shaderc_compilation_result_t result);

// Returns the number of errors generated during the compilation.
SHADERC_EXPORT size_t shaderc_result_get_num_errors(const shaderc_compilation_result_t result);

// Returns the compilation status, indicating whether the compilation succeeded,
// or failed due to some reasons, like invalid shader stage or compilation
// errors.
SHADERC_EXPORT shaderc_compilation_status shaderc_result_get_compilation_status(
    const shaderc_compilation_result_t);

// Returns a pointer to the start of the compilation output data bytes, either
// SPIR-V binary or char string. When the source string is compiled into SPIR-V
// binary, this is guaranteed to be castable to a uint32_t*. If the result
// contains assembly text or preprocessed source text, the pointer will point to
// the resulting array of characters.
SHADERC_EXPORT const char* shaderc_result_get_bytes(const shaderc_compilation_result_t result);

// Returns a null-terminated string that contains any error messages generated
// during the compilation.
SHADERC_EXPORT const char* shaderc_result_get_error_message(
    const shaderc_compilation_result_t result);

// Provides the version & revision of the SPIR-V which will be produced
SHADERC_EXPORT void shaderc_get_spv_version(unsigned int* version, unsigned int* revision);

// Parses the version and profile from a given null-terminated string
// containing both version and profile, like: '450core'. Returns false if
// the string can not be parsed. Returns true when the parsing succeeds. The
// parsed version and profile are returned through arguments.
SHADERC_EXPORT bool shaderc_parse_version_profile(const char* str, int* version,
                                   shaderc_profile* profile);

#ifdef __cplusplus
}
#endif  // __cplusplus

#endif  // SHADERC_SHADERC_H_
",c++
"/*
 * Problem Statement: https://www.hackerrank.com/contests/projecteuler/challenges/euler008/problem
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

static ll_t compute_largest_product(char[], const int);

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        while(test--) {
            getchar_unlocked();
            int n, k;
            if(2 == scanf(""%d%d"", &n, &k)) {
                getchar_unlocked();
                char number[n + 1];
                if(fgets(number, n + 1, stdin)) {
                    char *enter_char_loc = strchr(number, '\n');
                    if(enter_char_loc) {
                        *enter_char_loc = '\0';
                    }
                    printf(""%lld\n"", compute_largest_product(number, k));
                }
            } else {
                SCANF_READ_ERROR(2);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static ll_t compute_largest_product(char number[], const int digits) {
    int tot_digit = (int) strlen(number);
    ll_t max_product = 0;
    for(register int i = 0; i <= tot_digit - digits; ++i) {
        ll_t curr_product = 1;
        for(register int j = i, digit_limit = i + digits; j < digit_limit; ++j) {
            curr_product *= (number[j] - '0');
        }
        if(curr_product > max_product) {
            max_product = curr_product;
        }
    }
    return max_product;
}
",c++
"/*
** Copyright (c) 2014-2016 The Khronos Group Inc.
**
** Permission is hereby granted, free of charge, to any person obtaining a copy
** of this software and/or associated documentation files (the ""Materials""),
** to deal in the Materials without restriction, including without limitation
** the rights to use, copy, modify, merge, publish, distribute, sublicense,
** and/or sell copies of the Materials, and to permit persons to whom the
** Materials are furnished to do so, subject to the following conditions:
**
** The above copyright notice and this permission notice shall be included in
** all copies or substantial portions of the Materials.
**
** MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
** STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
** HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/ 
**
** THE MATERIALS ARE PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS
** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
** THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
** FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
** IN THE MATERIALS.
*/

#ifndef GLSLstd450_H
#define GLSLstd450_H

static const int GLSLstd450Version = 100;
static const int GLSLstd450Revision = 1;

enum GLSLstd450 {
    GLSLstd450Bad = 0,              // Don't use

    GLSLstd450Round = 1,
    GLSLstd450RoundEven = 2,
    GLSLstd450Trunc = 3,
    GLSLstd450FAbs = 4,
    GLSLstd450SAbs = 5,
    GLSLstd450FSign = 6,
    GLSLstd450SSign = 7,
    GLSLstd450Floor = 8,
    GLSLstd450Ceil = 9,
    GLSLstd450Fract = 10,

    GLSLstd450Radians = 11,
    GLSLstd450Degrees = 12,
    GLSLstd450Sin = 13,
    GLSLstd450Cos = 14,
    GLSLstd450Tan = 15,
    GLSLstd450Asin = 16,
    GLSLstd450Acos = 17,
    GLSLstd450Atan = 18,
    GLSLstd450Sinh = 19,
    GLSLstd450Cosh = 20,
    GLSLstd450Tanh = 21,
    GLSLstd450Asinh = 22,
    GLSLstd450Acosh = 23,
    GLSLstd450Atanh = 24,
    GLSLstd450Atan2 = 25,

    GLSLstd450Pow = 26,
    GLSLstd450Exp = 27,
    GLSLstd450Log = 28,
    GLSLstd450Exp2 = 29,
    GLSLstd450Log2 = 30,
    GLSLstd450Sqrt = 31,
    GLSLstd450InverseSqrt = 32,

    GLSLstd450Determinant = 33,
    GLSLstd450MatrixInverse = 34,

    GLSLstd450Modf = 35,            // second operand needs an OpVariable to write to
    GLSLstd450ModfStruct = 36,      // no OpVariable operand
    GLSLstd450FMin = 37,
    GLSLstd450UMin = 38,
    GLSLstd450SMin = 39,
    GLSLstd450FMax = 40,
    GLSLstd450UMax = 41,
    GLSLstd450SMax = 42,
    GLSLstd450FClamp = 43,
    GLSLstd450UClamp = 44,
    GLSLstd450SClamp = 45,
    GLSLstd450FMix = 46,
    GLSLstd450IMix = 47,            // Reserved
    GLSLstd450Step = 48,
    GLSLstd450SmoothStep = 49,

    GLSLstd450Fma = 50,
    GLSLstd450Frexp = 51,            // second operand needs an OpVariable to write to
    GLSLstd450FrexpStruct = 52,      // no OpVariable operand
    GLSLstd450Ldexp = 53,

    GLSLstd450PackSnorm4x8 = 54,
    GLSLstd450PackUnorm4x8 = 55,
    GLSLstd450PackSnorm2x16 = 56,
    GLSLstd450PackUnorm2x16 = 57,
    GLSLstd450PackHalf2x16 = 58,
    GLSLstd450PackDouble2x32 = 59,
    GLSLstd450UnpackSnorm2x16 = 60,
    GLSLstd450UnpackUnorm2x16 = 61,
    GLSLstd450UnpackHalf2x16 = 62,
    GLSLstd450UnpackSnorm4x8 = 63,
    GLSLstd450UnpackUnorm4x8 = 64,
    GLSLstd450UnpackDouble2x32 = 65,

    GLSLstd450Length = 66,
    GLSLstd450Distance = 67,
    GLSLstd450Cross = 68,
    GLSLstd450Normalize = 69,
    GLSLstd450FaceForward = 70,
    GLSLstd450Reflect = 71,
    GLSLstd450Refract = 72,

    GLSLstd450FindILsb = 73,
    GLSLstd450FindSMsb = 74,
    GLSLstd450FindUMsb = 75,

    GLSLstd450InterpolateAtCentroid = 76,
    GLSLstd450InterpolateAtSample = 77,
    GLSLstd450InterpolateAtOffset = 78,

    GLSLstd450NMin = 79,
    GLSLstd450NMax = 80,
    GLSLstd450NClamp = 81,

    GLSLstd450Count
};

#endif  // #ifndef GLSLstd450_H
",c++
"float4 i4;
",c++
"#include <stdio.h>

int main (void) {
    int a, b, c,d,e,f;


    scanf(""%d"", &a);

    for(b=a+1,c=1; b ; c++,b--) {
        for(d=b-1; d; d--) printf(""  "");
        for(d=c-1,e=0; d; d--,e++) printf(""%d "",e);
        for(d=c; d>1 ; d--,e--) printf(""%d "",e);

        printf(""0\n"");
    }

    for(b=a; b; b--) {
        for(d=a-b+1; d; d--) printf(""  "");
        for(d=b-1,e=0; d; d--,e++ )printf(""%d "",e);
        for(d=b-1; d; d-- )printf(""%d "",d);

        printf(""02\n"");
    }



    return 0;
}
",c++
"float4 i2;

#include ""foo.h""
",c++
"// Copyright 2015 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef LIBSHADERC_UTIL_SRC_DEATH_TEST_H
#define LIBSHADERC_UTIL_SRC_DEATH_TEST_H

#ifdef NDEBUG
#define EXPECT_DEBUG_DEATH_IF_SUPPORTED(statement, regexp)
#else
#define EXPECT_DEBUG_DEATH_IF_SUPPORTED(statement, regexp) \
  EXPECT_DEATH_IF_SUPPORTED(statement, regexp)
#endif

#endif  // LIBSHADERC_UTIL_SRC_DEATH_TEST_H
",c++
"#include <stdio.h>

int main () {
    int a;
    scanf(""%d"",&a);

    if(a%4==0)printf(""YES"");
    else if(a%2==0) {
        if(a/2 > 1) printf(""YES"");
        else printf(""NO"");
    }
    else printf(""No"");

    return 0;
}
",c++
"// Copyright 2018 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef SHADERC_ENV_H_
#define SHADERC_ENV_H_

#include <stdint.h>

#ifdef __cplusplus
extern ""C"" {
#endif

typedef enum {
  shaderc_target_env_vulkan,  // SPIR-V under Vulkan semantics
  shaderc_target_env_opengl,  // SPIR-V under OpenGL semantics
  // NOTE: SPIR-V code generation is not supported for shaders under OpenGL
  // compatibility profile.
  shaderc_target_env_opengl_compat,  // SPIR-V under OpenGL semantics,
                                     // including compatibility profile
                                     // functions
  shaderc_target_env_webgpu,         // Deprecated, SPIR-V under WebGPU
                                     // semantics
  shaderc_target_env_default = shaderc_target_env_vulkan
} shaderc_target_env;

typedef enum {
  // For Vulkan, use Vulkan's mapping of version numbers to integers.
  // See vulkan.h
  shaderc_env_version_vulkan_1_0 = ((1u << 22)),
  shaderc_env_version_vulkan_1_1 = ((1u << 22) | (1 << 12)),
  shaderc_env_version_vulkan_1_2 = ((1u << 22) | (2 << 12)),
  shaderc_env_version_vulkan_1_3 = ((1u << 22) | (3 << 12)),
  // For OpenGL, use the number from #version in shaders.
  // TODO(dneto): Currently no difference between OpenGL 4.5 and 4.6.
  // See glslang/Standalone/Standalone.cpp
  // TODO(dneto): Glslang doesn't accept a OpenGL client version of 460.
  shaderc_env_version_opengl_4_5 = 450,
  shaderc_env_version_webgpu,  // Deprecated, WebGPU env never defined versions
} shaderc_env_version;

// The known versions of SPIR-V.
typedef enum {
  // Use the values used for word 1 of a SPIR-V binary:
  // - bits 24 to 31: zero
  // - bits 16 to 23: major version number
  // - bits 8 to 15: minor version number
  // - bits 0 to 7: zero
  shaderc_spirv_version_1_0 = 0x010000u,
  shaderc_spirv_version_1_1 = 0x010100u,
  shaderc_spirv_version_1_2 = 0x010200u,
  shaderc_spirv_version_1_3 = 0x010300u,
  shaderc_spirv_version_1_4 = 0x010400u,
  shaderc_spirv_version_1_5 = 0x010500u,
  shaderc_spirv_version_1_6 = 0x010600u
} shaderc_spirv_version;

#ifdef __cplusplus
}
#endif  // __cplusplus

#endif  // SHADERC_ENV_H_
",c++
"#include <stdio.h>

int main (void) {
    int i,j,k,l=0;
    int prime[] ={
     2 ,     3   ,   5  ,    7    , 11 ,    13  ,   17   ,  19  ,   23 ,    29 ,
     31  ,   37  ,   41   ,  43  ,   47 , 0
    };


    scanf(""%d %d"", &i, &j);

    for(k=0; k<15; k++) {
        if(prime[k]==i) {
            if(prime[k+1]==j) {
                printf(""YES\n"");
                l=1;
            }
            else break;
        }
    }

    if(l==0) printf(""NO\n"");

    return 0;
}
",c++
"#include <stdio.h>
#include <conio.h>

int main (void) {
    char str1[27],ch1;
    char str2[100][100];
    int row, column,i,j,m,n=0,l;

    scanf(""%d %d"", &row, &column);
    scanf(""%c"",&ch1);
    scanf(""%c"",&ch1);

    for(i=0; i<row; i++){
        for(j=0; j<column; j++) str2[i][j]=getche();
    }

    for(i=0; i<row ;i++){
        for(j=0; j<column; j++){
            if(str2[i][j-1] == ch1 || str2[i][j+1] == ch1 || str2[i-1][j] == ch1 || str2[i+1][j] == ch1 ) {
                if(str2 != '.') {
                    for(l=0,m=1; l<27; l++) {
                        if(str1[l]== str2[i][j]) {
                            m=0;
                            break;
                        }
                    }
                    if(m=1) {
                        str1[n]= str2[i][j];
                        n++;
                    }
                }
            }
        }
    }

    printf(""%d"",n);

    return 0;
    }
",c++
"#include <stdio.h>

int main (void) {
    long long int n;
    int k,w,a=0,i=0;

    scanf(""%d %I64d %d"",&k,&n,&w);

    for(i=k; a<w ; i = i+k, a++) n = n-i;

    if(n>0) printf(""0\n"");
    else printf(""%d\n"", n*(-1));

    return 0;
}
",c++
"    #include<stdio.h>  
     int main()    
    {    
    int n,r,sum=0,temp;    
    printf(""enter the number="");    
    scanf(""%d"",&n);    
    temp=n;    
    while(n>0)    
    {    
    r=n%10;    
    sum=sum+(r*r*r);    
    n=n/10;    
    }    
    if(temp==sum)    
    printf(""armstrong  number "");    
    else    
    printf(""not armstrong number"");    
    return 0;  
    }   
",c++
"#include ""parentBad""
",c++
"/*  Problem Statement: https://www.spoj.com/problems/PIHU1/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<stdbool.h>
#include<assert.h>

const bool check_sorted(uint32_t *const,uint16_t);
void merge_sort(uint32_t *const,uint16_t,uint16_t);
void merge_data(uint32_t *const,uint16_t,uint16_t,uint16_t);
const bool is_representation_possible(uint32_t *const,uint16_t,uint32_t);

int main(void) {
    uint8_t test;
    scanf(""%""SCNu8, &test);
    assert(test > 0);
    while(test--) {
        uint16_t n;
        scanf(""%""SCNu16, &n);
        uint32_t *const data = calloc(n,sizeof(uint32_t));
        if(data) {
            for(uint16_t i = 0; i < n; ++i) {
                scanf(""%""SCNu32, &data[i]);
            }
            uint32_t p;
            scanf(""%""SCNu32, &p);
            if(!check_sorted(data,n)) {
                merge_sort(data,0,(n - 1));
            }
            printf(""%s"", (is_representation_possible(data,n,p) ? ""YES\n"" : ""NO\n""));
            free(data);
        } else {
            fprintf(stderr,""Not able to allocate %lu bytes of memory\n"", (n * sizeof(uint32_t)));
        }
    }
    return EXIT_SUCCESS;
}

const bool check_sorted(uint32_t *const data,uint16_t n) {
    bool is_sorted = true;
    for(uint32_t i = 0; i < (n - 1); ++i) {
        if(data[i] > data[i + 1]) {
            is_sorted = false;
            break;
        }
    }
    return is_sorted;
}

void merge_sort(uint32_t *const data,uint16_t start,uint16_t end) {
    if(start < end) {
        uint16_t mid = ((end - start) >> 1) + start;
        merge_sort(data,start,mid);
        merge_sort(data,(mid + 1),end);
        merge_data(data,start,mid,end);
    }
}

void merge_data(uint32_t *const data,uint16_t start,uint16_t mid,uint16_t end) {
    uint16_t left_size = (mid - start) + 1;
    uint32_t *const left_list = calloc(left_size,sizeof(uint32_t));
    if(left_list) {
        for(uint16_t i = 0; i < left_size; ++i) {
            left_list[i] = data[start + i];
        }
    } else {
        fprintf(stderr,""Not able to allocate %lu bytes of memory to left-list\n"", left_size * sizeof(uint32_t));
    }
    uint16_t right_size = end - mid;
    uint32_t *const right_list = calloc(right_size,sizeof(uint32_t));
    if(right_list) {
        for(uint32_t j = 0; j < right_size; ++j) {
            right_list[j] = data[(mid + 1) + j];
        }
    } else {
        fprintf(stderr,""Not able to allocate %lu bytes of memory to right-list\n"", right_size * sizeof(uint32_t));
    }
    for(uint16_t k = start, i = 0,j = 0; k <= end; ++k) {
        if(i == left_size) {
            data[k] = right_list[j];
            ++j;
        } else if(j == right_size) {
            data[k] = left_list[i];
            ++i;
        } else if(left_list[i] < right_list[j]) {
            data[k] = left_list[i];
            ++i;
        } else {
            data[k] = right_list[j];
            ++j;
        }
    }
    free(left_list);
    free(right_list);
}

const bool is_representation_possible(uint32_t *const data,uint16_t n,uint32_t p) {
    bool is_possible = false;
    for(uint16_t i = 0; i < (n - 2); ++i) {
        if(data[i] >= p) {
            continue;
        }
        uint32_t s = p - data[i];
        for(uint16_t start = (i + 1), end = (n - 1); start < end;) {
            if(data[start] + data[end] == s) {
                // printf(""Ai: %""PRIu32"" Aj: %""PRIu32"" Ak: %""PRIu32""\n"", data[start],data[end],(p - s));
                is_possible = true;
                break;
            } else if(data[start] + data[end] > s) {
                --end;
            } else {
                ++start;
            }
        }
        if(is_possible) {
            break;
        }
    }
    return is_possible;
}",c++
"/*
 * Problem Statement: https://www.spoj.com/problems/IITKWPCA/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

#define MAX_STRING_LENGTH 10002

typedef struct node {
    char *word;
    struct node *next;
} node_t;

static int compute_niceness_value(char*);
static node_t * makenode_list(char[]);
static void insert_node_list(node_t*, node_t*);
static bool search_data_list(const node_t*, char[]);
static int compute_list_length(node_t*);

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        getchar_unlocked();
        while(test--) {
            char sentence[MAX_STRING_LENGTH];
            if(fgets(sentence, MAX_STRING_LENGTH, stdin)) {
                char *const enter_char_loc = strchr(sentence, '\n');
                if(enter_char_loc) {
                    *enter_char_loc = '\0';
                }
                printf(""%d\n"", !strchr(sentence, ' ') ? 1 : compute_niceness_value(sentence));
            } else {
                fprintf(stderr, ""Line number: %u: Not able to read the string from stdin.\n"", __LINE__);
                exit(0);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static node_t * makenode_list(char data[]) {
    node_t *new_node = malloc(sizeof*new_node);
    if(new_node) {
        new_node->word = data;
        new_node->next = NULL;
    } else {
        MEMORY_ALLOCATION_FAILED_ERROR(new_node, sizeof*new_node);
        exit(0);
    }
    return new_node;
}

static void insert_node_list(node_t *traverse_ptr, node_t *new_node) {
    for(; traverse_ptr->next; traverse_ptr = traverse_ptr->next);
    traverse_ptr->next = new_node;
}

static bool search_data_list(const node_t *traverse_ptr, char search_data[]) {
    bool is_present = false;
    for(; traverse_ptr; traverse_ptr = traverse_ptr->next) {
        if(!strcmp(traverse_ptr->word, search_data)) {
            is_present = true;
            break;
        }
    }
    return is_present;
}

static int compute_list_length(node_t *traverse_ptr) {
    int list_length = 0;
    for(node_t *del_node = traverse_ptr; traverse_ptr; ++list_length) {
        traverse_ptr = traverse_ptr->next;
        free(del_node->word);
        free(del_node);
        del_node = traverse_ptr;
    }
    return list_length;
}

static int compute_niceness_value(char *sentence) {
    node_t *head_ptr = NULL;
    char *start_loc = sentence;
    unsigned long int whitespace_count, read_char_count;
    whitespace_count = read_char_count = 0;
    for(register int i = 0; sentence[i]; ++i) {
        if(sentence[i] == ' ') {
            ++whitespace_count;
            if(read_char_count && whitespace_count == 1) {
                char *token = calloc((size_t) (1 + read_char_count), sizeof*token);
                if(token) {
                    memcpy(token, start_loc, (read_char_count * sizeof*token));
                    token[read_char_count] = '\0';
                    read_char_count = 0;
                    if(!head_ptr) {
                        head_ptr = makenode_list(token);
                        continue;
                    }
                    if(!search_data_list(head_ptr, token)) {
                        insert_node_list(head_ptr, makenode_list(token));
                        continue;
                    }
                    free(token);
                } else {
                    MEMORY_ALLOCATION_FAILED_ERROR(token, 1 + read_char_count * sizeof*token);
                    exit(0);
                }
            }
            continue;
        }
        whitespace_count = 0;
        ++read_char_count;
        if(read_char_count == 1) {
            start_loc = sentence + i;
        }
    }
    if(read_char_count) {
        char *token = calloc((size_t) (1 + read_char_count), sizeof*token);
        if(token) {
            token[read_char_count] = '\0';
            memcpy(token, start_loc, read_char_count * sizeof*token);
            if(!search_data_list(head_ptr, token)) {
                insert_node_list(head_ptr, makenode_list(token));
            } else {
                free(token);
            }
        } else {
            MEMORY_ALLOCATION_FAILED_ERROR(token, 1 + read_char_count* sizeof*token);
        }
    }
    return compute_list_length(head_ptr);
}
",c++
"#include <stdio.h>

int main () {

    long long int number, height, procLength;
    long long int temp=0;
    long long int totalTime = 0;
    long long int load = 0;


    scanf(""%I64d %I64d %I64d"", &number, &height, &procLength);

    while(number--) {

        scanf(""%I64d"", &temp);

        if(load+temp > height) {

            int key = height - load;
            key = temp - key;

            if( key%procLength ) key += (procLength - (key%procLength));
            totalTime += (key/procLength);

            if(load < key) load = 0;
            else load -= key;
            load += temp;
        }
        else {
            load += temp;
            continue;
        }

    }

    if(load > 0) {

        totalTime += (load/procLength);
        if(load%procLength) totalTime++;
    }

    printf(""%I64d\n"", totalTime);

    return 0;
}
",c++
"/*  Problem Statement: https://www.hackerrank.com/contests/core-intra/challenges/clock-hands/problem
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<string.h>
#include<math.h>
#include<assert.h>

#define MAX_LENGTH 6

static double compute_angle_between_hands(const uint8_t,const uint8_t);

int main(void) {
    uint8_t test;
    scanf(""%""SCNu8, &test);
    assert(test > 0 && test < 11);
    while(test--) {
        char time[MAX_LENGTH];
        scanf(""%s"", time);
        uint8_t len = strlen(time) + 1;
        char *buffer = calloc(sizeof(char),len);
        snprintf(buffer,len,""%s"",time);
        uint8_t hr = atoi(__strtok_r(buffer,"":"",&buffer));
        uint8_t min = atoi(__strtok_r(NULL,"":"",&buffer));
        assert(min >= 0 && min < 61);
        if(min == 60) {
            min = 0;
            hr += 1;
        }
        if(hr > 12 && hr < 25) {
            hr %= 12;
        }
        assert(hr >= 0 && hr < 13);
        double angle_between_hands = compute_angle_between_hands(hr,min);
        if(floor(angle_between_hands) == angle_between_hands) {
            printf(""%""PRIu8""\n"", (int)(angle_between_hands));
        } else {
            printf(""%0.1lf\n"", angle_between_hands);
        }
    }
    return EXIT_SUCCESS;
}

static double compute_angle_between_hands(const uint8_t hr,const uint8_t min) {
    double hr_angle,min_angle;
    hr_angle = (30 * hr) + (0.5 * min);
    min_angle = 6 * min;
    double angle_between_hands = 0.0;
    angle_between_hands = fabs(hr_angle - min_angle);
    if(angle_between_hands > 180) {
        angle_between_hands = 360 - angle_between_hands;
    }
    return angle_between_hands;
}",c++
"/*
 * Problem Statement: https://www.linkedin.com/posts/gcnit_projecteuler-code-coding-activity-6636246267817226240-5lgK
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d\n"", __LINE__, return_val); exit(0)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

// Solution to the problem starts from below.

#define TOTAL_PRIMES 78498
#define LIMIT 1000001

unsigned int prime_number[TOTAL_PRIMES];

static void generate_primes(void);

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        generate_primes(); // Generate all the primes upto given n i.e. 10^5.
        while(test--) {
            int n;
            if(1 == scanf(""%d"", &n)) {
                printf(""%d\n"", prime_number[n - 1]); // After generating the prime, you can calculate the nth prime in O(1) time.
            } else {
                SCANF_READ_ERROR(1);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static void generate_primes(void) {
    bool sieve_table[LIMIT];
    memset(sieve_table, 1, LIMIT * sizeof(bool)); // Initialise every location of sieve_table array to true.
    // Sieve of Eratosthenes algorithm.
    sieve_table[0] = sieve_table[1] = false; // As 0 and 1 are not prime numbers.
    for(register ll_t i = 2, k = 0; i < LIMIT; ++i) {
        if(sieve_table[i]) {
            prime_number[k++] = i;
            for(register ll_t j = i * i; j < LIMIT; j += i) {
                sieve_table[j] = false;
                continue;
            }
        }
    }
}
",c++
"#include <stdio.h>
#include <string.h>

int main () {
    int i,j;
    char str1[101];

    scanf(""%d"", &i);

    for(; i; i--) {
        for (j=0; j<101; j++ ) {
            str1[j]=0;
        }
        scanf(""%s"", str1);
        j=strlen(str1);

        if (j>10) printf(""%c%d%c\n"", str1[0],j-2, str1[j-1]);
        else {
            printf(""%s"", str1);
            printf(""\n"");
        }
    }

    return 0;
}
",c++
"/*
 * Problem Statement: https://www.spoj.com/problems/BYTESM2
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <ctype.h>
#include <limits.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <time.h>

/*START OF CODE-TEMPLATE*/

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

/*END OF CODE-TEMPLATE*/

static int compute_maximum_element(const int *const, const int);
static int compute_maximum_path_cost(int **const, const int, const int);
static void free_dynamic_memory(int **const, const int);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        int nrows, ncols;
        if(2 == scanf(""%d%d"", &nrows, &ncols)) {
            int **const matrix = calloc((size_t) nrows, sizeof*matrix);
            if(!matrix) {
                MEMORY_ALLOCATION_FAILED_ERROR(matrix, (size_t) nrows * sizeof*matrix);
                exit(0);
            }
            for(int i = 0; i < nrows; ++i) {
                matrix[i] = calloc((size_t) ncols, sizeof**matrix);
                if(!matrix[i]) {
                    MEMORY_ALLOCATION_FAILED_ERROR(matrix[i], (size_t) ncols * sizeof**matrix);
                    exit(0);
                }
                for(int j = 0; j < ncols; ++j) {
                    if(1 != scanf(""%d"", &matrix[i][j])) {
                        SCANF_READ_ERROR(1);
                    }
                }
            }
            printf(""%d\n"", compute_maximum_path_cost(matrix, nrows, ncols));
            free_dynamic_memory(matrix, nrows);
            continue;
        }
        SCANF_READ_ERROR(2);
    }
    return EXIT_SUCCESS;
}

static int compute_maximum_element(const int *const sequence, const int n) {
    int max_value = 0;
    for(int i = 0; i < n; ++i) {
        if(sequence[i] > max_value) {
            max_value = sequence[i];
        }
    }
    return max_value;
}

static int compute_maximum_path_cost(int **const matrix, const int nrows, const int ncols) {
    if(nrows == 1 && ncols == 1) {
        return matrix[0][0];
    }
    if(nrows == 1) {
        return compute_maximum_element(matrix[0], ncols);
    }
    if(ncols == 1) {
        int value_sum = 0;
        for(int i = 0; i < nrows; ++i) {
            value_sum += matrix[i][0];
        }
        return value_sum;
    }
    int *cost_matrix, *temp_matrix;
    cost_matrix = calloc((size_t) ncols, sizeof*cost_matrix);
    if(!cost_matrix) {
        MEMORY_ALLOCATION_FAILED_ERROR(cost_matrix, (size_t) ncols * sizeof*cost_matrix);
        exit(0);
    }
    temp_matrix = calloc((size_t) ncols, sizeof*temp_matrix);
    if(!temp_matrix) {
        MEMORY_ALLOCATION_FAILED_ERROR(temp_matrix, (size_t) ncols * sizeof*temp_matrix);
        exit(0);
    }
    for(int j = 0; j < ncols; ++j) {
        cost_matrix[j] = matrix[0][j];
    }
    for(int i = 1; i < nrows; ++i) {
        for(int j = 0; j < ncols; ++j) {
            if(!j) {
                temp_matrix[j] = FIND_MAX(cost_matrix[j] + matrix[i][j], cost_matrix[j + 1] + matrix[i][j]);
                continue;
            }
            if(j == ncols - 1) {
                temp_matrix[j] = FIND_MAX(cost_matrix[j] + matrix[i][j], cost_matrix[j - 1] + matrix[i][j]);
                continue;
            }
            temp_matrix[j] = FIND_MAX(FIND_MAX(cost_matrix[j - 1] + matrix[i][j], cost_matrix[j] + matrix[i][j]), cost_matrix[j + 1] + matrix[i][j]);
        }
        for(int j = 0; j < ncols; ++j) {
            cost_matrix[j] = temp_matrix[j];
        }
    }
    int max_cost = compute_maximum_element(cost_matrix, ncols);
    free(cost_matrix);
    free(temp_matrix);
    return max_cost;
}

static void free_dynamic_memory(int **const matrix, const int nrows) {
    for(int i = 0; i < nrows; ++i) {
        free(matrix[i]);
    }
    free(matrix);
}
",c++
"#include <stdio.h>

int main () {
    int pass,plane,i=0;
    int seat[1000];

    for(i=0; i<100; i++) seat[i]=0;

    scanf(""%d %d"", &pass, &plane);

    for( i=0 ; i < plane ; i++) scanf(""%d"", &seat[i]);

    // min earning
    for()

    return 0;
}
",c++
"/*
 * Problem Statement: https://leetcode.com/problems/number-of-steps-to-reduce-a-number-to-zero/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d\n"", __LINE__, return_val); exit(0)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

static int number_of_steps(int);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    if(1 == scanf(""%d"", &test)) {
        if(test < 1) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(test, test value cannot be 0 or -ve);
            exit(0);
        }
        while(test--) {
            int n;
            if(1 == scanf(""%d"", &n)) {
                if(n < 0) {
                    CONSTRAINTS_OUT_OF_BOUND_ERROR(n, n cannot be 0 or -ve);
                    exit(0);
                }
                printf(""%d\n"", number_of_steps(n));
            } else {
                SCANF_READ_ERROR(1);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

/*
 * Function which needs to be written on Leet-Code.
*/

static int number_of_steps(int n) {
    if(n && !(n & (n - 1))) {
        return 1 + log2(n);
    }
    int nsteps = 0;
    while(n) {
        ++nsteps;
        if(n && !(n & (n - 1))) {
            nsteps += log2(n);
            break;
        }
        if(!(n % 2)) {
            n >>= 1;
            continue;
        }
        n -= 1;
    }
    return nsteps;
}
",c++
"/*
 * Problem Statement: https://leetcode.com/explore/featured/card/top-interview-questions-easy/92/array/727/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <ctype.h>
#include <limits.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <time.h>

/*START OF CODE-TEMPLATE*/

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

/*END OF CODE-TEMPLATE*/

static int remove_duplicates(int *const, const int);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        int n;
        if(1 != scanf(""%d"", &n)) {
            SCANF_READ_ERROR(1);
        }
        int *const sequence = calloc((size_t) n, sizeof*sequence);
        if(!sequence) {
            MEMORY_ALLOCATION_FAILED_ERROR(sequence, (size_t) n * sizeof*sequence);
            exit(0);
        }
        for(int i = 0; i < n; ++i) {
            if(1 != scanf(""%d"", sequence + i)) {
                SCANF_READ_ERROR(1);
            }
        }
        const int limit = remove_duplicates(sequence, n);
        for(int i = 0; i < limit; ++i) {
            printf(""%d "", sequence[i]);
        }
        printf(""\n"");
        free(sequence);
    }
    return EXIT_SUCCESS;
}

static int remove_duplicates(int *const sequence, const int n) {
    if(!n) {
        return 0;
    }
    int index = 0, i = 1;
    for(; i < n; ++i) {
        if(sequence[index] != sequence[i]) {
            sequence[++index] = sequence[i];
        }
    }
    return 1 + index;
}
",c++
"#include <stdio.h>

int main (void) {
    char str1[51],changer;
    int stu, time, count=0,i;

    scanf(""%d %d"", &stu, &time);

    gets(str1);
    gets(str1);

    for ( ; time ; time--) {
        for(i=0 ; str1[i]; i++ ) {
            if(str1[i]== 'B' && str1[i+1]=='G') {
                changer= str1[i];
                str1[i]= str1[i+1];
                str1[i+1]= changer;
                i++;
            }
        }
    }

    printf(str1);

    return 0;
}
",c++
"#include <stdio.h>

int main (void) {
    int a, b, c, e1,e2,e3,e4,e5,e6,sum=0;

    scanf(""%d %d %d"", &a, &b,&c);

    e1=a + b + c;
    e2=a * b * c;
    e3=a + b * c;
    e4=a * b + c;
    e5=(a + b)* c;
    e6=a * (b+c);


    if (e1>sum) sum = e1;
    if (e2>sum) sum = e2;
    if (e3 >sum) sum = e3;
    if (e4 >sum) sum = e4;
    if (e5 >sum) sum = e5;
    if (e6>sum) sum = e6;

    printf(""%d"", sum);

    return 0;
}
",c++
"/*
 * Problem Statement: https://github.com/strikersps/Competitive-Programming/blob/master/Other-Programs/Best-Pair/readme.md
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define INITIALISE_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

static bool check_sorted(const ll_t *const, const int);
static void merge_sort(ll_t *const, const int, const int);
static void merge_data(ll_t *const, const int, const int, const int);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    scanf(""%d"", &test);
    while(test--) {
        int n;
        scanf(""%d"", &n);
        ll_t *const data = calloc(n, sizeof*data);
        if(data) {
            for(int i = 0; i < n; ++i) {
                scanf(""%lld"", &data[i]);
            }
            if(!check_sorted(data, n)) {
                merge_sort(data, 0, n - 1);
            }
            printf(""%lld\n"", FIND_MAX((data[0] * data[1]), (data[n - 1] * data[n - 2])));
            free(data);
        } else {
            MEMORY_ALLOCATION_FAILED_ERROR(data, n * sizeof*data);
            exit(0);
        }
    }
    return EXIT_SUCCESS;
}

static bool check_sorted(const ll_t *const data, const int n) {
    bool is_sorted = true;
    for(int i = 0; i < (n - 1); ++i) {
        if(data[i] > data[i + 1]) {
            is_sorted = false;
            break;
        }
    }
    return is_sorted;
}

static void merge_sort(ll_t *const data, const int start, const int end) {
    if(start < end) {
        const int mid = FIND_MID(start, end);
        merge_sort(data, start, mid);
        merge_sort(data, mid + 1, end);
        merge_data(data, start, mid, end);
    }
}

static void merge_data(ll_t *const data, const int start, const int mid, const int end) {
    const int left_size = (mid - start) + 1;
    ll_t *const left_data = calloc(left_size, sizeof*left_data);
    if(left_data) {
        memcpy(left_data, &data[start], left_size * sizeof*data);
    } else {
        MEMORY_ALLOCATION_FAILED_ERROR(left_data, left_size * sizeof*left_data);
        exit(0);
    }
    const int right_size = end - mid;
    ll_t *const right_data = calloc(right_size, sizeof*right_data);
    if(right_data) {
        memcpy(right_data, &data[mid + 1], right_size * sizeof*data);
    } else {
        MEMORY_ALLOCATION_FAILED_ERROR(right_data, right_size * sizeof*right_data);
        exit(0);
    }
    for(int i = 0, j = 0, k = start; k <= end;) {
        if(i == left_size) {
            data[k++] = right_data[j++];
        } else if(j == right_size) {
            data[k++] = left_data[i++];
        } else if(left_data[i] < right_data[j]) {
            data[k++] = left_data[i++];
        } else {
            data[k++] = right_data[j++];
        }
    }
    free(left_data);
    free(right_data);
}
",c++
"#include <stdio.h>

int main () {
    int m,n,a;

    scanf(""%d %d"", &m, &n);

    a= m*n;
    printf(""%d"", a/2);

    return 0;
}
",c++
"#include <stdio.h>

void simple_merge(int a[], int f, int s, int t){
    int i=f, j=s, k=-1;
    int temp[20];
    while(i<=s-1 && j<=t){
        if(a[i]>a[j]){
            k++;
            temp[k] = a[j];
            j++;
        }
        else{
            k++;
            temp[k] = a[i];
            i++;
        }
    }
    if(i>s-1){
        for(int w=j; w<=t; w++){
            k++;
            temp[k] = a[w];
        }
    }else{
        for(int w=i; w<=s-1; w++){
            k++;
            temp[k] = a[w];
        }
    }
    for(int w=0; w<=k; w++){
        a[f+w] = temp[w];
    }
}


int merge_sort(int a[], int l, int r){
    int mid = (l+r)/2;
    if(l!=r){
        merge_sort(a, l, mid);
        merge_sort(a, mid+1, r);
        simple_merge(a, l, mid+1, r);
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call merge sort
    // a, 0, n-1
    merge_sort(a, 0, 5);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c++
"#include <stdio.h>
#include <math.h>

int main () {

    long long int a,b;
    int i=0,j,k,m,n=0;

    scanf(""%I64d"", &a);

    for ( b=a ; b ; ) {
        b = b/10;
        i++;
    }

    for(j=1; j<i; j++) {
        for(k=1, m=1; k<=j; k++) {
            m= m*2;
        }
        n=n+m;
    }


    if(a%((i-1)*10)==4) n = n+1;



    printf(""%d"", n);

    return 0;
}
",c++
"// Copyright 2018 The Shaderc Authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef SHADERC_VISIBILITY_H_
#define SHADERC_VISIBILITY_H_

// SHADERC_EXPORT tags symbol that will be exposed by the shared libraries.
#if defined(SHADERC_SHAREDLIB)
#if defined(_WIN32)
#if defined(SHADERC_IMPLEMENTATION)
#define SHADERC_EXPORT __declspec(dllexport)
#else
#define SHADERC_EXPORT __declspec(dllimport)
#endif
#else
#if defined(SHADERC_IMPLEMENTATION)
#define SHADERC_EXPORT __attribute__((visibility(""default"")))
#else
#define SHADERC_EXPORT
#endif
#endif
#else
#define SHADERC_EXPORT
#endif

#endif  // SHADERC_VISIBILITY_H_
",c++
"float4 p3;
",c++
"/*  Problem Statement: Refer the readme.md file.
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<assert.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

void take_input(size_t *const,size_t);
size_t* transform_list(size_t *const,size_t);
void display_list(size_t *const,size_t);

int main(void) {
    int test;
    printf(""Enter the number of test-cases\n"");
    scanf(""%d"",&test);
    assert(test > 0);
    while(test--) {
        size_t n;
        printf(""Enter the length of the sequence\n"");
        scanf(""%lu"",&n);
        assert(n > 0);
        // Assumption: All the numbers in the sequence are positive, and zero is not allowed.
        size_t *const data = calloc(n,sizeof(size_t));
        if(data) {
            printf(""Enter the data into the sequence\n"");
            take_input(data,n);
            size_t *const transformed_list = transform_list(data,n);
            display_list(transformed_list,n);
            free(transformed_list);
            free(data);
        } else {
            fprintf(stderr,""Memory not allocated to *data pointer!\n"");
        }
    }
    return 0;
}

void take_input(size_t *const data,size_t n) {
    for(size_t i = 0; i < n; ++i) {
        scanf(""%lu"",&data[i]);
        assert(data[i] != 0);
    }
}

size_t* transform_list(size_t *const data,size_t n) {
    ull_t cummulative_product = 1;
    size_t *left_list = calloc(n,sizeof(size_t));
    if(left_list) {
        for(size_t i = 0; i < n; ++i) {
            cummulative_product *= data[i];
            left_list[i] = cummulative_product;
        }
    } else {
        fprintf(stderr,""Memory not allocated to *left-list pointer!\n"");
    }
    cummulative_product = 1;
    size_t *right_list = calloc(n,sizeof(size_t));
    if(right_list) {
        for(int i = (n - 1); i >= 0; --i) {
            cummulative_product *= data[i];
            right_list[i] = cummulative_product;
        }
    } else {
        fprintf(stderr,""Memory not allocated to the *right-list pointer!\n"");
    }
    size_t *transformed_list = calloc(n,sizeof(size_t));
    for(size_t i = 0; i < n; ++i) {
        if(!i) {
            transformed_list[i] = right_list[i + 1];
        } else if(i == (n - 1)) {
            transformed_list[i] = left_list[i - 1];
        } else {
            transformed_list[i] = right_list[i + 1] * left_list[i - 1];
        }
    }
    free(left_list);
    free(right_list);
    return transformed_list;
}

void display_list(size_t *const data,size_t n) {
    for(size_t i = 0; i < n; ++i) {
        printf(""%lu "",data[i]);
    }
    printf(""\n"");
}",c++
"#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#define MAX 5

struct vertex{
    char lable;
    bool visited;
};

// graph variables
struct vertex *vertices[MAX];
int adjencencymatrix[MAX][MAX];
int vertexcount = 0;

// stack variables
int stack[MAX];
int top = -1;

// stack functions
void push(int x){
    stack[++top] = x;
}

int pop(){
    return stack[top--];
}

int peek(){
    return stack[top];
}

bool isstackempty(){
    return(top==-1);    
}

// graph functions
void addVertex(char x){
    struct vertex *v = (struct vertex *)malloc(sizeof(struct vertex));
    v -> lable = x;
    v -> visited = false;
    vertices[vertexcount++] = v;
}

void addEdge(int start, int end){
    adjencencymatrix[start][end] = 1;
    adjencencymatrix[end][start] = 1;
}

void displayvertex(int vertexindex){
    printf(""%c "", vertices[vertexindex]->lable);
}

int getadjecentvertex(int vertexindex){
    int i;
    for(i = 0; i<vertexcount; i++){
        if(adjencencymatrix[vertexindex][i]==1 && vertices[i]->visited == false){
            return i;
        }
    }
    return -1;
}

void depthFirstSearch(){
    int i;
    vertices[0] -> visited = true;
    displayvertex(0);
    push(0);
    
    while(!isstackempty()){
        //get the unvisited vertex of vertex which is at top of the stack
        int unvisited = getadjecentvertex(peek());
        
        //no adjacent vertex found
        if(unvisited == -1){
            pop();
        }
        else{
            vertices[unvisited]->visited = true;
            displayvertex(unvisited);
            push(unvisited);
        }
    }
    
    //stack is empty, search is complete, reset the visited flag
    for(i=0; i< vertexcount; i++){
        vertices[i]->visited = false;
    }
}


int main(void) {
	// your code goes here
	int i, j;
	for(i=0; i<MAX; i++){
	    for(j=0; j<MAX; j++){
	        adjencencymatrix[i][j] = 0;
	    }
	}
	
    addVertex('S');   // 0
    addVertex('A');   // 1
    addVertex('B');   // 2
    addVertex('C');   // 3
    addVertex('D');   // 4

    addEdge(0, 1);    // S - A
    addEdge(0, 2);    // S - B
    addEdge(0, 3);    // S - C
    addEdge(1, 4);    // A - D
    addEdge(2, 4);    // B - D
    addEdge(3, 4);    // C - D
    
    printf(""Depth First Search: "");
    depthFirstSearch(); 
    
	return 0;
}
",c++
"#include <stdio.h>

int insertion_sort(int a[], int n){
    for(int i=0; i<=n-1; i++){
        int j = i;
        int x = a[i];
        while(j>0 && a[j-1]>x){
            a[j] = a[j-1];
            j--;
        }
        a[j] = x;
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call insertion sort
    insertion_sort(a, 6);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c++
"#https://codeforces.com/problemset/problem/554/A



s = input()
result = 26
for l in s:
  result += 25
print(result)

# or print(len(input()) * 25 + 26)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1077/A

Solution: The total distance travelled towards right would be a * k/2. So would be towards left amounting to b * k/2. 
If k is odd, we do an extra move towards right and needs to be added. The difference of right and left net distances is
the final answer.  
'''


def solve(a, b, k):

    dist_right = a * (k/2)
    dist_left = b * (k/2)

    if k % 2 == 1:
        dist_right += a

    return dist_right - dist_left


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        a, b, k = map(int, raw_input().split("" ""))
        print solve(a, b, k)
",python
"#https://codeforces.com/problemset/problem/588/A




n = int(input())

a, p = map(int, input().split("" ""))
mm = a * p # minimum money
mp = p # minimum price
for i in range(n - 1):
  a, p = map(int, input().split("" ""))
  if p < mp:
    mp = p
  mm += a * mp

print(mm)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1451/A

Solution: The only condition is not not use the number itself for its divisor. Hence if n is even, we divide it by
its half and then use that divisor to divide itself. That amounts to 2 moves. If n is odd, we first reduce it by 1 to 
make it even and then follow the above steps. That amounts to 2 + 1 = 3 moves. For n = 1,2 and 3, we handle it explicitly
since they are outliers to the above optimal methodology. 
'''


def solve(n):

    if n <= 1:
        return 0
    elif n == 2:
        return 1
    elif n == 3:
        return 2
    elif n % 2 == 0:
        return 2
    else:
        return 3


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        n = int(raw_input())
        print solve(n)
",python
"class_list = []

print('Welcome to the class list program.')

addClass = input('Would you like to add a class? Please enter Y or N: ')

while addClass == 'Y' or addClass == 'y':
    x = input('Please enter a class name to add to the list: ')
    class_list.append(x)
    addClass = input('Add another class? Enter Y or N: ')

    if addClass == 'N' or addClass == 'n':
        print('Thank you for using this program. Here is a list of classes you entered: ')
        for e in class_list:
            print(e)
    else: # double check if this should be elif
        addClass = input('That is not a valid input, please enter Y or N: ')
        # TO ADD: if N, still print the list
        if addClass == 'N' or addClass == 'n':
            print('Thank you for using this program. Here is a list of classes you entered: ')
            for e in class_list:
                print(e)
        elif addClass == 'Y' or addClass == 'y':
            x = input('Please enter a class name to add to the list: ')
            

else: # this may have to be moved into the while loop
    print('It appears you have not entered a class. Thank you for using this program.')


",python
"s = input()
t = input()

yn = """"

for i in range(len(s)):
    # This line checks if the first letter in s is the same as the last one in t and if the second is the same as the second last, and so on
    if s[i] == t[len(t)-1-i]:
        yn += ""YES""
    else:
        yn += ""NO""

if ""NO"" in yn:
    print(""NO"")
else:
    print(""YES"")







# https://codeforces.com/problemset/problem/41/A

# The translation from the Berland language into the Birland language is not an easy task. Those languages are very similar: a berlandish word differs from a birlandish word with the same meaning a little: it is spelled (and pronounced) reversely. For example, a Berlandish word code corresponds to a Birlandish word edoc. However, it's easy to make a mistake during the «translation». Vasya translated word s from Berlandish into Birlandish as t. Help him: find out if he translated the word correctly.
#
# Input
# The first line contains word s, the second line contains word t. The words consist of lowercase Latin letters. The input data do not consist unnecessary spaces. The words are not empty and their lengths do not exceed 100 symbols.
#
# Output
# If the word t is a word s, written reversely, print YES, otherwise print NO.
#
# Examples
# inputCopy
# code
# edoc
# outputCopy
# YES
# inputCopy
# abb
# aba
# outputCopy
# NO
# inputCopy
# code
# code
# outputCopy
# NO
",python
"n = int(input())

bills = 0

if n >= 100:
    while n >= 100:
        n -= 100
        bills += 1

if n >= 20:
    while n >= 20:
        n -= 20
        bills += 1

if n >= 10:
    while n >= 10:
        n -= 10
        bills += 1

if n >= 5:
    while n >= 5:
        n -= 5
        bills += 1

if n >= 1:
    while n >= 1:
        n -= 1
        bills += 1

print(bills)




# Note: Use PyPy 3 instead on Python in this problem because Python is slower


# Allen has a LOT of money. He has 𝑛 dollars in the bank. For security reasons, he wants to withdraw it in cash (we will not disclose the reasons here). The denominations for dollar bills are 1, 5, 10, 20, 100. What is the minimum number of bills Allen could receive after withdrawing his entire balance?
# 
# Input
# The first and only line of input contains a single integer 𝑛 (1≤𝑛≤109).
# 
# Output
# Output the minimum number of bills that Allen could receive.
# 
# Examples
# input
# 125
# output
# 3
# input
# 43
# output
# 5
# input
# 1000000000
# output
# 10000000
# Note
# In the first sample case, Allen can withdraw this with a 100 dollar bill, a 20 dollar bill, and a 5 dollar bill. There is no way for Allen to receive 125 dollars in one or two bills.
# 
# In the second sample case, Allen can withdraw two 20 dollar bills and three 1 dollar bills.
# 
# In the third sample case, Allen can withdraw 100000000 (ten million!) 100 dollar bills.
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1487/A

Solution: All players which have a higher level from the weakest player(s) in the 
group can win at least one game. Hence we need find the minimum level for a player
and count how many of those are present. All the remaining players are potential
winners. 
'''


def solve(n, arr):
    min_elem = min(arr)

    min_elem_freq = 0
    for a in arr:
        if a == min_elem:
            min_elem_freq += 1

    return n - min_elem_freq


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        n = int(raw_input())
        arr = map(int, raw_input().split("" ""))
        print solve(n, arr)
",python
"import pytest

from ClassCreator import *

# Class

def test_class():
   c = Class()
   c.setKey(""PHIL 204"")
   c.setCourseName(""Introduction to the Philosophy of Science"")
   c.setUnits(4)
   object = c.getClass()
   assert object['courseKey'] == ""PHIL 204""
   assert object['courseName'] == ""Introduction to the Philosophy of Science""
   assert object['units'] == 4
   

def test_class_completion():
   c = Class()
   print(c.isCompleted)
   assert c.isCompleted == False
   c.complete()
   assert c.isCompleted == True
   

def test_classes_different():
   c1 = Class()
   c1.setKey(""ART 101"")
   c1.setCourseName(""Art History"")
   c1.setUnits(3)
   c2 = Class()
   c2.setKey(""BUS 101"")
   c2.setCourseName(""Business Accounting"")
   c2.setUnits(5)
   assert c1.courseKey != c2.courseKey
   assert c1.courseName != c2.courseName
   assert c1.units != c2.units
   assert c1 != c2


# ClassList

def test_classlist_add_single_class():
   c = Class()
   class_list = ClassList()
   class_list.addClass(c)
   assert isinstance(class_list.classes[0], Class)
   assert len(class_list.classes) == 1
   assert isinstance(class_list, ClassList)


# ClassList

def test_classlist_add_single_class2():
   c = Class()
   class_list = ClassList()
   class_list.addClass(c)
   assert isinstance(class_list.classes[0], Class)
   assert len(class_list.classes) == 1


def test_classlist_add_three_classes():
   class_list = ClassList()
   for i in range(0, 3):
      c = Class()
      class_list.addClass(c)
      assert len(class_list.classes) == i + 1


def test_classlist_add_three_classes2():
   c1 = Class()
   class_list = ClassList()
   class_list.addClass(c1)
   assert len(class_list.classes) == 1
   c2 = Class()
   class_list.addClass(c2)
   print(type(class_list))
   assert len(class_list.classes) == 2
   c3 = Class()
   class_list.addClass(c3)
   assert len(class_list.classes) == 3


def test_classlist_completion1():
   class_lists = ClassList()
   c1 = Class()
   c2 = Class()
   c3 = Class()

   c1.complete()

   class_lists.addClass(c1)
   class_lists.addClass(c2)
   class_lists.addClass(c3)

   assert class_lists.checkCompletion() == False


def test_classlist_completion2():
   class_lists1 = ClassList()
   c1 = Class()
   c2 = Class()
   c3 = Class()

   c3.complete()

   class_lists1.addClass(c1)
   class_lists1.addClass(c2)
   class_lists1.addClass(c3)

   assert class_lists1.checkCompletion() == False


def test_classlist_completion3():

   class_lists2 = ClassList()
   c1 = Class()
   c2 = Class()
   c3 = Class()

   c1.complete()
   c2.complete()
   c3.complete()

   class_lists2.addClass(c1)
   class_lists2.addClass(c2)
   class_lists2.addClass(c3)
   print(""running comp3"")
   assert class_lists2.checkCompletion() == True


def test_classlist_newempty():
   asdf = ClassList()
   assert len(asdf.classes) == 0",python
"#! /usr/bin/env python

# Copyright 2012 Tom SF Haines

# Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at

#   http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.



import df

from utils import doc_gen



# Setup...
doc = doc_gen.DocGen('df', 'Decision Forests', 'Extensive random forests implimentation')
doc.addFile('readme.txt', 'Overview')


# Classes...
doc.addClass(df.DF)
doc.addClass(df.ExemplarSet)
doc.addClass(df.MatrixES)
doc.addClass(df.MatrixGrow)
doc.addClass(df.Goal)
doc.addClass(df.Classification)
doc.addClass(df.DensityGaussian)
doc.addClass(df.Pruner)
doc.addClass(df.PruneCap)
doc.addClass(df.Test)
doc.addClass(df.AxisSplit)
doc.addClass(df.LinearSplit)
doc.addClass(df.DiscreteBucket)
doc.addClass(df.Generator)
doc.addClass(df.MergeGen)
doc.addClass(df.RandomGen)
doc.addClass(df.AxisMedianGen)
doc.addClass(df.LinearMedianGen)
doc.addClass(df.AxisRandomGen)
doc.addClass(df.LinearRandomGen)
doc.addClass(df.DiscreteRandomGen)
doc.addClass(df.AxisClassifyGen)
doc.addClass(df.LinearClassifyGen)
doc.addClass(df.DiscreteClassifyGen)
doc.addClass(df.SVMClassifyGen)
doc.addClass(df.Node)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/151/A

Solution: We first count the total drinks possible to be made, and the salt packs. With that we 
can get the total toasts possible. Since we do the toasts in batches of all people, we divide that
with n to get the total rounds of toast or no. of toast each person can have. 
'''


def solve(n, k, l, c, d, p, nl, np):

    drinks_count = min((k*l)/nl, c * d)
    salts_count = p / np
    toasts_count = min(drinks_count, salts_count)

    return toasts_count / n


if __name__ == ""__main__"":

    n, k, l, c, d, p, nl, np = map(int, raw_input().split("" ""))
    print solve(n, k, l, c, d, p, nl, np)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1061/A

Solution: Greedily, we start by using the highest denomination coins. If the current coin's denomination is <= required
sum s, we add s/n coins to the total coins used. Further we reduce the the sum s to s % n. We try this calculation from
the highest to lowest denomination coins. 
'''


def solve(n, s):

    coins = 0
    while s > 0:

        if s >= n:
            coins += (s/n)
            s %= n

        n -= 1

    return coins


if __name__ == ""__main__"":

    n, s = map(int, raw_input().split("" ""))
    print solve(n, s)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1480/A

Solution: Greedily, make every non-a as a and a as b when its Alice's turn. Similarly change all non-z to z and z to y
in Bob's turn. Make these mutation from left to right so that their objective to making the lexicographically smallest
and largest string is attained respectively. 
'''


def solve(s):

    c_arr = list(s)
    is_alice_turn = True
    for i in xrange(0, len(c_arr)):

        if is_alice_turn:
            if c_arr[i] != 'a':
                c_arr[i] = 'a'
            else:
                c_arr[i] = 'b'
        else:
            if c_arr[i] != 'z':
                c_arr[i] = 'z'
            else:
                c_arr[i] = 'y'

        is_alice_turn = not is_alice_turn

    return """".join(c_arr)


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        s = raw_input()
        print solve(s)
",python
"# https://codeforces.com/problemset/problem/231/A
### 231 A. Team

# Read number of problems
n = int(input())

# Count the number of implemented problems
problems = 0

# Iterate for each problem
for i in range(n):
    # Read if the input data for each problem
    friends = input().split()
    # If two of more of the friends are sure about the problem implement it
    if friends.count(""1"") >= 2:
        problems += 1
        
print(problems)

# https://codeforces.com/problemset/problem/231/A

# One day three best friends Petya, Vasya and Tonya decided to form a team and 
# take part in programming contests. Participants are usually offered several 
# problems during programming contests. Long before the start the friends 
# decided that they will implement a problem if at least two of them are sure
# about the solution. Otherwise, the friends won't write the problem's solution.

# This contest offers n problems to the participants. For each problem we know, 
# which friend is sure about the solution. Help the friends find the number of 
# problems for which they will write a solution.

#Input
# The first input line contains a single integer n (1 ≤ n ≤ 1000) — the number 
# of problems in the contest. Then n lines contain three integers each, each 
# integer is either 0 or 1. If the first number in the line equals 1, then 
# Petya is sure about the problem's solution, otherwise he isn't sure. The 
# second number shows Vasya's view on the solution, the third number shows 
# Tonya's view. The numbers on the lines are separated by spaces.

# Output
# Print a single integer — the number of problems the friends will implement on 
# the contest.

# Examples

# input
# 3
# 1 1 0
# 1 1 1
# 0 0 1
# output
# 2

# input
# 2
# 1 0 0
# 0 1 1
# output 
# 1

# Note
# In the first sample Petya and Vasya are sure that they know how to solve the 
# first problem and all three of them know how to solve the second problem. 
# That means that they will write solutions for these problems. Only Petya is 
# sure about the solution for the third problem, but that isn't enough, so the 
# friends won't take it.
# In the second sample the friends will only implement the second problem, as 
# Vasya and Tonya are sure about the solution.
",python
"import unittest
from ClassCollection import ClassCollection

# Todo
# Check if the classes exist in the classCollection (helper?)
# Check if relationship already exists (helper?)
# if it does, error
# if not, add parameter pair to the relationshipCollection

class RelationshipTest(unittest.TestCase):
    def testAddRelationshipNoFirstClass(self):
        collection = ClassCollection()
        collection.addClass(""foo"")
        self.assertRaises(KeyError, collection.addRelationship, ""bar"", ""foo"", ""aggregation"")

    def testAddRelationshipNoSecondClass(self):
        collection = ClassCollection()
        collection.addClass(""bar"")
        self.assertRaises(KeyError, collection.addRelationship, ""bar"", ""foo"", ""aggregation"")
    
    def testAddRelationshipNeitherClassExist(self):
        collection = ClassCollection()
        self.assertRaises(KeyError, collection.addRelationship, ""bar"", ""foo"", ""aggregation"")

    # Adding a relationship that already exists
    def testAddRelationshipAlreadyExists(self):
        collection = ClassCollection()
        collection.addClass(""foo"")
        collection.addClass(""bar"")
        collection.addRelationship(""bar"", ""foo"", ""aggregation"")
        self.assertRaises(KeyError, collection.addRelationship, ""bar"", ""foo"", ""aggregation"")

    def testRelationshipAddedSuccesfully(self):
        collection = ClassCollection()
        collection.addClass(""foo"")
        collection.addClass(""bar"")
        collection.addRelationship(""foo"", ""bar"", ""realization"")
        self.assertIsNotNone(collection.getRelationship(""foo"", ""bar""))

    def testDeleteRelationshipNoFirstClass(self):
        collection = ClassCollection()
        collection.addClass(""foo"")
        self.assertRaises(KeyError, collection.deleteRelationship, ""bar"", ""foo"")

    def testDeleteRelationshipNoSecondClass(self):
        collection = ClassCollection()
        collection.addClass(""bar"")
        self.assertRaises(KeyError, collection.deleteRelationship, ""bar"", ""foo"")
    
    def testDeleteRelationshipNeitherClassExist(self):
        collection = ClassCollection()
        self.assertRaises(KeyError, collection.deleteRelationship, ""bar"", ""foo"")

    def testRelationshipDeletedSuccesfully(self):
        collection = ClassCollection()
        collection.addClass(""foo"")
        collection.addClass(""bar"")
        collection.addRelationship(""foo"", ""bar"", ""inheritance"")
        collection.deleteRelationship(""foo"", ""bar"")
        self.assertNotIn((""foo"", ""bar""), collection.relationshipDict)
        self.assertRaises(KeyError, collection.deleteRelationship, ""foo"", ""bar"")

    def testRenameRelationship(self):
        collection = ClassCollection()
        collection.addClass(""foo"")
        collection.addClass(""bar"")
        collection.addRelationship(""foo"", ""bar"", ""inheritance"")
        collection.renameRelationship(""foo"", ""bar"", ""composition"")
        self.assertEquals(""composition"",collection.relationshipDict[(""foo"", ""bar"")].typ)
        
if __name__ == '__main__':
    unittest.main()
    ",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/732/B

Solution: Greedy approach. Iterate over the array and take the sum of current and
previous element. If that is smaller than k, then we add the diff to current cell.
Adding to current cell is a greedy choice since that helps in handling the next
pair of cells too. The total of those diffs added and the updated array are the
final answers.
'''


def solve(n, k, arr):

    all_needed = 0
    for i in xrange(1, n):

        curr_needed = k - (arr[i-1] + arr[i])
        if curr_needed > 0:
            arr[i] += curr_needed
            all_needed += curr_needed

    print all_needed
    print "" "".join(str(_) for _ in arr)


if __name__ == ""__main__"":

    n, k = map(int, raw_input().split("" ""))
    arr = map(int, raw_input().split("" ""))
    solve(n, k, arr)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/588/A

Solution: A greedy approach can give a good solution to it. We would always want to buy at the cheapest rate so far. 
Hence we keep track of that as we go through the list of quantities (a) and rates (p). The current quantity is multiplied
with that rate and added to the total. 

Time Complexity: O(n) 
'''


def solve(a, p, n):

    if len(a) == 0:
        return 0

    minRateSoFar = p[0]
    total = p[0] * a[0]

    for i in xrange(1, n):

        minRateSoFar = min(minRateSoFar, p[i])
        total += minRateSoFar * a[i]

    return total

if __name__ == ""__main__"":
    n = int(raw_input())
    a = []
    p = []
    for i in xrange(0,n):
        a_i, p_i = map(int, raw_input().split("" ""))
        a.append(a_i)
        p.append(p_i)
    print solve(a, p, n)",python
"# Number of stones
n = int(input())
# Stone colors
stones = input()

stonesToMove = 0

for i in range(n-1):
    # If two corresponding stones are the same, stonesToMove gets incremented
    if stones[i] == stones[i+1]:
        stonesToMove += 1

print(stonesToMove)




# https://codeforces.com/problemset/problem/266/A
# There are n stones on the table in a row, each of them can be red, green or blue. Count the minimum number of stones to take from the table so that any two neighboring stones had different colors. Stones in a row are considered neighboring if there are no other stones between them.
#
# Input
# The first line contains integer n (1 ≤ n ≤ 50) — the number of stones on the table.
#
# The next line contains string s, which represents the colors of the stones. We'll consider the stones in the row numbered from 1 to n from left to right. Then the i-th character s equals ""R"", if the i-th stone is red, ""G"", if it's green and ""B"", if it's blue.
#
# Output
# Print a single integer — the answer to the problem.
#
# Examples
# input
# 3
# RRG
# output
# 1
# input
# 5
# RRRRR
# output
# 4
# input
# 4
# BRBG
# output
# 0
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1516/A

Solution: Iterate over the array and reduce the elements left to right and
increase the last element in every move. This ensures that we generate the 
lexicographically smallest array. In order to not let an array element go 
negative, we move the index rightwards when an element is already 0 or negative.
'''


def solve(n, k, arr):

    i = 0
    while k > 0 and i < n:

        if arr[i] <= 0:
            i += 1
            continue

        arr[i] -= 1
        arr[n-1] += 1
        k -= 1

    return "" "".join(str(_) for _ in arr)


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        n, k = map(int, raw_input().split("" ""))
        arr = map(int, raw_input().split("" ""))
        print solve(n, k, arr)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1301/A

Solution: Iterate over the strings (since they're of equal lengths, just run a loop of any of a,b or c's length.
Since we need to swap a character of string a or b at ith position with that of c, we need to check the following 
condition: if a[i] != c[i] and b[i] != c[i]. 
If this is true, it means we cannot swap either a or b and hence we will have this as a different character in a and b.
Hence return NO. If we cannot satisfy the condition all positions, the strings a and b can be made same and hence return
YES.

Time Complexity: O(n)
'''


def solve(a, b, c):

    l = len(a) #a, b and c are of equal length

    for i in xrange(0, l):

        if a[i] != c[i] and b[i] != c[i]:
                return ""NO""

    return ""YES""


if __name__ == ""__main__"":
    n = int(raw_input())

    answers = []
    for i in xrange(0,n):
        a = raw_input()
        b = raw_input()
        c = raw_input()
        answers.append(solve(a, b, c))

    for answer in answers:
        print answer
",python
"# https://codeforces.com/problemset/problem/59/A
s = str(input())
d={""UPPER_CASE"":0, ""LOWER_CASE"":0}
for c in s:
    if c.isupper():
       d[""UPPER_CASE""]+=1
    elif c.islower():
       d[""LOWER_CASE""]+=1
    else:
       pass

l=len(s)

if(d[""UPPER_CASE""]>l/2):
    print(s.upper())
else:
    print(s.lower())

",python
"# https://codeforces.com/problemset/problem/118/A

word = input().lower()
new_word = """"

for letter in word:
    if letter in {""a"", ""i"", ""u"", ""e"", ""o"", ""y""}:
        continue
    else:
        new_word += ""."" + letter

print(new_word)",python
"distance = int(input())
counter = 0

# While the distance is not 0
while distance != 0:
    # Check if the available number of steps can be taken
    if distance > 4:
        distance -= 5
        counter += 1
    elif distance > 3:
        distance -= 4
        counter += 1
    elif distance > 2:
        distance -= 3
        counter += 1
    elif distance > 1:
        distance -= 2
        counter += 1
    elif distance > 0:
        distance -= 1
        counter += 1

print(counter)





# https://codeforces.com/problemset/problem/617/A

# An elephant decided to visit his friend. It turned out that the elephant's house is located at point 0 and his friend's house is located at point x(x > 0) of the coordinate line. In one step the elephant can move 1, 2, 3, 4 or 5 positions forward. Determine, what is the minimum number of steps he need to make in order to get to his friend's house.
#
# Input
# The first line of the input contains an integer x (1 ≤ x ≤ 1 000 000) — The coordinate of the friend's house.
#
# Output
# Print the minimum number of steps that elephant needs to make to get from point 0 to point x.
#
# Examples
# input
# 5
# output
# 1
# input
# 12
# output
# 3
# Note
# In the first sample the elephant needs to make one step of length 5 to reach the point x.
#
# In the second sample the elephant can get to point x if he moves by 3, 5 and 4. There are other ways to get the optimal answer but the elephant cannot reach x in less than three moves.
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1433/C

Solution: If there exists at least 2 different values of the piranhas, then there is a 
possibility of dominant piranha. We find the index of it and check if its left or right
neighbor isn't equal to it. If that is validated, the current piranha is the dominant one.
Note we return +1 with the index since the question required 1-indexed answer.
'''


def solve(n, arr):

    max_pir = max(arr)

    for i in xrange(0, n):

        if arr[i] != max_pir:
            continue

        if i > 0 and arr[i-1] != max_pir:
            return i+1
        elif i < n-1 and arr[i+1] != max_pir:
            return i+1

    return -1


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        n = int(raw_input())
        arr = map(int, raw_input().split("" ""))
        print solve(n, arr)
",python
"ip = input()
ipArr = ip.split("" "")

opp = False

height = int(ipArr[0])
width = int(ipArr[1])

for i in range(height):
    if (i + 1) % 2 == 0:
        if opp == False:
            for n in range(width - 1):
                print('.', end='')
            print('#')
            opp = True
        else:
            print('#', end="""")
            for k in range(width - 2):
                print('.', end="""")
            print('.')
            opp = False

    else:
        for j in range(width - 1):
            print('#', end='')
        print('#')






# https://codeforces.com/problemset/problem/510/A

# Fox Ciel starts to learn programming. The first task is drawing a fox! However, that turns out to be too hard for a beginner, so she decides to draw a snake instead.
# 
# A snake is a pattern on a n by m table. Denote c-th cell of r-th row as (r, c). The tail of the snake is located at (1, 1), then it's body extends to (1, m), then goes down 2 rows to (3, m), then goes left to (3, 1) and so on.
# 
# Your task is to draw this snake for Fox Ciel: the empty cells should be represented as dot characters ('.') and the snake cells should be filled with number signs ('#').
# 
# Consider sample tests in order to understand the snake pattern.
# 
# Input
# The only line contains two integers: n and m (3 ≤ n, m ≤ 50).
# 
# n is an odd number.
# 
# Output
# Output n lines. Each line should contain a string consisting of m characters. Do not output spaces.
# 
# Examples
# input
# 3 3
# output
# ###
# ..#
# ###
# input
# 3 4
# output
# ####
# ...#
# ####
# input
# 5 3
# output
# ###
# ..#
# ###
# #..
# ###
# input
# 9 9
# output
# #########
# ........#
# #########
# #........
# #########
# ........#
# #########
# #........
# #########
# 
",python
"from classes.OnlineClassroom.createPost import post


class addclasspostAdapter(post):
    def __init__(self,addclass):
        self.addclass=addclass
    def getposttext(self):
        return ""next class about "" +self.addclass.details+"" will be held on ""+ self.addclass.starttime+"" to "" +self.addclass.endtime
    def getpostfile(self):
        return """"
    def getauthor(self):
        return self.addclass.author
    def get_course_id(self):
        return self.addclass.course_id",python
"
def main(j, args, params, tags, tasklet):

    page = args.page
    params.extend(args)
    page.addHTMLHeader('''<link rel=""shortcut icon"" type=""image/png"" href=""/system/.files/img/favicon.png"">''')
    page.addCSS('/jslib/bootstrap/css/bootstrap-3-3-1.min.css')
    page.addCSS('/jslib/flatui/css/flat-ui.css')
    page.addCSS('/jslib/new-ui/new-ui.css')
    page.addCSS('/jslib/new-ui/oocss.css')

    page.addJS('/jslib/jquery/jquery-2.0.3.min.js')
    page.addJS('/jslib/jquery/jquery-migrate-1.2.1.js')
    page.addJS('/jslib/old/jquery.cookie.js')
    page.addJS('/jslib/bootstrap/js/bootstrap-3-3-2.min.js')

    page.addJS(jsContent='''
        $( function () {
        $('body').addClass('flatTheme');
        // fix firefox elements size on windows
        var operatingSystem = navigator.platform;
        if(operatingSystem.indexOf('Win') >= 0 && $.browser.mozilla == true){
            $('body').addClass('fixFirefoxSizing');
        }else{
            $('body').addClass('removeTransform');
        }

        $('link[href=""/jslib/old/bootstrap/css/bootstrap.css""]').remove();
        $('link[href=""/jslib/old/bootstrap/css/bootstrap-responsive.css""]').remove();
        $('link[href=""/jslib/old/breadcrumbs/breadcrumbs.css""]').remove();
        $('link[href=""/jslib/swagger/css/reset.css""]').remove();


        $('.nav-collapse.collapse').removeClass('nav-collapse').addClass('navbar-collapse');
        $('.btn.btn-navbar').replaceWith('<button type=""button"" class=""navbar-toggle collapsed"" data-toggle=""collapse"" data-target="".nav-collapse"" aria-expanded=""false"">' +
            '<span class=""sr-only"">Toggle navigation</span>' +
            '<span class=""icon-bar""></span>' +
            '<span class=""icon-bar""></span>' +
            '<span class=""icon-bar""></span>' +
          '</button>'
        );
        $('.brand').removeClass('brand').addClass('navbar-brand');
        $('.navbar-inner').addClass('navbar-form');
        $('.search-query').addClass('form-control');
        $('.newBreadcrumbArrow').removeClass('newBreadcrumbArrow separator').addClass('fui-arrow-right');

        $('.span1').removeClass('span1').addClass('col-md-1');
        $('.span2').removeClass('span2').addClass('col-md-2');
        $('.span3').removeClass('span3').addClass('col-md-3');
        $('.span4').removeClass('span4').addClass('col-md-4');
        $('.span5').removeClass('span5').addClass('col-md-5');
        $('.span6').removeClass('span6').addClass('col-md-6');
        $('.span7').removeClass('span7').addClass('col-md-7');
        $('.span8').removeClass('span8').addClass('col-md-8');
        $('.span9').removeClass('span9').addClass('col-md-9');
        $('.span10').removeClass('span10').addClass('col-md-10');
        $('.span11').removeClass('spa11').addClass('col-md-11');
        $('.span12').removeClass('span12').addClass('col-md-12');

        var toggles = document.querySelectorAll("".c-hamburger"");
        for (var i = toggles.length - 1; i >= 0; i--) {
            var toggle = toggles[i];
            toggleHandler(toggle);
        };
        function toggleHandler(toggle) {
            toggle.addEventListener( ""click"", function(e) {
              e.preventDefault();
              (this.classList.contains(""is-active"") === true) ? this.classList.remove(""is-active"") : this.classList.add(""is-active"");
              $('.page-content').find('.sidebar-nav').toggleClass('hide');
              $('.page-content').find('.content').toggleClass('less-wide');
              $('.page-content').find('.navigation').toggleClass('wide-sidebar');
            });
        }

    });
     ''')

    page.removeJS('/jslib/old/jquery-latest.js')
    page.removeJS('/jslib/old/bootstrap/js/bootstrap.js')
    page.removeJS('/jslib/old/jquery.cookie.js')

    page.addCSS('/system/.files/css/flatTheme.css')

    params.result = page

    return params


def match(j, args, params, tags, tasklet):
    return True
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/61/A

Solution: Brute force, where we compare each corresponding characters of both numbers, thereby adding 0 when same and
1 when different to the resultant string. 
'''


def solve(num1, num2):

    n = len(num1)
    result = [''] * n

    for i in xrange(0, n):

        if num1[i] == num2[i]:
            result[i] = '0'
        else:
            result[i] = '1'

    return """".join(result)


if __name__ == ""__main__"":

    num1 = raw_input()
    num2 = raw_input()
    print solve(num1, num2)
",python
"n = int(input())
ad = input()

a = 0
d = 0

for i in range(n):
    # Check if the ith term is A. If yes, add 1 to the a counter
    if ad[i] == ""A"":
        a += 1
    # If it isnt A, it is D. So add 1 to the d counter
    else:
        d += 1

# Check if who had more wins or if it was a draw
if a > d:
    print(""Anton"")
elif d > a:
    print(""Danik"")
else:
    print(""Friendship"")


# https://codeforces.com/problemset/problem/734/A
#
# Anton likes to play chess, and so does his friend Danik.
#
# Once they have played n games in a row. For each game it's known who was the winner — Anton or Danik. None of the games ended with a tie.
#
# Now Anton wonders, who won more games, he or Danik? Help him determine this.
#
# Input
# The first line of the input contains a single integer n (1 ≤ n ≤ 100 000) — the number of games played.
#
# The second line contains a string s, consisting of n uppercase English letters 'A' and 'D' — the outcome of each of the games. The i-th character of the string is equal to 'A' if the Anton won the i-th game and 'D' if Danik won the i-th game.
#
# Output
# If Anton won more games than Danik, print ""Anton"" (without quotes) in the only line of the output.
#
# If Danik won more games than Anton, print ""Danik"" (without quotes) in the only line of the output.
#
# If Anton and Danik won the same number of games, print ""Friendship"" (without quotes).
#
# Examples
# input
# 6
# ADAAAA
# output
# Anton
# input
# 7
# DDDAADA
# output
# Danik
# input
# 6
# DADADA
# output
# Friendship
# Note
# In the first sample, Anton won 6 games, while Danik — only 1. Hence, the answer is ""Anton"".
#
# In the second sample, Anton won 3 games and Danik won 4 games, so the answer is ""Danik"".
#
# In the third sample, both Anton and Danik won 3 games and the answer is ""Friendship"".
",python
"# https://codeforces.com/problemset/problem/546/A

case = [int(num) for num in input().split()]

cost = case[2] * case[0] * (case[2] + 1) / 2

if cost > case[1]:
    print(int(cost - case[1]))
else:
    print(0)",python
"#https://codeforces.com/problemset/problem/611/B



a, b = map(int, input().split())

candidate=0
limark_count = 0
for i in range(1, 64):
  ip = 2 ** i
  for j in range(i - 1):
    jp = 2 ** j
    candidate = ip - jp - 1
    if candidate >= a and candidate <= b:
      limark_count += 1

  if candidate >= b: break

print(limark_count)
",python
"# https://codeforces.com/problemset/problem/71/A

i = input

for _ in [0] * int(i()):
    s = i(); l = len(s) - 2; print([s, s[0] + str(l) + s[-1]][l>8])



    
    
    










# Sometimes some words like ""localization"" or ""internationalization"" are so long that writing them many times in one text is quite tiresome.

# Let's consider a word too long, if its length is strictly more than 10 characters. All too long words should be replaced with a special abbreviation.

# This abbreviation is made like this: we write down the first and the last letter of a word and between them we write the number of letters between the first and the last letters. That number is in decimal system and doesn't contain any leading zeroes.

# Thus, ""localization"" will be spelt as ""l10n"", and ""internationalization» will be spelt as ""i18n"".

# You are suggested to automatize the process of changing the words with abbreviations. At that all too long words should be replaced by the abbreviation and the words that are not too long should not undergo any changes.

# Input
# The first line contains an integer n (1 ≤ n ≤ 100). Each of the following n lines contains one word. All the words consist of lowercase Latin letters and possess the lengths of from 1 to 100 characters.

# Output
# Print n lines. The i-th line should contain the result of replacing of the i-th word from the input data.

# Examples
# input
# 4
# word
# localization
# internationalization
# pneumonoultramicroscopicsilicovolcanoconiosis
# output
# word
# l10n
# p43s

# First enter the number of words you want to converst to shortforms
# Then enter the word and press enter.
",python
"from plone.app.discussion.browser.comments import CommentForm
import logging

logger = logging.getLogger('Comment Form Patch')

def updateActions(self):
    super(CommentForm, self).updateActions()
    self.actions['cancel'].addClass(""standalone"")
    self.actions['cancel'].addClass(""hide"")
    self.actions['cancel'].addClass(""button"")
    self.actions['cancel'].addClass(""tiny"")
    self.actions['cancel'].addClass(""radius"")
    self.actions['comment'].addClass(""context"")
    self.actions['comment'].addClass(""button"")
    self.actions['comment'].addClass(""tiny"")
    self.actions['comment'].addClass(""radius"")

CommentForm.updateActions = updateActions
logger.info(""Patching plone.app.discussion.browser.comments.CommentForm.updateActions"")
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/133/A

Solution: Just check if any of the characters in the string is H,Q or 9. + does not print anything. 
'''


def solve(input):
    printableChars = set('HQ9')
    for i in xrange(0, len(input)):
        if input[i] in printableChars:
            return ""YES""
    return ""NO""


if __name__ == ""__main__"":
    input = raw_input()
    print solve(input)",python
"import unittest
from ClassCollection import ClassCollection
from Class import Class

class ClassTests(unittest.TestCase):

    # Checks if class is in the ClassDict
    def testAddClass(self):
        collection = ClassCollection() 
        collection.addClass(""A"")
        self.assertIsNotNone( collection.getClass(""A""))

    # Checks if a class is successfully deleted
    def testDeleteClass(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        #collection.addAttribute(""A"", ""count"")
        collection.deleteClass(""A"")
        self.assertRaises(KeyError, collection.getClass, ""A"")

     # Checks if a class is successfully deleted
    def testRenameClass(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        collection.renameClass(""A"",""B"")
        self.assertIsNotNone(collection.getClass(""B""))
    #rename Class with attributes. Ensure there is no leftover Class
    def testRenameClassComplex(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        collection.renameClass(""A"",""B"")
      #  collection.addAttribute(""B"", ""count"")
        self.assertRaises(KeyError, collection.deleteClass, ""A"")
        self.assertIsNotNone( collection.getClass(""B""))
        collection.deleteClass(""B"")
        self.assertRaises(KeyError, collection.getClass, ""A"")
        self.assertRaises(KeyError, collection.getClass, ""B"")

    #Ensure relations are also removed when a class is removed
    def testDeleteClassWithRelationship(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        collection.addClass(""B"")
        collection.addRelationship(""A"", ""B"", ""composition"")
        collection.deleteClass(""A"")
        self.assertRaises(KeyError, collection.getClass, ""A"")
        self.assertIsNotNone( collection.getClass(""B""))
        self.assertEqual( collection.relationshipDict, {})

    #test error on adding duplicate classes
    def testAddDuplicateClass(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        self.assertRaises(KeyError, collection.addClass, ""A"")
    
    #test error on removing nonexisted classes
    def testRemoveNonExistentClass(self):
        collection = ClassCollection()
        self.assertRaises(KeyError, collection.deleteClass, ""A"")

    #test error on renaming duplicate classes
    def testRenameDuplicateClass(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        collection.addClass(""B"")
        self.assertRaises(KeyError, collection.renameClass, ""A"", ""B"")

    #test error on removing nonexisted classes
    def testRenameNonExistentClass(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        self.assertRaises(KeyError, collection.renameClass, ""C"", ""D"")

    def testDeleteClassWithRelationshipandField(self):
        collection = ClassCollection()
        collection.addClass(""A"")
        collection.addClass(""B"")
        collection.addField(""A"", ""name"", ""String"")
        collection.addField(""B"", ""name"", ""String"")
        collection.addRelationship(""A"", ""B"", ""composition"")
        collection.deleteClass(""A"")
        collection.deleteClass(""B"")
        #Ok as long as there are no errors

if __name__ == '__main__':
    unittest.main()
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1334/A

Solution: Its easy to deduce that even for one player, it is impossible to clear more levels than the plays done. This
also is true when multiple players are there. Secondly, the number of plays or levels cleared cannot go done as they are
non decreasing sequences. Incorporating these 2 conditions, we can check each testcase and evaluate its validity. 
'''


def solve(all_p_c):

    prev_p = prev_c = 0

    for this_p_c in all_p_c:

        delta_p = this_p_c[0] - prev_p
        delta_c = this_p_c[1] - prev_c
        if delta_p < 0 or delta_c < 0 or delta_p < delta_c:
            return ""NO""
        prev_p = this_p_c[0]
        prev_c = this_p_c[1]

    return ""YES""


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        n = int(raw_input())
        all_p_c = list()
        for _n in xrange(0, n):
            p_c = map(int, raw_input().split("" ""))
            all_p_c.append(p_c)
        print solve(all_p_c)
",python
"# https://codeforces.com/problemset/problem/4/A
# One hot summer day Pete and his friend Billy decided to buy a watermelon. They chose the biggest and the ripest one, in their opinion. After that the watermelon was weighed, and the scales showed w kilos. They rushed home, dying of thirst, and decided to divide the berry, however they faced a hard problem.

# Pete and Billy are great fans of even numbers, that's why they want to divide the watermelon in such a way that each of the two parts weighs even number of kilos, at the same time it is not obligatory that the parts are equal. The boys are extremely tired and want to start their meal as soon as possible, that's why you should help them and find out, if they can divide the watermelon in the way they want. For sure, each of them should get a part of positive weight.

# Input
# The first (and the only) input line contains integer number w (1 ≤ w ≤ 100) — the weight of the watermelon bought by the boys.

# Output
# Print YES, if the boys can divide the watermelon into two parts, each of them weighing even number of kilos; and NO in the opposite case.

# Examples
# input
# 8
# output
# YES 


input = int(input())

if input % 2 == 0 and input > 3:
    print('YES')
    
else:
    print('NO') 



           ",python
"import ast

def createSampleV2(rep):
  f1 = ast.File(""Class1"")
  rep.addFile(f1)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f1.addNamespace(n1)
  c1 = ast.Cl(""Class1"")
  n1.addClass(c1)
  s=ast.Type(""string［］"")
  mod = ast.Modifier()
  mod.access=""public""
  m = ast.Method()
  m.name=""setState""
  m.setModifiers(mod)
  m.setReturnType(s)
  c1.addMethod(m)
  
  f2 = ast.File(""Class2"")
  rep.addFile(f2)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f2.addNamespace(n1)
  c2 = ast.Cl(""Class2"")
  e1 = ast.Type(""Class1"")
  c2.setExtend(e1)
  n1.addClass(c2)
  
  f3 = ast.File(""Class3"")
  rep.addFile(f3)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f3.addNamespace(n1)
  c3 = ast.Cl(""Class3"")
  e2 = ast.Type(""Class2"")
  c3.setExtend(e2)
  n1.addClass(c3)
  
  f4 = ast.File(""Class4"")
  rep.addFile(f4)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f4.addNamespace(n1)
  in1 = ast.Namespace(""Inner1"")
  n1.addNamespace(in1)
  c4 = ast.Cl(""Class4"")
  e3 = ast.Type(""Class3"")
  c4.setExtend(e3)
  in1.addClass(c4)

  f5 = ast.File(""Class5"")
  rep.addFile(f5)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f5.addNamespace(n1)
  in2 = ast.Namespace(""Inner2"")
  u1=ast.Using(""Inner1"")
  in2.addUsing(u1)
  n1.addNamespace(in2)
  c5 = ast.Cl(""Class5"")
  e4 = ast.Type(""Class4"")
  c5.setExtend(e4)
  in2.addClass(c5)
  in3 = ast.Namespace(""Inner3"")
  in2.addNamespace(in3)
  c6 = ast.Cl(""Class6"")
  e4 = ast.Type(""Class4"")
  c6.setExtend(e4)
  in3.addClass(c6)
  in4 = ast.Namespace(""Inner4"")
  in3.addNamespace(in4)
  c7 = ast.Cl(""Class7"")
  e1 = ast.Type(""Class1"")
  c7.setExtend(e1)
  in4.addClass(c7)
  
  f6 = ast.File(""Class6"")
  rep.addFile(f6)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f6.addNamespace(n1)
  u1=ast.Using(""Inner6.Inner7.Inner8"")
  n1.addUsing(u1)
  in12 = ast.Namespace(""Inner12"")
  n1.addNamespace(in12)
  u611=ast.Using(""Inner6.Inner7.Inner8.Inner9.Inner10.Inner11"")
  in12.addUsing(u611)
  u9=ast.Using(""Inner9"")
  in12.addUsing(u9)
  c7 = ast.Cl(""Class7"")
  i1 = ast.Type(""Interface1"")
  c7.addImplement(i1)
  in12.addClass(c7)
  
  fi1 = ast.File(""Interface1"")
  rep.addFile(fi1)
  n1 = ast.Namespace(""ConsoleApplication1"")
  fi1.addNamespace(n1)
  n6 = ast.Namespace(""Inner6"")
  n1.addNamespace(n6)
  n7 = ast.Namespace(""Inner7"")
  n6.addNamespace(n7)
  n8 = ast.Namespace(""Inner8"")
  n7.addNamespace(n8)
  n9 = ast.Namespace(""Inner9"")
  n8.addNamespace(n9)
  n10 = ast.Namespace(""Inner10"")
  n9.addNamespace(n10)
  n11 = ast.Namespace(""Inner11"")
  n10.addNamespace(n11)  
  i1=ast.Iface(""Interface1"")
  n11.addInterface(i1)
  mod = ast.Modifier()
  mod.access=""public""
  m = ast.Method()
  m.name=""hello""
  m.setModifiers(mod)
  m.setReturnType(ast.Type(""string""))
  i1.addMethod(m)
  
  
    
  f7 = ast.File(""Class7"")
  rep.addFile(f7)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f7.addNamespace(n1)
  c8 = ast.Cl(""Class8"")
  e7 = ast.Type(""Inner12.Class7"")
  c8.setExtend(e7)
  n1.addClass(c8)
  
  f9 = ast.File(""Class9"")
  rep.addFile(f9)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f9.addNamespace(n1)
  n15 = ast.Namespace(""Inner15"")
  n1.addNamespace(n15)
  n16 = ast.Namespace(""Inner16"")
  n15.addNamespace(n16)
  c9 = ast.Cl(""Class9"")
  n16.addClass(c9)
  
  f10 = ast.File(""Class10"")
  rep.addFile(f10)
  n1 = ast.Namespace(""ConsoleApplication1"")
  f10.addNamespace(n1)
  n15 = ast.Namespace(""Inner15"")
  n1.addNamespace(n15)
  

  c10 = ast.Cl(""Class10"")
  e169 = ast.Type(""Inner16.Class9"")
  c10.setExtend(e169)
  n15.addClass(c10)
  
  n17 = ast.Namespace(""Inner17"")
  n15.addNamespace(n17)
  u16=ast.Using(""Inner16"")
  n17.addUsing(u16)
  c12 = ast.Cl(""Class12"")
  e9 = ast.Type(""Class9"")
  c12.setExtend(e9)
  n17.addClass(c12)
  
  n18 = ast.Namespace(""Inner18"")
  n1.addNamespace(n18)
  u15=ast.Using(""Inner15"")
  n18.addUsing(u15)
  n19 = ast.Namespace(""Inner19"")
  n18.addNamespace(n19)
  u1516=ast.Using(""Inner15.Inner16"")
  n19.addUsing(u1516)
  c12 = ast.Cl(""Class12"")
  e9 = ast.Type(""Class9"")
  c12.setExtend(e9)
  n19.addClass(c12)
  
def createSample(rep):
  #rep = Representation()
  intrn = ast.Modifier()
  publ = ast.Modifier()
  publ.setPublic()
  priv = ast.Modifier()
  priv.setPrivate()
  prot = ast.Modifier()
  prot.setProtected()
  void = ast.Type(""Void"")
  
  basicFunctions = ast.File(""BasicFunctions"")
  rep.addFile(basicFunctions)
  
  breathing = ast.Namespace(""Breathing"")
  basicFunctions.addNamespace(breathing)
  
  breath = ast.Iface(""Breath"")
  breathing.addInterface(breath)
  lungs = ast.Type(""Lungs"")
  lungsA = ast.Attr(""lungs"",lungs,priv)
  breath.addAttribute(lungsA)
  respire = ast.Method(""respire"",void,priv)
  breath.addMethod(respire)

  eating = ast.Namespace(""Eating"")
  basicFunctions.addNamespace(eating)
  eat = ast.Iface(""Eat"")
  eating.addInterface(eat)
  mouth = ast.Type(""Mouth"")
  mouthA = ast.Attr(""mouth"",mouth,prot)
  energy = ast.Type(""Energy"")
  consume = ast.Method(""consume"",energy,priv)
  meal = ast.Type(""Meal"")
  food = ast.Parameter(meal,""food"")
  consume.addParameter(food)
  eat.addMethod(consume)
  eat.addAttribute(mouthA)
  body = ast.Type(""Body"")
  bodyA = ast.Attr(""body"",body,prot)
  eat.addAttribute(bodyA)

  
  liveFunctions = ast.File(""LiveFunctions"")
  rep.addFile(liveFunctions)
  usingBreathing = ast.Using(""Breathing"")
  liveFunctions.addUsing(usingBreathing)
  usingEating = ast.Using(""Eating"")
  liveFunctions.addUsing(usingEating)
  living = ast.Namespace(""Living"")
  
  liveFunctions.addNamespace(living)
  live = ast.Iface(""Live"")
  living.addInterface(live)
  breathT = ast.Type(""Breath"")
  eatT = ast.Type(""Eat"")
  live.addExtend(breathT)
  live.addExtend(eatT)
  exist = ast.Method(""exist"",void,priv)
  live.addMethod(exist)

  
  biteFile = ast.File(""Bite"")
  rep.addFile(biteFile)
  biteNamespace = ast.Namespace(""Bite"")
  biteFile.addNamespace(biteNamespace);
  bite = ast.Iface(""Bite"")
  biteNamespace.addInterface(bite)
  teeth = ast.Type(""Teeth"")
  teethA = ast.Attr(""teeth"",teeth,priv)
  bite.addAttribute(teethA)
  hurt = ast.Type(""Hurt"")
  attack = ast.Method(""attack"",hurt,prot)
  attack.isAbstract(True)
  bite.addMethod(attack)

  familiarFile = ast.File(""Familiar"")
  rep.addFile(familiarFile)
  familiar = ast.Iface(""Familiar"")
  familarNamespace = ast.Namespace(""Familiar"")
  familiarFile.addNamespace(familarNamespace)
  familarNamespace.addInterface(familiar)
  cares = ast.Method(""cares"",void,intrn)
  cares.isAbstract(True)
  familiar.addMethod(cares)

  animalFile = ast.File(""Animal"")
  rep.addFile(animalFile)
  usingLiving = ast.Using(""Living"")
  
  animalFile.addUsing(usingLiving)
  animal = ast.Cl(""Animal"")
  animalFile.addClass(animal)
  bone = ast.Type(""Bone"")
  boneA = ast.Attr(""bone"",bone,publ)
  animal.addAttribute(boneA)
  liveT = ast.Type(""Live"")
  animal.addImplement(liveT)
  move = ast.Method(""move"",void,prot)
  animal.addMethod(move)
  animal.isAbstract(True)

  
  petFile = ast.File(""Pet"")
  petNamespace = ast.Namespace(""Pet"")
  familiarNT = ast.Using(""Familiar"")
  petNamespace.addUsing(familiarNT)
  petFile.addNamespace(petNamespace)
  rep.addFile(petFile)
  animalT = ast.Type(""Animal"")
  
  pet = ast.Cl(""Pet"")
  petNamespace.addClass(pet)
  pet.setExtend(animalT)
  pet.addImplement(familiar)
  pet.isAbstract(True)
  friendliness = ast.Type(""Friendliness"")
  friendlinessA = ast.Attr(""friendliness"",friendliness,publ)
  pet.addMethod(cares)
  pet.addAttribute(friendlinessA)

  wildFile = ast.File(""Wild"")
  wildNamespace = ast.Namespace(""Wild"")
  wildFile.addNamespace(wildNamespace)
  rep.addFile(wildFile)  
  wild = ast.Cl(""Wild"")
  wildNamespace.addClass(wild)
  usingBite = ast.Using(""Bite"")
  wildNamespace.addUsing(usingBite)
  wild.setExtend(animalT)
  biteT = ast.Type(""Bite"")
  wild.addImplement(biteT)
  wild.isAbstract(True)
  wildness = ast.Type(""Wildness"")
  wildnessA = ast.Attr(""wildness"",wildness,publ)
  wild.addAttribute(wildnessA)
  wild.addMethod(attack)

  dogFile = ast.File(""Dog"")
  rep.addFile(dogFile)
  usingPet = ast.Using(""Pet"")
  dogFile.addUsing(usingPet)
  dog = ast.Cl(""Dog"")
  dogFile.addClass(dog)
  petT= ast.Type(""Pet"")
  dog.setExtend(petT)
  caresImpl = ast.Method(""cares"",void,intrn)
  dog.addMethod(caresImpl)
  huntCat = ast.Method(""huntCat"", void, prot)
  catT = ast.Type(""Cat"")
  catP = ast.Parameter(catT,""cat"")
  huntCat.addParameter(catP)
  energyT = ast.Type(""Energy"")
  energyP = ast.Parameter(energyT,""energy"")
  huntCat.addParameter(energyP)
  dog.addMethod(huntCat)

  catFile = ast.File(""Cat"")
  rep.addFile(catFile)
  usingPetC = ast.Using(""Pet"")
  catFile.addUsing(usingPetC)
  cat = ast.Cl(""Cat"")
  catFile.addClass(cat)
  cat.setExtend(petT)
  cat.addMethod(caresImpl)
  mouw = ast.Method(""mouw"",void,prot)
  cat.addMethod(mouw)

  cowFile = ast.File(""Cow"")
  rep.addFile(cowFile)
  usingPetCow = ast.Using(""Pet"")
  cowFile.addUsing(usingPetCow)  
  cow = ast.Cl(""Cow"")
  cowFile.addClass(cow)
  cow.setExtend(petT)
  milk = ast.Type(""Milk"")
  milkA = ast.Attr(""milk"",milk,intrn)
  cow.addAttribute(milkA)
  cow.addMethod(caresImpl)
  giveMilk = ast.Method(""giveMilk"",milk,publ)
  cow.addMethod(giveMilk)

  tigerFile = ast.File(""Tiger"")
  rep.addFile(tigerFile)
  usingWild = ast.Using(""Wild"")
  tigerFile.addUsing(usingWild)
  tiger = ast.Cl(""Tiger"")
  tigerFile.addClass(tiger)
  wildT = ast.Type(""Wild"")
  tiger.setExtend(wildT)
  stripe = ast.Type(""Stripe"")
  stripeA = ast.Attr(""stripe"",stripe,prot)
  tiger.addAttribute(stripeA)
  attackImpl = ast.Method(""attack"",hurt,prot)
  tiger.addMethod(attackImpl)

  lionFile = ast.File(""Lion"")
  rep.addFile(lionFile)
  lionFile.addUsing(usingWild)
  lion = ast.Cl(""Lion"")
  lionFile.addClass(lion)
  lion.setExtend(wild)
  mane = ast.Type(""Mane"")
  maneA = ast.Attr(""mane"",mane,prot)
  lion.addAttribute(maneA)
  lion.addMethod(attackImpl)

def createSampleV1(rep):
  #rep = Representation()
  intrn = Modifier()
  publ = Modifier()
  publ.setPublic()
  priv = Modifier()
  priv.setPrivate()
  prot = Modifier()
  prot.setProtected()
  void = Type(""Void"")
  
  breath = Iface(""Breath"")
  lungs = Type(""Lungs"")
  lungsA = Attr(""lungs"",lungs,priv)
  breath.addAttribute(lungsA)
  respire=Method(""respire"",void,priv)
  breath.addMethod(respire)
  rep.addInterface(breath)
  eat = Iface(""Eat"")
  mouth = Type(""Mouth"")
  mouthA = Attr(""mouth"",mouth,prot)
  energy = Type(""Energy"")
  consume = Method(""consume"",energy,priv)
  meal = Type(""Meal"")
  food=Parameter(meal,""food"")
  consume.addParameter(food)
  eat.addMethod(consume)
  eat.addAttribute(mouthA)
  rep.addInterface(eat)
  
  live = Iface(""Live"")
  live.addExtend(breath)
  live.addExtend(eat)
  body = Type(""Body"")
  bodyA = Attr(""body"",body,prot)
  eat.addAttribute(bodyA)
  exist=Method(""exist"",void,priv)
  live.addMethod(exist)
  rep.addInterface(live)
  
  bite = Iface(""Bite"")
  teeth = Type(""Teeth"")
  teethA = Attr(""teeth"",teeth,priv)
  bite.addAttribute(teethA)
  hurt = Type(""Hurt"")
  attack=Method(""attack"",hurt,prot)
  attack.isAbstract(True)
  bite.addMethod(attack)
  rep.addInterface(bite)
  familiar = Iface(""Familiar"")
  cares = Method(""cares"",void,intrn)
  cares.isAbstract(True)
  familiar.addMethod(cares)
  rep.addInterface(familiar)
  
  animal = Cl(""Animal"")
  bone = Type(""Bone"")
  boneA = Attr(""bone"",bone,publ)
  animal.addAttribute(boneA)
  animal.addImplement(live)
  move = Method(""move"",void,prot)
  animal.addMethod(move)
  animal.isAbstract(True)
  rep.addClass(animal)
  
  
  pet = Cl(""Pet"")
  pet.setExtend(animal)
  pet.addImplement(familiar)
  pet.isAbstract(True)
  friendliness = Type(""Friendliness"")
  friendlinessA = Attr(""friendliness"",friendliness,publ)
  pet.addMethod(cares)
  pet.addAttribute(friendlinessA)
  rep.addClass(pet)
  
  wild = Cl(""Wild"")
  wild.setExtend(animal)
  wild.addImplement(bite)
  wild.isAbstract(True)
  wildness = Type(""Wildness"")
  wildnessA = Attr(""wildness"",wildness,publ)
  wild.addAttribute(wildnessA)
  wild.addMethod(attack)
  rep.addClass(wild)
  
  dog = Cl(""Dog"")
  dog.setExtend(pet)
  caresImpl = Method(""cares"",void,intrn)
  dog.addMethod(caresImpl)
  huntCat = Method(""huntCat"", void, prot)
  catT = Type(""Cat"")
  catP=Parameter(catT,""cat"")
  huntCat.addParameter(catP)
  energyT = Type(""Energy"")
  energyP=Parameter(energyT,""energy"")
  huntCat.addParameter(energyP)
  dog.addMethod(huntCat)
  rep.addClass(dog)
  
  cat = Cl(""Cat"")
  cat.setExtend(pet)
  cat.addMethod(caresImpl)
  mouw = Method(""mouw"",void,prot)
  cat.addMethod(mouw)
  rep.addClass(cat)
  
  cow = Cl(""Cow"")
  cow.setExtend(pet)
  milk = Type(""Milk"")
  milkA = Attr(""milk"",milk,intrn)
  cow.addAttribute(milkA)
  cow.addMethod(caresImpl)
  giveMilk = Method(""giveMilk"",milk,publ)
  cow.addMethod(giveMilk)
  rep.addClass(cow)
  
  tiger = Cl(""Tiger"")
  tiger.setExtend(wild)
  stripe = Type(""Stripe"")
  stripeA = Attr(""stripe"",stripe,prot)
  tiger.addAttribute(stripeA)
  attackImpl = Method(""attack"",hurt,prot)
  tiger.addMethod(attackImpl)
  rep.addClass(tiger)
  
  lion = Cl(""Lion"")
  lion.setExtend(wild)
  mane = Type(""Mane"")
  maneA = Attr(""mane"",mane,prot)
  lion.addAttribute(maneA)
  lion.addMethod(attackImpl)
  rep.addClass(lion)
",python
"#https://codeforces.com/contest/588/problem/B



n=int(input())
for i in range(2, 10**6):
	while n%(i*i)==0:
		n//= i
print(n)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/50/A

Solution: Simply divide the board-area by tile-area. Do integer division to ignore the fractional tiles. 
'''


def solve(m, n):
    tileArea = 2*1
    boardArea = m*n
    return boardArea / tileArea

if __name__ == ""__main__"":
    m, n = map(int, raw_input().split("" ""))
    print solve(m,n)",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/489/A

Solution: Create a sorted copy of the array. Iterate over the array and check if the current indexed element
is same as the one in its sorted version. If not, we need to swap. Hence iterate on the sub-array on the right
of this element to find its swap partner. Find it and swap the given array. Each of these swaps are captured
for the final answer. 
'''


def solve(n, arr):

    sorted_arr = sorted(arr)

    swaps = list()

    for i in xrange(0, n):

        if arr[i] != sorted_arr[i]:

            for j in xrange(i+1, n):

                if arr[j] == sorted_arr[i]:

                    arr[i], arr[j] = arr[j], arr[i]
                    swaps.append([i, j])
                    break

    swaps_count = len(swaps)
    ans = str(swaps_count)
    if swaps_count != 0:
        ans += ""\n"" + ""\n"".join(str(swap[0]) + "" "" + str(swap[1]) for swap in swaps)

    return ans


if __name__ == ""__main__"":

    n = int(raw_input())
    arr = map(int, raw_input().split("" ""))
    print solve(n, arr)
",python
"# https://codeforces.com/problemset/problem/4/C


def solve(n, names):

    db = {}
    result = []

    for i in range(0, n):

        if names[i] not in db:
            result.append(""OK"")
            db[names[i]] = 1
        else:
            postfix = db[names[i]]
            result.append(names[i] + str(postfix))
            db[names[i]] = postfix + 1

    return result



if __name__ == ""__main__"":

    n = int(input())
    names = []
    for i in range(0, n):
        names.append(input())

    result = solve(n, names)
    for i in range(0, n):
        print(result[i])
",python
"# https://codeforces.com/problemset/problem/231/A

# This will take input for the number of problems the team has
n = int(input())

# This is a counter for all solvable problems
solve = 0

ok = [
    ""1 0 1"", ""1 1 0"", ""0 1 1"", ""1 1 1""
]

notok = [
    ""0 0 0"", ""1 0 0"", ""0 1 0"", ""0 0 1""
]

# Loop to take input as many times as entered
for i in range(n):
    solvable = input()
    if solvable in ok:
        solve += 1
print(solve)

    















































'''
A. Team
time limit per test2 seconds
memory limit per test256 megabytes
inputstandard input
outputstandard output
One day three best friends Petya, Vasya and Tonya decided to form a team and take part in programming contests. Participants are usually offered several problems during programming contests. Long before the start the friends decided that they will implement a problem if at least two of them are sure about the solution. Otherwise, the friends won't write the problem's solution.

This contest offers n problems to the participants. For each problem we know, which friend is sure about the solution. Help the friends find the number of problems for which they will write a solution.

Input
The first input line contains a single integer n (1 ≤ n ≤ 1000) — the number of problems in the contest. Then n lines contain three integers each, each integer is either 0 or 1. If the first number in the line equals 1, then Petya is sure about the problem's solution, otherwise he isn't sure. The second number shows Vasya's view on the solution, the third number shows Tonya's view. The numbers on the lines are separated by spaces.

Output
Print a single integer — the number of problems the friends will implement on the contest.

Examples
input
3
1 1 0
1 1 1
1 0 0
output
2
input
2
1 0 0
0 1 1
output
1
Note
In the first sample Petya and Vasya are sure that they know how to solve the first problem and all three of them know how to solve the second problem. That means that they will write solutions for these problems. Only Petya is sure about the solution for the third problem, but that isn't enough, so the friends won't take it.

In the second sample the friends will only implement the second problem, as Vasya and Tonya are sure about the solution.
'''",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1481/A

Solution: The idea is that you should have enough R and L moves to have destination x co-ordinate. Same goes for destination
y co-ordinate. Make sure the counts are compared to the abs() of the co-ordinate value when they are negative. We leverage
collections.Counter for easy frequency map of moves. We destination is 0,0 we can delete all the moves and we would be
at it. Hence we can avoid checking that condition. 
'''

import collections


def solve(p_x, p_y, s):

    freq_map = collections.Counter(s)

    if p_x > 0:
        if freq_map['R'] < p_x:
            return ""NO""
    elif p_x < 0:
        if freq_map['L'] < abs(p_x):
            return ""NO""

    if p_y > 0:
        if freq_map['U'] < p_y:
            return ""NO""
    elif p_y < 0:
        if freq_map['D'] < abs(p_y):
            return ""NO""

    return ""YES""


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        p_x, p_y = map(int, raw_input().split("" ""))
        s = list(raw_input())
        print solve(p_x, p_y, s)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1325/B

Solution: Since we can make n copies of the array, we can pick the smallest element in first
copy, second smallest in second copy and so on. This way we can construct the longest strictly
increasing sub-sequence from the copy array. Therefore, the number of distinct elements in the
original array would bound the length of this sub-sequence. We find that via a set and return its
length as the final answer.  
'''


def solve(n, arr):

    distinct = set()

    for i in xrange(0, n):
        distinct.add(arr[i])

    return len(distinct)


if __name__ == ""__main__"":

    t = int(raw_input())

    results = list()
    for _ in xrange(0, t):
        n = int(raw_input())
        arr = map(int, raw_input().split("" ""))
        results.append(solve(n, arr))

    for result in results:
        print result
",python
"# https://codeforces.com/problemset/problem/158/A

participants = input().split()
scores = [int(score) for score in input().split()]
kth_score = scores[int(participants[1]) - 1]
total = 0

for i in range(0, len(scores)):
    if scores[i] == 0 or scores[i] < kth_score:
        break
    
    total += 1

print(total)",python
"ip = input()

ip = ip.split("" "")

n = int(ip[0])
k = int(ip[1])

for i in range(k):
    # Check if last digit is 0
    if n % 10 == 0:
        # Divide n by 10
        n /= 10
    else:
        # Subtract 1 from n
        n -= 1

# Printing inside int() because if not, it prints in float.0
print(int(n))







# https://codeforces.com/problemset/problem/977/A

# Little girl Tanya is learning how to decrease a number by one, but she does it wrong with a number consisting of two or more digits. Tanya subtracts one from a number by the following algorithm:
#
# if the last digit of the number is non-zero, she decreases the number by one;
# if the last digit of the number is zero, she divides the number by 10 (i.e. removes the last digit).
# You are given an integer number 𝑛. Tanya will subtract one from it 𝑘 times. Your task is to print the result after all 𝑘 subtractions.
#
# It is guaranteed that the result will be positive integer number.
#
# Input
# The first line of the input contains two integer numbers 𝑛 and 𝑘 (2≤𝑛≤109, 1≤𝑘≤50) — the number from which Tanya will subtract and the number of subtractions correspondingly.
#
# Output
# Print one integer number — the result of the decreasing 𝑛 by one 𝑘 times.
#
# It is guaranteed that the result will be positive integer number.
#
# Examples
# input
# 512 4
# output
# 50
# input
# 1000000000 9
# output
# 1
# Note
# The first example corresponds to the following sequence: 512→511→510→51→50.
",python
"__author__ = 'Devesh Bajpai'
'''
http://codeforces.com/problemset/problem/401/A
Solution: Sum all the numbers available in the cards list. If the current sum is more than
0, try to make it zero. For that, check if the current sum - x is becoming >= 0. If so,
subtract it and reiterate. Else, reduce x by 1. Keep doing this till the sum becomes 0.
Now for the case when the initial sum was negative, do the reverse of the above step.
Keep counting the missing cards whenever the sum is updated. Return missing as the answer.
'''
class VanyaandCards:

    n = -1
    x = -1
    cards = list()

    def solve(self):
        sum = 0
        for card in self.cards:
            sum += card
        #print sum

        missing = 0
        if(sum>0):
            while(sum>0):
                if(sum-self.x >= 0):
                    sum-= self.x
                    missing +=1
                else:
                    self.x -= 1
        elif(sum<0):
            while(sum<0):
                if(sum+self.x <= 0):
                    sum+= self.x
                    missing +=1
                else:
                    self.x -= 1

        return missing


if __name__ == ""__main__"":
    v = VanyaandCards()
    v.n,v.x = map(int, raw_input().split("" ""))
    v.cards = map(int, raw_input().split("" ""))
    print v.solve()",python
"#https://codeforces.com/problemset/problem/567/A


n = int(input())
cities = list(map(int, input().split("" "")))

for i in range(len(cities)):
  minimum = 0 # tmp
  maximum = 0 # tmp
  if i == 0:
    minimum = cities[ 1] - cities[0]
    maximum = cities[-1] - cities[0]
  elif i == n - 1:
    minimum = cities[-1] - cities[i - 1]
    maximum = cities[-1] - cities[0]
  else:
    if cities[i] - cities[i-1] > cities[i+1] - cities[i]:
      minimum = cities[i+1] - cities[i]
    else:
      minimum = cities[i] - cities[i-1]

    if cities[i] - cities[0] > cities[-1] - cities[i]:
      maximum = cities[i] - cities[0]
    else:
      maximum = cities[-1] - cities[i]

  print(""%i %i"" %(minimum, maximum))
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/contest/1337/problem/B

Solution: The need is decide the ordering of spells. 
Void Absorption: VA : x/2 + 10
Lightening Strikes: LS: x - 10

if we do LS and then VA: (x-10)/2 + 10 = x/2 - 5 + 10 = x/2 + 5
if we do VA and then LS: x/2 + 10 - 10 = x/2

Hence we would want to do all the VAs till doing that actually reduces x. e.g. imagine x = 2.
Then x/2 + 10 = 11. Then in second round it becomes 11/2 + 10 = 15. So it stars growing. That is when
we need to employ LS. So once the VAs are over, we need to check we have enough LS to bring x to 0 or less.
This means x <= m * 10. Return the decision accordingly. 

'''


def solve(x, n, m):

    while x > 0 and n > 0 and x/2 + 10 < x:

        if n > 0:
            x = x/2 + 10
            n -= 1

    return ""YES"" if x <= m * 10 else ""NO""


if __name__ == ""__main__"":

    t = int(raw_input())

    results = list()
    for _ in xrange(0, t):
        x, n, m = map(int, raw_input().split("" ""))
        results.append(solve(x, n, m))

    for result in results:
        print result
",python
"# https://codeforces.com/problemset/problem/467/A

n = int(input())
count_accomodations = 0

for i in range(n):
    accomodation = [int(num) for num in input().split()]
    if (accomodation[1] - accomodation[0] >= 2):
        count_accomodations += 1

print(count_accomodations)",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/894/A

Solution: Observing the required string structure QAQ, we can deduce 2 important points:
1. For each A, we need to know how many Qs were present before it. That would help to create combination of QA with this
A
2. For each Q, we need to know how many QAQ and QA where present before it. The QAs of QAQs would combine with this Q to
build another QAQ. Also the earlier formed QAs would use this Q to form QAQ. 

Using this information, we can see that there is a sub-problem in this question which requires previous states of Q, QA
and QAQ to form their current counterparts. Hence solve this by using DP keeping the previous and current values of these
states. Finally, the answer lies in QAQ counter. Since we carry forward the current state value into its previous
one, in the end we will have the answer previous QAQ counter. 
'''


def solve(s):

    prev_q = curr_q = prev_qa = curr_qa = prev_qaq = curr_qaq = 0

    for i in xrange(0, len(s)):

        curr_q = curr_qa = curr_qaq = 0

        if s[i] == 'Q':
            curr_qaq = prev_qaq + prev_qa
            curr_q = prev_q + 1
        elif s[i] == 'A':
            curr_qa = prev_qa + prev_q

        prev_q = max(prev_q, curr_q)
        prev_qa = max(prev_qa, curr_qa)
        prev_qaq = max(prev_qaq, curr_qaq)

    return prev_qaq


if __name__ == ""__main__"":

    s = raw_input()
    print solve(s)
",python
"__pragma__(""alias"",""s"",""$"")
from Widget import Widget
import random
config=Config.Config()
class Image(Widget):
	""""""docstring for Button""""""
	def __init__(self, titulo=""""):
		Widget.__init__(self,titulo)
		self._html=""<b class='titulo'></b><figure><img></figure><span class='descripcion'></span>""
		self.target.html(self._html)
		self.__button=self.target.find("">button"")
		self._html=""""
		self._src=""""
		self.activador=None
		self._hoverEffect=None #vibrar, 
		#obscurecer, zoomIn, zoomOut, slide, blur,grayScale, sepia, blurGrayScale, opacity, opacityColor, opacityColorRandom
		#Flash, Shine, Circle
		self.inMoving=None #function(self)
		self.rotation=None # random, random[1,3] , 20ª
		self.width=400
		self._tooltip=None #top,bottom
		self._load_css=[config.base_url+""/static/css/hint.css-master/hint.css""]
		self._hint=self._titulo
	
	
	def titulo(self,titulo):
		self.target.find("">.titulo"").text(titulo)
		self._titulo=titulo

	
	def update(self):
		self.format=[self._titulo]
		self.__update__()
		self.target.trigger(""click"",[self])

		if self.activador!=None:
			self.target.bind(""click"",self.activador(self))
		self.__titulo=self.target.find("">.titulo"")
		self.titulo(self._titulo)
		self.target.find("">figure"").find("">img"").attr(""src"",self._src)
		if self._hoverEffect==""vibrar"":
			pass
		elif self._hoverEffect==""oscurecer"":
			pass
		elif self._hoverEffect==""zoomIn"":
			self.target.find("">figure"").addClass(""hover03"")
		elif self._hoverEffect==""zoomOut"":
			self.target.find("">figure"").addClass(""hover04"")
			pass
		elif self._hoverEffect==""slide"":
			self.target.find("">figure"").addClass(""hover05"")
		elif self._hoverEffect==""rotate"":
			self.target.find("">figure"").addClass(""hover06"")
		elif self._hoverEffect==""blur"":
			self.target.find("">figure"").addClass(""hover07"")
		elif self._hoverEffect==""grayScale"":
			self.target.find("">figure"").addClass(""hover08"")
		elif self._hoverEffect==""sepia"":
			self.target.find("">figure"").addClass(""hover09"")
		elif self._hoverEffect==""blurGrayScale"":
			self.target.find("">figure"").addClass(""hover10"")
		elif self._hoverEffect==""opacity"":
			self.target.find("">figure"").addClass(""hover11"")
		elif self._hoverEffect==""opacityColor"":
			self.target.find("">figure"").addClass(""hover12"")
		elif self._hoverEffect==""opacityColorRandom"":
			pass
		elif self._hoverEffect==""flash"":
			self.target.find("">figure"").addClass(""hover13"")
		elif self._hoverEffect==""shine"":
			self.target.find("">figure"").addClass(""hover14"")

		elif self._hoverEffect==""circle"":
			self.target.find("">figure"").addClass(""hover15"")

		if self.rotation!=None:
			
			if type(self.rotation)==list:

				self.target.find("">figure"").find("">img"").css({""transform"":""rotate(""+str(random.randint(self.rotation[0],self.rotation[1]))+""deg)"",""width"":self.width})
			elif self.rotation==""random"":
				self.target.find("">figure"").find("">img"").css({""transform"":""rotate(""+str(random.random()*10)+""deg)"",""width"":self.width})
			else:
				self.target.find("">figure"").find("">img"").css({""transform"":""rotate(""+str(self.rotation)+""deg)"",""width"":self.width})
		if self._tooltip!=None:
			self.target.addClass(""hint--""+self._tooltip)
			self.target.attr(""data-hint"",self._hint)


		
	
	
		


		",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1206/B

Solution: Convert all the positives into 1, negatives as -1 and zeroes as is.
Now we need to check if we have odd number of negatives. If so, we if have some
zeroes, we take one of those and make it -1 so that even number of -1s multiply
to make +1. If not, we make one of the -1s as +1 using 2 moves. No we have -1s
and +1s multiplying to make +1. What's remaining is zeroes if left any. Convert
all of them as +1s for ease using that much of moves. The total of all these moves
is the final answer.
'''


def solve(n, arr):

    moves = negatives = zeroes = 0
    for i in xrange(0, n):
        if arr[i] > 0:
            # making them 1
            moves += (arr[i] - 1)
        elif arr[i] < 0:
            # making them -1
            moves += (-1 - arr[i])
            negatives += 1
        else:
            zeroes += 1

    # if odd number of negatives are there
    if negatives % 2 == 1:

        # if we can spare a 0, make it -1, which needs 1 moves
        if zeroes > 0:
            moves += 1
            zeroes -= 1
        # if not, make one of the -1 as +1, which needs 2 moves
        else:
            moves += 2
            negatives -= 1

    # make all zeroes as 1s
    if zeroes > 0:
        moves += zeroes

    return moves


if __name__ == ""__main__"":

    n = int(raw_input())
    arr = map(int, raw_input().split("" ""))
    print solve(n, arr)
",python
"# https://codeforces.com/problemset/problem/1581/B


from sys import stdin,stdout

input=stdin.readline
 
def inp(): return map(int,input().split())
 
for _ in range(int(input())):
    n,m,k=inp()
    if k<=1:
        print(""NO"")
    elif k==2:
        if n==1 and m==0:
            print(""YES"")
        else:
            print(""NO"")
    elif k==3:
        if m==(n*(n-1))//2:
            print(""YES"")
        else:
            print(""NO"")
    else:
        if m>=(n-1) and m<=(n*(n-1))//2:
            print(""YES"")
        else:
            print(""NO"")",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/750/A

Solution: Brute-force approach. Initialize the total time taken by k since that is anyways needed for the commute to 
the party. Now see if its safe to solve the ith problem and still not exceed the minutes to midnight, if so proceed
with the iteration. If not, return the previous i as the answer. If all the problems can be solved, return n.
TODO: This should be solvable optimally via binary search as well. 
'''


def solve(n, k):

    min_to_midnight = 240
    total = k

    for i in xrange(1, n+1):
        this_prob = 5 * i
        if total + this_prob <= min_to_midnight:
            total += this_prob
        else:
            return i-1

    return n


if __name__ == ""__main__"":

    n, k = map(int, raw_input().split("" ""))
    print solve(n, k)
",python
"# test

import os, sys, inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0, parentdir) 
from bot import Bot

b = Bot()

b.addClass('tcj29', 'tc2013j@cony', '1234', test=True)

# b.addClass('tcj29','tc2013j@cony','4468', '','', test = True)  #Single Class

# b.addClass('tcj29','tc2013j@cony','9190','9191','', test = True)  #Disscusion no Lab



# b.addClass('tcj29','tc2013j@cony','16587','','16588', test = True)  #Lab no Dicussion
# b.addClass('tcj29','tc2013j@cony','16587','','16594', test = True)  #Lab no Dicussion

# b.addClass('tcj29','tc2013j@cony','5741','5743','', test = True)  #Lab no Dicussion

# b.addClass('tcj29','tc2013j@cony','6133', '6140','6180', test = True)  #Disscussion and Lab  FIRST PAGE
# b.addClass('tcj29','tc2013j@cony','6133', '6147','6190', test = True)  #Disscussion and Lab	 SECOND PAGE

# b.addClass('tcj29','tc2013j@cony','6133', '7927','6195', test = True)  #Disscussion and Lab  LAST PAGE

",python
"toPrint = """"

ip = input()

toSort = ip.split(""+"")

# Turn string list to int list
for i in range(len(toSort)):
    toSort[i] = int(toSort[i])

# Sort the list
toSort.sort()

# Turn int list back to string list
for i in range(len(toSort)):
    toSort[i] = str(toSort[i])

# Print the list and put '+' between each number
for i in range(len(toSort)):
    toPrint += toSort[i]
    toPrint += ""+""

# The result gives a '+' at the end; this eleinimate that:
print(toPrint[0:-1])






# Xenia the beginner mathematician is a third year student at elementary school. She is now learning the addition operation.
#
# The teacher has written down the sum of multiple numbers. Pupils should calculate the sum. To make the calculation easier, the sum only contains numbers 1, 2 and 3. Still, that isn't enough for Xenia. She is only beginning to count, so she can calculate a sum only if the summands follow in non-decreasing order. For example, she can't calculate sum 1+3+2+1 but she can calculate sums 1+1+2 and 3+3.
#
# You've got the sum that was written on the board. Rearrange the summans and print the sum in such a way that Xenia can calculate the sum.
#
# Input
# The first line contains a non-empty string s — the sum Xenia needs to count. String s contains no spaces. It only contains digits and characters ""+"". Besides, string s is a correct sum of numbers 1, 2 and 3. String s is at most 100 characters long.
#
# Output
# Print the new sum that Xenia can count.
#
# Examples
# input
# 3+2+1
# output
# 1+2+3
# input
# 1+1+3+1+3
# output
# 1+1+1+3+3
# input
# 2
# output
# 2
",python
"from orm.tables import Library
from orm.tables import Log
# from sqlalchemy.orm import sessionmaker
# from sqlalchemy.orm.session import Session
from orm.tables import session



def add(BookName,Yearofpublication,AuthorName,Category,Addp):
    l1=Library(BookName,Yearofpublication,AuthorName,Category,Addp)
    l1.addClass()
    lg=Log(Library_id=l1.BookID,Info='Book added',Name=Addp,OldVersion=None,NewVersion=BookName)
    lg.addClass()
    



def delete(key):
    Person=input(""Name: "")
    session.query(Library).filter(Library.BookID==key).delete()
    session.commit()

    lg=Log(Info='Book Deleted',Name=Person,OldVersion=None,NewVersion=None)
    lg.addClass()
  



def update(key):

    Person=input(""Name: "")

    question=int(input('''
                     Update Book Name: 1
                     Update Year: 2
                     Update Author Name: 3
                     Update category: 4
                     Update Person: 5
                     Update all : 6
                   '''))

    if question==1:

        veri=session.query(Library).filter(Library.BookID==key).one()
        temp=veri.BookName

        a=input(""Update Bookname: "")
        upd=session.query(Library).get(key)
        upd.BookName=a
        session.commit()


        lg=Log(Library_id=key,Info='Book updated',Name=Person,OldVersion=temp,NewVersion=a)
        lg.addClass()
        
    
    elif question==2:

        veri=session.query(Library).filter(Library.BookID==key).one()
        temp=veri.Yearofpublication
        
        b=input(""Update Year: "")
        upd=session.query(Library).get(key)
        upd.Yearofpublication=b
        session.commit()

        lg=Log(Library_id=key,Info='Book updated',Name=Person,OldVersion=temp,NewVersion=b)
        Log.addClass(lg)#böyle de çağırabiliyorum**
        temp=veri.BookName
        

    elif question==3:

        veri=session.query(Library).filter(Library.BookID==key).one()
        temp=veri.AuthorName

        c=input(""Update Author Name: "")
        upd=session.query(Library).get(key)
        upd.AuthorName=c
        session.commit()

        lg=Log(Library_id=key,Info='Book updated',Name=Person,OldVersion=temp,NewVersion=c)
        lg.addClass()

    
    elif question==4:

        veri=session.query(Library).filter(Library.BookID==key).one()
        temp=veri.Category

        d=input(""Update Category: "")
        upd=session.query(Library).get(key)
        upd.Category=d
        session.commit()

        lg=Log(Library_id=key,Info='Book updated',Name=Person,OldVersion=temp,NewVersion=d)
        lg.addClass()


    elif question==5:

        veri=session.query(Library).filter(Library.BookID==key).one()
        temp=veri.Addp

        e=input(""Enter new data: "")
        upd=session.query(Library).get(key)
        upd.Addp=e
        session.commit()

        lg=Log(Library_id=key,Info='Book updated',Name=Person,OldVersion=temp,NewVersion=e)
        lg.addClass()


    elif question==6:
        #old
        veri=session.query(Library).filter(Library.BookID==key).one()
        temp=veri.BookName
        temp1=veri.Yearofpublication
        temp2=veri.AuthorName
        temp3=veri.Category
        temp4=veri.Addp


        q1=input(""Update BookName: "")
        q2=int(input(""Update Year: ""))
        q3=input(""Update Author Name: "")
        q4=input(""Update Category: "")
        q5=input(""Update person: "")


        upd=session.query(Library).get(key)
        upd.BookName=q1
        session.commit()
        upd.Yearofpublication=q2
        session.commit()
        upd.AuthorName=q3
        session.commit()
        upd.Category=q4
        session.commit()
        upd.Addp=q5
        session.commit()


        lg=Log(Library_id=key,Info='Book updated',Name=Person,OldVersion=""{},{},{},{},{}"".format(temp,temp1,temp2,temp3,temp4),NewVersion=""{},{},{},{},{}"".format(q1,q2,q3,q4,q5))
        lg.addClass()
    

    else:
        print(""False expression!"")


   

",python
"#https://codeforces.com/problemset/problem/271/A
year=int(input())
def check(year):
    lst=[int(x) for x in str(year)]
    count=0
    for i in range (0,3):
        for j in range(i+1,4):
            if lst[i]==lst[j]:
                count+=1
    if count!=0:
        year+=1
        check(year)
    else:
        print(year)

check(year+1)
",python
"n = input()
arr = []
counter = 0

for i in range(int(n)):
    arr.append(input())

# Check if consecutive elements in the array are the same. If they aren't, add one to counter
for i in range(len(arr) - 1):
    if arr[i] == arr[i + 1]:
        pass
    else:
        counter += 1

# We add 1 to the counter because the code above counts the number of spaces between the magnet groups
# Not the groups themselves like this:
# V V => I counts that there is 1 space between the V's but there are acctually spaces + 1 V's. Hence the +1
print(counter + 1)
",python
"#https://codeforces.com/contest/611/problem/A



ins = input().split()
dict = {'week': [0, 52, 52, 52, 52, 53, 53, 52], 'month': 30 * [12] + [11, 7]}
print(dict[ins[2]][int(ins[0])])
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/580/A

Solution: Iterate over the list and check for each element if its >= its left neighbor. If so, it is part of a non-
decreasing sub-segment. Therefore, increase the counter of length, otherwise reset it to 1. Keep a variable to track
the max length of that sub-segment seen so far which is the final answer. 
'''


def solve(n , arr):

    length = 1
    max_length = 1

    for i in xrange(1, n):

        if arr[i] >= arr[i-1]:
            length += 1
        else:
            length = 1

        max_length = max(max_length, length)

    return max_length


if __name__ == ""__main__"":

    n = int(raw_input())
    arr = map(int, raw_input().split("" ""))
    print solve(n, arr)
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1374/A

Solution: Since is the upper limit of the range, we get the quotient and remainder by dividing it by x. Now if the 
required remainder (i.e. y) is less than or equal to the one got, we can safely multiply quotient by x and add y to it
to get the largest possible k. Else, we need to try the last multiple of x, i.e quotient needs to be reduced by 1 and
then the result is calculated. 
'''


def solve(x, y, n):

    quotient = n / x
    remainder = n % x

    if y > remainder:
        quotient -= 1

    return (quotient * x) + y


if __name__ == ""__main__"":

    t = int(raw_input())

    results = list()
    for _ in xrange(0, t):
        x, y, n = map(int, raw_input().split("" ""))
        results.append(solve(x, y, n))

    for result in results:
        print result
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/80/A

Solution: The idea is to check numbers in the range [n+1, m) if anyone of them is prime or not. If so, then surely m
is not the next prime number. If that range doesn't find a prime number, we need to check if m itself is prime or not.
Accordingly, we return the result.  

Improvement: We can surely use Sieve of Eratosthenes for a better way to figure out if a number is prime or not.
'''

import math


def is_prime(x):

    for i in xrange(2, int(math.sqrt(x))+1):

        if x % i == 0:
            return False

    return True


def solve(n, m):

    for i in xrange(n+1, m):

        if is_prime(i):
            return ""NO""

    return ""YES"" if is_prime(m) else ""NO""


if __name__ == ""__main__"":

    n,m = map(int, raw_input().split("" ""))
    print solve(n, m)",python
"###
#   colum append
#
####

DataProc.appendColumns (['lmn_user_features_4_11_6_15_t',
				'lmn_u_class_4_11_6_15_indc'],
				'lmn_user_features_4_11_6_15_t_addclass')

DataProc.appendColumns (['lmn_brand_features_4_11_6_15_t',
				'lmn_b_class_4_11_6_15_indc'],
				'lmn_brand_features_4_11_6_15_t_addclass')

DataProc.appendColumns (['lmn_user_features_5_11_7_15_t',
				'lmn_u_class_5_11_7_15_indc'],
				'lmn_user_features_5_11_7_15_t_addclass')

DataProc.appendColumns (['lmn_brand_features_5_11_7_15_t',
				'lmn_b_class_5_11_7_15_indc'],
				'lmn_brand_features_5_11_7_15_t_addclass')










# connect 

sql(""""""
drop table if  exists lmn_train_area_validate_4_11_7_15_addclass  ;
create table lmn_train_area_validate_4_11_7_15_addclass as
select
	lmn_user_brand_features_4_11_6_15_addclass.user_id,
      lmn_user_brand_features_4_11_6_15_addclass.brand_id,
 	 click1	 ,
	click3	 ,
	click5	 ,
	click7	 ,
	click10	,
	click15	 ,
	click25	 ,

	buy1	 ,
	buy3	 ,
	buy5	 ,
	buy7	 ,
	buy10	,
	buy15	 ,
	buy25	 ,

	collect1	 ,
	collect3	 ,
	collect5	 ,
	collect7	 ,
	collect10	,
	collect15	 ,
	collect25	 ,

	basket1	 ,
	basket3	 ,
	basket5	 ,
	basket7	 ,
	basket10	,
	basket15	 ,
	basket25	,
      
       click_this_ratio	,
	 buy_this_ratio	,
	 collect_this_ratio	 ,
	 basket_this_ratio	,
	 action_this	,
	lmn_user_brand_features_4_11_6_15_addclass.cluster_index ub_class ,

 -- brand features
      --
  	n_clicked_ratio,
	n_bought_ratio,
	n_collected_ratio,	
	n_basketed_ratio,	
	actions_by ,

	clicked_dist_ratio,
	bought_dist_ratio,
	collected_dist_ratio,
	basketed_dist_ratio ,
       users_dist ,
	lmn_brand_features_4_11_6_15_addclass.cluster_index  b_class,

--user features 
	n_click_ratio,
	n_buy_ratio,
	n_collect_ratio ,
	n_basket_ratio,
	actions_sum ,

	click_dist_ratio,
	buy_dist_ratio,
	collect_dist_ratio,
	basket_dist_ratio,
      brand_dist  ,
      lmn_user_features_4_11_6_15_addclass.cluster_index  u_class ,	

	last_datetime ,		

      --label
      buy_brand	,
	case
	when buy_brand is not null then 1
	when buy_brand is null then 0
	end as buy_label

from
 lmn_user_brand_features_4_11_6_15_addclass

left outer join
lmn_user_features_4_11_6_15_addclass
on 	lmn_user_brand_features_4_11_6_15_addclass.user_id = lmn_user_features_4_11_6_15_addclass.user_id

left outer join
lmn_brand_features_4_11_6_15_addclass
on 	lmn_user_brand_features_4_11_6_15_addclass.brand_id = lmn_brand_features_4_11_6_15_addclass.brand_id		

left outer join(
   select
   user_id,
   brand_id  buy_brand
from(
	select user_id,brand_id 
	from t_alibaba_bigdata_user_brand_total_1
	where type = '1' and  visit_datetime>='06-16' and   visit_datetime <= '07-15'
	group by  user_id , brand_id
    )label
) buy_label_table_6_16_7_15
on 	lmn_user_brand_features_4_11_6_15_addclass.user_id = buy_label_table_6_16_7_15.user_id and 	lmn_user_brand_features_4_11_6_15_addclass.brand_id = buy_label_table_6_16_7_15.buy_brand

where actions_sum is not null and  actions_by is not null   ; --fliter
"""""")


############################################################################################################################################################

#connect all ,get train table for validate

sql(""""""
drop table if  exists lmn_predict_area_validate_5_11_7_15_addclass  ;
create table lmn_predict_area_validate_5_11_7_15_addclass as
select
	lmn_user_brand_features_5_11_7_15_addclass.user_id,
      lmn_user_brand_features_5_11_7_15_addclass.brand_id,
 	 click1	 ,
	click3	 ,
	click5	 ,
	click7	 ,
	click10	,
	click15	 ,
	click25	 ,

	buy1	 ,
	buy3	 ,
	buy5	 ,
	buy7	 ,
	buy10	,
	buy15	 ,
	buy25	 ,

	collect1	 ,
	collect3	 ,
	collect5	 ,
	collect7	 ,
	collect10	,
	collect15	 ,
	collect25	 ,

	basket1	 ,
	basket3	 ,
	basket5	 ,
	basket7	 ,
	basket10	,
	basket15	 ,
	basket25	,
      
       click_this_ratio	,
	 buy_this_ratio	,
	 collect_this_ratio	 ,
	 basket_this_ratio	,
	 action_this	,
	lmn_user_brand_features_5_11_7_15_addclass.cluster_index ub_class ,

 -- brand features
      --
  	n_clicked_ratio,
	n_bought_ratio,
	n_collected_ratio,	
	n_basketed_ratio,	
	actions_by ,

	clicked_dist_ratio,
	bought_dist_ratio,
	collected_dist_ratio,
	basketed_dist_ratio ,
       users_dist ,
	lmn_brand_features_5_11_7_15_addclass.cluster_index  b_class,

--user features 
	n_click_ratio,
	n_buy_ratio,
	n_collect_ratio ,
	n_basket_ratio,
	actions_sum ,

	click_dist_ratio,
	buy_dist_ratio,
	collect_dist_ratio,
	basket_dist_ratio,
      brand_dist  ,
      lmn_user_features_5_11_7_15_addclass.cluster_index  u_class ,	

	last_datetime 	

from
 lmn_user_brand_features_5_11_7_15_addclass

left outer join
lmn_user_features_5_11_7_15_addclass
on 	lmn_user_brand_features_5_11_7_15_addclass.user_id = lmn_user_features_5_11_7_15_addclass.user_id

left outer join
lmn_brand_features_5_11_7_15_addclass
on 	lmn_user_brand_features_5_11_7_15_addclass.brand_id = lmn_brand_features_5_11_7_15_addclass.brand_id		

where actions_sum is not null and  actions_by is not null   ; --fliter
"""""")



",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/contest/1324/problem/C

Solution: The frog jumps from the outside of the array (from left) and aims to reach the outside
of the array (on the right). Any of the 'L' cells disrupt the movement towards the goal since they
bring the frog back. Instead, the frog should try to get to the 'R' cells. In order to make the best
use of them, we calculate the difference between consecutive 'R' cells and consider the maximum of it.
That seems easy but there are test cases where we need to handle special cases when there are no 'R'
cells, or only 1 'R' cell; to cleanly handle that, we add a 'S' (source) and 'D' (destination) cells
to the string.  
'''


def solve(s):

    max_diff = 0
    prev_idx = -1

    s = s + 'D' # destination
    s = 'S' + s  # source

    n = len(s)

    for i in xrange(0, n):

        if s[i] == 'S':
            prev_idx = i
        elif s[i] == 'R':
            max_diff = max(max_diff, i - prev_idx)
            prev_idx = i
        elif s[i] == 'D':
            max_diff = max(max_diff, i - prev_idx)

    return max_diff


if __name__ == ""__main__"":

    t = int(raw_input())

    results = list()
    for _ in xrange(0, t):
        s = raw_input()
        results.append(solve(s))

    for result in results:
        print result
",python
"__author__ = 'Devesh Bajpai'
'''
http://codeforces.com/problemset/problem/25/A
Algorithm: Since the numbers are from 1 to n, one possible way can be considering numbers into 2 buckets: odd and even.
Increase the count by 1 each time of the particular bucket found. Since there is only one different element present,
only one of the bucket count will be 1. Just print its index value (since the question requires index of list from 1),
return found_index+1.
'''

def solve(n,nums):

    even_diffElemIndex = 0
    even_elemCount = 0

    odd_diffElemIndex = 0
    odd_elemCount = 0

    for i in range(0,n):

        if(nums[i]%2==0):
            even_diffElemIndex = i
            even_elemCount+=1
        elif(nums[i]%2!=0):
            odd_diffElemIndex = i
            odd_elemCount+=1

    if(even_elemCount==1):
        return even_diffElemIndex+1
    return odd_diffElemIndex+1






if __name__ == ""__main__"":
    n = int(raw_input())
    nums = map(int,raw_input().split("" ""))
    #print nums

    print solve(n,nums)
",python
"#test
import threading,time

from bot import Bot
bots = [Bot() for x in range(10)] 

netid = 'tcj29'
password = 'tc2013j@cony'

classes =      ['10803','4468', '9190', '16587', '5741', '6133','13290','12576', '11161', '11166' ]
disscussions = ['10821', ' '   , '9191', ' '     , '5743', '6140', ' '    ,'12578', '11165', ' '    ]
labs =         ['10804',  ' '  ,   ' '  , '16588',   ' '  , '6180', ' '    , ' '    ,   ' '   , '11168' ]

for x in range (0, len(classes)):
          t = threading.Thread(target=bots[x].addClass, args=(netid ,password ,classes[x], disscussions[x], labs[x]), kwargs = {'test': True, 'hidden': True}  )
          t.daemon = True
          t.start()
    #thread.start_new_thread(bots[x].addClass, args=(netid ,password ,classes[x], disscussions[x], labs[x]), kwargs = {'test': True, 'hidden': True}  )
	#bots[x].addClass(netid ,password ,classes[x], disscussions[x], labs[x],  test = True, hidden = True) 

time.sleep(60)

'''
bots[0].addClass('tcj29','tc2013j@cony','10803', '10821','10804', test = True)  #Single Class

bots[1].addClass('tcj29','tc2013j@cony','4468', '','', test = True)  #Single Class

bots[2].addClass('tcj29','tc2013j@cony','9190','9191','', test = True)  #Disscusion no Lab



bots[3].addClass('tcj29','tc2013j@cony','16587','','16588', test = True)  #Lab no Dicussion
#b.addClass('tcj29','tc2013j@cony','16587','','16594', test = True)  #Lab no Dicussion

bots[4].addClass('tcj29','tc2013j@cony','5741','5743','', test = True)  #Lab no Dicussion

bots[5].addClass('tcj29','tc2013j@cony','6133', '6140','6180', test = True)  #Disscussion and Lab  FIRST PAGE
#b.addClass('tcj29','tc2013j@cony','6133', '6147','6190', test = True)  #Disscussion and Lab	 SECOND PAGE
#
#b.addClass('tcj29','tc2013j@cony','6133', '7927','6195', test = True)  #Disscussion and Lab  LAST PAGE

'''",python
"#!/usr/bin/python

# Python 2->3 libraries that were renamed.
try:
    from urllib2 import urlopen
except:
    from urllib.request import urlopen
try:
    from HTMLParser import HTMLParser
except:
    from html.parser import HTMLParser

# Other libraries.
from sys import argv
from subprocess import call
from functools import partial, wraps

import re
import argparse
import platform

###########################
# User modifiable constants
###########################
language_params = {
        'c++14' : {
            'TEMPLATE'    : 'main.cc',
            'DEBUG_FLAGS' : '-DDEBUG',
            'COMPILE_CMD' : 'g++ -g -std=c++14 -Wall $DBG',
            'RUN_CMD'     : './a.out'
            },
        'go'    : {
            'TEMPLATE'    : 'main.go',
            'COMPILE_CMD' : 'go build $DBG -o a.out',
            'DEBUG_FLAGS' : '''""-ldflags '-X=main.DEBUG=Y'""''',
            'RUN_CMD'     : './a.out'
            },
        'kotlin'    : {
            'TEMPLATE'    : 'main.kt',
            'COMPILE_CMD' : 'kotlinc -include-runtime -d out.jar',
            'DEBUG_FLAGS' : ""-d"",
            'RUN_CMD'     : 'java -jar out.jar $DBG'
            },
        }

SAMPLE_INPUT='input'
SAMPLE_OUTPUT='output'
MY_OUTPUT='my_output'

# Do not modify these!
VERSION='CodeForces Parser v1.5.1: https://github.com/johnathan79717/codeforces-parser'
RED_F='\033[31m'
GREEN_F='\033[32m'
BOLD='\033[1m'
NORM='\033[0m'
if (platform.system() == ""Darwin""):
    TIME_CMD='`which gtime` -o time.out -f ""(%es)""'
else:
    TIME_CMD='`which time` -o time.out -f ""(%es)""'
TIME_AP='`cat time.out`'

# Problems parser.
class CodeforcesProblemParser(HTMLParser):

    def __init__(self, folder):
        HTMLParser.__init__(self)
        self.folder = folder
        self.num_tests = 0
        self.testcase = None
        self.start_copy = False

    def handle_starttag(self, tag, attrs):
        if tag == 'div':
            if attrs == [('class', 'input')]:
                self.num_tests += 1
                self.testcase = open(
                    '%s/%s%d' % (self.folder, SAMPLE_INPUT, self.num_tests), 'wb')
            elif attrs == [('class', 'output')]:
                self.testcase = open(
                    '%s/%s%d' % (self.folder, SAMPLE_OUTPUT, self.num_tests), 'wb')
        elif tag == 'pre':
            if self.testcase != None:
                self.start_copy = True

    def handle_endtag(self, tag):
        if tag == 'br':
            if self.start_copy:
                self.testcase.write('\n'.encode('utf-8'))
                self.end_line = True
        if tag == 'pre':
            if self.start_copy:
                if not self.end_line:
                    self.testcase.write('\n'.encode('utf-8'))
                self.testcase.close()
                self.testcase = None
                self.start_copy = False

    def handle_entityref(self, name):
        if self.start_copy:
            self.testcase.write(self.unescape(('&%s;' % name)).encode('utf-8'))

    def handle_data(self, data):
        if self.start_copy:
            self.testcase.write(data.strip('\n').encode('utf-8'))
            self.end_line = False

# Contest parser.
class CodeforcesContestParser(HTMLParser):

    def __init__(self, contest):
        HTMLParser.__init__(self)
        self.contest = contest
        self.start_contest = False
        self.start_problem = False
        self.name = ''
        self.problem_name = ''
        self.problems = []
        self.problem_names = []

    def handle_starttag(self, tag, attrs):
        if self.name == '' and attrs == [('style', 'color: black'), ('href', '/contest/%s' % (self.contest))]:
                self.start_contest = True
        elif tag == 'option':
            if len(attrs) == 1:
                regexp = re.compile(r""'[A-Z][0-9]?'"") # The attrs will be something like: ('value', 'X'), or ('value', 'X1')
                string = str(attrs[0])
                search = regexp.search(string)
                if search is not None:
                    self.problems.append(search.group(0).split(""'"")[-2])
                    self.start_problem = True

    def handle_endtag(self, tag):
        if tag == 'a' and self.start_contest:
            self.start_contest = False
        elif self.start_problem:
            self.problem_names.append(self.problem_name)
            self.problem_name = ''
            self.start_problem = False

    def handle_data(self, data):
        if self.start_contest:
            self.name = data
        elif self.start_problem:
            self.problem_name += data

# Parses each problem page.
def parse_problem(folder, contest, problem):
    url = 'http://codeforces.com/contest/%s/problem/%s' % (contest, problem)
    html = urlopen(url).read()
    parser = CodeforcesProblemParser(folder)
    parser.feed(html.decode('utf-8'))
    # .encode('utf-8') Should fix special chars problems?
    return parser.num_tests

# Parses the contest page.
def parse_contest(contest):
    url = 'http://codeforces.com/contest/%s' % (contest)
    html = urlopen(url).read()
    parser = CodeforcesContestParser(contest)
    parser.feed(html.decode('utf-8'))
    return parser

# Generates the test script.
def generate_test_script(folder, language, num_tests, problem):
    param = language_params[language]

    with open(folder + 'test.sh', 'w') as test:
        test.write(
            ('#!/bin/bash\n'
            'DBG=""""\n'
            'while getopts "":d"" opt; do\n'
            '  case $opt in\n'
            '    d)\n'
            '      echo ""-d was selected; compiling in DEBUG mode!"" >&2\n'
            '      DBG=' + param[""DEBUG_FLAGS""] +'\n'
            '      ;;\n'
            '    \?)\n'
            '      echo ""Invalid option: -$OPTARG"" >&2\n'
            '      ;;\n'
            '  esac\n'
            'done\n'
            '\n'
            'if ! ' + param[""COMPILE_CMD""] +' {0}.{1}; then\n'
            '    exit\n'
            'fi\n'
            'INPUT_NAME='+SAMPLE_INPUT+'\n'
            'OUTPUT_NAME='+SAMPLE_OUTPUT+'\n'
            'MY_NAME='+MY_OUTPUT+'\n'
            'rm -R $MY_NAME* &>/dev/null\n').format(problem, param[""TEMPLATE""].split('.')[1]))
        test.write(
            'for test_file in $INPUT_NAME*\n'
            'do\n'
            '    i=$((${{#INPUT_NAME}}))\n'
            '    test_case=${{test_file:$i}}\n'
            '    if ! {5} {run_cmd} < $INPUT_NAME$test_case > $MY_NAME$test_case; then\n'
            '        echo {1}{4}Sample test \#$test_case: Runtime Error{2} {6}\n'
            '        echo ========================================\n'
            '        echo Sample Input \#$test_case\n'
            '        cat $INPUT_NAME$test_case\n'
            '    else\n'
            '        if diff --brief --ignore-space-change --ignore-blank-lines $MY_NAME$test_case $OUTPUT_NAME$test_case; then\n'
            '            echo {1}{3}Sample test \#$test_case: Accepted{2} {6}\n'
            '        else\n'
            '            echo {1}{4}Sample test \#$test_case: Wrong Answer{2} {6}\n'
            '            echo ========================================\n'
            '            echo Sample Input \#$test_case\n'
            '            cat $INPUT_NAME$test_case\n'
            '            echo ========================================\n'
            '            echo Sample Output \#$test_case\n'
            '            cat $OUTPUT_NAME$test_case\n'
            '            echo ========================================\n'
            '            echo My Output \#$test_case\n'
            '            cat $MY_NAME$test_case\n'
            '            echo ========================================\n'
            '        fi\n'
            '    fi\n'
            'done\n'
            .format(num_tests, BOLD, NORM, GREEN_F, RED_F, TIME_CMD, TIME_AP, run_cmd=param[""RUN_CMD""]))
    call(['chmod', '+x', folder + 'test.sh'])


# Main function.
def main():
    print (VERSION)
    parser = argparse.ArgumentParser()
    parser.add_argument('--language', '-l', default=""c++14"", help=""The programming language you want to use ""
            ""(c++14, go)"")
    parser.add_argument('contest', help="""")
    args = parser.parse_args()

    contest = args.contest
    language = args.language

    # Find contest and problems.
    print ('Parsing contest %s for language %s, please wait...' % (contest, language))
    content = parse_contest(contest)
    print (BOLD+GREEN_F+'*** Round name: '+content.name+' ***'+NORM)
    print ('Found %d problems!' % (len(content.problems)))

    # Find problems and test cases.
    TEMPLATE = language_params[language][""TEMPLATE""]
    for index, problem in enumerate(content.problems):
        print ('Downloading Problem %s: %s...' % (problem, content.problem_names[index]))
        folder = '%s-%s/%s/' % (contest, language, problem)
        call(['mkdir', '-p', folder])
        call(['cp', '-n', TEMPLATE, '%s/%s.%s' % (folder, problem, TEMPLATE.split('.')[1])])
        num_tests = parse_problem(folder, contest, problem)
        print('%d sample test(s) found.' % num_tests)
        generate_test_script(folder, language, num_tests, problem)
        print ('========================================')

    print ('Use ./test.sh to run sample tests in each directory.')


if __name__ == '__main__':
    main()
",python
"#https://codeforces.com/problemset/problem/158/B

one=0
two=0
three=0
four=0
car=0
n=int(input())
L=list(map(int,input().split()))
l=len(L)

        
one=L.count(1)
two=L.count(2)
three=L.count(3)
four=L.count(4)

if ((two%2)*2+three>=one):
    car=two//2+four+three+two%2
else:
    if (one-((two%2)*2+three))%4>0:
        car=(one-((two%2)*2+three))//4+two//2+four+three+two%2+1
    else:
        car=(one-((two%2)*2+three))//4+two//2+four+three+two%2

#if three>1 and two%2>0h:
    #car+=0
if three!=0 and two!=0:
    if one%4>three:
    #if three>one%4:
        #car+=0
        if ((one%4)-three)>(two%2)*2:
            car+=1
            




        
print(car)
    
",python
"# https://codeforces.com/problemset/problem/112/A
### 112 A. Petya and Strings

# Store input and set strings to lowercase
str1 = input().lower()
str2 = input().lower()

# Compare strings
if str1 < str2:
    print(-1)
elif str1 > str2:
    print(1)
else:
    print(0)
    
# https://codeforces.com/problemset/problem/112/A
    
# Little Petya loves presents. His mum bought him two strings of the same size 
# for his birthday. The strings consist of uppercase and lowercase Latin letters. 
# Now Petya wants to compare those two strings lexicographically. The letters' 
# case does not matter, that is an uppercase letter is considered equivalent to 
# the corresponding lowercase letter. Help Petya perform the comparison.

# Input

# Each of the first two lines contains a bought string. The strings' lengths 
# range from 1 to 100 inclusive. It is guaranteed that the strings are of the 
# same length and also consist of uppercase and lowercase Latin letters.

# Output

# If the first string is less than the second one, print ""-1"". If the second 
# string is less than the first one, print ""1"". If the strings are equal, print 
# ""0"". Note that the letters' case is not taken into consideration when the 
# strings are compared.

# Contraints
# time limit per test
# 2 seconds
# memory limit per test
# 256 megabytes
# input
# standard input
# output
# standard output

# Examples

# Input
# aaaa
# aaaA

# Output
# 0

# Input
# abs
# Abz

# Output
# -1

# Input
# abcdefg
# AbCdEfF

# Output
# 1

# Note

# If you want more formal information about the lexicographical order (also 
# known as the ""dictionary order"" or ""alphabetical order""), you can visit 
# the following site:

#    http://en.wikipedia.org/wiki/Lexicographical_order
",python
"'''
https://codeforces.com/problemset/problem/71/A

Sometimes some words like ""localization"" or ""internationalization"" are so long that writing them many times in one text is quite tiresome.

Let's consider a word too long, if its length is strictly more than 10 characters. All too long words should be replaced with a special abbreviation.

This abbreviation is made like this: we write down the first and the last letter of a word and between them we write the number of letters between the first and the last letters. That number is in decimal system and doesn't contain any leading zeroes.

Thus, ""localization"" will be spelt as ""l10n"", and ""internationalization"" will be spelt as ""i18n"".

You are suggested to automatize the process of changing the words with abbreviations. At that all too long words should be replaced by the abbreviation and the words that are not too long should not undergo any changes.

Input
The first line contains an integer n. Each of the following n lines contains one word.
All the words consist of lowercase Latin letters and possess the lengths of from 1 to 100 characters.

Output
Print n lines. The i-th line should contain the result of replacing of the i-th word from the input data.
'''
class WayTooLongWords:
    
    def solve(self,strInputs):
        strOutputs = list()
        for line in strInputs:
            if(len(line)>10):
                line = line[0]+str(len(line)-2)+line[-1]
            strOutputs.append(line)
        return strOutputs 
        

if __name__ == ""__main__"":
    
    i = 0
    strInputs = list()
    n = int(raw_input())
    while(i<n):
        strInputs.append(raw_input()) 
        i+=1
    
    wtlw = WayTooLongWords()
    for line_output in wtlw.solve(strInputs):
        print line_output
    
    ",python
"#https://codeforces.com/problemset/problem/58/A



s = input()

j = 0
if s[0] == ""h"":
  j += 1

l_flag = True
for i in range(1, len(s)):
  if s[i] == s[i-1] and l_flag:
    continue

  if s[i] == ""hello""[j]:
    if j == 4: 
      j += 1
      break
    j += 1
    if j == 3: l_flag = False
    else: l_flag = True
    continue

if j == 5: 
  print(""YES"")
else: 
  print(""NO"")
",python
"__author__ = 'Devesh Bajpai'

'''
https://codeforces.com/problemset/problem/1509/A

Solution: Since the adjacent pairs have to sum and be completely divisible by 2 for being most photogenic, the elements
in the pair should both be odd or even (odd + odd and even + even makes an even number). Hence we segregate the array
keeping odds on on end and evens on the other.  
'''


def solve(n, arr):

    result = [0] * n
    odd_idx = 0
    even_idx = n-1
    for i in xrange(0, n):
        if arr[i] % 2 == 0:
            result[even_idx] = arr[i]
            even_idx -= 1
        else:
            result[odd_idx] = arr[i]
            odd_idx += 1

    return "" "".join(str(_) for _ in result)


if __name__ == ""__main__"":

    t = int(raw_input())

    for _ in xrange(0, t):
        n = int(raw_input())
        arr = map(int, raw_input().split("" ""))
        print solve(n, arr)
",python
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int m = sc.nextInt();

      System.out.println(solve(n, m));
    }

    sc.close();
  }

  static int solve(int n, int m) {
    if (n > m) {
      return solve(m, n);
    }
    if (n == 1) {
      return (m <= 2) ? (m - 1) : -1;
    }

    return (m - 1) * 2 - ((n % 2 == m % 2) ? 0 : 1);
  }
}",java
"import java.util.Arrays;
import java.util.Comparator;
import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a));
    }

    sc.close();
  }

  static int solve(int[] a) {
    return Arrays.stream(a)
        .boxed()
        .sorted(Comparator.reverseOrder())
        .limit(2)
        .mapToInt(x -> x)
        .sum();
  }
}",java
"package org.hightail.ui;

import java.awt.Cursor;
import java.awt.Desktop;
import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;
import javax.swing.JFrame;

public class AboutJDialog extends javax.swing.JDialog {

    public AboutJDialog(JFrame parent) {
        super(parent, true); // makes it modal
        initComponents();
        setLocationRelativeTo(parent);
        linkLabel.setCursor(new Cursor(Cursor.HAND_CURSOR));
        jTextArea1.setEditable(false);
    }

    /**
     * This method is called from within the constructor to initialize the form.
     * WARNING: Do NOT modify this code. The content of this method is always
     * regenerated by the Form Editor.
     */
    @SuppressWarnings(""unchecked"")
    // <editor-fold defaultstate=""collapsed"" desc=""Generated Code"">//GEN-BEGIN:initComponents
    private void initComponents() {

        linkLabel = new javax.swing.JLabel();
        jScrollPane1 = new javax.swing.JScrollPane();
        jTextArea1 = new javax.swing.JTextArea();
        linkLabelCompetitiveCompanion = new javax.swing.JLabel();
        linkLabelCompetitiveCompanionChrome = new javax.swing.JLabel();
        linkLabelCompetitiveCompanionFirefox = new javax.swing.JLabel();

        setDefaultCloseOperation(javax.swing.WindowConstants.DISPOSE_ON_CLOSE);
        setTitle(""About Hightail"");

        linkLabel.setFont(new java.awt.Font(""Tahoma"", 0, 12)); // NOI18N
        linkLabel.setText(""<html><a href=\""https://github.com/dj3500/hightail\"">Hightail's website</a></html>"");
        linkLabel.addMouseListener(new java.awt.event.MouseAdapter() {
            public void mouseClicked(java.awt.event.MouseEvent evt) {
                linkLabelMouseClicked(evt);
            }
        });

        jScrollPane1.setBorder(null);

        jTextArea1.setBackground(linkLabel.getBackground());
        jTextArea1.setColumns(20);
        jTextArea1.setFont(new java.awt.Font(""Tahoma"", 0, 12)); // NOI18N
        jTextArea1.setForeground(linkLabel.getForeground());
        jTextArea1.setLineWrap(true);
        jTextArea1.setRows(5);
        jTextArea1.setText(""Hightail is an automatic tester for programming contests such as CodeForces rounds. It will parse the problem statement, extract sample test cases (inputs and outputs) from it, and verify the correctness of your program against them. It is built to provide maximum automation and to relieve the contestant as much as possible.\n\nHightail is an open source project maintained by dj3500. More information on Hightail can be found on its website on GitHub."");
        jTextArea1.setWrapStyleWord(true);
        jTextArea1.setBorder(null);
        jTextArea1.setFocusable(false);
        jTextArea1.setOpaque(false);
        jScrollPane1.setViewportView(jTextArea1);

        linkLabelCompetitiveCompanion.setFont(new java.awt.Font(""Tahoma"", 0, 12)); // NOI18N
        linkLabelCompetitiveCompanion.setText(""<html><a href=\""https://github.com/jmerle/competitive-companion\"">Website of Competitive Companion</a> (plugin for Chrome/Firefox <br />that parses problems/contests and sends them to Hightail)</html>"");
        linkLabelCompetitiveCompanion.addMouseListener(new java.awt.event.MouseAdapter() {
            public void mouseClicked(java.awt.event.MouseEvent evt) {
                linkLabelCompetitiveCompanionMouseClicked(evt);
            }
        });

        linkLabelCompetitiveCompanionChrome.setFont(new java.awt.Font(""Tahoma"", 0, 12)); // NOI18N
        linkLabelCompetitiveCompanionChrome.setText(""<html><a href=\""https://chrome.google.com/webstore/detail/chelper-companion/cjnmckjndlpiamhfimnnjmnckgghkjbl\"">Chrome plugin</a></html>"");
        linkLabelCompetitiveCompanionChrome.addMouseListener(new java.awt.event.MouseAdapter() {
            public void mouseClicked(java.awt.event.MouseEvent evt) {
                linkLabelCompetitiveCompanionChromeMouseClicked(evt);
            }
        });

        linkLabelCompetitiveCompanionFirefox.setFont(new java.awt.Font(""Tahoma"", 0, 12)); // NOI18N
        linkLabelCompetitiveCompanionFirefox.setText(""<html><a href=\""https://addons.mozilla.org/en-US/firefox/addon/competitive-companion/\"">Firefox plugin</a></html>"");
        linkLabelCompetitiveCompanionFirefox.addMouseListener(new java.awt.event.MouseAdapter() {
            public void mouseClicked(java.awt.event.MouseEvent evt) {
                linkLabelCompetitiveCompanionFirefoxMouseClicked(evt);
            }
        });

        javax.swing.GroupLayout layout = new javax.swing.GroupLayout(getContentPane());
        getContentPane().setLayout(layout);
        layout.setHorizontalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(layout.createSequentialGroup()
                .addContainerGap()
                .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addComponent(jScrollPane1, javax.swing.GroupLayout.DEFAULT_SIZE, 480, Short.MAX_VALUE)
                    .addGroup(layout.createSequentialGroup()
                        .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                            .addComponent(linkLabel, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                            .addGroup(layout.createSequentialGroup()
                                .addComponent(linkLabelCompetitiveCompanionChrome, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                                .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.UNRELATED)
                                .addComponent(linkLabelCompetitiveCompanionFirefox, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)))
                        .addGap(0, 0, Short.MAX_VALUE))
                    .addComponent(linkLabelCompetitiveCompanion))
                .addContainerGap())
        );
        layout.setVerticalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(layout.createSequentialGroup()
                .addContainerGap()
                .addComponent(jScrollPane1, javax.swing.GroupLayout.PREFERRED_SIZE, 123, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.UNRELATED)
                .addComponent(linkLabel, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.UNRELATED)
                .addComponent(linkLabelCompetitiveCompanion, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED)
                .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.BASELINE)
                    .addComponent(linkLabelCompetitiveCompanionChrome, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                    .addComponent(linkLabelCompetitiveCompanionFirefox, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE))
                .addContainerGap(javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE))
        );

        pack();
    }// </editor-fold>//GEN-END:initComponents

    private void linkLabelMouseClicked(java.awt.event.MouseEvent evt) {//GEN-FIRST:event_linkLabelMouseClicked
        try {
            Desktop.getDesktop().browse(new URI(""https://github.com/dj3500/hightail""));
        } catch (URISyntaxException | IOException ex) {
            // problem?
        }
    }//GEN-LAST:event_linkLabelMouseClicked

    private void linkLabelCompetitiveCompanionMouseClicked(java.awt.event.MouseEvent evt) {//GEN-FIRST:event_linkLabelCompetitiveCompanionMouseClicked
        try {
            Desktop.getDesktop().browse(new URI(""https://github.com/jmerle/competitive-companion""));
        } catch (URISyntaxException | IOException ex) {
            // problem?
        }
    }//GEN-LAST:event_linkLabelCompetitiveCompanionMouseClicked

    private void linkLabelCompetitiveCompanionChromeMouseClicked(java.awt.event.MouseEvent evt) {//GEN-FIRST:event_linkLabelCompetitiveCompanionChromeMouseClicked
        try {
            Desktop.getDesktop().browse(new URI(""https://chrome.google.com/webstore/detail/chelper-companion/cjnmckjndlpiamhfimnnjmnckgghkjbl""));
        } catch (URISyntaxException | IOException ex) {
            // problem?
        }
    }//GEN-LAST:event_linkLabelCompetitiveCompanionChromeMouseClicked

    private void linkLabelCompetitiveCompanionFirefoxMouseClicked(java.awt.event.MouseEvent evt) {//GEN-FIRST:event_linkLabelCompetitiveCompanionFirefoxMouseClicked
        try {
            Desktop.getDesktop().browse(new URI(""https://addons.mozilla.org/en-US/firefox/addon/competitive-companion/""));
        } catch (URISyntaxException | IOException ex) {
            // problem?
        }
    }//GEN-LAST:event_linkLabelCompetitiveCompanionFirefoxMouseClicked

    // Variables declaration - do not modify//GEN-BEGIN:variables
    private javax.swing.JScrollPane jScrollPane1;
    private javax.swing.JTextArea jTextArea1;
    private javax.swing.JLabel linkLabel;
    private javax.swing.JLabel linkLabelCompetitiveCompanion;
    private javax.swing.JLabel linkLabelCompetitiveCompanionChrome;
    private javax.swing.JLabel linkLabelCompetitiveCompanionFirefox;
    // End of variables declaration//GEN-END:variables
}
",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();

      System.out.println(solve(n));
    }

    sc.close();
  }

  static String solve(int n) {
    return String.format(""%d 1 1 1"", n - 3);
  }
}",java
"/*
 * Copyright 2012-2016 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.springframework.boot.loader.tools;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.ExpectedException;
import org.junit.rules.TemporaryFolder;

import org.springframework.boot.loader.tools.MainClassFinder.MainClass;
import org.springframework.boot.loader.tools.MainClassFinder.MainClassCallback;
import org.springframework.boot.loader.tools.sample.AnnotatedClassWithMainMethod;
import org.springframework.boot.loader.tools.sample.ClassWithMainMethod;
import org.springframework.boot.loader.tools.sample.ClassWithoutMainMethod;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * Tests for {@link MainClassFinder}.
 *
 * @author Phillip Webb
 */
public class MainClassFinderTests {

	@Rule
	public TemporaryFolder temporaryFolder = new TemporaryFolder();

	@Rule
	public ExpectedException thrown = ExpectedException.none();

	private TestJarFile testJarFile;

	@Before
	public void setup() throws IOException {
		this.testJarFile = new TestJarFile(this.temporaryFolder);
	}

	@Test
	public void findMainClassInJar() throws Exception {
		this.testJarFile.addClass(""B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""A.class"", ClassWithoutMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarFile(), """");
		assertThat(actual).isEqualTo(""B"");
	}

	@Test
	public void findMainClassInJarSubFolder() throws Exception {
		this.testJarFile.addClass(""a/b/c/D.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithoutMainMethod.class);
		this.testJarFile.addClass(""a/b/F.class"", ClassWithoutMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarFile(), """");
		assertThat(actual).isEqualTo(""a.b.c.D"");
	}

	@Test
	public void usesBreadthFirstJarSearch() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarFile(), """");
		assertThat(actual).isEqualTo(""a.B"");
	}

	@Test
	public void findSingleJarSearch() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithMainMethod.class);
		this.thrown.expect(IllegalStateException.class);
		this.thrown.expectMessage(""Unable to find a single main class ""
				+ ""from the following candidates [a.B, a.b.c.E]"");
		MainClassFinder.findSingleMainClass(this.testJarFile.getJarFile(), """");
	}

	@Test
	public void findSingleJarSearchPrefersAnnotatedMainClass() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", AnnotatedClassWithMainMethod.class);
		String mainClass = MainClassFinder.findSingleMainClass(
				this.testJarFile.getJarFile(), """",
				""org.springframework.boot.loader.tools.sample.SomeApplication"");
		assertThat(mainClass).isEqualTo(""a.b.c.E"");
	}

	@Test
	public void findMainClassInJarSubLocation() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarFile(),
				""a/"");
		assertThat(actual).isEqualTo(""B"");

	}

	@Test
	public void findMainClassInFolder() throws Exception {
		this.testJarFile.addClass(""B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""A.class"", ClassWithoutMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarSource());
		assertThat(actual).isEqualTo(""B"");
	}

	@Test
	public void findMainClassInSubFolder() throws Exception {
		this.testJarFile.addClass(""a/b/c/D.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithoutMainMethod.class);
		this.testJarFile.addClass(""a/b/F.class"", ClassWithoutMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarSource());
		assertThat(actual).isEqualTo(""a.b.c.D"");
	}

	@Test
	public void usesBreadthFirstFolderSearch() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithMainMethod.class);
		String actual = MainClassFinder.findMainClass(this.testJarFile.getJarSource());
		assertThat(actual).isEqualTo(""a.B"");
	}

	@Test
	public void findSingleFolderSearch() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithMainMethod.class);
		this.thrown.expect(IllegalStateException.class);
		this.thrown.expectMessage(""Unable to find a single main class ""
				+ ""from the following candidates [a.B, a.b.c.E]"");
		MainClassFinder.findSingleMainClass(this.testJarFile.getJarSource());
	}

	@Test
	public void findSingleFolderSearchPrefersAnnotatedMainClass() throws Exception {
		this.testJarFile.addClass(""a/B.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", AnnotatedClassWithMainMethod.class);
		String mainClass = MainClassFinder.findSingleMainClass(
				this.testJarFile.getJarSource(),
				""org.springframework.boot.loader.tools.sample.SomeApplication"");
		assertThat(mainClass).isEqualTo(""a.b.c.E"");
	}

	@Test
	public void doWithFolderMainMethods() throws Exception {
		this.testJarFile.addClass(""a/b/c/D.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithoutMainMethod.class);
		this.testJarFile.addClass(""a/b/F.class"", ClassWithoutMainMethod.class);
		this.testJarFile.addClass(""a/b/G.class"", ClassWithMainMethod.class);
		ClassNameCollector callback = new ClassNameCollector();
		MainClassFinder.doWithMainClasses(this.testJarFile.getJarSource(), callback);
		assertThat(callback.getClassNames().toString()).isEqualTo(""[a.b.G, a.b.c.D]"");
	}

	@Test
	public void doWithJarMainMethods() throws Exception {
		this.testJarFile.addClass(""a/b/c/D.class"", ClassWithMainMethod.class);
		this.testJarFile.addClass(""a/b/c/E.class"", ClassWithoutMainMethod.class);
		this.testJarFile.addClass(""a/b/F.class"", ClassWithoutMainMethod.class);
		this.testJarFile.addClass(""a/b/G.class"", ClassWithMainMethod.class);
		ClassNameCollector callback = new ClassNameCollector();
		MainClassFinder.doWithMainClasses(this.testJarFile.getJarFile(), null, callback);
		assertThat(callback.getClassNames().toString()).isEqualTo(""[a.b.G, a.b.c.D]"");
	}

	private static class ClassNameCollector implements MainClassCallback<Object> {

		private final List<String> classNames = new ArrayList<String>();

		@Override
		public Object doWith(MainClass mainClass) {
			this.classNames.add(mainClass.getName());
			return null;
		}

		public List<String> getClassNames() {
			return this.classNames;
		}

	}

}
",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      long p = sc.nextLong();
      int q = sc.nextInt();

      System.out.println(solve(p, q));
    }

    sc.close();
  }

  static long solve(long p, int q) {
    if (p % q != 0) {
      return p;
    }

    long result = 0;
    for (int i = 2; i * i <= q; ++i) {
      if (q % i == 0) {
        int exponent = 0;
        while (q % i == 0) {
          ++exponent;
          q /= i;
        }

        long x = p;
        while (x % i == 0) {
          x /= i;
        }
        for (int j = 0; j < exponent - 1; ++j) {
          x *= i;
        }
        result = Math.max(result, x);
      }
    }
    if (q != 1) {
      long x = p;
      while (x % q == 0) {
        x /= q;
      }

      result = Math.max(result, x);
    }

    return result;
  }
}",java
"import java.util.Arrays;
import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a) ? ""YES"" : ""NO"");
    }

    sc.close();
  }

  static boolean solve(int[] a) {
    int[] sorted = Arrays.stream(a).boxed().sorted().mapToInt(x -> x).toArray();

    return (a.length == 1 && sorted[0] == 1)
        || (a.length != 1 && sorted[sorted.length - 1] - sorted[sorted.length - 2] <= 1);
  }
}",java
"/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package org.hightail.ui;

import java.awt.Frame;
import java.awt.event.ActionEvent;
import java.awt.event.KeyEvent;
import javax.swing.AbstractAction;
import javax.swing.JComponent;
import javax.swing.KeyStroke;
import javax.swing.table.DefaultTableModel;
import org.hightail.Config;
import org.hightail.KeyboardShortcuts;

/**
 *
 * @author krig
 */
public class ShortcutsJDialog extends javax.swing.JDialog {

    /**
     * Creates new form ShortcutsJDialog
     */
    public ShortcutsJDialog(java.awt.Frame parent) {
        super(parent, true); // makes it modal
        initComponents();
        
        setLocationRelativeTo(parent);
        
        makeShortcuts();
        
        fillTable();
    }

    /**
     * This method is called from within the constructor to initialize the form.
     * WARNING: Do NOT modify this code. The content of this method is always
     * regenerated by the Form Editor.
     */
    @SuppressWarnings(""unchecked"")
    // <editor-fold defaultstate=""collapsed"" desc=""Generated Code"">//GEN-BEGIN:initComponents
    private void initComponents() {

        jScrollPane1 = new javax.swing.JScrollPane();
        shortcutsTable = new javax.swing.JTable();
        closeButton = new javax.swing.JButton();
        jLabel1 = new javax.swing.JLabel();
        jLabel2 = new javax.swing.JLabel();

        setDefaultCloseOperation(javax.swing.WindowConstants.DISPOSE_ON_CLOSE);
        setTitle(""Shortcuts"");

        shortcutsTable.setModel(new javax.swing.table.DefaultTableModel(
            new Object [][] {

            },
            new String [] {
                ""Action"", ""Shorcut""
            }
        ) {
            Class[] types = new Class [] {
                java.lang.Object.class, java.lang.String.class
            };
            boolean[] canEdit = new boolean [] {
                false, false
            };

            public Class getColumnClass(int columnIndex) {
                return types [columnIndex];
            }

            public boolean isCellEditable(int rowIndex, int columnIndex) {
                return canEdit [columnIndex];
            }
        });
        shortcutsTable.getTableHeader().setReorderingAllowed(false);
        shortcutsTable.addMouseListener(new java.awt.event.MouseAdapter() {
            public void mouseClicked(java.awt.event.MouseEvent evt) {
                shortcutsTableMouseClicked(evt);
            }
        });
        jScrollPane1.setViewportView(shortcutsTable);
        shortcutsTable.getColumnModel().getColumn(0).setResizable(false);
        shortcutsTable.getColumnModel().getColumn(1).setResizable(false);

        closeButton.setText(""Close"");
        closeButton.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                closeButtonActionPerformed(evt);
            }
        });

        jLabel1.setText(""doubleclick to change"");

        jLabel2.setText(""changes take effect after restart"");

        javax.swing.GroupLayout layout = new javax.swing.GroupLayout(getContentPane());
        getContentPane().setLayout(layout);
        layout.setHorizontalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(layout.createSequentialGroup()
                .addContainerGap()
                .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addComponent(jScrollPane1, javax.swing.GroupLayout.PREFERRED_SIZE, 0, Short.MAX_VALUE)
                    .addGroup(javax.swing.GroupLayout.Alignment.TRAILING, layout.createSequentialGroup()
                        .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                            .addGroup(layout.createSequentialGroup()
                                .addComponent(jLabel1)
                                .addGap(0, 0, Short.MAX_VALUE))
                            .addComponent(jLabel2, javax.swing.GroupLayout.DEFAULT_SIZE, 260, Short.MAX_VALUE))
                        .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED)
                        .addComponent(closeButton)))
                .addContainerGap())
        );
        layout.setVerticalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(layout.createSequentialGroup()
                .addContainerGap()
                .addComponent(jScrollPane1, javax.swing.GroupLayout.PREFERRED_SIZE, 171, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED)
                .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addGroup(layout.createSequentialGroup()
                        .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED, 1, Short.MAX_VALUE)
                        .addComponent(closeButton)
                        .addContainerGap())
                    .addGroup(layout.createSequentialGroup()
                        .addComponent(jLabel1)
                        .addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                        .addComponent(jLabel2))))
        );

        pack();
    }// </editor-fold>//GEN-END:initComponents

    private void closeButtonActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_closeButtonActionPerformed
        dispose();
    }//GEN-LAST:event_closeButtonActionPerformed

    private void editShortcut() {
        int selectedRow = shortcutsTable.getSelectedRow();
        if (selectedRow == -1) {
            return;
        }
        KeyboardShortcuts shortcut = (KeyboardShortcuts) shortcutsTable.getValueAt(selectedRow, 0);
        new EditShortcutJDialog((Frame) getParent(), shortcut).setVisible(true);
        shortcutsTable.setValueAt(shortcut.getCode().replace(' ', '+'), selectedRow, 1);
    }
    
    private void shortcutsTableMouseClicked(java.awt.event.MouseEvent evt) {//GEN-FIRST:event_shortcutsTableMouseClicked
        if (evt.getClickCount() == 2) {
            editShortcut();
        }
    }//GEN-LAST:event_shortcutsTableMouseClicked

    private void makeShortcuts() {
        // escape key will close the dialog
        getRootPane().getInputMap(JComponent.WHEN_ANCESTOR_OF_FOCUSED_COMPONENT).put(KeyStroke.getKeyStroke(KeyEvent.VK_ESCAPE, 0), ""close"");
        getRootPane().getActionMap().put(""close"", new AbstractAction() {
            @Override
            public void actionPerformed(ActionEvent e) {
                dispose();
            }
        });
    }
    
    private void fillTable() {
        DefaultTableModel model = (DefaultTableModel) shortcutsTable.getModel();
        for (KeyboardShortcuts shortcut : KeyboardShortcuts.values()) {
            model.addRow(new Object[]{
                shortcut,
                Config.get(""shortcut "" + shortcut.getAction(), shortcut.getCode()).replace(' ', '+'),
            });
        }
    }
    
    // Variables declaration - do not modify//GEN-BEGIN:variables
    private javax.swing.JButton closeButton;
    private javax.swing.JLabel jLabel1;
    private javax.swing.JLabel jLabel2;
    private javax.swing.JScrollPane jScrollPane1;
    private javax.swing.JTable shortcutsTable;
    // End of variables declaration//GEN-END:variables
}
",java
"import java.util.Arrays;
import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int B = sc.nextInt();
      int x = sc.nextInt();
      int y = sc.nextInt();

      System.out.println(solve(n, B, x, y));
    }

    sc.close();
  }

  static long solve(int n, int B, int x, int y) {
    int[] a = new int[n + 1];
    for (int i = 1; i < a.length; ++i) {
      if (a[i - 1] + x <= B) {
        a[i] = a[i - 1] + x;
      } else {
        a[i] = a[i - 1] - y;
      }
    }

    return Arrays.stream(a).asLongStream().sum();
  }
}",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      sc.nextInt();
      String s = sc.next();

      System.out.println(solve(s));
    }

    sc.close();
  }

  static String solve(String s) {
    int operationNum = 0;
    int beginIndex = 0;
    int depth = 0;
    for (int i = 0; i < s.length(); ++i) {
      char c = s.charAt(i);
      if (c == '(') {
        ++depth;
      } else {
        --depth;
      }

      if ((depth == 0 && s.charAt(beginIndex) == '(')
          || (s.startsWith("")("", beginIndex) && c == ')' && i != beginIndex)
          || (i == beginIndex + 1 && s.charAt(i) == s.charAt(beginIndex))) {
        ++operationNum;
        beginIndex = i + 1;
        depth = 0;
      }
    }

    return String.format(""%d %d"", operationNum, s.length() - beginIndex);
  }
}",java
"import java.util.HashMap;
import java.util.Map;
import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    String s1 = sc.nextLine();
    String s2 = sc.nextLine();

    System.out.println(solve(s1, s2) ? ""YES"" : ""NO"");

    sc.close();
  }

  static boolean solve(String s1, String s2) {
    Map<Character, Integer> letterToCount1 = buildLetterToCount(s1);
    Map<Character, Integer> letterToCount2 = buildLetterToCount(s2);

    return letterToCount2.keySet().stream()
        .allMatch(
            letter2 -> letterToCount2.get(letter2) <= letterToCount1.getOrDefault(letter2, 0));
  }

  static Map<Character, Integer> buildLetterToCount(String s) {
    Map<Character, Integer> letterToCount = new HashMap<>();
    for (char c : s.toCharArray()) {
      if (c != ' ') {
        letterToCount.put(c, letterToCount.getOrDefault(c, 0) + 1);
      }
    }

    return letterToCount;
  }
}",java
"import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Scanner;

public class Main {
  static final int ALPHABET_SIZE = 26;

  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      String s = sc.next();

      System.out.println(solve(s));
    }

    sc.close();
  }

  static int solve(String s) {
    @SuppressWarnings(""unchecked"")
    List<Integer>[] indexLists = new List[ALPHABET_SIZE];
    for (int i = 0; i < indexLists.length; ++i) {
      indexLists[i] = new ArrayList<>();
    }

    int[] keepNums = new int[s.length() + 1];
    for (int i = 0; i < s.length(); ++i) {
      keepNums[i + 1] = keepNums[i];

      List<Integer> indexList = indexLists[s.charAt(i) - 'a'];
      indexList.add(i);
      if (indexList.size() >= 2) {
        keepNums[i + 1] =
            Math.max(keepNums[i + 1], keepNums[indexList.get(indexList.size() - 2)] + 2);
      }
    }

    return s.length() - Arrays.stream(keepNums).max().getAsInt();
  }
}",java
"import java.util.Scanner;
import java.util.stream.IntStream;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }
      int[] b = new int[n];
      for (int i = 0; i < b.length; ++i) {
        b[i] = sc.nextInt();
      }

      System.out.println(solve(a, b));
    }

    sc.close();
  }

  static long solve(int[] a, int[] b) {
    return IntStream.range(0, a.length - 1)
        .map(
            i ->
                Math.min(
                    Math.abs(a[i] - a[i + 1]) + Math.abs(b[i] - b[i + 1]),
                    Math.abs(a[i] - b[i + 1]) + Math.abs(b[i] - a[i + 1])))
        .asLongStream()
        .sum();
  }
}",java
"package fr.unice.polytech.isa.resort.integration;

import fr.unice.polytech.isa.accounts.components.CardRegistryBean;
import fr.unice.polytech.isa.accounts.components.CustomerLinkerBean;
import fr.unice.polytech.isa.accounts.components.CustomerRegistryBean;
import fr.unice.polytech.isa.accounts.components.PassRegistryBean;
import fr.unice.polytech.isa.accounts.exceptions.CardNotFoundException;
import fr.unice.polytech.isa.accounts.exceptions.CustomerNotFoundException;
import fr.unice.polytech.isa.accounts.interfaces.*;
import fr.unice.polytech.isa.common.entities.accounts.Customer;
import fr.unice.polytech.isa.common.entities.shopping.catalog.ItemCatalog;
import fr.unice.polytech.isa.common.entities.shopping.catalog.ItemType;
import fr.unice.polytech.isa.common.entities.items.ItemTypeName;
import fr.unice.polytech.isa.common.entities.items.SuperCartex;
import fr.unice.polytech.isa.common.exceptions.*;
import fr.unice.polytech.isa.notifications.components.NotificationProcessorBean;
import fr.unice.polytech.isa.notifications.components.NotificationRegistryBean;
import fr.unice.polytech.isa.notifications.components.NotificationSchedulerBean;
import fr.unice.polytech.isa.notifications.interfaces.NotificationProcessing;
import fr.unice.polytech.isa.notifications.interfaces.NotificationRegistration;
import fr.unice.polytech.isa.notifications.interfaces.NotificationScheduling;
import fr.unice.polytech.isa.payment.components.BillingBean;
import fr.unice.polytech.isa.payment.interfaces.PaymentProcessor;
import fr.unice.polytech.isa.resort.components.*;
import fr.unice.polytech.isa.resort.exceptions.ResortNotFoundException;
import fr.unice.polytech.isa.resort.exceptions.SkiLiftNotFoundException;
import fr.unice.polytech.isa.resort.exceptions.SkiTrailNotFoundException;
import fr.unice.polytech.isa.resort.exceptions.UnavailableNameException;
import fr.unice.polytech.isa.resort.interfaces.*;
import fr.unice.polytech.isa.shopping.components.CartManagerBean;
import fr.unice.polytech.isa.shopping.components.CatalogBean;
import fr.unice.polytech.isa.shopping.components.DiscountBean;
import fr.unice.polytech.isa.shopping.interfaces.*;
import fr.unice.polytech.isa.statistics.components.presence.PresenceStatisticsFindingBean;
import fr.unice.polytech.isa.statistics.components.presence.PresenceStatisticsRegistryBean;
import fr.unice.polytech.isa.statistics.components.presence.PresenceStatisticsUpdateBean;
import fr.unice.polytech.isa.statistics.interceptors.CardCounter;
import fr.unice.polytech.isa.statistics.interfaces.presence.PresenceStatisticsFinder;
import fr.unice.polytech.isa.statistics.interfaces.presence.PresenceStatisticsRegistration;
import fr.unice.polytech.isa.statistics.interfaces.presence.PresenceStatisticsUpdater;
import org.jboss.arquillian.container.test.api.Deployment;
import org.jboss.arquillian.junit.Arquillian;
import org.jboss.arquillian.transaction.api.annotation.TransactionMode;
import org.jboss.arquillian.transaction.api.annotation.Transactional;
import org.jboss.shrinkwrap.api.ShrinkWrap;
import org.jboss.shrinkwrap.api.asset.ClassLoaderAsset;
import org.jboss.shrinkwrap.api.spec.JavaArchive;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;

import javax.ejb.EJB;
import javax.inject.Inject;
import javax.persistence.EntityManager;
import javax.persistence.PersistenceContext;
import javax.transaction.UserTransaction;
import java.time.LocalDateTime;

import static fr.unice.polytech.isa.resort.ResortTestUtil.*;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

@RunWith(Arquillian.class)
@Transactional(TransactionMode.COMMIT)
public class SuperCartexIntegrationTest {
    @EJB
    private CreditCardRegistration creditCardRegistration;

    @EJB
    private CatalogModifier catalogModifier;

    @EJB
    private CatalogExplorer catalogExplorer;

    @EJB
    private SuperCartexProcessor superCartexProcessor;

    @EJB
    private CardRegistration cardRegistration;

    @EJB
    private CardFinder cardFinder;

    @EJB
    private CardChecker cardChecker;

    @EJB
    private ResortRegister resortRegister;

    @EJB
    private ResortFinder resortFinder;

    @EJB
    private SkiLiftRegister skiLiftRegister;

    @EJB
    private SkiLiftFinder skiLiftFinder;

    @PersistenceContext private EntityManager entityManager;
    @Inject
    private UserTransaction utx;
    private Customer marcel_account;
    private String resortId;

    @Deployment
    public static JavaArchive createDeployment() {
        return ShrinkWrap.create(JavaArchive.class)
            //Add this server's classes
            .addClass(AccessControllerBean.class)
            .addClass(AccessRegisterBean.class)
            .addClass(ResortRegistryBean.class)
            .addClass(SkiLiftRegistryBean.class)
            .addClass(SkiTrailRegistryBean.class)
            .addClass(ResortNotFoundException.class)
            .addClass(SkiLiftNotFoundException.class)
            .addClass(SkiTrailNotFoundException.class)
            .addClass(UnavailableNameException.class)
            .addClass(AccessRegister.class)
            .addClass(CardChecker.class)
            .addClass(ResortFinder.class)
            .addClass(ResortRegister.class)
            .addClass(SkiLiftFinder.class)
            .addClass(SkiLiftRegister.class)
            .addClass(SkiTrailFinder.class)
            .addClass(SkiTrailRegister.class)
            //Account server's classes
            .addClass(CustomerRegistration.class)
            .addClass(CustomerRegistryBean.class)
            .addClass(CardRegistration.class)
            .addClass(CardFinder.class)
            .addClass(CardRegistryBean.class)
            .addClass(PassRegistration.class)
            .addClass(CustomerPassFinder.class)
            .addClass(PassRegistryBean.class)
            .addClass(CustomerCardLinker.class)
            .addClass(CustomerLinkerBean.class)
            //Shopping server's classes
            .addClass(CatalogModifier.class)
            .addClass(CatalogBean.class)
            .addClass(SuperCartexProcessor.class)
            .addClass(CartManagerBean.class)
            .addClass(SuperCartexDiscount.class)
            .addClass(DiscountBean.class)
            //Payment server's classes
            .addClass(PaymentProcessor.class)
            .addClass(BillingBean.class)
            //Statistics server's classes
            .addClass(CardCounter.class)
            .addClass(PresenceStatisticsUpdater.class)
            .addClass(PresenceStatisticsUpdateBean.class)
            .addClass(PresenceStatisticsFinder.class)
            .addClass(PresenceStatisticsFindingBean.class)
            .addClass(PresenceStatisticsRegistration.class)
            .addClass(PresenceStatisticsRegistryBean.class)
            //Add the notification server's classes
            .addClass(NotificationRegistration.class)
            .addClass(NotificationRegistryBean.class)
            .addClass(NotificationScheduling.class)
            .addClass(NotificationSchedulerBean.class)
            .addClass(NotificationProcessing.class)
            .addClass(NotificationProcessorBean.class)
            //Persistence manifest
            .addAsManifestResource(new ClassLoaderAsset(""META-INF/persistence.xml""), ""persistence.xml"");
    }

    @Before
    public void setUpContext() throws ItemAlreadyExistException, UnavailableNameException, ResortNotFoundException {
        marcel_account = new Customer(MARCEL_FIRSTNAME, MARCEL_LASTNAME, MARCEL_EMAIL);
        resortRegister.registerResort(RESORT_NAME, RESORT_EMAIL, OPEN, RESORT_CITY_NAME);
        resortId = resortFinder.findByName(RESORT_NAME).getId();
        skiLiftRegister.registerSkiLift(resortId, SKI_LIFT_NAME, OPEN);
        entityManager.persist(marcel_account);
        initCatalog();
    }

    public void initCatalog() throws ItemAlreadyExistException {
        catalogModifier.addCard(SUPER_CARTEX, SUPERCARTEX_CARD, PRICE_10, PUBLIC_ITEM);
        catalogModifier.addPass(SUPER_ORIGINAL_PASS, PRICE_10, PRICE_10, DAYS_1, PRIVATE_ITEM);
        catalogModifier.addPass(SUPER_FREE_HOUR_PASS, PRICE_0, PRICE_0, HOURS_1, PRIVATE_ITEM);
        catalogModifier.addPass(SUPER_FREE_EIGHTH, PRICE_0, PRICE_0, DAYS_1, PRIVATE_ITEM);
    }


    @Test
    public void checkSuperCartex() throws CustomerNotFoundException, PaymentException, PassNotFoundException, NoCreditCardException, CardNotFoundException, EmptyCartException, UnknownCatalogEntryException, NullQuantityException, ResortNotFoundException, SkiLiftNotFoundException {
        cardRegistration.addCard(MARCEL_EMAIL, new ItemType(SUPER_CARTEX, PRICE_10, ItemTypeName.SUPERCARTEX));
        SuperCartex superCartex = (SuperCartex) cardFinder.findSuperCartexCards().get(0);
        assertTrue(cardChecker.checkCard(skiLiftFinder.findByName(resortId, SKI_LIFT_NAME), superCartex)); //first hour
        assertEquals(SUPER_FREE_HOUR_PASS, superCartex.getPass().getType().getName());
        creditCardRegistration.creditCardRegistry(marcel_account, MARCEL_LASTNAME, CREDIT_CARD_NO, CVV, EXPIRY_DATE, SAVE);
        assertTrue(superCartexProcessor.processSuperCartex(superCartex)); //pay original pass
        assertEquals(SUPER_ORIGINAL_PASS, superCartex.getPass().getType().getName());
        superCartex.setFirstSwipe(LocalDateTime.now().minusDays(7));
        assertTrue(superCartexProcessor.processSuperCartex(superCartex)); //free eighth day pass
        assertEquals(SUPER_FREE_EIGHTH, superCartex.getPass().getType().getName());

    }

    @After
    public void cleaningUp() throws Exception {
        utx.begin();
        marcel_account = entityManager.merge(marcel_account);
        entityManager.remove(marcel_account);
        for (ItemCatalog c : catalogExplorer.displayCatalog()){
            ItemCatalog item  = entityManager.merge(c);
            entityManager.remove(item);
        }
        for (ItemCatalog c : catalogExplorer.displayPrivateCatalog()){
            ItemCatalog item  = entityManager.merge(c);
            entityManager.remove(item);
        }
        entityManager.remove(resortFinder.findById(resortId));
        marcel_account = null;
        utx.commit();
    }
}
",java
"/*
 * Copyright (C) 2008-2010 by Holger Arndt
 *
 * This file is part of the Universal Java Matrix Package (UJMP).
 * See the NOTICE file distributed with this work for additional
 * information regarding copyright ownership and licensing.
 *
 * UJMP is free software; you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as
 * published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * UJMP is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with UJMP; if not, write to the
 * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
 * Boston, MA  02110-1301  USA
 */

package org.ujmp.core.util.matrices;

import java.util.ArrayList;
import java.util.List;

import org.ujmp.core.Matrix;
import org.ujmp.core.MatrixFactory;
import org.ujmp.core.enums.ValueType;
import org.ujmp.core.stringmatrix.stub.AbstractDenseStringMatrix2D;
import org.ujmp.core.util.AbstractPlugin;

public class UJMPPluginsMatrix extends AbstractDenseStringMatrix2D {
	private static final long serialVersionUID = 9076856922668700140L;

	private final List<String> classes = new ArrayList<String>();

	private Matrix matrix = null;

	public UJMPPluginsMatrix() {
		addClass(""ujmp-core"");
		addClass(""ujmp-gui"");
		addClass(""ujmp-colt"");
		addClass(""ujmp-commonsmath"");
		addClass(""ujmp-ehcache"");
		addClass(""ujmp-ejml"");
		addClass(""ujmp-hadoop"");
		addClass(""ujmp-itext"");
		addClass(""ujmp-jackcess"");
		addClass(""ujmp-jama"");
		addClass(""ujmp-jampack"");
		addClass(""ujmp-jblas"");
		addClass(""ujmp-jbpcafill"");
		addClass(""ujmp-jlinalg"");
		addClass(""ujmp-jdbc"");
		addClass(""ujmp-jexcelapi"");
		addClass(""ujmp-jfreechart"");
		addClass(""ujmp-jmatharray"");
		addClass(""ujmp-jmathplot"");
		addClass(""ujmp-jmatio"");
		addClass(""ujmp-jmatrices"");
		addClass(""ujmp-jsci"");
		addClass(""ujmp-jscience"");
		addClass(""ujmp-jung"");
		addClass(""ujmp-lsimpute"");
		addClass(""ujmp-lucene"");
		addClass(""ujmp-mail"");
		addClass(""ujmp-mantissa"");
		addClass(""ujmp-mtj"");
		addClass(""ujmp-ojalgo"");
		addClass(""ujmp-orbital"");
		addClass(""ujmp-owlpack"");
		addClass(""ujmp-parallelcolt"");
		addClass(""ujmp-pdfbox"");
		addClass(""ujmp-sst"");
		addClass(""ujmp-vecmath"");
		refresh();
		setLabel(""UJMP Plugins"");
		setColumnLabel(0, ""Name"");
		setColumnLabel(1, ""Available"");
		setColumnLabel(2, ""Description"");
		setColumnLabel(3, ""Dependencies"");
		setColumnLabel(4, ""Status"");
	}

	public void refresh() {
		matrix = MatrixFactory.dense(ValueType.STRING, classes.size(), 5);

		int r = 0;

		for (String s : classes) {

			matrix.setAsString(s, r, 0);

			Class<?> cl = null;
			if (s.startsWith(""ujmp"")) {
				try {
					cl = Class.forName(""org.ujmp."" + s.substring(5) + "".Plugin"");
				} catch (ClassNotFoundException e) {
				}
			} else {
				try {
					cl = Class.forName(""org.jdmp."" + s.substring(5) + "".Plugin"");
				} catch (ClassNotFoundException e) {
				}
			}

			AbstractPlugin o = null;
			if (cl != null) {
				try {
					o = (AbstractPlugin) cl.newInstance();
				} catch (Exception e) {
				}
			}

			if (o != null) {
				try {
					matrix.setAsString(""yes"", r, 1);
					matrix.setAsString(o.getDescription(), r, 2);
					matrix.setAsString("""" + o.getDependencies(), r, 3);
					matrix.setAsString(o.getStatus(), r, 4);
				} catch (Throwable t) {
					matrix.setAsString(""no"", r, 1);
					matrix.setAsString(""n/a"", r, 2);
					matrix.setAsString(""n/a"", r, 3);
					matrix.setAsString(t.getMessage(), r, 4);
				}
			} else {
				matrix.setAsString(""no"", r, 1);
				matrix.setAsString(""n/a"", r, 2);
				matrix.setAsString(""n/a"", r, 3);
				matrix.setAsString(""n/a"", r, 4);
			}

			r++;

		}
	}

	protected void addClass(String c) {
		classes.add(c);
	}

	public String getString(long row, long column) {
		return matrix.getAsString(row, column);
	}

	public void setString(String value, long row, long column) {
	}

	public long[] getSize() {
		return matrix.getSize();
	}

}
",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int x = sc.nextInt();
      int y = sc.nextInt();

      System.out.println(solve(x, y));
    }

    sc.close();
  }

  static int solve(int x, int y) {
    if (x == 0 && y == 0) {
      return 0;
    }

    return isSquare(x * x + y * y) ? 1 : 2;
  }

  static boolean isSquare(int a) {
    int root = (int) Math.round(Math.sqrt(a));

    return root * root == a;
  }
}",java
"/*******************************************************************************
 * Copyright (c) 2006 - 2011 SJRJ.
 * 
 *     This file is part of SIGA.
 * 
 *     SIGA is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU General Public License as published by
 *     the Free Software Foundation, either version 3 of the License, or
 *     (at your option) any later version.
 * 
 *     SIGA is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU General Public License for more details.
 * 
 *     You should have received a copy of the GNU General Public License
 *     along with SIGA.  If not, see <http://www.gnu.org/licenses/>.
 ******************************************************************************/
package br.gov.jfrj.siga.ex.util;

import java.io.File;
import java.io.OutputStreamWriter;
import java.io.Writer;
import java.util.HashMap;
import java.util.Map;
import java.util.TreeMap;

import junit.framework.TestCase;
import br.gov.jfrj.siga.cp.CpPapel;
import br.gov.jfrj.siga.dp.CpOrgaoUsuario;
import br.gov.jfrj.siga.dp.DpCargo;
import br.gov.jfrj.siga.dp.DpFuncaoConfianca;
import br.gov.jfrj.siga.dp.DpLotacao;
import br.gov.jfrj.siga.dp.DpPessoa;
import br.gov.jfrj.siga.ex.ExDocumento;
import br.gov.jfrj.siga.ex.ExMovimentacao;
import br.gov.jfrj.siga.ex.util.FuncoesEL;
import br.gov.jfrj.siga.ex.util.ProcessadorModeloFreemarker;
import br.gov.jfrj.siga.hibernate.ExDao;
import br.gov.jfrj.siga.model.Diagram;
import freemarker.template.Configuration;
import freemarker.template.DefaultObjectWrapper;
import freemarker.template.Template;

public class ModeloTest extends TestCase {

	private Configuration cfg;

	public ModeloTest() throws Exception {
		cfg = new Configuration();
		String s = cfg.getVersionNumber();
		// Specify the data source where the template files come from.
		// Here I set a file directory for it:
		cfg.setDirectoryForTemplateLoading(new File(
				""src/main/resources/br/gov/jfrj/siga/ex/util/test""));
		// Specify how templates will see the data-model. This is an
		// advanced
		// topic...
		// but just use this:
		cfg.setObjectWrapper(new DefaultObjectWrapper());
		cfg.setWhitespaceStripping(true);
	}

	public void testGeraModelo() throws Exception {
		if (true)
			return;
		ProcessadorModeloFreemarker p = new ProcessadorModeloFreemarker();

		Map<String, Object> attrs = new TreeMap<String, Object>();
		Map<String, Object> params = new TreeMap<String, Object>();

		ExDocumento doc = new ExDocumento();
		doc.setOrgaoUsuario(ExDao.getInstance().consultar(1L,
				CpOrgaoUsuario.class, false));
		ExMovimentacao mov = new ExMovimentacao();
		attrs.put(""doc"", doc);
		attrs.put(""mov"", mov);
		attrs.put(""mob"", mov.getExMobil());
		attrs.put(""template"", ""teste freemarker: ${param.doc!}."");

		params.put(""processar_modelo"", ""1"");
		if (doc != null && doc.getIdDoc() != null)
			params.put(""idDoc"", doc.getIdDoc().toString());
		if (mov != null && mov.getIdMov() != null) {
			params.put(""id"", mov.getIdMov().toString());
		}

		String s = p.processarModelo(doc.getOrgaoUsuario(), attrs, params);
		System.out.println(s);
	}

	public void testGeraModeloAntigo() throws Exception {
		if (true)
			return;
		// Create the root hash
		Map root = new HashMap();
		Map param = new HashMap();
		root.put(""root"", root);
		root.put(""param"", param);
		root.put(""entrevista"", false);
		root.put(""formulario"", true);
		root.put(""documento"", false);
		root.put(""assinatura"", false);
		root.put(""finalizacao"", false);
		root.put(""func"", new FuncoesEL());

		Template temp = cfg.getTemplate(""memorando.ftl"");

		try (Writer out = new OutputStreamWriter(System.out)) {
			temp.process(root, out);
			out.flush();
		}
	}

	public void testGeraDesenhoCp() throws Exception {
		Diagram d = new Diagram();
		d.setfMergeWithAbstractClass(true);
		boolean fI = true;

		d.addClass(DpPessoa.class, fI);
		d.addClass(DpLotacao.class, fI);
		d.addClass(DpFuncaoConfianca.class, fI);
		d.addClass(DpCargo.class, fI);
		d.addClass(CpPapel.class, fI);
		d.addClass(CpOrgaoUsuario.class, fI);

		d.addClass(br.gov.jfrj.siga.dp.CpOrgao.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.DpSubstituicao.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpFeriado.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpOcorrenciaFeriado.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpAplicacaoFeriado.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpLocalidade.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpUF.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpPersonalizacao.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpConfiguracao.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpServico.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoGrupo.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpGrupo.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpTipoLotacao.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoPapel.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpPapel.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoServico.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoIdentidade.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpIdentidade.class, fI);

		d.createGraphML(""target/siga.graphml"", true, false);
	}

	public void testGeraDesenhoEx() throws Exception {
		Diagram d = new Diagram();
		d.setfMergeWithAbstractClass(true);
		boolean fI = true;

		d.addClass(DpPessoa.class, fI);
		d.addClass(DpLotacao.class, fI);
		d.addClass(DpFuncaoConfianca.class, fI);
		d.addClass(DpCargo.class, fI);
		d.addClass(CpPapel.class, fI);
		d.addClass(CpOrgaoUsuario.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpOrgao.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.DpSubstituicao.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpFeriado.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpOcorrenciaFeriado.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpAplicacaoFeriado.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpLocalidade.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpUF.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpPersonalizacao.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpConfiguracao.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpServico.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoGrupo.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpGrupo.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpTipoLotacao.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoPapel.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpPapel.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoServico.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpTipoIdentidade.class, fI);
		d.addClass(br.gov.jfrj.siga.cp.CpIdentidade.class, fI);

		d.addClass(br.gov.jfrj.siga.ex.ExMobil.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExDocumento.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExFormaDocumento.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExConfiguracao.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExClassificacao.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExModelo.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTemporalidade.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTipoDespacho.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTipoDestinacao.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTipoDocumento.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExNivelAcesso.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExEstadoDoc.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExPreenchimento.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTipoFormaDoc.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExVia.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExMovimentacao.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTpDocPublicacao.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExTipoMobil.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.BIE.ExBoletimDoc.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExPapel.class, fI);
		d.addClass(br.gov.jfrj.siga.ex.ExEmailNotificacao.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpMarcador.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpTipoMarca.class, fI);

		d.addClass(br.gov.jfrj.siga.ex.ExMarca.class, fI);
		d.addClass(br.gov.jfrj.siga.dp.CpMarca.class, fI);

		d.createGraphML(""target/siga-ex.graphml"", false, false);
	}

}
",java
"package org.hightail.ui;

import java.awt.Component;
import java.awt.Toolkit;
import java.awt.event.ActionEvent;
import java.awt.event.ActionListener;
import java.awt.event.MouseAdapter;
import java.awt.event.MouseEvent;
import java.io.IOException;
import java.util.ArrayList;
import javax.swing.JComponent;
import javax.swing.JMenuItem;
import javax.swing.JOptionPane;
import javax.swing.JPopupMenu;
import javax.swing.KeyStroke;
import javax.swing.UIManager;
import org.hightail.Config;
import org.hightail.server.HTTPServer;
import org.hightail.Problem;
import org.hightail.util.AbstractActionWithInteger;

// button-green.png icon comes from http://openiconlibrary.sourceforge.net/gallery2/?./Icons/others/button-green.png

public class MainJFrame extends javax.swing.JFrame {
    private HTTPServer httpServer;
    
    @SuppressWarnings(""LeakingThisInConstructor"")
    public MainJFrame() {
        initComponents();
        
        makeShortcuts();
        
        //Set the system proxy if there is one
        try {
            System.setProperty(""java.net.useSystemProxies"", ""true"");
        }
        finally {
        }
        
        // We load the configuration
        boolean ok = Config.load();
        if (!ok) { // couldn't load
            JOptionPane.showMessageDialog(this,
                      ""If you're a new user, welcome!\n""
                    + ""Hightail uses a config file, which resides in the same directory as the .jar file.\n""
                    + ""This config file could not be loaded (probably this is the first run of Hightail).\n""
                    + ""A new one will be created now and you will be taken to settings.\n""
                    + ""\n""
                    + ""Wish you high rating!"",
                    ""Hightail"",
                    JOptionPane.INFORMATION_MESSAGE);
            try {
                Config.save();
            } catch (IOException e2) {
                JOptionPane.showMessageDialog(this,
                        ""The configuration file could not be created. Make sure Hightail has write rights to its directory."",
                        ""Output error"",
                        JOptionPane.ERROR_MESSAGE);
                System.exit(0);
            }
            // show them the config dialog
            new ConfigJDialog(this).setVisible(true);
        }
        
        addPopupMenu();

        // on the first run of a version with this feature,
        // inform the user about the Competitive Companion browser extension
        // (in particular, that the Windows Firewall is going to complain)
        if (!Config.containsKey(""userInformedOfCompetitiveCompanionAndFirewall"")) {
            JOptionPane.showMessageDialog(this,
                    ""Hightail now supports Competitive Companion - a browser plugin\n""
                  + ""that parses problems and contests directly from the browser via a single click.\n""
                  + ""Competitive Companion supports a wide variety of online judges and contests\n""
                  + ""(more than the built-in parsers of Hightail - e.g. Google Code Jam, Facebook Hacker Cup, ...).\n""
                  + ""Try it! (Find the link in Help->About, or google for Competitive Companion.)\n""
                  + ""\n""
                  + ""(Due to this, Hightail now runs a local HTTP server on port "" + HTTPServer.PORT + "".)\n""
                  + ""\n""
                  + ""\n""
                  + ""(You are receiving this message because either this the first run of Hightail,\n""
                  + ""or you updated from a version that did not have this feature.)"",
                    ""Competitive Companion support is new in this release"",
                    JOptionPane.INFORMATION_MESSAGE);
            Config.set(""userInformedOfCompetitiveCompanionAndFirewall"", ""1"");
            try {
                Config.save();
            } catch (IOException e2) {
                JOptionPane.showMessageDialog(this,
                        ""The configuration file could not be created. Make sure Hightail has write rights to its directory."",
                        ""Output error"",
                        JOptionPane.ERROR_MESSAGE);
                System.exit(0);
            }
        }
        
        httpServer = new HTTPServer();
        httpServer.start(problem -> {
            // Add the problem
            ArrayList<Problem> problems = new ArrayList<>();
            problems.add(problem);
            addProblems(problems);

            // Focus the window
            // toFront() doesn't work on Ubuntu 18.04, but this little workaround does
            boolean currentAlwaysOnTop = this.isAlwaysOnTop();
            this.setAlwaysOnTop(true);
            this.setAlwaysOnTop(currentAlwaysOnTop);
        });
        
        setLocationRelativeTo(null);
    }
    
    /** This method is called from within the constructor to
     * initialize the form.
     * WARNING: Do NOT modify this code. The content of this method is
     * always regenerated by the Form Editor.
     */
    @SuppressWarnings(""unchecked"")
    // <editor-fold defaultstate=""collapsed"" desc=""Generated Code"">//GEN-BEGIN:initComponents
    private void initComponents() {

        tabbedPane = new javax.swing.JTabbedPane();
        menuBar = new javax.swing.JMenuBar();
        fileMenu = new javax.swing.JMenu();
        newFromURL = new javax.swing.JMenuItem();
        newContest = new javax.swing.JMenuItem();
        jSeparator1 = new javax.swing.JPopupMenu.Separator();
        openConfig = new javax.swing.JMenuItem();
        exit = new javax.swing.JMenuItem();
        helpMenu = new javax.swing.JMenu();
        about = new javax.swing.JMenuItem();
        shortcuts = new javax.swing.JMenuItem();

        setDefaultCloseOperation(javax.swing.WindowConstants.DO_NOTHING_ON_CLOSE);
        setTitle(""Hightail"");
        setIconImage(Toolkit.getDefaultToolkit().getImage(getClass().getResource(""resources/button-green.png"")));
        addWindowListener(new java.awt.event.WindowAdapter() {
            public void windowClosing(java.awt.event.WindowEvent evt) {
                formWindowClosing(evt);
            }
        });

        tabbedPane.setTabLayoutPolicy(javax.swing.JTabbedPane.SCROLL_TAB_LAYOUT);
        tabbedPane.setTabPlacement(javax.swing.JTabbedPane.LEFT);
        tabbedPane.setCursor(new java.awt.Cursor(java.awt.Cursor.DEFAULT_CURSOR));
        tabbedPane.setFont(new java.awt.Font(""Tahoma"", 1, 13)); // NOI18N

        fileMenu.setText(""File"");

        newFromURL.setAccelerator(javax.swing.KeyStroke.getKeyStroke(java.awt.event.KeyEvent.VK_N, java.awt.event.InputEvent.CTRL_MASK));
        newFromURL.setText(""New problem..."");
        newFromURL.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                newFromURLActionPerformed(evt);
            }
        });
        fileMenu.add(newFromURL);

        newContest.setAccelerator(javax.swing.KeyStroke.getKeyStroke(java.awt.event.KeyEvent.VK_B, java.awt.event.InputEvent.CTRL_MASK));
        newContest.setText(""New contest..."");
        newContest.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                newContestActionPerformed(evt);
            }
        });
        fileMenu.add(newContest);
        fileMenu.add(jSeparator1);

        openConfig.setText(""Settings..."");
        openConfig.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                openConfigActionPerformed(evt);
            }
        });
        fileMenu.add(openConfig);

        exit.setText(""Exit"");
        exit.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                exitActionPerformed(evt);
            }
        });
        fileMenu.add(exit);

        menuBar.add(fileMenu);

        helpMenu.setText(""Help"");

        about.setText(""About..."");
        about.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                aboutActionPerformed(evt);
            }
        });
        helpMenu.add(about);

        shortcuts.setText(""Shortcuts"");
        shortcuts.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                shortcutsActionPerformed(evt);
            }
        });
        helpMenu.add(shortcuts);

        menuBar.add(helpMenu);

        setJMenuBar(menuBar);

        javax.swing.GroupLayout layout = new javax.swing.GroupLayout(getContentPane());
        getContentPane().setLayout(layout);
        layout.setHorizontalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addComponent(tabbedPane, javax.swing.GroupLayout.DEFAULT_SIZE, 970, Short.MAX_VALUE)
        );
        layout.setVerticalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addComponent(tabbedPane, javax.swing.GroupLayout.DEFAULT_SIZE, 606, Short.MAX_VALUE)
        );

        pack();
    }// </editor-fold>//GEN-END:initComponents
    
    private void addPopupMenu() {
        // adds popup menu to tabs with option to delete a tab
        final JPopupMenu singleTabJPopupMenu = new JPopupMenu();
        JMenuItem deleteJMenuItem = new JMenuItem(""Delete"");
        deleteJMenuItem.addActionListener(new ActionListener() {
            @Override
            public void actionPerformed(ActionEvent e) {
                tabbedPane.remove(tabbedPane.getSelectedComponent());
            }
        });
        singleTabJPopupMenu.add(deleteJMenuItem);
        tabbedPane.addMouseListener(new MouseAdapter() {
            @Override
            public void mousePressed(MouseEvent e) {
                if (e.isPopupTrigger()) {
                    doPop(e);
                }
            }
            
            @Override
            public void mouseReleased(MouseEvent e) {
                if (e.isPopupTrigger()) {
                    doPop(e);
                }
            }
            
            private void doPop(MouseEvent e) {
                singleTabJPopupMenu.show(e.getComponent(), e.getX(), e.getY());
            }
        });
    }
    
    private void makeShortcuts() {
        for (int index = 1; index <= 9; index++) {
            tabbedPane.getInputMap(JComponent.WHEN_IN_FOCUSED_WINDOW).put(KeyStroke.getKeyStroke(""alt "" + index), ""switch tab "" + index);
            tabbedPane.getActionMap().put(""switch tab "" + index, new AbstractActionWithInteger(index) {
                @Override
                public void actionPerformed(ActionEvent e) {
                    if (tabbedPane.getTabCount() >= getInteger()) {
                        tabbedPane.setSelectedIndex(getInteger() - 1);
                    }
                }
            });
        }
    }
    
    protected void addTabForProblem(Problem problem) {
        ProblemJPanel panel = new ProblemJPanel(problem, tabbedPane, this);
        // as recommended here: http://stackoverflow.com/questions/476678/tabs-with-equal-constant-width-in-jtabbedpane
        tabbedPane.addTab(""<html><body><table width='150'>"" + problem.getName() + ""</table></body></html>"", panel);
        tabbedPane.setSelectedComponent(panel);
    }
    
    private void confirmAndClose () {
        // Display confirm dialog
        int confirmed = JOptionPane.showConfirmDialog(this,
                ""Are you sure?"",
                ""Confirm quit"",
                JOptionPane.YES_NO_OPTION);
        
        // Close iff user confirmed
        if (confirmed == JOptionPane.YES_OPTION) {
            httpServer.stop();
            this.dispose();
            System.exit(0);
        }
    }
    
    private void formWindowClosing(java.awt.event.WindowEvent evt) {//GEN-FIRST:event_formWindowClosing
        confirmAndClose();
    }//GEN-LAST:event_formWindowClosing
    
    private void exitActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_exitActionPerformed
        confirmAndClose();
    }//GEN-LAST:event_exitActionPerformed
    
    private void openConfigActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_openConfigActionPerformed
        new ConfigJDialog(this).setVisible(true);
    }//GEN-LAST:event_openConfigActionPerformed
    
    public void addProblems(ArrayList<Problem> problems) {
        if (problems == null || problems.isEmpty()) {
            return;
        }
        Component firstProblem = null;
        for (Problem problem : problems) {
            addTabForProblem(problem);
            if (firstProblem == null) {
                firstProblem = tabbedPane.getComponentAt(tabbedPane.getTabCount() - 1);
            }
        }
        tabbedPane.setSelectedComponent(firstProblem);
    }
    
    private void newContestActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_newContestActionPerformed
        NewContestJDialog dialog = new NewContestJDialog(this);
        dialog.setVisible(true); // this is modal; it will block until window is closed
        addProblems(dialog.getProblemList());
    }//GEN-LAST:event_newContestActionPerformed
    
    private void newFromURLActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_newFromURLActionPerformed
        // show user a dialog to type the name, and the URL
        NewProblemJDialog dialog = new NewProblemJDialog(this);
        dialog.setVisible(true); // this is modal; it will block until window is closed
        if (dialog.getProblem() != null) { // a problem has been created
            addTabForProblem(dialog.getProblem());
        }
    }//GEN-LAST:event_newFromURLActionPerformed

    private void shortcutsActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_shortcutsActionPerformed
        new ShortcutsJDialog(this).setVisible(true);
    }//GEN-LAST:event_shortcutsActionPerformed

    private void aboutActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_aboutActionPerformed
        new AboutJDialog(this).setVisible(true);
    }//GEN-LAST:event_aboutActionPerformed
    
    
    /**
     * @param args the command line arguments
     */
    public static void main(String args[]) {
        // We set the look and feel for Swing
        try {
            UIManager.setLookAndFeel(UIManager.getSystemLookAndFeelClassName());
            // UIManager.put(""TabbedPane.tabInsets"", new Insets(5,20,6,20));
        } catch (Exception e) {
            // We fall back to Metal
        }
        
        // And we let the application run
        java.awt.EventQueue.invokeLater(new Runnable() {
            @Override
            public void run() {
                new MainJFrame().setVisible(true);
            }
        });
    }
    
    // Variables declaration - do not modify//GEN-BEGIN:variables
    private javax.swing.JMenuItem about;
    private javax.swing.JMenuItem exit;
    private javax.swing.JMenu fileMenu;
    private javax.swing.JMenu helpMenu;
    private javax.swing.JPopupMenu.Separator jSeparator1;
    private javax.swing.JMenuBar menuBar;
    private javax.swing.JMenuItem newContest;
    private javax.swing.JMenuItem newFromURL;
    private javax.swing.JMenuItem openConfig;
    private javax.swing.JMenuItem shortcuts;
    private javax.swing.JTabbedPane tabbedPane;
    // End of variables declaration//GEN-END:variables

}",java
"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hadoop.test;

import org.apache.hadoop.fs.DFSCIOTest;
import org.apache.hadoop.fs.DistributedFSCheck;
import org.apache.hadoop.fs.JHLogAnalyzer;
import org.apache.hadoop.fs.TestDFSIO;
import org.apache.hadoop.fs.TestFileSystem;
import org.apache.hadoop.fs.loadGenerator.DataGenerator;
import org.apache.hadoop.fs.loadGenerator.LoadGenerator;
import org.apache.hadoop.fs.loadGenerator.LoadGeneratorMR;
import org.apache.hadoop.fs.loadGenerator.StructureGenerator;
import org.apache.hadoop.fs.slive.SliveTest;
import org.apache.hadoop.hdfs.NNBench;
import org.apache.hadoop.hdfs.NNBenchWithoutMR;
import org.apache.hadoop.io.FileBench;
import org.apache.hadoop.io.TestSequenceFile;
import org.apache.hadoop.mapred.BigMapOutput;
import org.apache.hadoop.mapred.GenericMRLoadGenerator;
import org.apache.hadoop.mapred.MRBench;
import org.apache.hadoop.mapred.ReliabilityTest;
import org.apache.hadoop.mapred.SortValidator;
import org.apache.hadoop.mapred.TestMapRed;
import org.apache.hadoop.mapred.TestSequenceFileInputFormat;
import org.apache.hadoop.mapred.TestTextInputFormat;
import org.apache.hadoop.mapred.ThreadedMapBenchmark;
import org.apache.hadoop.mapreduce.FailJob;
import org.apache.hadoop.mapreduce.GrowingSleepJob;
import org.apache.hadoop.mapreduce.LargeSorter;
import org.apache.hadoop.mapreduce.MiniHadoopClusterManager;
import org.apache.hadoop.mapreduce.SleepJob;
import org.apache.hadoop.mapreduce.TimelineServicePerformance;
import org.apache.hadoop.util.ProgramDriver;

/**
 * Driver for Map-reduce tests.
 *
 */
public class MapredTestDriver {

  private ProgramDriver pgd;

  public MapredTestDriver() {
    this(new ProgramDriver());
  }

  public MapredTestDriver(ProgramDriver pgd) {
    this.pgd = pgd;
    try {
      pgd.addClass(""testsequencefile"", TestSequenceFile.class,
      ""A test for flat files of binary key value pairs."");
      pgd.addClass(""threadedmapbench"", ThreadedMapBenchmark.class,
          ""A map/reduce benchmark that compares the performance "" +
          ""of maps with multiple spills over maps with 1 spill"");
      pgd.addClass(""mrbench"", MRBench.class,
          ""A map/reduce benchmark that can create many small jobs"");
      pgd.addClass(""mapredtest"", TestMapRed.class, ""A map/reduce test check."");
      pgd.addClass(""testsequencefileinputformat"",
          TestSequenceFileInputFormat.class,
          ""A test for sequence file input format."");
      pgd.addClass(""testtextinputformat"", TestTextInputFormat.class,
          ""A test for text input format."");
      pgd.addClass(""testmapredsort"", SortValidator.class,
          ""A map/reduce program that validates the "" +
          ""map-reduce framework's sort."");
      pgd.addClass(""testbigmapoutput"", BigMapOutput.class,
          ""A map/reduce program that works on a very big "" +
          ""non-splittable file and does identity map/reduce"");
      pgd.addClass(""loadgen"", GenericMRLoadGenerator.class,
          ""Generic map/reduce load generator"");
      pgd.addClass(""MRReliabilityTest"", ReliabilityTest.class,
          ""A program that tests the reliability of the MR framework by "" +
          ""injecting faults/failures"");
      pgd.addClass(""fail"", FailJob.class, ""a job that always fails"");
      pgd.addClass(""sleep"", SleepJob.class,
                   ""A job that sleeps at each map and reduce task."");
      pgd.addClass(""gsleep"", GrowingSleepJob.class,
          ""A sleep job whose mappers create 1MB buffer for every record."");
      pgd.addClass(""timelineperformance"", TimelineServicePerformance.class,
                   ""A job that launches mappers to test timeline service "" +
                   ""performance."");
      pgd.addClass(""nnbench"", NNBench.class,
          ""A benchmark that stresses the namenode w/ MR."");
      pgd.addClass(""nnbenchWithoutMR"", NNBenchWithoutMR.class,
          ""A benchmark that stresses the namenode w/o MR."");
      pgd.addClass(""testfilesystem"", TestFileSystem.class,
          ""A test for FileSystem read/write."");
      pgd.addClass(TestDFSIO.class.getSimpleName(), TestDFSIO.class,
          ""Distributed i/o benchmark."");
      pgd.addClass(""DFSCIOTest"", DFSCIOTest.class, """" +
          ""Distributed i/o benchmark of libhdfs."");
      pgd.addClass(""DistributedFSCheck"", DistributedFSCheck.class,
          ""Distributed checkup of the file system consistency."");
      pgd.addClass(""filebench"", FileBench.class,
          ""Benchmark SequenceFile(Input|Output)Format "" +
          ""(block,record compressed and uncompressed), "" +
          ""Text(Input|Output)Format (compressed and uncompressed)"");
      pgd.addClass(JHLogAnalyzer.class.getSimpleName(), JHLogAnalyzer.class,
          ""Job History Log analyzer."");
      pgd.addClass(SliveTest.class.getSimpleName(), SliveTest.class,
          ""HDFS Stress Test and Live Data Verification."");
      pgd.addClass(""minicluster"", MiniHadoopClusterManager.class,
      ""Single process HDFS and MR cluster."");
      pgd.addClass(""largesorter"", LargeSorter.class,
          ""Large-Sort tester"");
      pgd.addClass(""NNloadGenerator"", LoadGenerator.class,
              ""Generate load on Namenode using NN loadgenerator run WITHOUT MR"");
      pgd.addClass(""NNloadGeneratorMR"", LoadGeneratorMR.class,
          ""Generate load on Namenode using NN loadgenerator run as MR job"");
      pgd.addClass(""NNstructureGenerator"", StructureGenerator.class,
          ""Generate the structure to be used by NNdataGenerator"");
      pgd.addClass(""NNdataGenerator"", DataGenerator.class,
          ""Generate the data to be used by NNloadGenerator"");
    } catch(Throwable e) {
      e.printStackTrace();
    }
  }

  public void run(String argv[]) {
    int exitCode = -1;
    try {
      exitCode = pgd.run(argv);
    } catch(Throwable e) {
      e.printStackTrace();
    }
    System.exit(exitCode);
  }

  public static void main(String argv[]){
    new MapredTestDriver().run(argv);
  }
}

",java
"import java.util.ArrayList;
import java.util.List;
import java.util.Scanner;

public class Main {
  static final int[] R_OFFSETS = {-1, 0, 1, 0};
  static final int[] C_OFFSETS = {0, 1, 0, -1};

  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int m = sc.nextInt();
      char[][] cells = new char[n][m];
      for (int r = 0; r < n; ++r) {
        String line = sc.next();
        for (int c = 0; c < m; ++c) {
          cells[r][c] = line.charAt(c);
        }
      }

      System.out.println(solve(cells) ? ""YES"" : ""NO"");
    }

    sc.close();
  }

  static boolean solve(char[][] cells) {
    int n = cells.length;
    int m = cells[0].length;

    boolean[][] visited = new boolean[n][m];
    for (int r = 0; r < n; ++r) {
      for (int c = 0; c < m; ++c) {
        if (!visited[r][c] && cells[r][c] == '1') {
          List<Point> points = new ArrayList<>();
          search(points, cells, visited, r, c);

          int minR = points.stream().mapToInt(p -> p.r).min().getAsInt();
          int maxR = points.stream().mapToInt(p -> p.r).max().getAsInt();
          int minC = points.stream().mapToInt(p -> p.c).min().getAsInt();
          int maxC = points.stream().mapToInt(p -> p.c).max().getAsInt();

          if (points.size() != (maxR - minR + 1) * (maxC - minC + 1)) {
            return false;
          }
        }
      }
    }

    return true;
  }

  static void search(List<Point> points, char[][] cells, boolean[][] visited, int r, int c) {
    int n = cells.length;
    int m = cells[0].length;

    visited[r][c] = true;
    points.add(new Point(r, c));

    for (int i = 0; i < R_OFFSETS.length; ++i) {
      int adjR = r + R_OFFSETS[i];
      int adjC = c + C_OFFSETS[i];
      if (adjR >= 0
          && adjR < n
          && adjC >= 0
          && adjC < m
          && !visited[adjR][adjC]
          && cells[adjR][adjC] == '1') {
        search(points, cells, visited, adjR, adjC);
      }
    }
  }
}

class Point {
  int r;
  int c;

  Point(int r, int c) {
    this.r = r;
    this.c = c;
  }
}",java
"import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Scanner;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] u = new int[n - 1];
      int[] v = new int[n - 1];
      for (int i = 0; i < n - 1; ++i) {
        u[i] = sc.nextInt() - 1;
        v[i] = sc.nextInt() - 1;
      }

      System.out.println(solve(u, v));
    }

    sc.close();
  }

  static String solve(int[] u, int[] v) {
    int n = u.length + 1;

    @SuppressWarnings(""unchecked"")
    List<Integer>[] edgeLists = new List[n];
    for (int i = 0; i < edgeLists.length; ++i) {
      edgeLists[i] = new ArrayList<>();
    }
    for (int i = 0; i < u.length; ++i) {
      edgeLists[u[i]].add(i);
      edgeLists[v[i]].add(i);
    }

    if (Arrays.stream(edgeLists).anyMatch(edgeList -> edgeList.size() >= 3)) {
      return ""-1"";
    }

    int start =
        IntStream.range(0, edgeLists.length)
            .filter(i -> edgeLists[i].size() == 1)
            .findAny()
            .getAsInt();

    int[] weights = new int[u.length];
    search(weights, u, v, edgeLists, start, 2);

    return Arrays.stream(weights).mapToObj(String::valueOf).collect(Collectors.joining("" ""));
  }

  static void search(
      int[] weights, int[] u, int[] v, List<Integer>[] edgeLists, int node, int weight) {
    for (int edge : edgeLists[node]) {
      if (weights[edge] == 0) {
        weights[edge] = weight;

        search(weights, u, v, edgeLists, (node == u[edge]) ? v[edge] : u[edge], 5 - weight);
      }
    }
  }
}",java
"import java.util.HashSet;
import java.util.Scanner;
import java.util.Set;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

public class Main {
  static final int ALPHABET_SIZE = 26;

  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int T = sc.nextInt();
    for (int tc = 0; tc < T; ++tc) {
      String s = sc.next();

      System.out.println(solve(s));
    }

    sc.close();
  }

  static String solve(String s) {
    @SuppressWarnings(""unchecked"")
    Set<Integer>[] adjSets = new Set[ALPHABET_SIZE];
    for (int i = 0; i < adjSets.length; ++i) {
      adjSets[i] = new HashSet<>();
    }
    for (int i = 0; i < s.length() - 1; ++i) {
      int index1 = s.charAt(i) - 'a';
      int index2 = s.charAt(i + 1) - 'a';

      adjSets[index1].add(index2);
      adjSets[index2].add(index1);
    }

    StringBuilder layout =
        new StringBuilder(
            IntStream.range(0, adjSets.length)
                .filter(i -> adjSets[i].isEmpty())
                .mapToObj(i -> String.valueOf((char) (i + 'a')))
                .collect(Collectors.joining()));
    boolean[] visited = new boolean[adjSets.length];
    int[] begins = IntStream.range(0, adjSets.length).filter(i -> adjSets[i].size() == 1).toArray();
    for (int begin : begins) {
      if (!visited[begin]) {
        visited[begin] = true;
        layout.append((char) (begin + 'a'));
        int current = begin;
        while (!adjSets[current].isEmpty()) {
          int next = adjSets[current].iterator().next();
          adjSets[next].remove(current);

          current = next;
          if (visited[current]) {
            return ""NO"";
          }
          visited[current] = true;
          layout.append((char) (current + 'a'));
        }
      }
    }

    return (layout.length() == ALPHABET_SIZE) ? String.format(""YES\n%s"", layout) : ""NO"";
  }
}",java
"import java.util.Arrays;
import java.util.Scanner;
import java.util.Set;
import java.util.stream.Collectors;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int k = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a, k) ? ""YES"" : ""NO"");
    }

    sc.close();
  }

  static boolean solve(int[] a, int k) {
    Set<Integer> set = Arrays.stream(a).boxed().collect(Collectors.toSet());

    return Arrays.stream(a).anyMatch(ai -> set.contains(ai + k));
  }
}",java
"package br.gov.jfrj.siga.gc;

public class DoDiagram {
	static {
		// ClassPool pool = ClassPool.getDefault();
		// CtClass cc;
		// try {
		// cc = pool.get(""br.gov.jfrj.siga.model.Objeto"");
		// cc.setSuperclass(pool.get(""play.db.jpa.GenericModel""));
		// cc.writeFile();
		//
		// } catch (Exception e) {
		// e.printStackTrace();
		// }
		System.out.println(""*** Classe alterada."");
	}

	public static void testGeraDiagramaGC() throws Exception {
		// Diagram d = new Diagram();
		// d.setfMergeWithAbstractClass(true);
		// boolean fI = false;
		//
		// d.addClass(DpPessoa.class, fI, false, false);
		// d.addClass(DpLotacao.class, fI, false, false);
		// d.addClass(CpOrgaoUsuario.class, fI, false, false);
		// d.addClass(CpMarca.class, fI, true, false);
		// d.addClass(CpConfiguracao.class, false, false, false);
		//
		// d.addClass(GcArquivo.class, fI, true, false);
		// d.addClass(GcConfiguracao.class, fI, true, false);
		// d.addClass(GcInformacao.class, fI, true, false);
		// d.addClass(GcMarca.class, fI, true, false);
		// d.addClass(GcMovimentacao.class, fI, true, false);
		// d.addClass(GcTipoInformacao.class, fI, true, false);
		// d.addClass(GcTipoMovimentacao.class, fI, true, false);
		// d.addClass(GcTag.class, fI, true, false);
		//
		// d.createGraphML(""sigagc.graphml"", true, false);
		//
		// GcMarca m = new GcMarca();
		// System.out.println(m.toString());
	}

	/**
	 * @param args
	 * @throws Exception
	 */
	public static void main(String[] args) throws Exception {
		testGeraDiagramaGC();
	}

}
",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      sc.nextInt();
      String s = sc.next();

      System.out.println(solve(s));
    }

    sc.close();
  }

  static int solve(String s) {
    int result = 0;
    int lastZeroIndex = -1;
    for (int i = 0; i < s.length(); ++i) {
      if (s.charAt(i) == '0') {
        if (lastZeroIndex != -1) {
          result += Math.max(0, 3 - (i - lastZeroIndex));
        }

        lastZeroIndex = i;
      }
    }

    return result;
  }
}",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int a = sc.nextInt();
      int b = sc.nextInt();
      int k = sc.nextInt();

      System.out.println(solve(a, b, k) ? ""YES"" : ""NO"");
    }

    sc.close();
  }

  static boolean solve(int a, int b, int k) {
    if (a < b) {
      return solve(b, a, k);
    }

    if (k == 1) {
      return a != b && a % b == 0;
    }

    return computeExponentSum(a) + computeExponentSum(b) >= k;
  }

  static int computeExponentSum(int x) {
    int result = 0;
    for (int i = 2; i * i <= x; ++i) {
      while (x % i == 0) {
        x /= i;
        ++result;
      }
    }
    if (x != 1) {
      ++result;
    }

    return result;
  }
}",java
"import generateFiles.GenerateHiveFile;

import org.apache.hadoop.util.ProgramDriver;

import autodeploy.createSSH.CreateSSHTrust;
import autodeploy.createuser.CreateUser;



/**
 * liulu5
 * 2013-9-22
 */
public class HadoopToolDriver {

	/**
	 * @param args
	 */
	public static void main(String[] args) {
	    int exitCode = -1;
	    ProgramDriver pgd = new ProgramDriver();
	    try {
	    	pgd.addClass(""createuser"", CreateUser.class, 
	                   ""Create linux user."");
	      pgd.addClass(""createsshtrust"", CreateSSHTrust.class, 
	                   ""Create SSH trust for cluster node."");
	      pgd.addClass(""generatehivefile"", GenerateHiveFile.class, 
                  		""generate file for hive table."");
	      
//	      pgd.addClass(""aggregatewordcount"", AggregateWordCount.class, 
//	                   ""An Aggregate based map/reduce program that counts the words in the input files."");
//	      pgd.addClass(""aggregatewordhist"", AggregateWordHistogram.class, 
//	                   ""An Aggregate based map/reduce program that computes the histogram of the words in the input files."");
//	      pgd.addClass(""grep"", Grep.class, 
//	                   ""A map/reduce program that counts the matches of a regex in the input."");
//	      pgd.addClass(""randomwriter"", RandomWriter.class, 
//	                   ""A map/reduce program that writes 10GB of random data per node."");
//	      pgd.addClass(""randomtextwriter"", RandomTextWriter.class, 
//	      ""A map/reduce program that writes 10GB of random textual data per node."");
//	      pgd.addClass(""sort"", Sort.class, ""A map/reduce program that sorts the data written by the random writer."");
//	      pgd.addClass(""pi"", PiEstimator.class, ""A map/reduce program that estimates Pi using monte-carlo method."");
//	      pgd.addClass(""pentomino"", DistributedPentomino.class,
//	      ""A map/reduce tile laying program to find solutions to pentomino problems."");
//	      pgd.addClass(""secondarysort"", SecondarySort.class,
//	                   ""An example defining a secondary sort to the reduce."");
//	      pgd.addClass(""sudoku"", Sudoku.class, ""A sudoku solver."");
//	      pgd.addClass(""sleep"", SleepJob.class, ""A job that sleeps at each map and reduce task."");
//	      pgd.addClass(""join"", Join.class, ""A job that effects a join over sorted, equally partitioned datasets"");
//	      pgd.addClass(""multifilewc"", MultiFileWordCount.class, ""A job that counts words from several files."");
//	      pgd.addClass(""dbcount"", DBCountPageView.class, ""An example job that count the pageview counts from a database."");
//	      pgd.addClass(""teragen"", TeraGen.class, ""Generate data for the terasort"");
//	      pgd.addClass(""terasort"", TeraSort.class, ""Run the terasort"");
//	      pgd.addClass(""teravalidate"", TeraValidate.class, ""Checking results of terasort"");
	      pgd.driver(args);
	      
	      // Success
	      exitCode = 0;
	    }
	    catch(Throwable e){
	      e.printStackTrace();
	    }
	    
	    System.exit(exitCode);
	  }

}

",java
"/**
 * ************************************************************************
 * * The contents of this file are subject to the MRPL 1.2
 * * (the  ""License""),  being   the  Mozilla   Public  License
 * * Version 1.1  with a permitted attribution clause; you may not  use this
 * * file except in compliance with the License. You  may  obtain  a copy of
 * * the License at http://www.floreantpos.org/license.html
 * * Software distributed under the License  is  distributed  on  an ""AS IS""
 * * basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
 * * License for the specific  language  governing  rights  and  limitations
 * * under the License.
 * * The Original Code is FLOREANT POS.
 * * The Initial Developer of the Original Code is OROCUBE LLC
 * * All portions are Copyright (C) 2015 OROCUBE LLC
 * * All Rights Reserved.
 * ************************************************************************
 */
package com.floreantpos.model.dao;

import java.sql.Connection;

import org.hibernate.Session;
import org.hibernate.cfg.Configuration;

import com.floreantpos.Database;
import com.floreantpos.config.AppConfig;
import com.floreantpos.model.ActionHistory;
import com.floreantpos.model.AttendenceHistory;
import com.floreantpos.model.CashDrawer;
import com.floreantpos.model.CashDrawerResetHistory;
import com.floreantpos.model.CookingInstruction;
import com.floreantpos.model.Currency;
import com.floreantpos.model.CurrencyBalance;
import com.floreantpos.model.CustomPayment;
import com.floreantpos.model.Customer;
import com.floreantpos.model.DataUpdateInfo;
import com.floreantpos.model.DeliveryAddress;
import com.floreantpos.model.DeliveryCharge;
import com.floreantpos.model.DeliveryConfiguration;
import com.floreantpos.model.DeliveryInstruction;
import com.floreantpos.model.Discount;
import com.floreantpos.model.DrawerAssignedHistory;
import com.floreantpos.model.DrawerPullReport;
import com.floreantpos.model.EmployeeInOutHistory;
import com.floreantpos.model.GlobalConfig;
import com.floreantpos.model.Gratuity;
import com.floreantpos.model.InventoryGroup;
import com.floreantpos.model.InventoryItem;
import com.floreantpos.model.InventoryLocation;
import com.floreantpos.model.InventoryMetaCode;
import com.floreantpos.model.InventoryTransaction;
import com.floreantpos.model.InventoryUnit;
import com.floreantpos.model.InventoryVendor;
import com.floreantpos.model.InventoryWarehouse;
import com.floreantpos.model.KitchenTicket;
import com.floreantpos.model.KitchenTicketItem;
import com.floreantpos.model.MenuCategory;
import com.floreantpos.model.MenuGroup;
import com.floreantpos.model.MenuItem;
import com.floreantpos.model.MenuItemModifierGroup;
import com.floreantpos.model.MenuItemShift;
import com.floreantpos.model.MenuItemSize;
import com.floreantpos.model.MenuModifier;
import com.floreantpos.model.MenuModifierGroup;
import com.floreantpos.model.ModifierMultiplierPrice;
import com.floreantpos.model.Multiplier;
import com.floreantpos.model.PackagingUnit;
import com.floreantpos.model.PayoutReason;
import com.floreantpos.model.PayoutRecepient;
import com.floreantpos.model.PizzaCrust;
import com.floreantpos.model.PizzaModifierPrice;
import com.floreantpos.model.PizzaPrice;
import com.floreantpos.model.PosTransaction;
import com.floreantpos.model.PrinterConfiguration;
import com.floreantpos.model.PrinterGroup;
import com.floreantpos.model.PurchaseOrder;
import com.floreantpos.model.Recepie;
import com.floreantpos.model.RecepieItem;
import com.floreantpos.model.Restaurant;
import com.floreantpos.model.Shift;
import com.floreantpos.model.ShopFloor;
import com.floreantpos.model.ShopFloorTemplate;
import com.floreantpos.model.ShopTable;
import com.floreantpos.model.ShopTableType;
import com.floreantpos.model.TableBookingInfo;
import com.floreantpos.model.Tax;
import com.floreantpos.model.Terminal;
import com.floreantpos.model.TerminalPrinters;
import com.floreantpos.model.Ticket;
import com.floreantpos.model.TicketDiscount;
import com.floreantpos.model.TicketItem;
import com.floreantpos.model.TicketItemDiscount;
import com.floreantpos.model.TicketItemModifier;
import com.floreantpos.model.User;
import com.floreantpos.model.UserPermission;
import com.floreantpos.model.UserType;
import com.floreantpos.model.VirtualPrinter;
import com.floreantpos.model.VoidReason;
import com.floreantpos.model.ZipCodeVsDeliveryCharge;

public abstract class _RootDAO extends com.floreantpos.model.dao._BaseRootDAO {

	/*
	 * If you are using lazy loading, uncomment this Somewhere, you should call
	 * RootDAO.closeCurrentThreadSessions(); public void closeSession (Session
	 * session) { // do nothing here because the session will be closed later }
	 */

	/*
	 * If you are pulling the SessionFactory from a JNDI tree, uncomment this
	 * protected SessionFactory getSessionFactory(String configFile) { // If you
	 * have a single session factory, ignore the configFile parameter //
	 * Otherwise, you can set a meta attribute under the class node called
	 * ""config-file"" which // will be passed in here so you can tell what
	 * session factory an individual mapping file // belongs to return
	 * (SessionFactory) new
	 * InitialContext().lookup(""java:/{SessionFactoryName}""); }
	 */

	public static void initialize(String configFileName, Configuration configuration) {
		com.floreantpos.model.dao._RootDAO.setSessionFactory(configuration.buildSessionFactory());
	}

	public static Configuration getNewConfiguration(String configFileName) {
		Configuration configuration = new Configuration();
		configuration.addClass(ActionHistory.class);
		configuration.addClass(AttendenceHistory.class);
		configuration.addClass(CashDrawerResetHistory.class);
		configuration.addClass(CookingInstruction.class);
		configuration.addClass(Discount.class);
		configuration.addClass(Gratuity.class);
		configuration.addClass(MenuCategory.class);
		configuration.addClass(MenuGroup.class);
		configuration.addClass(MenuItem.class);
		configuration.addClass(MenuItemModifierGroup.class);
		configuration.addClass(MenuItemShift.class);
		configuration.addClass(MenuModifier.class);
		configuration.addClass(MenuModifierGroup.class);
		configuration.addClass(PayoutReason.class);
		configuration.addClass(PayoutRecepient.class);
		configuration.addClass(Restaurant.class);
		configuration.addClass(Shift.class);
		configuration.addClass(Tax.class);
		configuration.addClass(Terminal.class);
		configuration.addClass(Ticket.class);
		configuration.addClass(KitchenTicket.class);
		configuration.addClass(TicketDiscount.class);
		configuration.addClass(TicketItem.class);
		configuration.addClass(TicketItemModifier.class);
		//configuration.addClass(TicketItemModifierGroup.class);
		configuration.addClass(TicketItemDiscount.class);
		configuration.addClass(KitchenTicketItem.class);
		configuration.addClass(PosTransaction.class);
		configuration.addClass(User.class);
		configuration.addClass(VirtualPrinter.class);
		configuration.addClass(TerminalPrinters.class);
		configuration.addClass(VoidReason.class);
		configuration.addClass(DrawerPullReport.class);
		configuration.addClass(PrinterConfiguration.class);
		configuration.addClass(UserPermission.class);
		configuration.addClass(UserType.class);
		configuration.addClass(Customer.class);
		configuration.addClass(PurchaseOrder.class);
		configuration.addClass(ZipCodeVsDeliveryCharge.class);
		configuration.addClass(ShopFloor.class);
		configuration.addClass(ShopFloorTemplate.class);
		configuration.addClass(ShopTable.class);
		configuration.addClass(ShopTableType.class);
		configuration.addClass(PrinterGroup.class);
		configuration.addClass(DrawerAssignedHistory.class);
		configuration.addClass(DataUpdateInfo.class);
		configuration.addClass(TableBookingInfo.class);
		configuration.addClass(CustomPayment.class);
		configuration.addClass(com.floreantpos.model.OrderType.class);
		configuration.addClass(DeliveryAddress.class);
		configuration.addClass(DeliveryInstruction.class);
		configuration.addClass(DeliveryCharge.class);
		configuration.addClass(DeliveryConfiguration.class);
		configuration.addClass(EmployeeInOutHistory.class);
		configuration.addClass(Currency.class);
		configuration.addClass(CashDrawer.class);
		configuration.addClass(CurrencyBalance.class);
		configuration.addClass(GlobalConfig.class);
		configuration.addClass(MenuItemSize.class);
		configuration.addClass(PizzaCrust.class);
		configuration.addClass(PizzaPrice.class);
		configuration.addClass(PizzaModifierPrice.class);
		configuration.addClass(Multiplier.class);
		configuration.addClass(ModifierMultiplierPrice.class);

		configureInventoryClasses(configuration);

		Database defaultDatabase = AppConfig.getDefaultDatabase();

		configuration.setProperty(""hibernate.dialect"", defaultDatabase.getHibernateDialect()); //$NON-NLS-1$
		configuration.setProperty(""hibernate.connection.driver_class"", defaultDatabase.getHibernateConnectionDriverClass()); //$NON-NLS-1$

		configuration.setProperty(""hibernate.connection.url"", AppConfig.getConnectString()); //$NON-NLS-1$
		configuration.setProperty(""hibernate.connection.username"", AppConfig.getDatabaseUser()); //$NON-NLS-1$
		configuration.setProperty(""hibernate.connection.password"", AppConfig.getDatabasePassword()); //$NON-NLS-1$
		configuration.setProperty(""hibernate.hbm2ddl.auto"", ""update""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.connection.autocommit"", ""false""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.max_fetch_depth"", ""3""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.show_sql"", ""false""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.connection.isolation"", String.valueOf(Connection.TRANSACTION_READ_COMMITTED)); //$NON-NLS-1$

		configureC3p0ConnectionPool(configuration);

		return configuration;
	}

	private static void configureC3p0ConnectionPool(Configuration configuration) {
		//min pool size
		configuration.setProperty(""hibernate.c3p0.min_size"", ""0""); //$NON-NLS-1$ //$NON-NLS-2$
		//max pool size
		configuration.setProperty(""hibernate.c3p0.max_size"", ""5""); //$NON-NLS-1$ //$NON-NLS-2$
		// When an idle connection is removed from the pool (in second)
		configuration.setProperty(""hibernate.c3p0.timeout"", ""300""); //$NON-NLS-1$ //$NON-NLS-2$
		//Number of prepared statements will be cached
		configuration.setProperty(""hibernate.c3p0.max_statements"", ""50""); //$NON-NLS-1$ //$NON-NLS-2$
		//The number of milliseconds a client calling getConnection() will wait for a Connection to be 
		//checked-in or acquired when the pool is exhausted. Zero means wait indefinitely.
		//Setting any positive value will cause the getConnection() call to time-out and break 
		//with an SQLException after the specified number of milliseconds. 
		configuration.setProperty(""hibernate.c3p0.checkoutTimeout"", ""10000""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.c3p0.acquireRetryAttempts"", ""1""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.c3p0.acquireIncrement"", ""1""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.c3p0.maxIdleTime"", ""3000""); //$NON-NLS-1$ //$NON-NLS-2$
		//idle time in seconds before a connection is automatically validated
		configuration.setProperty(""hibernate.c3p0.idle_test_period"", ""3000""); //$NON-NLS-1$ //$NON-NLS-2$
		configuration.setProperty(""hibernate.c3p0.breakAfterAcquireFailure"", ""false""); //$NON-NLS-1$ //$NON-NLS-2$
	}

	private static Configuration configureInventoryClasses(Configuration configuration) {
		configuration.addClass(InventoryGroup.class);
		configuration.addClass(InventoryItem.class);
		configuration.addClass(InventoryLocation.class);
		configuration.addClass(InventoryMetaCode.class);
		configuration.addClass(InventoryTransaction.class);
		configuration.addClass(InventoryUnit.class);
		configuration.addClass(InventoryVendor.class);
		configuration.addClass(InventoryWarehouse.class);
		configuration.addClass(Recepie.class);
		configuration.addClass(RecepieItem.class);
		configuration.addClass(PackagingUnit.class);

		return configuration;
	}

	public static Configuration reInitialize() {
		Configuration configuration = getNewConfiguration(null);
		com.floreantpos.model.dao._RootDAO.setSessionFactory(configuration.buildSessionFactory());

		return configuration;
	}

	public void refresh(Object obj) {
		Session session = createNewSession();
		super.refresh(obj, session);
		session.close();
	}
}",java
"import java.util.Arrays;
import java.util.Scanner;
import java.util.stream.IntStream;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a));
    }

    sc.close();
  }

  static String solve(int[] a) {
    int min = Arrays.stream(a).min().getAsInt();
    int indexWithMin = IntStream.range(0, a.length).filter(i -> a[i] == min).findAny().getAsInt();
    int max = Arrays.stream(a).max().getAsInt();
    int indexWithMax = IntStream.range(0, a.length).filter(i -> a[i] == max).findAny().getAsInt();

    return String.format(""%d %d"", indexWithMin + 1, indexWithMax + 1);
  }
}",java
"package org.hightail.parsers.contest;

import java.util.ArrayList;
import org.hightail.parsers.task.JutgeTaskParser;
import org.hightail.parsers.task.TaskParser;
import org.htmlparser.util.ParserException;

/**
 * Jutge (UPC local online judge) contest parser.
 * @author Sergio Rodriguez Guasch
 */
public class JutgeContestParser implements ContestParser {
    
    @Override
    public ArrayList<String> getProblemURLListFromURL(String URL) throws ParserException, InterruptedException {
        /*
            Problem lists (which can be interpreted as contests) are only available if you are logged in.
            Also, it doesn't make much sense here since most problems are public and they are usually solved
            one by one in pratice.
        */
        throw new ParserException(""Contest parser for Jutge is not implemented."");
    }
    
    private final TaskParser taskParser = new JutgeTaskParser();

    @Override
    public TaskParser getTaskParser() {
        return taskParser;
    }    

    @Override
    public boolean isCorrectURL(String URL) {
        return URL.contains(""jutge."");
    }
}
",java
"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hadoop.examples;

import org.apache.hadoop.examples.dancing.DistributedPentomino;
import org.apache.hadoop.examples.dancing.Sudoku;
import org.apache.hadoop.examples.pi.DistBbp;
import org.apache.hadoop.examples.terasort.TeraGen;
import org.apache.hadoop.examples.terasort.TeraSort;
import org.apache.hadoop.examples.terasort.TeraValidate;
import org.apache.hadoop.util.ProgramDriver;

/**
 * A description of an example program based on its class and a 
 * human-readable description.
 */
public class ExampleDriver {
  
  public static void main(String argv[]){
    int exitCode = -1;
    ProgramDriver pgd = new ProgramDriver();
    try {
      pgd.addClass(""wordcount"", WordCount.class, 
                   ""A map/reduce program that counts the words in the input files."");
      pgd.addClass(""wordmean"", WordMean.class,
                   ""A map/reduce program that counts the average length of the words in the input files."");
      pgd.addClass(""wordmedian"", WordMedian.class,
                   ""A map/reduce program that counts the median length of the words in the input files."");
      pgd.addClass(""wordstandarddeviation"", WordStandardDeviation.class,
                   ""A map/reduce program that counts the standard deviation of the length of the words in the input files."");
      pgd.addClass(""aggregatewordcount"", AggregateWordCount.class, 
                   ""An Aggregate based map/reduce program that counts the words in the input files."");
      pgd.addClass(""aggregatewordhist"", AggregateWordHistogram.class, 
                   ""An Aggregate based map/reduce program that computes the histogram of the words in the input files."");
      pgd.addClass(""grep"", Grep.class, 
                   ""A map/reduce program that counts the matches of a regex in the input."");
      pgd.addClass(""randomwriter"", RandomWriter.class, 
                   ""A map/reduce program that writes 10GB of random data per node."");
      pgd.addClass(""randomtextwriter"", RandomTextWriter.class, 
      ""A map/reduce program that writes 10GB of random textual data per node."");
      pgd.addClass(""sort"", Sort.class, ""A map/reduce program that sorts the data written by the random writer."");

      pgd.addClass(""pi"", QuasiMonteCarlo.class, QuasiMonteCarlo.DESCRIPTION);
      pgd.addClass(""bbp"", BaileyBorweinPlouffe.class, BaileyBorweinPlouffe.DESCRIPTION);
      pgd.addClass(""distbbp"", DistBbp.class, DistBbp.DESCRIPTION);

      pgd.addClass(""pentomino"", DistributedPentomino.class,
      ""A map/reduce tile laying program to find solutions to pentomino problems."");
      pgd.addClass(""secondarysort"", SecondarySort.class,
                   ""An example defining a secondary sort to the reduce."");
      pgd.addClass(""sudoku"", Sudoku.class, ""A sudoku solver."");
      pgd.addClass(""join"", Join.class, ""A job that effects a join over sorted, equally partitioned datasets"");
      pgd.addClass(""multifilewc"", MultiFileWordCount.class, ""A job that counts words from several files."");
      pgd.addClass(""dbcount"", DBCountPageView.class, ""An example job that count the pageview counts from a database."");
      pgd.addClass(""teragen"", TeraGen.class, ""Generate data for the terasort"");
      pgd.addClass(""terasort"", TeraSort.class, ""Run the terasort"");
      pgd.addClass(""teravalidate"", TeraValidate.class, ""Checking results of terasort"");
      exitCode = pgd.run(argv);
    }
    catch(Throwable e){
      e.printStackTrace();
    }
    
    System.exit(exitCode);
  }
}
	
",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int a = sc.nextInt();
      int b = sc.nextInt();

      System.out.println(solve(a, b));
    }

    sc.close();
  }

  static int solve(int a, int b) {
    return (a == 0) ? 1 : (a + 2 * b + 1);
  }
}",java
"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hadoop.test;

import org.apache.hadoop.util.ProgramDriver;
import org.apache.hadoop.mapred.BigMapOutput;
import org.apache.hadoop.mapred.GenericMRLoadGenerator;
import org.apache.hadoop.mapred.MRBench;
import org.apache.hadoop.mapred.ReliabilityTest;
import org.apache.hadoop.mapred.SortValidator;
import org.apache.hadoop.mapred.TestMapRed;
import org.apache.hadoop.mapred.TestSequenceFileInputFormat;
import org.apache.hadoop.mapred.TestTextInputFormat;
import org.apache.hadoop.hdfs.BenchmarkThroughput;
import org.apache.hadoop.hdfs.NNBench;
import org.apache.hadoop.fs.DistributedFSCheck;
import org.apache.hadoop.fs.TestDFSIO;
import org.apache.hadoop.fs.DFSCIOTest;
import org.apache.hadoop.fs.TestFileSystem;
import org.apache.hadoop.io.FileBench;
import org.apache.hadoop.io.TestArrayFile;
import org.apache.hadoop.io.TestSequenceFile;
import org.apache.hadoop.io.TestSetFile;
import org.apache.hadoop.ipc.TestIPC;
import org.apache.hadoop.ipc.TestRPC;
import org.apache.hadoop.mapred.ThreadedMapBenchmark;

public class AllTestDriver {
  
  /**
   * A description of the test program for running all the tests using jar file
   */
  public static void main(String argv[]){
    ProgramDriver pgd = new ProgramDriver();
    try {
      pgd.addClass(""threadedmapbench"", ThreadedMapBenchmark.class, 
                   ""A map/reduce benchmark that compares the performance "" + 
                   ""of maps with multiple spills over maps with 1 spill"");
      pgd.addClass(""mrbench"", MRBench.class, ""A map/reduce benchmark that can create many small jobs"");
      pgd.addClass(""nnbench"", NNBench.class, ""A benchmark that stresses the namenode."");
      pgd.addClass(""mapredtest"", TestMapRed.class, ""A map/reduce test check."");
      pgd.addClass(""testfilesystem"", TestFileSystem.class, ""A test for FileSystem read/write."");
      pgd.addClass(""testsequencefile"", TestSequenceFile.class, ""A test for flat files of binary key value pairs."");
      pgd.addClass(""testsetfile"", TestSetFile.class, ""A test for flat files of binary key/value pairs."");
      pgd.addClass(""testarrayfile"", TestArrayFile.class, ""A test for flat files of binary key/value pairs."");
      pgd.addClass(""testrpc"", TestRPC.class, ""A test for rpc."");
      pgd.addClass(""testipc"", TestIPC.class, ""A test for ipc."");
      pgd.addClass(""testsequencefileinputformat"", TestSequenceFileInputFormat.class, ""A test for sequence file input format."");
      pgd.addClass(""testtextinputformat"", TestTextInputFormat.class, ""A test for text input format."");
      pgd.addClass(""TestDFSIO"", TestDFSIO.class, ""Distributed i/o benchmark."");
      pgd.addClass(""DFSCIOTest"", DFSCIOTest.class, ""Distributed i/o benchmark of libhdfs."");
      pgd.addClass(""DistributedFSCheck"", DistributedFSCheck.class, ""Distributed checkup of the file system consistency."");
      pgd.addClass(""testmapredsort"", SortValidator.class, 
                   ""A map/reduce program that validates the map-reduce framework's sort."");
      pgd.addClass(""testbigmapoutput"", BigMapOutput.class, 
                   ""A map/reduce program that works on a very big "" + 
                   ""non-splittable file and does identity map/reduce"");
      pgd.addClass(""loadgen"", GenericMRLoadGenerator.class, ""Generic map/reduce load generator"");
      pgd.addClass(""filebench"", FileBench.class, ""Benchmark SequenceFile(Input|Output)Format (block,record compressed and uncompressed), Text(Input|Output)Format (compressed and uncompressed)"");
      pgd.addClass(""dfsthroughput"", BenchmarkThroughput.class, 
                   ""measure hdfs throughput"");
      pgd.addClass(""MRReliabilityTest"", ReliabilityTest.class,
          ""A program that tests the reliability of the MR framework by "" +
          ""injecting faults/failures"");
      pgd.driver(argv);
    } catch(Throwable e) {
      e.printStackTrace();
    }
  }
}

",java
"import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Scanner;

public class Main {
  static final int ALPHABET_SIZE = 26;

  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    String s = sc.next();

    System.out.println(solve(s));

    sc.close();
  }

  static long solve(String s) {
    @SuppressWarnings(""unchecked"")
    List<Integer>[] indexLists = new List[ALPHABET_SIZE];
    for (int i = 0; i < indexLists.length; ++i) {
      indexLists[i] = new ArrayList<>();
    }
    for (int i = 0; i < s.length(); ++i) {
      indexLists[s.charAt(i) - 'a'].add(i);
    }

    long result = Arrays.stream(indexLists).mapToInt(List::size).max().getAsInt();
    for (int i = 0; i < indexLists.length; ++i) {
      for (int j = 0; j < indexLists.length; ++j) {
        result = Math.max(result, computePairNum(indexLists[i], indexLists[j]));
      }
    }

    return result;
  }

  static long computePairNum(List<Integer> indices1, List<Integer> indices2) {
    long result = 0;
    int pos2 = 0;
    for (int index1 : indices1) {
      while (pos2 != indices2.size() && indices2.get(pos2) <= index1) {
        ++pos2;
      }

      result += indices2.size() - pos2;
    }

    return result;
  }
}",java
"import java.util.HashSet;
import java.util.Scanner;
import java.util.Set;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      String s = sc.next();

      System.out.println(solve(s));
    }

    sc.close();
  }

  static String solve(String s) {
    int beginIndex = -1;
    Set<Character> seen = new HashSet<>();
    for (int i = s.length() - 1; i >= 0; --i) {
      char c = s.charAt(i);
      if (!seen.contains(c)) {
        beginIndex = i;
        seen.add(c);
      }
    }

    return s.substring(beginIndex);
  }
}",java
"package org.hightail.server;

import com.sun.net.httpserver.HttpExchange;
import com.sun.net.httpserver.HttpServer;
import java.io.IOException;
import java.io.InputStream;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.util.Scanner;
import java.util.concurrent.Executors;
import org.hightail.Config;
import org.hightail.Problem;
import org.hightail.Testcase;
import org.hightail.TestcaseSet;
import org.hightail.util.ProblemNameFormatter;
import org.json.JSONArray;
import org.json.JSONException;
import org.json.JSONObject;

/**
 * This class makes it possible for Hightail to pick up tasks
 * sent via HTTP requests. This makes it possible for browser extensions
 * to parse tasks in the browser and send them to a running Hightail instance.
 *
 * @author Jasper van Merle
 */
public class HTTPServer {
    /**
     * CHelper runs on port 4243. By running Hightail on a different
     * port it's possible to use both tools at the same time.
     */
    public static final int PORT = 4244;

    private HttpServer server = null;
    private ProblemHandler problemHandler = null;

    /**
     * Start the HTTP server and start listening for tasks.
     * If the port is already occupied, it doesn't do anything.
     */
    public void start(ProblemHandler problemHandler) {
        try {
            this.problemHandler = problemHandler;

            server = HttpServer.create(new InetSocketAddress(InetAddress.getByName(null), PORT), 0);
            server.createContext(""/"", this::handleRequest);
            server.setExecutor(Executors.newSingleThreadExecutor());            
            server.start();
        } catch (IOException ex) {
            // Do nothing
        }
    }

    /**
     * Gracefully stop the server if it's running.
     */
    public void stop() {
        if (server != null) {
            server.stop(0);
        }
    }

    /**
     * Handle a request to the server.
     *
     * Does three things:
     * 1. Check if the request is a POST request.
     * 2. Attempt to parse the body of the request.
     * 3. If successful, add the task with it's tests.
     *
     * @param exchange
     */
    private void handleRequest(HttpExchange exchange) throws IOException {
        if (exchange.getRequestMethod().toUpperCase().equals(""POST"")) {
            // Convert the request body into a string
            InputStream bodyStream = exchange.getRequestBody();
            Scanner sc = new Scanner(bodyStream).useDelimiter(""\\A"");
            String body = sc.hasNext() ? sc.next() : """";
            sc.close();

            try {
                JSONObject obj = new JSONObject(body);
                Problem problem = jsonToProblem(obj);
                problemHandler.handle(problem);
            } catch (JSONException e) {
                // Do nothing, received data is not JSON or is invalid
            }

            // HTTP 200 - OK
            exchange.sendResponseHeaders(200, 0);
            exchange.getResponseBody().close();
        } else {
            // HTTP 405 - Method Not Allowed
            exchange.sendResponseHeaders(405, 0);
            exchange.getResponseBody().close();
        }
    }

    /**
     * Convert the JSON data to a Problem instance.
     *
     * @param obj
     * @return
     * @throws JSONException
     */
    private Problem jsonToProblem(JSONObject obj) throws JSONException {
        String url = obj.getString(""url"");

        String name = ProblemNameFormatter.getFormattedName(obj.getString(""name""));
        if (name.length() > Problem.PROBLEM_NAME_MAX_LENGTH) {
            name = name.substring(0, Problem.PROBLEM_NAME_MAX_LENGTH);
        }

        if (url.contains(""codeforces.com"") && !Config.getBoolean(""putWholeName"")) {
            name = String.valueOf(name.charAt(0));
        }

        int timeLimit = obj.getInt(""timeLimit"");

        JSONArray testsArr = obj.getJSONArray(""tests"");
        TestcaseSet testsSet = new TestcaseSet();

        for (int i = 0, iMax = testsArr.length(); i < iMax; i++) {
            JSONObject test = testsArr.getJSONObject(i);

            String input = test.getString(""input"");
            String output = test.getString(""output"");

            testsSet.add(new Testcase(input, output, timeLimit));
        }

        return new Problem(name, testsSet, null);
    }
}
",java
"import java.util.Scanner;
import java.util.stream.IntStream;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int k = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a, k));
    }

    sc.close();
  }

  static long solve(int[] a, int k) {
    long result = 0;
    int rest = k + 1;
    for (int i = 0; i < a.length; ++i) {
      int noteNum =
          Math.min((i == a.length - 1) ? Integer.MAX_VALUE : pow10(a[i + 1] - a[i]) - 1, rest);
      result += (long) pow10(a[i]) * noteNum;

      rest -= noteNum;
    }

    return result;
  }

  static int pow10(int exponent) {
    return IntStream.range(0, exponent).reduce(1, (x, y) -> x * 10);
  }
}",java
"package org.hightail.util;

import java.io.File;
import java.util.TimerTask;

public class FileMonitorTask extends TimerTask {
    private final FileChangeListener listener;
    private final File file;
    private boolean exists;
    private long lastModified;
    
    FileMonitorTask(FileChangeListener listener, File file) {
        this.listener = listener;
        this.file = file;
        this.exists = false;
        this.lastModified = -1;
    }

    @Override
    public void run() {
        if (exists != file.exists()) {
            exists = file.exists();
            if (exists) {
                lastModified = file.lastModified();
                listener.onFileCreate();
            } else {
                lastModified = -1;
                listener.onFileDelete();
            }
        } else if (exists) {
            if (lastModified != file.lastModified()) {
                lastModified = file.lastModified();
                listener.onFileChange();
            }
        }
    }
    
}
",java
"import java.util.Map;
import java.util.Scanner;
import java.util.function.Function;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

public class Main {
  static final int MODULUS = 1_000_000_007;

  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[][] grid = new int[2][n];
      for (int r = 0; r < grid.length; ++r) {
        for (int c = 0; c < grid[r].length; ++c) {
          grid[r][c] = sc.nextInt();
        }
      }

      System.out.println(solve(grid));
    }

    sc.close();
  }

  static int solve(int[][] grid) {
    int n = grid[0].length;

    Map<Integer, Integer> valueToIndex =
        IntStream.range(0, n)
            .boxed()
            .collect(Collectors.toMap(i -> grid[0][i], Function.identity()));

    int result = 1;
    boolean[] visited = new boolean[n];
    for (int i = 0; i < n; ++i) {
      if (!visited[i]) {
        search(grid, valueToIndex, visited, i);

        result = result * 2 % MODULUS;
      }
    }

    return result;
  }

  static void search(
      int[][] grid, Map<Integer, Integer> valueToIndex, boolean[] visited, int index) {
    visited[index] = true;

    int otherIndex = valueToIndex.get(grid[1][index]);
    if (!visited[otherIndex]) {
      search(grid, valueToIndex, visited, otherIndex);
    }
  }
}",java
"import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;
import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a));
    }

    sc.close();
  }

  static int solve(int[] a) {
    if (Arrays.stream(a).distinct().count() == 1) {
      return 0;
    }

    Map<Integer, Integer> valueToCount = new HashMap<>();
    for (int value : a) {
      valueToCount.put(value, valueToCount.getOrDefault(value, 0) + 1);
    }

    int result = 1;
    int current = valueToCount.values().stream().mapToInt(x -> x).max().getAsInt();
    while (true) {
      int delta = Math.min(a.length - current, current);
      result += delta;
      current += delta;
      if (current == a.length) {
        break;
      }

      ++result;
    }

    return result;
  }
}",java
"package com.hiernate.util;          		//���ཨ��com.hibernate.util����
import org.hibernate.Session;       		//����org.hibernate.Session��
import org.hibernate.SessionFactory; 		//����org.hibernate.SessionFactory��
import org.hibernate.cfg.Configuration; 	//����org.hibernate.cfg.Configuration��
import com.hiernate.persistence.Bm;     	//����com.hiernate.persistence.Bm��
import com.hiernate.persistence.Chuchai;	//����com.hiernate.persistence.Chuchai��
import com.hiernate.persistence.Meeting;	//����com.hiernate.persistence.Meeting��
import com.hiernate.persistence.Menu;		//����com.hiernate.persistence.Menu��
import com.hiernate.persistence.Onduty;		//����com.hiernate.persistence.Onduty��
import com.hiernate.persistence.Person;		//����com.hiernate.persistence.Person��
import com.hiernate.persistence.Placard;	//����com.hiernate.persistence.Placard��
import com.hiernate.persistence.Qingjia;	//����com.hiernate.persistence.Qingjia��
import com.hiernate.persistence.Qiye;		//����com.hiernate.persistence.Qiye��
import com.hiernate.persistence.Shenhe;		//����com.hiernate.persistence.Shenhe��
import com.hiernate.persistence.TongXunAdd;	//����com.hiernate.persistence.TongXunAdd��
import com.hiernate.persistence.Tongxun;	//����com.hiernate.persistence.Tongxun��
import com.hiernate.persistence.User;		//����com.hiernate.persistence.User��
import com.hiernate.persistence.Waichu;		//����com.hiernate.persistence.Waichu��
public class GetHibernate {
	
	private static SessionFactory sf = null;//����SessionFactoryʵ��
	static {
		try {
			Configuration conf = new Configuration().addClass(User.class)
					.addClass(Menu.class).addClass(Meeting.class)
					.addClass(Placard.class).addClass(Waichu.class)
					.addClass(Qingjia.class).addClass(Chuchai.class)
					.addClass(Onduty.class).addClass(Qiye.class)
					.addClass(Bm.class).addClass(Person.class)
					.addClass(Shenhe.class).addClass(TongXunAdd.class)
					.addClass(Tongxun.class);
			 sf = conf.buildSessionFactory();
		} catch (Exception e) {
			e.printStackTrace();
		}
	}
	//���Hibernate�������ļ�ΪXML��ʽ��ֻ���������ļ�������ӳ���ļ����ڳ����в��ص���Configuration
	//���addClass����������ӳ���ļ����������£�
	// SessionFactory sf = new Configuration()
	//                     .configure().buildSessionFactory()
   public Session openSession(){			//��SessionΪ����ֵ������Session����
	   Session session = sf.openSession();   //SessionFactory��openSession()�������Sessionʵ��
	   return session;
   }
   public void closeSession(Session session){  //�����ر�Session����������ΪSessionʵ��
	   if(session != null){                //close()�����ر�session
		   session.close();
	   }
   }
  }
",java
"package org.hightail.util;

import org.junit.Test;
import static org.junit.Assert.*;

/**
 *
 * @author Joseph
 */
public class ProblemNameFormatterTest {
    private final String PROBLEM_NAME_A = ""E. 09 - _ .test""; 
    private final String PROBLEM_NAME_B = ""+T?E]S'T""; 
    private final String PROBLEM_NAME_EXPECTED_B = ""TEST"";
    
    @Test
    public void testGetFormattedNameAllowedCharacters() {
        String formattedName = ProblemNameFormatter.getFormattedName(PROBLEM_NAME_A);
        assertEquals(PROBLEM_NAME_A, formattedName);
    }
    
    @Test
    public void testGetFormattedNameNotAllowedCharacters() {
        String formattedName = ProblemNameFormatter.getFormattedName(PROBLEM_NAME_B);
        assertEquals(PROBLEM_NAME_EXPECTED_B, formattedName);
    }
}
",java
"import java.util.Scanner;

public class Main {
  static final int MODULUS = 998_244_353;

  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();

      System.out.println(solve(n));
    }

    sc.close();
  }

  static int solve(int n) {
    if (n % 2 != 0) {
      return 0;
    }

    int result = 1;
    for (int i = 1; i <= n / 2; ++i) {
      result = multiplyMod(result, i);
    }
    result = multiplyMod(result, result);

    return result;
  }

  static int multiplyMod(int x, int y) {
    return (int) ((long) x * y % MODULUS);
  }
}",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int q = sc.nextInt();
    for (int tc = 0; tc < q; ++tc) {
      String s = sc.next();
      String t = sc.next();

      System.out.println(solve(s, t) ? ""YES"" : ""NO"");
    }

    sc.close();
  }

  static boolean solve(String s, String t) {
    int sIndex = s.length() - 1;
    int tIndex = t.length() - 1;
    while (sIndex >= 0) {
      if (s.charAt(sIndex) == t.charAt(tIndex)) {
        --sIndex;
        --tIndex;

        if (tIndex == -1) {
          return true;
        }
      } else {
        sIndex -= 2;
      }
    }

    return false;
  }
}",java
"/*
 * Parabuild CI licenses this file to You under the LGPL 2.1
 * (the ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      https://www.gnu.org/licenses/lgpl-3.0.txt
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.parabuild.ci.services;

import net.sf.hibernate.HibernateException;
import net.sf.hibernate.Query;
import net.sf.hibernate.SessionFactory;
import net.sf.hibernate.cfg.Configuration;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.quartz.Scheduler;
import org.quartz.SchedulerException;
import org.quartz.SchedulerFactory;
import org.quartz.impl.StdSchedulerFactory;
import org.parabuild.ci.common.IoUtils;
import org.parabuild.ci.common.StringUtils;
import org.parabuild.ci.configuration.BuildConfigCloner;
import org.parabuild.ci.configuration.ConfigurationConstants;
import org.parabuild.ci.configuration.ConfigurationManager;
import org.parabuild.ci.configuration.PersistanceConstants;
import org.parabuild.ci.configuration.SystemConfigurationManager;
import org.parabuild.ci.configuration.SystemConfigurationManagerFactory;
import org.parabuild.ci.configuration.SystemConstants;
import org.parabuild.ci.configuration.TransactionCallback;
import org.parabuild.ci.object.*;
import org.parabuild.ci.statistics.StatisticsManager;
import org.parabuild.ci.statistics.StatisticsManagerFactory;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Iterator;
import java.util.List;
import java.util.Properties;

/**
 * @noinspection StaticFieldReferencedViaSubclass
 */
public final class ConfigurationService implements Service {

  private static final Log log = LogFactory.getLog(ConfigurationService.class);
  private SessionFactory sessionFactory = null;


  private byte status = SERVICE_STATUS_NOT_STARTED;


  /**
   * Returns serivce status
   *
   * @return service status
   */
  public byte getServiceStatus() {
    return status;
  }


  public void shutdownService() {
    try {
      shutdownQuarts();
    } catch (Exception e) {
      System.err.println(""Error while shutting down configuration service: "" + StringUtils.toString(e)); // NOPMD
    }
  }


  private void shutdownQuarts() throws SchedulerException {
    final SchedulerFactory factory = new StdSchedulerFactory();
    final Scheduler scheduler = factory.getScheduler();
    scheduler.shutdown();
  }


  public ServiceName serviceName() {
    return ServiceName.CONFIGURATION_SERVICE;
  }


  public void startupService() {
    try {
      initConfigManager();
      initQuartz();
      status = SERVICE_STATUS_STARTED;
      runPostStartUpActions();
    } catch (Exception e) {
      log.error(""Error while starting configuration service"", e);
    }
  }


  /**
   * Starts up Quartz scheduler.
   */
  private void initQuartz() throws SchedulerException {
    final SchedulerFactory factory = new StdSchedulerFactory();
    final Scheduler scheduler = factory.getScheduler();
    scheduler.start();
  }


  /**
   * Inits configuration manager
   */
  private void initConfigManager() throws HibernateException, IOException {

    // get props made from config/hibernate.properties
    final Properties props = new Properties();
    props.load(IoUtils.stringToInputStream(IoUtils.getResourceAsString(""hibernate.properties"")));

    // init hibernate
    final Configuration cfg = new Configuration();
    cfg.setProperties(props);
    cfg.setProperty(""hibernate.connection.url"", ""jdbc:hsqldb:"" + ConfigurationConstants.DATABASE_HOME.getAbsolutePath() + "";ifexists=true"");
    cfg.setProperty(""hibernate.connection.password"", PersistanceConstants.DATABASE_PASSWORD);
    cfg.setProperty(""hibernate.connection.username"", PersistanceConstants.DATABASE_USER_NAME);
    cfg.addClass(BuildConfig.class)
            .addClass(User.class)
            .addClass(SystemProperty.class)
            .addClass(VCSUserToEmailMap.class)
            .addClass(ScheduleProperty.class)
            .addClass(LabelProperty.class)
            .addClass(SourceControlSetting.class)
            .addClass(BuildRun.class)
            .addClass(StepRun.class)
            .addClass(StepLog.class)
            .addClass(Change.class)
            .addClass(ChangeList.class)
            .addClass(BuildRunParticipant.class)
            .addClass(ScheduleItem.class)
            .addClass(BuildConfigAttribute.class)
            .addClass(BuildWatcher.class)
            .addClass(BuildChangeList.class)
            .addClass(LogConfig.class)
            .addClass(LogConfigProperty.class)
            .addClass(BuildRunAttribute.class)
            .addClass(IssueTracker.class)
            .addClass(IssueTrackerProperty.class)
            .addClass(Issue.class)
            .addClass(IssueAttribute.class)
            .addClass(ReleaseNote.class)
            .addClass(PendingIssue.class)
            .addClass(IssueChangeList.class)
            .addClass(StepRunAttribute.class)
            .addClass(Group.class)
            .addClass(UserGroup.class)
            .addClass(GroupBuildAccess.class)
            .addClass(ResultConfig.class)
            .addClass(ResultConfigProperty.class)
            .addClass(StepResult.class)
            .addClass(UserProperty.class)
            .addClass(ActiveBuild.class)
            .addClass(ActiveBuildAttribute.class)
            .addClass(HourlyStats.class)
            .addClass(DailyStats.class)
            .addClass(YearlyStats.class)
            .addClass(MonthlyStats.class)
            .addClass(HourlyDistribution.class)
            .addClass(WeekDayDistribution.class)
            .addClass(StartParameter.class)
            .addClass(DisplayGroup.class)
            .addClass(DisplayGroupBuild.class)
            .addClass(BuilderConfiguration.class)
            .addClass(AgentConfig.class)
            .addClass(BuilderAgent.class)
            .addClass(HourlyTestStats.class)
            .addClass(DailyTestStats.class)
            .addClass(MonthlyTestStats.class)
            .addClass(YearlyTestStats.class)
            .addClass(ResultGroup.class)
            .addClass(PublishedStepResult.class)
            .addClass(ResultGroupAccess.class)
            .addClass(BuildRunAction.class)
            .addClass(BuildRunDependence.class)
            .addClass(Project.class)
            .addClass(ProjectAttribute.class)
            .addClass(ProjectBuild.class)
            .addClass(ProjectResultGroup.class)
            .addClass(MergeServiceConfiguration.class)
            .addClass(MergeConfiguration.class)
            .addClass(MergeConfigurationAttribute.class)
            .addClass(Merge.class)
            .addClass(MergeSourceBuildRun.class)
            .addClass(MergeTargetBuildRun.class)
            .addClass(MergeChangeList.class)
            .addClass(BranchChangeList.class)
            .addClass(BranchBuildRunParticipant.class)
            .addClass(PromotionPolicy.class)
            .addClass(PromotionPolicyStep.class)
            .addClass(PromotionStepDependency.class)
            .addClass(TestSuiteName.class)
            .addClass(TestCaseName.class)
            .addClass(BuildRunTest.class)
            .addClass(GlobalVCSUserMap.class)
            .addClass(BuildChangeListAttribute.class)
            .addClass(BuildSequence.class);
    if (log.isDebugEnabled()) {
      log.debug(""creating session factory"");
    }
    sessionFactory = cfg.buildSessionFactory();
  }


  /**
   * Runs actions that might need to run at startup.
   */
  private void runPostStartUpActions() {
    if (Boolean.valueOf(System.getProperty(SystemConstants.SYSTEM_PROPERTY_POPULATE_BUILD_RUN_CONFIGS, ""false"")).booleanValue()) {
      // have to create missing build run configs.
      final List buildRunList = (List) ConfigurationManager.runInHibernate(new TransactionCallback() {
        public Object runInTransaction() throws Exception {
          final Collection result = new ArrayList(7777);
          // get all build runs that are tied to active builds
          // (i.e. don't have copy versions of build configs.
          // that is, we can use build run's config id being
          // cerain it is an active build config.

          // first process automatic
          final Query qNonRef = session.createQuery(
                  "" select br from BuildRun br, BuildConfig bc, ActiveBuild ab "" +
                          ""   where br.buildID = bc.buildID "" +
                          ""     and bc.buildID = ab.ID"" +
                          ""     and bc.sourceControl != ?"");
          qNonRef.setInteger(0, BuildConfig.SCM_REFERENCE);
          result.addAll(qNonRef.list());

          // than process sched/ref
          final Query qRef = session.createQuery(
                  "" select br from BuildRun br, BuildConfig bc, ActiveBuild ab "" +
                          ""   where br.buildID = bc.buildID "" +
                          ""     and bc.buildID = ab.ID"" +
                          ""     and bc.sourceControl = ?"");
          qRef.setInteger(0, BuildConfig.SCM_REFERENCE);
          result.addAll(qRef.list());

          // traverse result
          return result;
        }
      });

      final BuildConfigCloner cloner = new BuildConfigCloner();
      for (final Iterator i = buildRunList.iterator(); i.hasNext();) {
        final BuildRun buildRun = (BuildRun) i.next();
        // have to create missing build run configs.
        ConfigurationManager.runInHibernate(new TransactionCallback() {
          public Object runInTransaction() throws Exception {
            if (log.isDebugEnabled()) {
              log.debug(""Will create config for "" + buildRun);
            }
            // create build run config copy
            final BuildConfig newBuildRunConfig = cloner.createBuildRunConfig(buildRun.getBuildID(), ""null"");
            // set new ID
            buildRun.setBuildID(newBuildRunConfig.getBuildID());
            // save
            session.saveOrUpdate(buildRun);
            // flush - size of the session object can be pretty build.
            session.flush();
            if (log.isDebugEnabled()) {
              log.debug(""Created config "" + buildRun.getBuildRunID());
            }
            return null;
          }
        });
      }
    }

    // init statistics if requested by updater
    if (Boolean.valueOf(System.getProperty(SystemConstants.SYSTEM_PROPERTY_INIT_STATISTICS, ""false"")).booleanValue()) {
      final ConfigurationManager cm = ConfigurationManager.getInstance();
      for (final Iterator i = cm.getExistingBuildConfigs().iterator(); i.hasNext();) {
        final StatisticsManager statisticsManager = StatisticsManagerFactory
                .getStatisticsManager(((BuildConfig) i.next()).getActiveBuildID());
        statisticsManager.initStatistics();
      }
    }

    // enable advanced settings if missed. this is done for customers that
    // already used Parabuild when advanced seeting appeared - they should
    // have it enabled so that they don't face change of UI behaviour.
    final SystemConfigurationManager scm = SystemConfigurationManagerFactory.getManager();
    if (Boolean.valueOf(System.getProperty(SystemConstants.SYSTEM_PROPERTY_INIT_ADVANCED_SETTINGS, ""false"")).booleanValue()) {
      scm.createSystemPropertyIfDoesNotExist(SystemProperty.ENABLE_ADVANCED_BUILD_SETTING, SystemProperty.OPTION_CHECKED);
    }

    // Init retry settings
    if (Boolean.valueOf(System.getProperty(SystemConstants.SYSTEM_PROPERTY_INIT_RETRY_SETTINGS, ""false"")).booleanValue()) {
      scm.createSystemPropertyIfDoesNotExist(SystemProperty.RETRY_VCS_COMMAND_INTERVAL, SystemProperty.DEFAULT_RETRY_VCS_COMMAND_INTERVAL);
      scm.createSystemPropertyIfDoesNotExist(SystemProperty.RETRY_VCS_COMMAND_TIMES, SystemProperty.DEFAULT_RETRY_VCS_COMMAND_TIMES);
      scm.createSystemPropertyIfDoesNotExist(SystemProperty.RETRY_VCS_COMMAND_PATTERNS, SystemProperty.DEFAULT_RETRY_VCS_COMMAND_PATTERNS);
    }


    //
    // Set default values if not set
    //
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.ROUND_ROBIN_LOAD_BALANCING, SystemProperty.OPTION_CHECKED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.DEFAULT_BUILD_NAME_VALIDATION, SystemProperty.RADIO_SELECTED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.DEFAULT_VARIABLE_NAME_VALIDATION, SystemProperty.RADIO_SELECTED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.CUSTOM_BUILD_NAME_VALIDATION, SystemProperty.RADIO_UNSELECTED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.CUSTOM_VARIABLE_NAME_VALIDATION, SystemProperty.RADIO_UNSELECTED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.USE_XML_LOG_FORMAT_FOR_SUBVERSION, SystemProperty.OPTION_CHECKED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.NOTIFY_USERS_WITH_EDIT_RIGHTS_ABOUT_SYSTEM_ERRORS, SystemProperty.OPTION_CHECKED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.RESPECT_INTERMEDIATE_STEP_FAILURE, SystemProperty.OPTION_CHECKED);
    scm.createSystemPropertyIfDoesNotExist(SystemProperty.MAX_PARALLEL_UPGRADES, ""2"");
  }


  public SessionFactory getSessionFactory() {
    validateIsUp();
    return sessionFactory;
  }


  private void validateIsUp() {
    if (status != SERVICE_STATUS_STARTED) {
      throw new IllegalStateException(""Service "" + serviceName() + "" has not started yet"");
    }
  }


  public String toString() {
    return ""ConfigurationService{"" +
            ""status="" + status +
            '}';
  }
}
",java
"/*
 * Copyright (c) 2014-2022 All Rights Reserved by the RWS Group for and on behalf of its affiliates and subsidiaries.
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.sdl.odata.edm.factory.annotations;

import com.sdl.odata.api.edm.ODataEdmException;
import com.sdl.odata.api.edm.annotations.EdmActionImport;
import com.sdl.odata.test.model.ActionSample;
import com.sdl.odata.test.model.Address;
import com.sdl.odata.test.model.Category;
import com.sdl.odata.test.model.Customer;
import com.sdl.odata.test.model.ExampleFlags;
import com.sdl.odata.test.model.Order;
import com.sdl.odata.test.model.OrderLine;
import com.sdl.odata.test.model.Product;
import org.junit.Test;

/**
 * Annotation Action Import Factory test.
 */
public class AnnotationActionImportFactoryTest {
    @Test(expected = IllegalArgumentException.class)
    public void testLookupGetFunctionFail() throws ODataEdmException {
        AnnotationEntityDataModelFactory factory = new AnnotationEntityDataModelFactory();

        factory.addClass(Address.class);
        factory.addClass(Category.class);
        factory.addClass(Customer.class);
        factory.addClass(Order.class);
        factory.addClass(OrderLine.class);
        factory.addClass(Product.class);
        factory.addClass(ExampleFlags.class);
        factory.addClass(ActionSample.class);
        factory.addClass(WrongActionImportSample.class);
        factory.setSchemaAlias(""ODataDemo"", ""TestAlias"");

        factory.buildEntityDataModel();
    }

    @Test(expected = IllegalArgumentException.class)
    public void testLookupGetFunctionNoEntitySetFail() throws ODataEdmException {
        AnnotationEntityDataModelFactory factory = new AnnotationEntityDataModelFactory();

        factory.addClass(Address.class);
        factory.addClass(Category.class);
        factory.addClass(Customer.class);
        factory.addClass(Order.class);
        factory.addClass(OrderLine.class);
        factory.addClass(Product.class);
        factory.addClass(ExampleFlags.class);
        factory.addClass(ActionSample.class);
        factory.addClass(ActionImportWithoutEntitySetDefinedSample.class);
        factory.setSchemaAlias(""ODataDemo"", ""TestAlias"");

        factory.buildEntityDataModel();
    }

    /**
     * Action import sample without defined name and other annotation fields.
     */
    @EdmActionImport(entitySet = ""Customers"")
    public static class WrongActionImportSample {
    }

    /**
     * Action import sample without defined entity set.
     */
    @EdmActionImport
    public static class ActionImportWithoutEntitySetDefinedSample {
    }
}
",java
"import java.util.Arrays;
import java.util.Scanner;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int n = sc.nextInt();
    int[] a = new int[n];
    for (int i = 0; i < a.length; ++i) {
      a[i] = sc.nextInt();
    }

    System.out.println(solve(a));

    sc.close();
  }

  static String solve(int[] a) {
    return Arrays.stream(a)
        .map(Main::computeMinOperationNum)
        .mapToObj(String::valueOf)
        .collect(Collectors.joining("" ""));
  }

  static int computeMinOperationNum(int x) {
    return IntStream.range(0, 15)
        .map(
            i -> {
              int oneBit = Integer.lowestOneBit(Math.floorMod(x + i, 32768));

              return i + ((oneBit == 0) ? 0 : (15 - Integer.numberOfTrailingZeros(oneBit)));
            })
        .min()
        .getAsInt();
  }
}",java
"import java.util.Arrays;
import java.util.Scanner;
import java.util.stream.IntStream;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a) ? ""YES"" : ""NO"");
    }

    sc.close();
  }

  static boolean solve(int[] a) {
    int[] values = Arrays.stream(a).boxed().sorted().distinct().mapToInt(x -> x).toArray();

    return values.length == 1
        || values[0] >= 2
        || (values[0] == 0 && values[1] >= 2)
        || !((values[0] == 0 && values[1] == 1)
            || IntStream.range(0, values.length - 1).anyMatch(i -> values[i] + 1 == values[i + 1]));
  }
}",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      int n = sc.nextInt();
      int k = sc.nextInt();
      int[] a = new int[n];
      for (int i = 0; i < a.length; ++i) {
        a[i] = sc.nextInt();
      }

      System.out.println(solve(a, k));
    }

    sc.close();
  }

  static long solve(int[] a, int k) {
    long result = Long.MIN_VALUE;
    for (int j = a.length - 1; j >= 0; --j) {
      for (int i = j - 1; i >= 0 && (i + 1L) * (j + 1) >= result; --i) {
        result = Math.max(result, (i + 1L) * (j + 1) - (long) k * (a[i] | a[j]));
      }
    }

    return result;
  }
}",java
"import java.util.Scanner;

public class Main {
  public static void main(String[] args) {
    Scanner sc = new Scanner(System.in);

    int t = sc.nextInt();
    for (int tc = 0; tc < t; ++tc) {
      String s = sc.next();

      System.out.println(solve(s));
    }

    sc.close();
  }

  static String solve(String s) {
    int n = s.length();

    boolean[][] palindromes = new boolean[n][n];
    for (int i = 0; i < n; ++i) {
      for (int j = 0; j <= 1; ++j) {
        for (int beginIndex = i, endIndex = i + j;
            beginIndex >= 0 && endIndex < n && s.charAt(beginIndex) == s.charAt(endIndex);
            --beginIndex, ++endIndex) {
          palindromes[beginIndex][endIndex] = true;
        }
      }
    }

    int bestLeftLength = -1;
    int bestRightLength = -1;
    for (int leftLength = 0; leftLength <= n; ++leftLength) {
      for (int rightLength = 0; leftLength + rightLength <= n; ++rightLength) {
        if (rightLength <= leftLength
            && rightLength != 0
            && s.charAt(n - rightLength) != s.charAt(rightLength - 1)) {
          break;
        }

        int beginIndex;
        int endIndex;
        if (leftLength <= rightLength) {
          beginIndex = n - leftLength - (rightLength - leftLength);
          endIndex = n - leftLength - 1;
        } else {
          beginIndex = rightLength;
          endIndex = leftLength - 1;
        }

        if ((leftLength == rightLength || palindromes[beginIndex][endIndex])
            && leftLength + rightLength >= bestLeftLength + bestRightLength) {
          bestLeftLength = leftLength;
          bestRightLength = rightLength;
        }
      }
    }

    return String.format(""%s%s"", s.substring(0, bestLeftLength), s.substring(n - bestRightLength));
  }
}",java
"/*
* Copyright (C) 2007-2007 the GSAN - Sistema Integrado de Gest�o de Servi�os de Saneamento
*
* This file is part of GSAN, an integrated service management system for Sanitation
*
* GSAN is free software; you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation; either version 2 of the License.
*
* GSAN is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with this program; if not, write to the Free Software
* Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA
*/

/*
* GSAN - Sistema Integrado de Gest�o de Servi�os de Saneamento
* Copyright (C) <2007> 
* Adriano Britto Siqueira
* Alexandre Santos Cabral
* Ana Carolina Alves Breda
* Ana Maria Andrade Cavalcante
* Aryed Lins de Ara�jo
* Bruno Leonardo Rodrigues Barros
* Carlos Elmano Rodrigues Ferreira
* Cl�udio de Andrade Lira
* Denys Guimar�es Guenes Tavares
* Eduardo Breckenfeld da Rosa Borges
* Fab�ola Gomes de Ara�jo
* Fl�vio Leonardo Cavalcanti Cordeiro
* Francisco do Nascimento J�nior
* Homero Sampaio Cavalcanti
* Ivan S�rgio da Silva J�nior
* Jos� Edmar de Siqueira
* Jos� Thiago Ten�rio Lopes
* K�ssia Regina Silvestre de Albuquerque
* Leonardo Luiz Vieira da Silva
* M�rcio Roberto Batista da Silva
* Maria de F�tima Sampaio Leite
* Micaela Maria Coelho de Ara�jo
* Nelson Mendon�a de Carvalho
* Newton Morais e Silva
* Pedro Alexandre Santos da Silva Filho
* Rafael Corr�a Lima e Silva
* Rafael Francisco Pinto
* Rafael Koury Monteiro
* Rafael Palermo de Ara�jo
* Raphael Veras Rossiter
* Roberto Sobreira Barbalho
* Rodrigo Avellar Silveira
* Rosana Carvalho Barbosa
* S�vio Luiz de Andrade Cavalcante
* Tai Mu Shih
* Thiago Augusto Souza do Nascimento
* Tiago Moreno Rodrigues
* Vivianne Barbosa Sousa
*
* Este programa � software livre; voc� pode redistribu�-lo e/ou
* modific�-lo sob os termos de Licen�a P�blica Geral GNU, conforme
* publicada pela Free Software Foundation; vers�o 2 da
* Licen�a.
* Este programa � distribu�do na expectativa de ser �til, mas SEM
* QUALQUER GARANTIA; sem mesmo a garantia impl�cita de
* COMERCIALIZA��O ou de ADEQUA��O A QUALQUER PROP�SITO EM
* PARTICULAR. Consulte a Licen�a P�blica Geral GNU para obter mais
* detalhes.
* Voc� deve ter recebido uma c�pia da Licen�a P�blica Geral GNU
* junto com este programa; se n�o, escreva para Free Software
* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
* 02111-1307, USA.
*/  
package gcom.util;

import gcom.arrecadacao.ArrecadacaoContabilParametros;
import gcom.arrecadacao.ArrecadacaoDadosDiarios;
import gcom.arrecadacao.ArrecadacaoForma;
import gcom.arrecadacao.Arrecadador;
import gcom.arrecadacao.ArrecadadorContrato;
import gcom.arrecadacao.ArrecadadorContratoTarifa;
import gcom.arrecadacao.ArrecadadorMovimento;
import gcom.arrecadacao.ArrecadadorMovimentoItem;
import gcom.arrecadacao.BandeiraCartao;
import gcom.arrecadacao.ContratoDemanda;
import gcom.arrecadacao.ContratoMotivoCancelamento;
import gcom.arrecadacao.DebitoCarteiraMovimento;
import gcom.arrecadacao.DeducaoTipo;
import gcom.arrecadacao.Devolucao;
import gcom.arrecadacao.DevolucaoDadosDiarios;
import gcom.arrecadacao.DevolucaoHistorico;
import gcom.arrecadacao.DevolucaoSituacao;
import gcom.arrecadacao.GuiaDevolucao;
import gcom.arrecadacao.MetasArrecadacao;
import gcom.arrecadacao.MovimentoCartaoRejeita;
import gcom.arrecadacao.RecebimentoTipo;
import gcom.arrecadacao.RegistroCodigo;
import gcom.arrecadacao.ResumoArrecadacao;
import gcom.arrecadacao.aviso.AvisoAcerto;
import gcom.arrecadacao.aviso.AvisoBancario;
import gcom.arrecadacao.aviso.AvisoDeducoes;
import gcom.arrecadacao.banco.Agencia;
import gcom.arrecadacao.banco.Banco;
import gcom.arrecadacao.banco.ContaBancaria;
import gcom.arrecadacao.debitoautomatico.DebitoAutomatico;
import gcom.arrecadacao.debitoautomatico.DebitoAutomaticoMovimento;
import gcom.arrecadacao.debitoautomatico.DebitoAutomaticoMovimentoParcelamentoCliente;
import gcom.arrecadacao.debitoautomatico.DebitoAutomaticoParcelamentoCliente;
import gcom.arrecadacao.debitoautomatico.DebitoAutomaticoRetornoCodigo;
import gcom.arrecadacao.pagamento.GuiaPagamento;
import gcom.arrecadacao.pagamento.GuiaPagamentoCategoria;
import gcom.arrecadacao.pagamento.GuiaPagamentoCategoriaHistorico;
import gcom.arrecadacao.pagamento.GuiaPagamentoHistorico;
import gcom.arrecadacao.pagamento.GuiaPagamentoItem;
import gcom.arrecadacao.pagamento.GuiaPagamentoItemCategoria;
import gcom.arrecadacao.pagamento.GuiaPagamentoItemCategoriaHistorico;
import gcom.arrecadacao.pagamento.GuiaPagamentoItemHistorico;
import gcom.arrecadacao.pagamento.GuiaPagamentoParcelamentoCartao;
import gcom.arrecadacao.pagamento.Pagamento;
import gcom.arrecadacao.pagamento.PagamentoCartaoDebito;
import gcom.arrecadacao.pagamento.PagamentoCartaoDebitoItem;
import gcom.arrecadacao.pagamento.PagamentoHistorico;
import gcom.arrecadacao.pagamento.PagamentoSituacao;
import gcom.arrecadacao.pagamento.SequenciaCartao;
import gcom.atendimentopublico.EspecificacaoPavimentacaoServicoTipo;
import gcom.atendimentopublico.EspecificacaoUnidadeCobranca;
import gcom.atendimentopublico.FiscalizarParametroCalculoDebito;
import gcom.atendimentopublico.LigacaoOrigem;
import gcom.atendimentopublico.ResolucaoImagem;
import gcom.atendimentopublico.contratoadesao.ContratoAdesao;
import gcom.atendimentopublico.ligacaoagua.CorteTipo;
import gcom.atendimentopublico.ligacaoagua.EmissaoOrdemCobrancaTipo;
import gcom.atendimentopublico.ligacaoagua.LigacaoAgua;
import gcom.atendimentopublico.ligacaoagua.LigacaoAguaDiametro;
import gcom.atendimentopublico.ligacaoagua.LigacaoAguaMaterial;
import gcom.atendimentopublico.ligacaoagua.LigacaoAguaPerfil;
import gcom.atendimentopublico.ligacaoagua.LigacaoAguaSituacao;
import gcom.atendimentopublico.ligacaoagua.LigacaoAguaSituacaoConsumoTipo;
import gcom.atendimentopublico.ligacaoagua.MotivoCorte;
import gcom.atendimentopublico.ligacaoagua.RamalLocalInstalacao;
import gcom.atendimentopublico.ligacaoagua.SupressaoTipo;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgoto;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoCaixaInspecao;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoDestinoAguasPluviais;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoDestinoDejetos;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoDiametro;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoEsgotamento;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoMaterial;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoPerfil;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoSituacao;
import gcom.atendimentopublico.ligacaoesgoto.LigacaoEsgotoSituacaoConsumoTipo;
import gcom.atendimentopublico.ordemservico.AnormalidadeComandoOSS;
import gcom.atendimentopublico.ordemservico.ArquivoTextoAcompanhamentoServico;
import gcom.atendimentopublico.ordemservico.ArquivoTextoRetornoAcaoVisitaCampo;
import gcom.atendimentopublico.ordemservico.ArquivoTextoRetornoClienteFoneVisitaCampo;
import gcom.atendimentopublico.ordemservico.ArquivoTextoRetornoClienteVisitaCampo;
import gcom.atendimentopublico.ordemservico.ArquivoTextoRetornoVisitaCampo;
import gcom.atendimentopublico.ordemservico.ArquivoTextoVisitaCampo;
import gcom.atendimentopublico.ordemservico.Atividade;
import gcom.atendimentopublico.ordemservico.BoletimOsConcluida;
import gcom.atendimentopublico.ordemservico.CapacidHidrComandoOSS;
import gcom.atendimentopublico.ordemservico.ClieFoneSeletivaVisitaCampo;
import gcom.atendimentopublico.ordemservico.ClieOsSeletivaVisitaCampo;
import gcom.atendimentopublico.ordemservico.ComandoOrdemSeletiva;
import gcom.atendimentopublico.ordemservico.CoordenadaPercursoEquipe;
import gcom.atendimentopublico.ordemservico.DataFiscalizacaoOsSeletiva;
import gcom.atendimentopublico.ordemservico.EquipamentosEspeciais;
import gcom.atendimentopublico.ordemservico.Equipe;
import gcom.atendimentopublico.ordemservico.EquipeComponentes;
import gcom.atendimentopublico.ordemservico.EquipeEquipamentosEspeciais;
import gcom.atendimentopublico.ordemservico.EspecificacaoServicoTipo;
import gcom.atendimentopublico.ordemservico.FiscalizacaoColetiva;
import gcom.atendimentopublico.ordemservico.FiscalizacaoFoto;
import gcom.atendimentopublico.ordemservico.FiscalizacaoSituacao;
import gcom.atendimentopublico.ordemservico.FiscalizacaoSituacaoAgua;
import gcom.atendimentopublico.ordemservico.FiscalizacaoSituacaoEsgoto;
import gcom.atendimentopublico.ordemservico.FiscalizacaoSituacaoHidrometroCapacidade;
import gcom.atendimentopublico.ordemservico.FiscalizacaoSituacaoServicoACobrar;
import gcom.atendimentopublico.ordemservico.FotoSituacaoOrdemServico;
import gcom.atendimentopublico.ordemservico.FotoTipo;
import gcom.atendimentopublico.ordemservico.LigacaoSitComandoOSS;
import gcom.atendimentopublico.ordemservico.Material;
import gcom.atendimentopublico.ordemservico.MaterialUnidade;
import gcom.atendimentopublico.ordemservico.MensagemAcompanhamentoServico;
import gcom.atendimentopublico.ordemservico.MotivoRejeicao;
import gcom.atendimentopublico.ordemservico.OSAtividadeExecucaoAcompanhamentoServico;
import gcom.atendimentopublico.ordemservico.OSAtividadeMaterialProgramacaoAcompanhamentoServico;
import gcom.atendimentopublico.ordemservico.OSAtividadeProgramacaoAcompanhamentoServico;
import gcom.atendimentopublico.ordemservico.OSPriorizacaoTipo;
import gcom.atendimentopublico.ordemservico.OSProgramacaoAcompanhamentoServico;
import gcom.atendimentopublico.ordemservico.OSProgramacaoCalibragem;
import gcom.atendimentopublico.ordemservico.OrdemServico;
import gcom.atendimentopublico.ordemservico.OrdemServicoAtividade;
import gcom.atendimentopublico.ordemservico.OrdemServicoBoletim;
import gcom.atendimentopublico.ordemservico.OrdemServicoFiscSit;
import gcom.atendimentopublico.ordemservico.OrdemServicoFoto;
import gcom.atendimentopublico.ordemservico.OrdemServicoMovimento;
import gcom.atendimentopublico.ordemservico.OrdemServicoMovimentoHistorico;
import gcom.atendimentopublico.ordemservico.OrdemServicoPavimento;
import gcom.atendimentopublico.ordemservico.OrdemServicoProgramacao;
import gcom.atendimentopublico.ordemservico.OrdemServicoSituacao;
import gcom.atendimentopublico.ordemservico.OrdemServicoUnidade;
import gcom.atendimentopublico.ordemservico.OsAtividadeMaterialExecucao;
import gcom.atendimentopublico.ordemservico.OsAtividadePeriodoExecucao;
import gcom.atendimentopublico.ordemservico.OsExecucaoEquipe;
import gcom.atendimentopublico.ordemservico.OsExecucaoEquipeComponentes;
import gcom.atendimentopublico.ordemservico.OsProgramNaoEncerMotivo;
import gcom.atendimentopublico.ordemservico.OsReferidaRetornoTipo;
import gcom.atendimentopublico.ordemservico.OsSeletivaVisitaCampo;
import gcom.atendimentopublico.ordemservico.ProgramacaoRoteiro;
import gcom.atendimentopublico.ordemservico.ServicoCobrancaValor;
import gcom.atendimentopublico.ordemservico.ServicoNaoCobrancaMotivo;
import gcom.atendimentopublico.ordemservico.ServicoPerfilTipo;
import gcom.atendimentopublico.ordemservico.ServicoTipo;
import gcom.atendimentopublico.ordemservico.ServicoTipoAtividade;
import gcom.atendimentopublico.ordemservico.ServicoTipoBoletim;
import gcom.atendimentopublico.ordemservico.ServicoTipoGrupo;
import gcom.atendimentopublico.ordemservico.ServicoTipoMaterial;
import gcom.atendimentopublico.ordemservico.ServicoTipoMotivoEncerramento;
import gcom.atendimentopublico.ordemservico.ServicoTipoOperacao;
import gcom.atendimentopublico.ordemservico.ServicoTipoPrioridade;
import gcom.atendimentopublico.ordemservico.ServicoTipoReferencia;
import gcom.atendimentopublico.ordemservico.ServicoTipoSubgrupo;
import gcom.atendimentopublico.ordemservico.SupressaoMotivo;
import gcom.atendimentopublico.portal.AcessoLojaVirtual;
import gcom.atendimentopublico.portal.QuestionarioSatisfacaoCliente;
import gcom.atendimentopublico.registroatendimento.AgenciaReguladoraMotReclamacao;
import gcom.atendimentopublico.registroatendimento.AgenciaReguladoraMotRetorno;
import gcom.atendimentopublico.registroatendimento.ArquivoProcedimentoOperacionalPadrao;
import gcom.atendimentopublico.registroatendimento.AtendimentoMotivoEncAcaoCobranca;
import gcom.atendimentopublico.registroatendimento.AtendimentoMotivoEncerramento;
import gcom.atendimentopublico.registroatendimento.AtendimentoRelacaoTipo;
import gcom.atendimentopublico.registroatendimento.EspecificacaoImovSitCriterio;
import gcom.atendimentopublico.registroatendimento.EspecificacaoImovelSituacao;
import gcom.atendimentopublico.registroatendimento.EspecificacaoTipoValidacao;
import gcom.atendimentopublico.registroatendimento.LocalOcorrencia;
import gcom.atendimentopublico.registroatendimento.LocalidadeEspecificacaoUnidade;
import gcom.atendimentopublico.registroatendimento.LocalidadeSolicTipoGrupo;
import gcom.atendimentopublico.registroatendimento.MeioSolicitacao;
import gcom.atendimentopublico.registroatendimento.OcorrenciaOperacional;
import gcom.atendimentopublico.registroatendimento.OcorrenciaOperacionalMotivo;
import gcom.atendimentopublico.registroatendimento.OcorrenciaOperacionalTipo;
import gcom.atendimentopublico.registroatendimento.RAReiteracao;
import gcom.atendimentopublico.registroatendimento.RAReiteracaoFone;
import gcom.atendimentopublico.registroatendimento.RaDadosAgenciaReguladora;
import gcom.atendimentopublico.registroatendimento.RaDadosAgenciaReguladoraFone;
import gcom.atendimentopublico.registroatendimento.RaEncerramentoComando;
import gcom.atendimentopublico.registroatendimento.RaEncerramentoComandoEspecificacoes;
import gcom.atendimentopublico.registroatendimento.RaEnderecoDescritivo;
import gcom.atendimentopublico.registroatendimento.RaMotivoReativacao;
import gcom.atendimentopublico.registroatendimento.RegistroAtendimento;
import gcom.atendimentopublico.registroatendimento.RegistroAtendimentoAnexo;
import gcom.atendimentopublico.registroatendimento.RegistroAtendimentoConta;
import gcom.atendimentopublico.registroatendimento.RegistroAtendimentoPagamentoDuplicidade;
import gcom.atendimentopublico.registroatendimento.RegistroAtendimentoSolicitante;
import gcom.atendimentopublico.registroatendimento.RegistroAtendimentoUnidade;
import gcom.atendimentopublico.registroatendimento.SolicitacaoDocumentoObrigatorio;
import gcom.atendimentopublico.registroatendimento.SolicitacaoTipo;
import gcom.atendimentopublico.registroatendimento.SolicitacaoTipoEspecificacao;
import gcom.atendimentopublico.registroatendimento.SolicitacaoTipoGrupo;
import gcom.atendimentopublico.registroatendimento.SolicitanteFone;
import gcom.atendimentopublico.registroatendimento.Tramite;
import gcom.atendimentopublico.registroatendimento.VisualizacaoRegistroAtendimentoUrgencia;
import gcom.atualizacaocadastral.AreaAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ArquivoTextoAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.AtributoAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.CepAtlzCadDM;
import gcom.atualizacaocadastral.ClienteAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ClienteFoneAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.DadosFinanceirosAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.HidrometroInstalacaoHistoricoAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ImovelAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ImovelFotoAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ImovelOcorrenciaAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ImovelSubcategoriaAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.LogradouroAtlzCadDM;
import gcom.atualizacaocadastral.LogradouroBairroAtlzCadDM;
import gcom.atualizacaocadastral.LogradouroCepAtlzCadDM;
import gcom.atualizacaocadastral.MapaAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.MensagemAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.OrdemServicoAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ParametroQuadraAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ParametroTabelaAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.ResumoDadosFinanceirosAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.RetornoAtualizacaoCadastralDM;
import gcom.atualizacaocadastral.SituacaoTransmissaoAtualizacaoCadastralDM;
import gcom.batch.FuncionalidadeIniciada;
import gcom.batch.FuncionalidadeSituacao;
import gcom.batch.Processo;
import gcom.batch.ProcessoFuncionalidade;
import gcom.batch.ProcessoIniciado;
import gcom.batch.ProcessoSituacao;
import gcom.batch.ProcessoTipo;
import gcom.batch.Relatorio;
import gcom.batch.RelatorioGerado;
import gcom.batch.UnidadeIniciada;
import gcom.batch.UnidadeProcessamento;
import gcom.batch.UnidadeSituacao;
import gcom.batch.auxiliarbatch.CobrancaDocumentoControleGeracao;
import gcom.cadastro.ArquivoTextoAtualizacaoCadastral;
import gcom.cadastro.ContaBraile;
import gcom.cadastro.ContaEmpresaSMS;
import gcom.cadastro.CpfTipo;
import gcom.cadastro.DbVersaoBase;
import gcom.cadastro.EmailClienteAlterado;
import gcom.cadastro.EmpresaContratoCadastro;
import gcom.cadastro.EmpresaContratoCadastroAtributo;
import gcom.cadastro.EnvioEmail;
import gcom.cadastro.MensagemEmailFaturamentoCobranca;
import gcom.cadastro.MensagemEmailHistorico;
import gcom.cadastro.MensagemRetornoReceitaFederal;
import gcom.cadastro.MensagemSMSFaturamentoCobranca;
import gcom.cadastro.MensagemSMSHistorico;
import gcom.cadastro.MotivoRetiradaCobranca;
import gcom.cadastro.ParametroTabelaAtualizacaoCadastro;
import gcom.cadastro.ParametrosMSGSMSEmail;
import gcom.cadastro.SMSSequenciaEnvio;
import gcom.cadastro.SistemaAndroid;
import gcom.cadastro.SituacaoAtualizacaoCadastral;
import gcom.cadastro.VersaoMobile;
import gcom.cadastro.VersaoSistemasAndroid;
import gcom.cadastro.atualizacaocadastralsimplificado.AtualizacaoCadastralSimplificado;
import gcom.cadastro.atualizacaocadastralsimplificado.AtualizacaoCadastralSimplificadoBinario;
import gcom.cadastro.atualizacaocadastralsimplificado.AtualizacaoCadastralSimplificadoCritica;
import gcom.cadastro.atualizacaocadastralsimplificado.AtualizacaoCadastralSimplificadoCriticaTipo;
import gcom.cadastro.atualizacaocadastralsimplificado.AtualizacaoCadastralSimplificadoLinha;
import gcom.cadastro.cliente.Cliente;
import gcom.cadastro.cliente.ClienteAtualizacaoCadastral;
import gcom.cadastro.cliente.ClienteConta;
import gcom.cadastro.cliente.ClienteContaAnterior;
import gcom.cadastro.cliente.ClienteContaHistorico;
import gcom.cadastro.cliente.ClienteEndereco;
import gcom.cadastro.cliente.ClienteFone;
import gcom.cadastro.cliente.ClienteFoneAtualizacaoCadastral;
import gcom.cadastro.cliente.ClienteGuiaPagamento;
import gcom.cadastro.cliente.ClienteGuiaPagamentoHistorico;
import gcom.cadastro.cliente.ClienteImovel;
import gcom.cadastro.cliente.ClienteImovelEconomia;
import gcom.cadastro.cliente.ClienteImovelFimRelacaoMotivo;
import gcom.cadastro.cliente.ClienteRelacaoTipo;
import gcom.cadastro.cliente.ClienteTipo;
import gcom.cadastro.cliente.ClienteVirtual;
import gcom.cadastro.cliente.EsferaPoder;
import gcom.cadastro.cliente.FoneTipo;
import gcom.cadastro.cliente.OrgaoExpedidorRg;
import gcom.cadastro.cliente.PessoaSexo;
import gcom.cadastro.cliente.Profissao;
import gcom.cadastro.cliente.RamoAtividade;
import gcom.cadastro.dadocensitario.FonteDadosCensitario;
import gcom.cadastro.dadocensitario.IbgeSetorCensitario;
import gcom.cadastro.dadocensitario.IbgeSetorCensitarioDado;
import gcom.cadastro.dadocensitario.LocalidadeDadosCensitario;
import gcom.cadastro.dadocensitario.MunicipioDadosCensitario;
import gcom.cadastro.descricaogenerica.DescricaoGenerica;
import gcom.cadastro.empresa.Empresa;
import gcom.cadastro.empresa.EmpresaCobranca;
import gcom.cadastro.empresa.EmpresaCobrancaFaixa;
import gcom.cadastro.empresa.EmpresaContratoCobranca;
import gcom.cadastro.endereco.Cep;
import gcom.cadastro.endereco.CepTipo;
import gcom.cadastro.endereco.EnderecoReferencia;
import gcom.cadastro.endereco.EnderecoTipo;
import gcom.cadastro.endereco.Logradouro;
import gcom.cadastro.endereco.LogradouroBairro;
import gcom.cadastro.endereco.LogradouroCep;
import gcom.cadastro.endereco.LogradouroTipo;
import gcom.cadastro.endereco.LogradouroTitulo;
import gcom.cadastro.funcionario.Funcionario;
import gcom.cadastro.funcionario.FuncionarioCargo;
import gcom.cadastro.geografico.Bairro;
import gcom.cadastro.geografico.BairroArea;
import gcom.cadastro.geografico.Microrregiao;
import gcom.cadastro.geografico.Municipio;
import gcom.cadastro.geografico.MunicipioFeriado;
import gcom.cadastro.geografico.Regiao;
import gcom.cadastro.geografico.RegiaoDesenvolvimento;
import gcom.cadastro.geografico.UnidadeFederacao;
import gcom.cadastro.imovel.AreaConstruidaFaixa;
import gcom.cadastro.imovel.CadastroOcorrencia;
import gcom.cadastro.imovel.Categoria;
import gcom.cadastro.imovel.CategoriaTipo;
import gcom.cadastro.imovel.Despejo;
import gcom.cadastro.imovel.EloAnormalidade;
import gcom.cadastro.imovel.EntidadeBeneficente;
import gcom.cadastro.imovel.FonteAbastecimento;
import gcom.cadastro.imovel.Imovel;
import gcom.cadastro.imovel.ImovelAtualizacaoCadastral;
import gcom.cadastro.imovel.ImovelCadastroOcorrencia;
import gcom.cadastro.imovel.ImovelCobrancaSituacao;
import gcom.cadastro.imovel.ImovelContaEnvio;
import gcom.cadastro.imovel.ImovelDoacao;
import gcom.cadastro.imovel.ImovelEconomia;
import gcom.cadastro.imovel.ImovelEloAnormalidade;
import gcom.cadastro.imovel.ImovelEnderecoAnterior;
import gcom.cadastro.imovel.ImovelHistoricoPerfil;
import gcom.cadastro.imovel.ImovelInscricaoAlterada;
import gcom.cadastro.imovel.ImovelPerfil;
import gcom.cadastro.imovel.ImovelPerfilCapacidadeHidrometro;
import gcom.cadastro.imovel.ImovelProgramaEspecial;
import gcom.cadastro.imovel.ImovelRamoAtividade;
import gcom.cadastro.imovel.ImovelSituacao;
import gcom.cadastro.imovel.ImovelSituacaoTipo;
import gcom.cadastro.imovel.ImovelSubcategoria;
import gcom.cadastro.imovel.ImovelSubcategoriaAtualizacaoCadastral;
import gcom.cadastro.imovel.ImovelSuprimido;
import gcom.cadastro.imovel.ImovelTipoCobertura;
import gcom.cadastro.imovel.ImovelTipoConstrucao;
import gcom.cadastro.imovel.ImovelTipoHabitacao;
import gcom.cadastro.imovel.ImovelTipoPropriedade;
import gcom.cadastro.imovel.ItemMovimentoProgramaEspecial;
import gcom.cadastro.imovel.MovimentoProgramaEspecial;
import gcom.cadastro.imovel.PavimentoCalcada;
import gcom.cadastro.imovel.PavimentoRua;
import gcom.cadastro.imovel.PerfilAlteracaoMotivo;
import gcom.cadastro.imovel.PerfilAlteracaoTipo;
import gcom.cadastro.imovel.PiscinaVolumeFaixa;
import gcom.cadastro.imovel.PocoTipo;
import gcom.cadastro.imovel.ReservatorioVolumeFaixa;
import gcom.cadastro.imovel.Subcategoria;
import gcom.cadastro.imovel.VwImovelPrincipalCategoria;
import gcom.cadastro.localidade.AreaTipo;
import gcom.cadastro.localidade.CondicaoAbastecimentoAgua;
import gcom.cadastro.localidade.GerenciaRegional;
import gcom.cadastro.localidade.GrauDificuldadeExecucao;
import gcom.cadastro.localidade.GrauIntermitencia;
import gcom.cadastro.localidade.GrauRiscoSegurancaFisica;
import gcom.cadastro.localidade.Localidade;
import gcom.cadastro.localidade.LocalidadeClasse;
import gcom.cadastro.localidade.LocalidadePorte;
import gcom.cadastro.localidade.NivelPressao;
import gcom.cadastro.localidade.Quadra;
import gcom.cadastro.localidade.QuadraFace;
import gcom.cadastro.localidade.QuadraPerfil;
import gcom.cadastro.localidade.SetorComercial;
import gcom.cadastro.localidade.UnidadeNegocio;
import gcom.cadastro.localidade.Zeis;
import gcom.cadastro.projeto.Projeto;
import gcom.cadastro.sistemaparametro.NacionalFeriado;
import gcom.cadastro.sistemaparametro.SistemaAlteracaoHistorico;
import gcom.cadastro.sistemaparametro.SistemaParametro;
import gcom.cadastro.tarifasocial.RendaTipo;
import gcom.cadastro.tarifasocial.TarifaSocialCarta;
import gcom.cadastro.tarifasocial.TarifaSocialCartaDebito;
import gcom.cadastro.tarifasocial.TarifaSocialCartaoTipo;
import gcom.cadastro.tarifasocial.TarifaSocialComandoCarta;
import gcom.cadastro.tarifasocial.TarifaSocialDadoEconomia;
import gcom.cadastro.tarifasocial.TarifaSocialExclusaoMotivo;
import gcom.cadastro.tarifasocial.TarifaSocialMotivoCarta;
import gcom.cadastro.tarifasocial.TarifaSocialRevisaoMotivo;
import gcom.cadastro.unidade.UnidadeOrganizacional;
import gcom.cadastro.unidade.UnidadeOrganizacionalMunicipio;
import gcom.cadastro.unidade.UnidadeRepavimentadoraCustoPavimentoCalcada;
import gcom.cadastro.unidade.UnidadeRepavimentadoraCustoPavimentoRua;
import gcom.cadastro.unidade.UnidadeTipo;
import gcom.cobranca.*;
import gcom.cobranca.contratoparcelamento.ContratoParcelamento;
import gcom.cobranca.contratoparcelamento.ContratoParcelamentoCliente;
import gcom.cobranca.contratoparcelamento.ContratoParcelamentoItem;
import gcom.cobranca.contratoparcelamento.ContratoParcelamentoRD;
import gcom.cobranca.contratoparcelamento.PrestacaoContratoParcelamento;
import gcom.cobranca.contratoparcelamento.PrestacaoItemContratoParcelamento;
import gcom.cobranca.contratoparcelamento.QuantidadePrestacoes;
import gcom.cobranca.contratoparcelamento.TipoRelacao;
import gcom.cobranca.parcelamento.PagamentoCartaoCreditoItem;
import gcom.cobranca.parcelamento.ParcDesctoInativVista;
import gcom.cobranca.parcelamento.Parcelamento;
import gcom.cobranca.parcelamento.ParcelamentoDescontoAntiguidade;
import gcom.cobranca.parcelamento.ParcelamentoDescontoInatividade;
import gcom.cobranca.parcelamento.ParcelamentoFaixaValor;
import gcom.cobranca.parcelamento.ParcelamentoItem;
import gcom.cobranca.parcelamento.ParcelamentoMotivoDesfazer;
import gcom.cobranca.parcelamento.ParcelamentoPagamentoCartaoCredito;
import gcom.cobranca.parcelamento.ParcelamentoPerfil;
import gcom.cobranca.parcelamento.ParcelamentoPerfilDebitos;
import gcom.cobranca.parcelamento.ParcelamentoQuantidadePrestacao;
import gcom.cobranca.parcelamento.ParcelamentoQuantidadePrestacaoSituacaoLigacaoAgua;
import gcom.cobranca.parcelamento.ParcelamentoQuantidadeReparcelamento;
import gcom.cobranca.parcelamento.ParcelamentoSituacao;
import gcom.cobranca.parcelamento.ParcelamentoTipo;
import gcom.faturamento.ConsumoFaixaCategoria;
import gcom.faturamento.ConsumoFaixaLigacao;
import gcom.faturamento.ConsumoMinimoParametro;
import gcom.faturamento.ContaRevisaoFaixaValor;
import gcom.faturamento.DocumentoNaoEntregue;
import gcom.faturamento.ExtratoQuitacao;
import gcom.faturamento.ExtratoQuitacaoItem;
import gcom.faturamento.FaturamentoAtivCronRota;
import gcom.faturamento.FaturamentoAtividade;
import gcom.faturamento.FaturamentoAtividadeCronograma;
import gcom.faturamento.FaturamentoContabilParametros;
import gcom.faturamento.FaturamentoDados;
import gcom.faturamento.FaturamentoGrupo;
import gcom.faturamento.FaturamentoGrupoCanceladoHistorico;
import gcom.faturamento.FaturamentoGrupoCronogramaMensal;
import gcom.faturamento.FaturamentoImediatoAjuste;
import gcom.faturamento.FaturamentoSituacaoComando;
import gcom.faturamento.FaturamentoSituacaoHistorico;
import gcom.faturamento.FaturamentoSituacaoMotivo;
import gcom.faturamento.FaturamentoSituacaoTipo;
import gcom.faturamento.FaturamentoTipo;
import gcom.faturamento.GuiaPagamentoGeral;
import gcom.faturamento.HistogramaAguaEconomia;
import gcom.faturamento.HistogramaAguaEconomiaSemQuadra;
import gcom.faturamento.HistogramaAguaLigacao;
import gcom.faturamento.HistogramaAguaLigacaoSemQuadra;
import gcom.faturamento.HistogramaEsgotoEconomia;
import gcom.faturamento.HistogramaEsgotoEconomiaSemQuadra;
import gcom.faturamento.HistogramaEsgotoLigacao;
import gcom.faturamento.HistogramaEsgotoLigacaoSemQuadra;
import gcom.faturamento.ImpostoTipo;
import gcom.faturamento.ImpostoTipoAliquota;
import gcom.faturamento.MotivoInterferenciaTipo;
import gcom.faturamento.MovimentoContaCategoriaConsumoFaixa;
import gcom.faturamento.MovimentoContaImpostoDeduzido;
import gcom.faturamento.MovimentoContaPrefaturada;
import gcom.faturamento.MovimentoContaPrefaturadaCategoria;
import gcom.faturamento.Prescricao;
import gcom.faturamento.QualidadeAgua;
import gcom.faturamento.QualidadeAguaPadrao;
import gcom.faturamento.ResumoFaturamentoSimulacao;
import gcom.faturamento.ResumoFaturamentoSimulacaoCredito;
import gcom.faturamento.ResumoFaturamentoSimulacaoDebito;
import gcom.faturamento.ResumoFaturamentoSituacaoEspecial;
import gcom.faturamento.ResumoFaturamentoSituacaoEspecialDetalhe;
import gcom.faturamento.TarifaTipoCalculo;
import gcom.faturamento.VencimentoAlternativo;
import gcom.faturamento.autoinfracao.AutoInfracaoSituacao;
import gcom.faturamento.autoinfracao.AutosInfracao;
import gcom.faturamento.autoinfracao.AutosInfracaoDebitoACobrar;
import gcom.faturamento.consumotarifa.ConsumoTarifa;
import gcom.faturamento.consumotarifa.ConsumoTarifaCategoria;
import gcom.faturamento.consumotarifa.ConsumoTarifaFaixa;
import gcom.faturamento.consumotarifa.ConsumoTarifaVigencia;
import gcom.faturamento.conta.Conta;
import gcom.faturamento.conta.ContaCategoria;
import gcom.faturamento.conta.ContaCategoriaConsumoFaixa;
import gcom.faturamento.conta.ContaCategoriaConsumoFaixaHistorico;
import gcom.faturamento.conta.ContaCategoriaHistorico;
import gcom.faturamento.conta.ContaComunicado;
import gcom.faturamento.conta.ContaComunicadoFaturamentoGrupo;
import gcom.faturamento.conta.ContaComunicadoQuadra;
import gcom.faturamento.conta.ContaComunicadoRota;
import gcom.faturamento.conta.ContaComunicadoSetor;
import gcom.faturamento.conta.ContaEmissao2Via;
import gcom.faturamento.conta.ContaGeral;
import gcom.faturamento.conta.ContaHistorico;
import gcom.faturamento.conta.ContaImpostosDeduzidos;
import gcom.faturamento.conta.ContaImpostosDeduzidosHistorico;
import gcom.faturamento.conta.ContaImpressao;
import gcom.faturamento.conta.ContaMensagem;
import gcom.faturamento.conta.ContaMotivoCancelamento;
import gcom.faturamento.conta.ContaMotivoInclusao;
import gcom.faturamento.conta.ContaMotivoRetificacao;
import gcom.faturamento.conta.ContaMotivoRetificacaoColuna;
import gcom.faturamento.conta.ContaMotivoRevisao;
import gcom.faturamento.conta.ContaTipo;
import gcom.faturamento.conta.Fatura;
import gcom.faturamento.conta.FaturaItem;
import gcom.faturamento.conta.FaturaItemHistorico;
import gcom.faturamento.conta.MotivoNaoEntregaDocumento;
import gcom.faturamento.conta.Refaturamento;
import gcom.faturamento.contratodemanda.ContratoDemandaFaixaConsumo;
import gcom.faturamento.contratodemanda.ContratoDemandaImovel;
import gcom.faturamento.contratodemanda.ContratoDemandaMotivoEncerramento;
import gcom.faturamento.contratodemanda.ContratoDemandaSituacao;
import gcom.faturamento.credito.CreditoARealizar;
import gcom.faturamento.credito.CreditoARealizarCategoria;
import gcom.faturamento.credito.CreditoARealizarCategoriaHistorico;
import gcom.faturamento.credito.CreditoARealizarGeral;
import gcom.faturamento.credito.CreditoARealizarHistorico;
import gcom.faturamento.credito.CreditoOrigem;
import gcom.faturamento.credito.CreditoRealizado;
import gcom.faturamento.credito.CreditoRealizadoCategoria;
import gcom.faturamento.credito.CreditoRealizadoCategoriaHistorico;
import gcom.faturamento.credito.CreditoRealizadoHistorico;
import gcom.faturamento.credito.CreditoTipo;
import gcom.faturamento.debito.DebitoACobrar;
import gcom.faturamento.debito.DebitoACobrarCategoria;
import gcom.faturamento.debito.DebitoACobrarCategoriaHistorico;
import gcom.faturamento.debito.DebitoACobrarGeral;
import gcom.faturamento.debito.DebitoACobrarHistorico;
import gcom.faturamento.debito.DebitoCobrado;
import gcom.faturamento.debito.DebitoCobradoCategoria;
import gcom.faturamento.debito.DebitoCobradoCategoriaHistorico;
import gcom.faturamento.debito.DebitoCobradoHistorico;
import gcom.faturamento.debito.DebitoCreditoSituacao;
import gcom.faturamento.debito.DebitoFaixaValore;
import gcom.faturamento.debito.DebitoTipo;
import gcom.faturamento.debito.DebitoTipoVigencia;
import gcom.financeiro.ContaAReceberContabil;
import gcom.financeiro.ContaContabil;
import gcom.financeiro.DevedoresDuvidososContabilParametro;
import gcom.financeiro.DocumentosAReceberFaixaResumo;
import gcom.financeiro.DocumentosAReceberResumo;
import gcom.financeiro.FaixaDocumentosAReceber;
import gcom.financeiro.FinanciamentoTipo;
import gcom.financeiro.LancamentoResumo;
import gcom.financeiro.LancamentoResumoConta;
import gcom.financeiro.LancamentoResumoContaHistorico;
import gcom.financeiro.LancamentoResumoValorTipo;
import gcom.financeiro.ParametrosDevedoresDuvidosos;
import gcom.financeiro.ParametrosDevedoresDuvidososItem;
import gcom.financeiro.ParametrosPerdasOrgaoPublico;
import gcom.financeiro.ParametrosPerdasSocietarias;
import gcom.financeiro.PerdasTipo;
import gcom.financeiro.ResumoDevedoresDuvidosos;
import gcom.financeiro.ResumoFaturamento;
import gcom.financeiro.ResumoReceita;
import gcom.financeiro.ValorConsumidoNaoFaturadoParametro;
import gcom.financeiro.ValorVolumesConsumidosNaoFaturado;
import gcom.financeiro.lancamento.LancamentoContabil;
import gcom.financeiro.lancamento.LancamentoContabilItem;
import gcom.financeiro.lancamento.LancamentoItem;
import gcom.financeiro.lancamento.LancamentoItemContabil;
import gcom.financeiro.lancamento.LancamentoOrigem;
import gcom.financeiro.lancamento.LancamentoTipo;
import gcom.financeiro.lancamento.LancamentoTipoItem;
import gcom.gerencial.arrecadacao.GArrecadacaoForma;
import gcom.gerencial.arrecadacao.GArrecadador;
import gcom.gerencial.arrecadacao.GDevolucaoSituacao;
import gcom.gerencial.arrecadacao.UnResumoArrecadacao;
import gcom.gerencial.arrecadacao.UnResumoArrecadacaoAguaEsgoto;
import gcom.gerencial.arrecadacao.UnResumoArrecadacaoCredito;
import gcom.gerencial.arrecadacao.UnResumoArrecadacaoOutro;
import gcom.gerencial.arrecadacao.UnResumoArrecadacaoPorAno;
import gcom.gerencial.arrecadacao.pagamento.GEpocaPagamento;
import gcom.gerencial.arrecadacao.pagamento.GPagamentoSituacao;
import gcom.gerencial.atendimentopublico.ligacaoagua.GLigacaoAguaPerfil;
import gcom.gerencial.atendimentopublico.ligacaoagua.GLigacaoAguaSituacao;
import gcom.gerencial.atendimentopublico.ligacaoesgoto.GLigacaoEsgotoPerfil;
import gcom.gerencial.atendimentopublico.ligacaoesgoto.GLigacaoEsgotoSituacao;
import gcom.gerencial.atendimentopublico.registroatendimento.GAtendimentoMotivoEncerramento;
import gcom.gerencial.atendimentopublico.registroatendimento.GMeioSolicitacao;
import gcom.gerencial.atendimentopublico.registroatendimento.GSolicitacaoTipo;
import gcom.gerencial.atendimentopublico.registroatendimento.GSolicitacaoTipoEspecificacao;
import gcom.gerencial.atendimentopublico.registroatendimento.UnResumoRegistroAtendimento;
import gcom.gerencial.atendimentopublico.registroatendimento.UnResumoRegistroAtendimentoPorAno;
import gcom.gerencial.cadastro.GEmpresa;
import gcom.gerencial.cadastro.Indicador;
import gcom.gerencial.cadastro.RgResumoLigacaoEconomia;
import gcom.gerencial.cadastro.UnResumoConsumoAgua;
import gcom.gerencial.cadastro.UnResumoIndicadorLigacaoEconomia;
import gcom.gerencial.cadastro.UnResumoLigacaoEconomia;
import gcom.gerencial.cadastro.cliente.GClienteTipo;
import gcom.gerencial.cadastro.cliente.GEsferaPoder;
import gcom.gerencial.cadastro.geografico.GBairro;
import gcom.gerencial.cadastro.geografico.GMicrorregiao;
import gcom.gerencial.cadastro.geografico.GMunicipio;
import gcom.gerencial.cadastro.geografico.GRegiao;
import gcom.gerencial.cadastro.imovel.GCategoria;
import gcom.gerencial.cadastro.imovel.GImovelPerfil;
import gcom.gerencial.cadastro.imovel.GSubcategoria;
import gcom.gerencial.cadastro.localidade.GGerenciaRegional;
import gcom.gerencial.cadastro.localidade.GLocalidade;
import gcom.gerencial.cadastro.localidade.GLocalidadePorte;
import gcom.gerencial.cadastro.localidade.GQuadra;
import gcom.gerencial.cadastro.localidade.GSetorComercial;
import gcom.gerencial.cadastro.localidade.GUnidadeNegocio;
import gcom.gerencial.cadastro.unidade.GUnidadeOrganizacional;
import gcom.gerencial.cobranca.FaixaValor;
import gcom.gerencial.cobranca.GDocumentoTipo;
import gcom.gerencial.cobranca.UnResumoIndicadoresCobranca;
import gcom.gerencial.cobranca.UnResumoParcelamento;
import gcom.gerencial.cobranca.UnResumoParcelamentoPorAno;
import gcom.gerencial.cobranca.UnResumoPendencia;
import gcom.gerencial.cobranca.UnResumoPendenciaSemQuadra;
import gcom.gerencial.faturamento.GConsumoTarifa;
import gcom.gerencial.faturamento.GFaturamentoGrupo;
import gcom.gerencial.faturamento.GImpostoTipo;
import gcom.gerencial.faturamento.UnResumoFaturamento;
import gcom.gerencial.faturamento.UnResumoIndicadoresFaturamento;
import gcom.gerencial.faturamento.UnResumoRefaturamento;
import gcom.gerencial.faturamento.credito.GCreditoOrigem;
import gcom.gerencial.faturamento.credito.GCreditoTipo;
import gcom.gerencial.faturamento.debito.GDebitoTipo;
import gcom.gerencial.financeiro.GFinanciamentoTipo;
import gcom.gerencial.financeiro.lancamento.GLancamentoItem;
import gcom.gerencial.financeiro.lancamento.GLancamentoItemContabil;
import gcom.gerencial.micromedicao.GRota;
import gcom.gerencial.micromedicao.UnResumoColetaEsgoto;
import gcom.gerencial.micromedicao.UnResumoHidrometro;
import gcom.gerencial.micromedicao.UnResumoIndicadorDesempenhoMicromedicao;
import gcom.gerencial.micromedicao.UnResumoIndicadorDesempenhoMicromedicaoRef2010;
import gcom.gerencial.micromedicao.UnResumoInstalacaoHidrometro;
import gcom.gerencial.micromedicao.UnResumoInstalacaoHidrometroPorAno;
import gcom.gerencial.micromedicao.UnResumoLeituraAnormalidade;
import gcom.gerencial.micromedicao.UnResumoMeta;
import gcom.gerencial.micromedicao.UnResumoMetasAcumulado;
import gcom.gerencial.micromedicao.consumo.GConsumoTipo;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroCapacidade;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroClasseMetrologica;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroDiametro;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroLocalArmazenagem;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroMarca;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroMotivoBaixa;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroSituacao;
import gcom.gerencial.micromedicao.hidrometro.GHidrometroTipo;
import gcom.gerencial.micromedicao.leitura.GLeituraSituacao;
import gcom.gerencial.micromedicao.medicao.GMedicaoTipo;
import gcom.gerencial.operacional.GDistritoOperacional;
import gcom.integracao.ServicoTerceiroAcompanhamentoServico;
import gcom.interceptor.Interceptador;
import gcom.micromedicao.ArquivoTextoRoteiroEmpresa;
import gcom.micromedicao.ArquivoTextoRoteiroEmpresaDivisao;
import gcom.micromedicao.ConsumoMinimoArea;
import gcom.micromedicao.ContratoEmpresaAditivo;
import gcom.micromedicao.ContratoEmpresaServico;
import gcom.micromedicao.ImovelTestesMedicaoConsumo;
import gcom.micromedicao.ItemContratoServicoTipo;
import gcom.micromedicao.ItemServico;
import gcom.micromedicao.ItemServicoContrato;
import gcom.micromedicao.Leiturista;
import gcom.micromedicao.MovimentoRoteiroEmpresa;
import gcom.micromedicao.MovimentoRoteiroEmpresaFoto;
import gcom.micromedicao.RateioTipo;
import gcom.micromedicao.ReleituraMobile;
import gcom.micromedicao.ResumoAnormalidadeLeitura;
import gcom.micromedicao.Rota;
import gcom.micromedicao.RotaAtualizacaoSeq;
import gcom.micromedicao.RoteiroEmpresa;
import gcom.micromedicao.ServicoTipoCelular;
import gcom.micromedicao.SituacaoTransmissaoLeitura;
import gcom.micromedicao.TelemetriaLog;
import gcom.micromedicao.TelemetriaLogErro;
import gcom.micromedicao.TelemetriaMov;
import gcom.micromedicao.TelemetriaMovReg;
import gcom.micromedicao.TelemetriaRetMot;
import gcom.micromedicao.consumo.ConsumoAnormalidade;
import gcom.micromedicao.consumo.ConsumoAnormalidadeAcao;
import gcom.micromedicao.consumo.ConsumoHistorico;
import gcom.micromedicao.consumo.ConsumoHistoricoAnterior;
import gcom.micromedicao.consumo.ConsumoTipo;
import gcom.micromedicao.consumo.LigacaoTipo;
import gcom.micromedicao.consumo.ResumoAnormalidadeConsumo;
import gcom.micromedicao.hidrometro.Hidrometro;
import gcom.micromedicao.hidrometro.HidrometroCapacidade;
import gcom.micromedicao.hidrometro.HidrometroClasseMetrologica;
import gcom.micromedicao.hidrometro.HidrometroClassePressao;
import gcom.micromedicao.hidrometro.HidrometroDiametro;
import gcom.micromedicao.hidrometro.HidrometroFaixaIdade;
import gcom.micromedicao.hidrometro.HidrometroFatorCorrecao;
import gcom.micromedicao.hidrometro.HidrometroInstalacaoHistorico;
import gcom.micromedicao.hidrometro.HidrometroLocalArmazenagem;
import gcom.micromedicao.hidrometro.HidrometroLocalInstalacao;
import gcom.micromedicao.hidrometro.HidrometroMarca;
import gcom.micromedicao.hidrometro.HidrometroMotivoBaixa;
import gcom.micromedicao.hidrometro.HidrometroMotivoMovimentacao;
import gcom.micromedicao.hidrometro.HidrometroMovimentacao;
import gcom.micromedicao.hidrometro.HidrometroMovimentado;
import gcom.micromedicao.hidrometro.HidrometroProtecao;
import gcom.micromedicao.hidrometro.HidrometroRelojoaria;
import gcom.micromedicao.hidrometro.HidrometroSituacao;
import gcom.micromedicao.hidrometro.HidrometroTipo;
import gcom.micromedicao.hidrometro.RetornoControleHidrometro;
import gcom.micromedicao.leitura.LeituraAnormalidade;
import gcom.micromedicao.leitura.LeituraAnormalidadeConsumo;
import gcom.micromedicao.leitura.LeituraAnormalidadeLeitura;
import gcom.micromedicao.leitura.LeituraFaixaFalsa;
import gcom.micromedicao.leitura.LeituraFiscalizacao;
import gcom.micromedicao.leitura.LeituraSituacao;
import gcom.micromedicao.leitura.LeituraTipo;
import gcom.micromedicao.medicao.MedicaoHistorico;
import gcom.micromedicao.medicao.MedicaoHistoricoAnterior;
import gcom.micromedicao.medicao.MedicaoTipo;
import gcom.mobile.execucaoordemservico.ArquivoTextoOSCobranca;
import gcom.mobile.execucaoordemservico.ArquivoTextoOSCobrancaCliente;
import gcom.mobile.execucaoordemservico.ArquivoTextoOSCobrancaItem;
import gcom.mobile.execucaoordemservico.ExecucaoOSCliente;
import gcom.mobile.execucaoordemservico.ExecucaoOSCorte;
import gcom.mobile.execucaoordemservico.ExecucaoOSFiscalizacao;
import gcom.mobile.execucaoordemservico.ExecucaoOSFoto;
import gcom.mobile.execucaoordemservico.ExecucaoOSOrdemServico;
import gcom.mobile.execucaoordemservico.ExecucaoOSSituacoesEncontradas;
import gcom.mobile.execucaoordemservico.ExecucaoOSVisita;
import gcom.mobile.execucaoordemservico.ParametrosArquivoTextoOSCobranca;
import gcom.mobile.execucaoordemservico.ParametrosArquivoTextoOSLocalidade;
import gcom.operacional.Bacia;
import gcom.operacional.DistritoOperacional;
import gcom.operacional.DivisaoEsgoto;
import gcom.operacional.FonteCaptacao;
import gcom.operacional.ProducaoAgua;
import gcom.operacional.SetorAbastecimento;
import gcom.operacional.SetorFonteCaptacao;
import gcom.operacional.SistemaAbastecimento;
import gcom.operacional.SistemaEsgoto;
import gcom.operacional.SistemaEsgotoTratamentoTipo;
import gcom.operacional.TipoCaptacao;
import gcom.operacional.ZonaAbastecimento;
import gcom.operacional.ZonaPressao;
import gcom.operacional.abastecimento.AbastecimentoProgramacao;
import gcom.operacional.abastecimento.ManutencaoProgramacao;
import gcom.seguranca.Atributo;
import gcom.seguranca.AtributoGrupo;
import gcom.seguranca.ConsultarReceitaFederal;
import gcom.seguranca.FuncionalidadeAtributo;
import gcom.seguranca.acesso.ControleLiberacaoPermissaoEspecial;
import gcom.seguranca.acesso.Funcionalidade;
import gcom.seguranca.acesso.FuncionalidadeCategoria;
import gcom.seguranca.acesso.FuncionalidadeDependencia;
import gcom.seguranca.acesso.Grupo;
import gcom.seguranca.acesso.GrupoAcesso;
import gcom.seguranca.acesso.GrupoFuncionalidadeOperacao;
import gcom.seguranca.acesso.GrupoPermissaoEspecial;
import gcom.seguranca.acesso.Modulo;
import gcom.seguranca.acesso.Operacao;
import gcom.seguranca.acesso.OperacaoEfetuada;
import gcom.seguranca.acesso.OperacaoOrdemExibicao;
import gcom.seguranca.acesso.OperacaoTabela;
import gcom.seguranca.acesso.OperacaoTipo;
import gcom.seguranca.acesso.PermissaoEspecial;
import gcom.seguranca.acesso.usuario.SolicitacaoAcesso;
import gcom.seguranca.acesso.usuario.SolicitacaoAcessoGrupo;
import gcom.seguranca.acesso.usuario.SolicitacaoAcessoSituacao;
import gcom.seguranca.acesso.usuario.Usuario;
import gcom.seguranca.acesso.usuario.UsuarioAbrangencia;
import gcom.seguranca.acesso.usuario.UsuarioAcao;
import gcom.seguranca.acesso.usuario.UsuarioAlteracao;
import gcom.seguranca.acesso.usuario.UsuarioBanco;
import gcom.seguranca.acesso.usuario.UsuarioFavorito;
import gcom.seguranca.acesso.usuario.UsuarioGrupo;
import gcom.seguranca.acesso.usuario.UsuarioGrupoRestricao;
import gcom.seguranca.acesso.usuario.UsuarioPermissaoEspecial;
import gcom.seguranca.acesso.usuario.UsuarioSenhaHistorico;
import gcom.seguranca.acesso.usuario.UsuarioSituacao;
import gcom.seguranca.acesso.usuario.UsuarioTipo;
import gcom.seguranca.parametrosistema.ParametroSistema;
import gcom.seguranca.parametrosistema.ParametroTipo;
import gcom.seguranca.transacao.AlteracaoTipo;
import gcom.seguranca.transacao.SgbdTabela;
import gcom.seguranca.transacao.SgbdTabelaColuna;
import gcom.seguranca.transacao.Tabela;
import gcom.seguranca.transacao.TabelaAtualizacaoCadastral;
import gcom.seguranca.transacao.TabelaAtualizacaoCadastralSituacao;
import gcom.seguranca.transacao.TabelaColuna;
import gcom.seguranca.transacao.TabelaColunaAtualizacaoCadastral;
import gcom.seguranca.transacao.TabelaLinhaAlteracao;
import gcom.seguranca.transacao.TabelaLinhaColunaAlteracao;

import java.io.File;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;

import org.apache.log4j.Logger;
import org.hibernate.HibernateException;
import org.hibernate.MappingException;
import org.hibernate.Session;
import org.hibernate.SessionFactory;
import org.hibernate.StatelessSession;
import org.hibernate.cfg.Configuration;
import org.hibernate.engine.EntityKey;
import org.hibernate.mapping.Column;
import org.hibernate.mapping.PersistentClass;
import org.hibernate.mapping.Property;
import org.hibernate.mapping.RootClass;
import org.w3c.dom.Document;
import org.w3c.dom.Element;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;

/**
 * Classe respons�vel pela instancia��o do Hibernate e servi�os espec�ficos da
 * tecnologia
 * 
 * @author rodrigo
 */
public class HibernateUtil {
	private static SessionFactory sessionFactory;

	private static SessionFactory sessionFactoryGerencial;
	
	private static SessionFactory sessionFactoryIntegracaoSAM;

	private static SessionFactory sessionFactoryIntegracaoIFS;

	private static SessionFactory sessionFactoryPentaho;
	
	private static Configuration configuration;
	
	private static Configuration configurationUser;

	private static Configuration configurationGerencial;
	
	private static Configuration configurationIFS;
	
	private static Configuration configurationPentaho;
		
	private static HashMap<Integer, Long> tempoSession = new HashMap<Integer, Long>();
	
	public static final Logger log;

	static { 
	      log = Logger.getLogger(""GSAN_ENTIDADES_CONSULTAS"");
	      log.debug("";ClasseChamadaN2;MetodoChamadaN2;ClasseChamadaN1;MetodoChamadaN1;NomeEntidade;QtdEntidadesConsultadas;TempoConsulta;OutrasEntidadesConsultadas"");
	}

	public static void inicializarSessionFactoryIFS() {
		configurationIFS = new Configuration();
		configurationIFS.setProperty(""hibernate.connection.datasource"",""java:/OracleIFSDS"");

		sessionFactoryIntegracaoIFS = configurationIFS.buildSessionFactory();
	}

	public static void inicializarSessionFactoryPentaho() throws ServiceLocatorException {
		if (ServiceLocator.getResource(""java:/PentahoDS"") == null) {
			return;
		}

		configurationPentaho = new Configuration();
		configurationPentaho.setProperty(""hibernate.connection.datasource"",""java:/PentahoDS"");
		configurationPentaho.setProperty(""hibernate.dialect"",""org.hibernate.dialect.PostgreSQLDialect"");

		configurationPentaho.addClass(DadosFinanceirosAtualizacaoCadastralDM.class)
			.addClass(ResumoDadosFinanceirosAtualizacaoCadastralDM.class);

		sessionFactoryPentaho = configurationPentaho.buildSessionFactory();
	}
	
	public static void inicializarSessionFactory() {

		try {
			configuration = new Configuration();
			configurationGerencial = new Configuration();
			
			verificaBaseDadosTipo(); 
			
			configurationGerencial.addClass(UnResumoArrecadacao.class).
				addClass(UnResumoArrecadacaoAguaEsgoto.class).
				addClass(UnResumoArrecadacaoCredito.class).
				addClass(UnResumoArrecadacaoOutro.class).
				addClass(UnResumoFaturamento.class).
				addClass(UnResumoColetaEsgoto.class).
				addClass(UnResumoConsumoAgua.class).
				addClass(UnResumoLigacaoEconomia.class).
				addClass(RgResumoLigacaoEconomia.class).
				addClass(GEsferaPoder.class).
				addClass(GClienteTipo.class).
				addClass(GCategoria.class).
				addClass(GSubcategoria.class).
				addClass(GRegiao.class).
				addClass(GMicrorregiao.class).
				addClass(GMunicipio.class).
				addClass(GBairro.class).
				addClass(GEpocaPagamento.class).
				addClass(GDocumentoTipo.class).
				addClass(GLocalidade.class).
				addClass(GLocalidadePorte.class).
				addClass(GLigacaoAguaPerfil.class).
				addClass(GLigacaoAguaSituacao.class).
				addClass(GLigacaoEsgotoPerfil.class).
				addClass(GLigacaoEsgotoSituacao.class).
				addClass(GRota.class).
				addClass(GPagamentoSituacao.class).
				addClass(GGerenciaRegional.class).
				addClass(GUnidadeNegocio.class).
				addClass(GSetorComercial.class).
				addClass(GQuadra.class).
				addClass(GImovelPerfil.class).
				addClass(GConsumoTipo.class).
				addClass(GLancamentoItem.class).
				addClass(GLancamentoItemContabil.class).
				addClass(GCreditoOrigem.class).
				addClass(GFinanciamentoTipo.class).
				addClass(UnResumoRegistroAtendimento.class).
				addClass(UnResumoInstalacaoHidrometro.class).
				addClass(GMeioSolicitacao.class).
				addClass(GSolicitacaoTipo.class).
				addClass(GSolicitacaoTipoEspecificacao.class).
				addClass(UnResumoParcelamento.class).
				addClass(UnResumoLeituraAnormalidade.class).
				addClass(UnResumoHidrometro.class).
				addClass(GMedicaoTipo.class).
				addClass(GHidrometroMarca.class).
				addClass(GHidrometroCapacidade.class).
				addClass(GHidrometroDiametro.class).
				addClass(GHidrometroLocalArmazenagem.class).
				addClass(GHidrometroSituacao.class).
				addClass(GHidrometroTipo.class).
				addClass(UnResumoRefaturamento.class).
				addClass(GEmpresa.class).
				addClass(GLeituraSituacao.class).
				addClass(GArrecadacaoForma.class).
				addClass(GArrecadador.class).
				addClass(UnResumoMeta.class).
				addClass(UnResumoMetasAcumulado.class).
				addClass(GDebitoTipo.class).
				addClass(GCreditoTipo.class).
				addClass(GImpostoTipo.class).
				addClass(Indicador.class).
				addClass(GConsumoTarifa.class).
				addClass(GHidrometroClasseMetrologica.class).
				addClass(GHidrometroMotivoBaixa.class).
				addClass(GFaturamentoGrupo.class).
				addClass(GUnidadeOrganizacional.class).
				addClass(FaixaValor.class).
				addClass(UnResumoIndicadoresFaturamento.class).
				addClass(UnResumoIndicadorLigacaoEconomia.class).
				addClass(UnResumoPendencia.class).
				addClass(UnResumoPendenciaSemQuadra.class).
				addClass(UnResumoIndicadorDesempenhoMicromedicao.class).
				addClass(GDevolucaoSituacao.class).
				addClass(GAtendimentoMotivoEncerramento.class).
				addClass(GDistritoOperacional.class).
				addClass(UnResumoIndicadoresCobranca.class).
				addClass(UnResumoIndicadorDesempenhoMicromedicaoRef2010.class).
				addClass(UnResumoArrecadacaoPorAno.class).
				addClass(UnResumoRegistroAtendimentoPorAno.class).
				addClass(UnResumoInstalacaoHidrometroPorAno.class).
				addClass(UnResumoParcelamentoPorAno.class);
			
			/*.addClass(GArrecadacaoForma.class).addClass(GArrecadador.class).addClass(UnResumoMeta.class).addClass(UnResumoMetasAcumulado.class)
			 .addClass(GCreditoTipo.class).addClass(GDebitoTipo.class);*/

			sessionFactoryGerencial = configurationGerencial
					.buildSessionFactory();

			//-------------------Configura��o do servidor Gerencial------------------//	
		

			configuration
			// **********************************************/
					// CLASSES DO PACOTE gcom.atendimentopublico //
					// ********************************************//
					// gcom.atendimentopublico.ligacaoagua
					.addClass(CorteTipo.class).addClass(
							EmissaoOrdemCobrancaTipo.class).addClass(
							LigacaoAgua.class).addClass(
							LigacaoAguaDiametro.class).addClass(
							LigacaoAguaMaterial.class).addClass(
							LigacaoAguaPerfil.class).addClass(
							LigacaoAguaSituacao.class).addClass(
							SupressaoTipo.class)
							
					//gvom.atendimentopublico.contratoadesao
							.addClass(ContratoAdesao.class)							
							
					// gcom.atendimentopublico.ligacaoesgoto
					.addClass(LigacaoEsgoto.class).addClass(
							LigacaoEsgotoDiametro.class).addClass(
							LigacaoEsgotoMaterial.class).addClass(
							LigacaoEsgotoPerfil.class).addClass(
							LigacaoEsgotoSituacao.class)
					// gcom.atendimentopublico.registroatendimento
					.addClass(RegistroAtendimento.class).addClass(
							AgenciaReguladoraMotReclamacao.class).addClass(
							AgenciaReguladoraMotRetorno.class).addClass(
							AtendimentoMotivoEncerramento.class).addClass(
							AtendimentoRelacaoTipo.class).addClass(
							LocalOcorrencia.class).addClass(
							MeioSolicitacao.class).addClass(
							RaDadosAgenciaReguladora.class).addClass(
							RaDadosAgenciaReguladoraFone.class).addClass(
							RaEnderecoDescritivo.class).addClass(
							RaMotivoReativacao.class).addClass(
							RegistroAtendimentoSolicitante.class).addClass(
							RegistroAtendimentoUnidade.class).addClass(
							SolicitacaoTipo.class).addClass(
							SolicitacaoTipoEspecificacao.class).addClass(
							SolicitacaoTipoGrupo.class).addClass(
							SolicitanteFone.class).addClass(Tramite.class)
					.addClass(EspecificacaoImovelSituacao.class).addClass(
							EspecificacaoImovSitCriterio.class).addClass(
							EspecificacaoTipoValidacao.class)
				    .addClass(RaEncerramentoComando.class)
				    .addClass(RaEncerramentoComandoEspecificacoes.class)
				    .addClass(RegistroAtendimentoAnexo.class)
				    .addClass(SolicitacaoDocumentoObrigatorio.class)
				    .addClass(LocalidadeEspecificacaoUnidade.class)
				    .addClass(RegistroAtendimentoConta.class)
				    .addClass(RegistroAtendimentoPagamentoDuplicidade.class)
				    .addClass(AtendimentoMotivoEncAcaoCobranca.class)
				   
					// gcom.atendimentopublico.ordemservico
					.addClass(OrdemServicoMovimento.class).addClass(OrdemServicoMovimentoHistorico.class).addClass(OrdemServico.class).addClass(ServicoTipo.class)
					.addClass(SupressaoMotivo.class).addClass(Atividade.class)
					.addClass(Equipe.class).addClass(
							EquipamentosEspeciais.class).addClass(
							EquipeComponentes.class).addClass(
							EspecificacaoServicoTipo.class).addClass(
							FiscalizacaoColetiva.class)
					.addClass(Material.class).addClass(MaterialUnidade.class)
					.addClass(OrdemServicoAtividade.class).addClass(
							OrdemServicoProgramacao.class).addClass(
							OrdemServicoUnidade.class).addClass(
							OsAtividadeMaterialExecucao.class).addClass(
							OsAtividadePeriodoExecucao.class).addClass(
							OsExecucaoEquipe.class).addClass(
							OsExecucaoEquipeComponentes.class).addClass(
							OsProgramNaoEncerMotivo.class).addClass(
							OsReferidaRetornoTipo.class).addClass(
							ProgramacaoRoteiro.class).addClass(
							ServicoCobrancaValor.class).addClass(
							ServicoNaoCobrancaMotivo.class).addClass(
							ServicoPerfilTipo.class).addClass(
							ServicoTipoAtividade.class).addClass(
							ServicoTipoGrupo.class).addClass(
							ServicoTipoMaterial.class).addClass(
							ServicoTipoOperacao.class).addClass(
							ServicoTipoPrioridade.class).addClass(
							ServicoTipoReferencia.class).addClass(
							ServicoTipoSubgrupo.class).addClass(
							LocalidadeSolicTipoGrupo.class).addClass(
							FiscalizacaoSituacao.class).addClass(
							FiscalizacaoSituacaoAgua.class).addClass(
							FiscalizacaoSituacaoEsgoto.class).addClass(
							FiscalizacaoSituacaoHidrometroCapacidade.class)
					.addClass(FiscalizacaoSituacaoServicoACobrar.class)
					.addClass(OrdemServicoPavimento.class)
					.addClass(BoletimOsConcluida.class)
					.addClass(DataFiscalizacaoOsSeletiva.class)
					.addClass(LigacaoOrigem.class)
					.addClass(VisualizacaoRegistroAtendimentoUrgencia.class)
					.addClass(OrdemServicoFiscSit.class)
					.addClass(MotivoRejeicao.class)
					.addClass(ServicoTipoBoletim.class)
					.addClass(OrdemServicoBoletim.class)
					.addClass(ContaBraile.class)
					.addClass(EspecificacaoPavimentacaoServicoTipo.class)
					.addClass(EspecificacaoUnidadeCobranca.class)
					.addClass(RAReiteracao.class)
					.addClass(RAReiteracaoFone.class)
					.addClass(OSProgramacaoCalibragem.class)
					.addClass(OSPriorizacaoTipo.class).addClass(EquipeEquipamentosEspeciais.class)
					.addClass(ArquivoTextoAcompanhamentoServico.class)
					.addClass(OSAtividadeExecucaoAcompanhamentoServico.class)
					.addClass(OSAtividadeMaterialProgramacaoAcompanhamentoServico.class)
					.addClass(OrdemServicoSituacao.class)
					.addClass(OSAtividadeProgramacaoAcompanhamentoServico.class)
					.addClass(OSProgramacaoAcompanhamentoServico.class)
					.addClass(ServicoTipoMotivoEncerramento.class)
					.addClass(OsSeletivaVisitaCampo.class)
					.addClass(ArquivoTextoVisitaCampo.class)
					.addClass(ClieOsSeletivaVisitaCampo.class)
					.addClass(ClieFoneSeletivaVisitaCampo.class)
					.addClass(OrdemServicoFoto.class)
					.addClass(FotoSituacaoOrdemServico.class)
					.addClass(MensagemAcompanhamentoServico.class)
					.addClass(CoordenadaPercursoEquipe.class)
					.addClass(ArquivoTextoRetornoVisitaCampo.class)
					.addClass(ArquivoTextoRetornoAcaoVisitaCampo.class)
					.addClass(ArquivoTextoRetornoClienteVisitaCampo.class)
					.addClass(ArquivoTextoRetornoClienteFoneVisitaCampo.class)
					.addClass(ArquivoProcedimentoOperacionalPadrao.class)
					.addClass(FiscalizarParametroCalculoDebito.class)
					.addClass(FotoTipo.class)
					.addClass(FiscalizacaoFoto.class)
					.addClass(OcorrenciaOperacionalTipo.class)
					.addClass(OcorrenciaOperacionalMotivo.class)
					.addClass(OcorrenciaOperacional.class)
					.addClass(ResolucaoImagem.class)
					// *************************************//
					// CLASSES DO PACOTE gcom.cadastro //
					// *************************************//
					.addClass(VersaoMobile.class)
					.addClass(VersaoSistemasAndroid.class)
					.addClass(SistemaAndroid.class)
					.addClass(ParametrosMSGSMSEmail.class)
					.addClass(MensagemSMSFaturamentoCobranca.class)
					.addClass(MensagemEmailFaturamentoCobranca.class)
					.addClass(MensagemEmailHistorico.class)
					.addClass(SMSSequenciaEnvio.class)
					.addClass(MensagemSMSHistorico.class)
					.addClass(ContaEmpresaSMS.class)
					// gcom.cadastro.cliente
					.addClass(CpfTipo.class)
					.addClass(Cliente.class)
					.addClass(ClienteEndereco.class)
					.addClass(ImovelCadastroOcorrencia.class)
					.addClass(ImovelEloAnormalidade.class)
					.addClass(ClienteFone.class)
					.addClass(ClienteImovel.class)
					.addClass(ClienteRelacaoTipo.class)
					.addClass(ClienteImovelEconomia.class)
					.addClass(ClienteImovelFimRelacaoMotivo.class)
					.addClass(ClienteTipo.class)
					.addClass(FoneTipo.class)
					.addClass(ClienteConta.class)
					.addClass(ClienteContaHistorico.class)
					.addClass(ClienteContaAnterior.class)
					.addClass(OrgaoExpedidorRg.class)
					.addClass(PessoaSexo.class)
					.addClass(Profissao.class)
					.addClass(RamoAtividade.class)
					.addClass(EsferaPoder.class)
					.addClass(ClienteGuiaPagamento.class)
					.addClass(ClienteGuiaPagamentoHistorico.class)
					.addClass(SituacaoAtualizacaoCadastral.class)
					.addClass(ClienteAtualizacaoCadastral.class)
					.addClass(ClienteFoneAtualizacaoCadastral.class)
					// gcom.cadastro.dadocensitario
					.addClass(LocalidadeDadosCensitario.class).addClass(
							MunicipioDadosCensitario.class).addClass(
							IbgeSetorCensitarioDado.class).addClass(
							FonteDadosCensitario.class).addClass(
							IbgeSetorCensitario.class)
					// gcom.cadastro.empresa
					.addClass(Empresa.class)
					.addClass(EmpresaCobranca.class)
					.addClass(EmpresaCobrancaFaixa.class)
					// gcom.cadastro.endereco
					.addClass(LogradouroCep.class).addClass(Cep.class)
					.addClass(CepTipo.class).addClass(EnderecoReferencia.class)
					.addClass(EnderecoTipo.class).addClass(Logradouro.class)
					.addClass(LogradouroBairro.class).addClass(
							LogradouroTipo.class).addClass(
							LogradouroTitulo.class)
					// gcom.cadastro.funcionario
					.addClass(Funcionario.class).addClass(FuncionarioCargo.class)
					// gcom.cadastro.geografico
					.addClass(Bairro.class).addClass(Microrregiao.class)
					.addClass(Municipio.class).addClass(MunicipioFeriado.class)
					.addClass(Regiao.class).addClass(
							RegiaoDesenvolvimento.class).addClass(
							UnidadeFederacao.class).addClass(BairroArea.class)
					// gcom.cadastro.imovel
					.addClass(AreaConstruidaFaixa.class).addClass(
							CadastroOcorrencia.class).addClass(
							CategoriaTipo.class).addClass(Categoria.class)
					.addClass(Despejo.class).addClass(EloAnormalidade.class)
					.addClass(FonteAbastecimento.class).addClass(Imovel.class)
					.addClass(ImovelCobrancaSituacao.class).addClass(
							ImovelEconomia.class).addClass(
							ImovelEnderecoAnterior.class).addClass(
							ImovelPerfil.class).addClass(
							ImovelSubcategoria.class).addClass(ImovelRamoAtividade.class).addClass(
							PavimentoRua.class)
					.addClass(PavimentoCalcada.class).addClass(
							PiscinaVolumeFaixa.class).addClass(PocoTipo.class)
					.addClass(ReservatorioVolumeFaixa.class).addClass(
							Subcategoria.class)
					.addClass(ImovelContaEnvio.class).addClass(
							ImovelDoacao.class).addClass(
							EntidadeBeneficente.class).addClass(
							ImovelTipoHabitacao.class).addClass(
							ImovelTipoPropriedade.class).addClass(
							ImovelTipoConstrucao.class).addClass(
							ImovelTipoCobertura.class)
							.addClass(ImovelAtualizacaoCadastral.class)
							.addClass(ImovelSubcategoriaAtualizacaoCadastral.class)
							.addClass(ImovelProgramaEspecial.class)
							.addClass(ImovelSuprimido.class)
							.addClass(ImovelInscricaoAlterada.class)
							.addClass(MovimentoProgramaEspecial.class)
							.addClass(ItemMovimentoProgramaEspecial.class)
							.addClass(ImovelPerfilCapacidadeHidrometro.class)
							.addClass(ImovelHistoricoPerfil.class)
							.addClass(PerfilAlteracaoTipo.class)
							.addClass(PerfilAlteracaoMotivo.class)
					// gcom.cadastro.localidade
					.addClass(GerenciaRegional.class)
					.addClass(Localidade.class).addClass(LocalidadePorte.class)
					.addClass(LocalidadeClasse.class).addClass(Quadra.class)
					.addClass(QuadraPerfil.class)
					.addClass(SetorComercial.class).addClass(Zeis.class)
					.addClass(AreaTipo.class).addClass(UnidadeNegocio.class)
					.addClass(QuadraFace.class)
					// gcom.cadastro.sistemaparametro
					.addClass(NacionalFeriado.class).addClass(
							SistemaParametro.class).addClass(
							SistemaAlteracaoHistorico.class)
					// gcom.cadastro.tarifasocial
					.addClass(RendaTipo.class).addClass(
							TarifaSocialCartaoTipo.class).addClass(
							TarifaSocialExclusaoMotivo.class).addClass(
							TarifaSocialDadoEconomia.class).addClass(
							TarifaSocialRevisaoMotivo.class)
					// gcom.cadastro.unidade
					.addClass(UnidadeOrganizacional.class).addClass(
							UnidadeTipo.class)
					.addClass(ArquivoTextoAtualizacaoCadastral.class)
					
					.addClass(EmpresaContratoCadastro.class)
					.addClass(EmpresaContratoCadastroAtributo.class)
					.addClass(UnidadeOrganizacionalMunicipio.class)
					// gcom.cadastro.atualizacaocadastralsimplificado
					.addClass(AtualizacaoCadastralSimplificado.class)
					.addClass(AtualizacaoCadastralSimplificadoCritica.class)
					.addClass(AtualizacaoCadastralSimplificadoBinario.class)
					.addClass(AtualizacaoCadastralSimplificadoCriticaTipo.class)
					.addClass(AtualizacaoCadastralSimplificadoLinha.class)
					// gcom.cadastro.projeto
					.addClass(Projeto.class)
					.addClass(EmpresaContratoCobranca.class)
					// gcom.cadastro.descricaogenerica
					.addClass(DescricaoGenerica.class)			
					.addClass(MensagemRetornoReceitaFederal.class)
					.addClass(ClienteVirtual.class)
					.addClass(MotivoRetiradaCobranca.class)					
					.addClass(ParametroTabelaAtualizacaoCadastro.class)
					
					// *************************************//
					// CLASSES DO PACOTE gcom.atualizacaocadastral //
					// *************************************//
					.addClass(ImovelAtualizacaoCadastralDM.class)
					.addClass(ClienteAtualizacaoCadastralDM.class)
					.addClass(ClienteFoneAtualizacaoCadastralDM.class)
					.addClass(AreaAtualizacaoCadastralDM.class)
					.addClass(ArquivoTextoAtualizacaoCadastralDM.class)
					.addClass(HidrometroInstalacaoHistoricoAtualizacaoCadastralDM.class)
					.addClass(ImovelSubcategoriaAtualizacaoCadastralDM.class)
					.addClass(ParametroQuadraAtualizacaoCadastralDM.class)
					.addClass(ParametroTabelaAtualizacaoCadastralDM.class)
					.addClass(SituacaoTransmissaoAtualizacaoCadastralDM.class)
					.addClass(CepAtlzCadDM.class)
					.addClass(LogradouroAtlzCadDM.class)
					.addClass(LogradouroBairroAtlzCadDM.class)
					.addClass(LogradouroCepAtlzCadDM.class)
					.addClass(ImovelOcorrenciaAtualizacaoCadastralDM.class)
					.addClass(ImovelFotoAtualizacaoCadastralDM.class)
					.addClass(RetornoAtualizacaoCadastralDM.class)
					.addClass(AtributoAtualizacaoCadastralDM.class)
					.addClass(MensagemAtualizacaoCadastralDM.class)
					.addClass(MapaAtualizacaoCadastralDM.class)
					.addClass(OrdemServicoAtualizacaoCadastralDM.class)
					
					// *************************************//
					// CLASSES DO PACOTE gcom.cobranca //
					// *************************************//
					.addClass(CobrancaGrupo.class).addClass(
							CobrancaSituacao.class).addClass(
							CobrancaSituacaoHistorico.class).addClass(
							CobrancaSituacaoMotivo.class).addClass(
							CobrancaSituacaoTipo.class).addClass(
							ParcelamentoGrupo.class).addClass(
							CobrancaForma.class).addClass(
							IndicesAcrescimosImpontualidade.class).addClass(
							ResumoCobrancaSituacaoEspecial.class).addClass(
							CobrancaAcaoSituacao.class).addClass(
							CobrancaDebitoSituacao.class).addClass(
							ResumoCobrancaAcao.class).addClass(
							ParcelamentoFaixaValor.class).addClass(NegativacaoComando.class)
							.addClass(NegativacaoCriterio.class).addClass(NegativacaoCriterioClienteTipo.class)
							.addClass(NegativacaoCriterioCpfTipo.class).addClass(NegativacaoCriterioImovelPerfil.class)
							.addClass(NegativacaoCriterioSubcategoria.class).addClass(NegativacaoImovei.class).addClass(Negativador.class).addClass(NegativadorContrato.class)
							.addClass(NegativadorExclusaoMotivo.class).addClass(NegativadorMovimento.class).addClass(NegativadorMovimentoReg.class)
							.addClass(NegativadorMovimentoRegItem.class).addClass(NegativadorMovimentoRegRetMot.class).addClass(NegativadorRegistroTipo.class)
							.addClass(NegativadorRetornoMotivo.class).addClass(NegativCritCobrGrupo.class)
							.addClass(NegativCritElo.class).addClass(NegativCritGerReg.class)
							.addClass(NegativCritUndNeg.class)
							.addClass(ResumoNegativacao.class)
							.addClass(NegativadorResultadoSimulacao.class).addClass(UnidadeOrganizacionalTestemunha.class)
							.addClass(CriterioSituacaoCobranca.class)
							.addClass(CriterioSituacaoLigacaoAgua.class)
							.addClass(CriterioSituacaoLigacaoEsgoto.class)
							.addClass(NegativacaoCriterioLigacaoAgua.class)
							.addClass(NegativacaoCriterioLigacaoEsgoto.class)
							.addClass(EmpresaCobrancaConta.class)
							.addClass(EmpresaCobrancaContaPagamentos.class)
							.addClass(ComandoEmpresaCobrancaConta.class)
							.addClass(ComandoEmpresaCobrancaContaExtensao.class)
							.addClass(CobrancaSituacaoComando.class)
							.addClass(NegativadorMovimentoRegParcelamento.class)
							.addClass(ParcelamentoPagamentoCartaoCredito.class)
							.addClass(PagamentoCartaoCreditoItem.class)
							.addClass(DocumentosReceberFaixaDiasVencidos.class)
							.addClass(NegativCritNegRetMot.class)
							.addClass(ParcDesctoInativVista.class)
							.addClass(CobrancaAcaoOrdemServicoNaoAceitas.class)
							.addClass(UnidadeRepavimentadoraCustoPavimentoRua.class)
							.addClass(UnidadeRepavimentadoraCustoPavimentoCalcada.class)
							.addClass(CobrancaBoletimMedicao.class)
							.addClass(CobrancaBoletimDesconto.class)
							.addClass(CobrancaBoletimExecutado.class)
							.addClass(CobrancaBoletimSucesso.class)
							.addClass(ComandoEmpresaCobrancaContaGerencia.class)
							.addClass(ComandoEmpresaCobrancaContaImovelPerfil.class)
							.addClass(ComandoEmpresaCobrancaContaUnidadeNegocio.class)
							.addClass(CmdEmpresaCobrancaContaLigacaoAguaSituacao.class)
							.addClass(MotivoNaoAceitacaoEncerramentoOS.class)
							.addClass(ComandoOrdemSeletiva.class)
							.addClass(LigacaoSitComandoOSS.class)
							.addClass(AnormalidadeComandoOSS.class)
							.addClass(CapacidHidrComandoOSS.class)
							.addClass(EmpresaCobrancaContaPenalidade.class)
							.addClass(EmpresaContaCobrancaCancelada.class)
							.addClass(EmpresaCobrancaContaBoletimMedicao.class)
							.addClass(CobrancaBoletimContrato.class)
							.addClass(BoletimMedicaoJustificativaPenalidade.class)
							.addClass(ComandoEmpresaCobrancaContaSetorComercial.class)
							.addClass(ImovelRetiradaComando.class)
							.addClass(CertidaoNegativaDebito.class)
							.addClass(ComandoAtividadeImoveis.class)
							.addClass(DividaAtivaCriterio.class)
							.addClass(DividaAtivaCriterioClienteTipo.class)
							.addClass(DividaAtivaCriterioEsferaPoder.class)
							.addClass(DividaAtivaImovel.class)
							.addClass(DividaAtivaDebito.class)
							.addClass(DividaAtivaAmortizacaoTipo.class)
							.addClass(DividaAtivaAmortizacao.class)
							.addClass(DividaAtivaAnalitico.class)							.addClass(CobrancaAcaoGrupoContrato.class)
							.addClass(ColunasTextoSMSEmail.class)
							.addClass(NegativacaoComandoImovel.class)
							// *************************************//
							// CLASSES DO PACOTE gcom.cobranca.contratoparcelamento //
							// *************************************//
							
							.addClass(ContratoParcelamentoRD.class)
							.addClass(QuantidadePrestacoes.class)
							.addClass(TipoRelacao.class)
							.addClass(ContratoParcelamento.class)
							.addClass(ContratoParcelamentoCliente.class)
							.addClass(PrestacaoContratoParcelamento.class)
							.addClass(ContratoParcelamentoItem.class)
							.addClass(PrestacaoItemContratoParcelamento.class)
							.addClass(ParcelamentoQuantidadePrestacaoSituacaoLigacaoAgua.class)
							
							// *************************************//
							// FIM CLASSES DO PACOTE gcom.cobranca.contratoparcelamento //
							// *************************************//

//							.addClass(CobrancaBoletimMedicao.class)
//							.addClass(CobrancaBoletimDesconto.class)
//							.addClass(CobrancaBoletimExecutado.class)
//							.addClass(CobrancaBoletimSucesso.class)


					// *************************************//
					// CLASSES DO PACOTE gcom.faturamento //
					// *************************************//
					.addClass(QualidadeAgua.class).addClass(ImpostoTipo.class)
					.addClass(ImpostoTipoAliquota.class).addClass(
							FaturamentoGrupo.class).addClass(
							FaturamentoSituacaoTipo.class).addClass(
							FaturamentoAtividade.class).addClass(
							FaturamentoAtividadeCronograma.class).addClass(
							FaturamentoGrupoCronogramaMensal.class).addClass(
							FaturamentoImediatoAjuste.class).addClass(
							FaturamentoSituacaoMotivo.class).addClass(
							FaturamentoSituacaoHistorico.class).addClass(
							FaturamentoTipo.class).addClass(
							FaturamentoAtivCronRota.class).addClass(
							FaturamentoDados.class).addClass(
							ResumoFaturamentoSimulacao.class)
							.addClass(ResumoFaturamentoSimulacaoDebito.class)
							.addClass(ResumoFaturamentoSimulacaoCredito.class)
							.addClass(VencimentoAlternativo.class).addClass(
							ResumoFaturamentoSituacaoEspecial.class).addClass(
							ResumoFaturamentoSituacaoEspecialDetalhe.class).addClass(
							FaturamentoContabilParametros.class).addClass(
							GuiaPagamentoGeral.class).addClass(
							DocumentoNaoEntregue.class).addClass(
							HistogramaAguaEconomia.class).addClass(
							HistogramaAguaLigacao.class).addClass(
							HistogramaEsgotoEconomia.class).addClass(
							HistogramaEsgotoLigacao.class).addClass(
							QualidadeAguaPadrao.class)
							.addClass(FaturamentoSituacaoComando.class)
							.addClass(TarifaTipoCalculo.class)
							.addClass(GuiaPagamentoParcelamentoCartao.class)
							.addClass(MotivoInterferenciaTipo.class)
							.addClass(ExtratoQuitacao.class)
							.addClass(ExtratoQuitacaoItem.class)
							.addClass(Prescricao.class)
							.addClass(ConsumoMinimoParametro.class)
							.addClass(FaturamentoGrupoCanceladoHistorico.class)
							.addClass(HistogramaEsgotoEconomiaSemQuadra.class)

					// gcom.faturamento.conta ContaMensagem
					.addClass(ContaCategoriaConsumoFaixa.class)
					.addClass(Conta.class)
					.addClass(ContaCategoria.class)
					.addClass(MotivoNaoEntregaDocumento.class)
					.addClass(Refaturamento.class)
					.addClass(Fatura.class)
					.addClass(FaturaItem.class)
					.addClass(ContaHistorico.class)
					.addClass(ContaImpostosDeduzidos.class)
					.addClass(ContaMotivoCancelamento.class)
					.addClass(ContaMotivoInclusao.class)
					.addClass(ContaMotivoRetificacao.class)
					.addClass(ContaMotivoRevisao.class)
					.addClass(ContaGeral.class)
					.addClass(ContaImpressao.class)
					.addClass(ContaCategoriaConsumoFaixaHistorico.class)
					.addClass(ContaCategoriaHistorico.class)
					.addClass(ContaImpostosDeduzidosHistorico.class)
					.addClass(ContaTipo.class)
					.addClass(ContaMotivoRetificacaoColuna.class)
					.addClass(ContaEmissao2Via.class)
									
					// gcom.faturamento.debito
					.addClass(DebitoCobrado.class).addClass(DebitoTipo.class)
					.addClass(DebitoACobrar.class).addClass(
							DebitoACobrarCategoria.class).addClass(
							DebitoCobradoHistorico.class).addClass(
							DebitoCobradoCategoria.class).addClass(
							DebitoACobrarHistorico.class).addClass(
							DebitoCreditoSituacao.class).addClass(
							ContaMensagem.class).addClass(
							DebitoACobrarGeral.class).addClass(
							DebitoTipoVigencia.class)

					// gcom.faturamento.credito
					.addClass(CreditoRealizado.class).addClass(
							CreditoARealizar.class).addClass(
							CreditoARealizarCategoria.class).addClass(
							CreditoRealizadoHistorico.class).addClass(
							CreditoRealizadoCategoria.class).addClass(
							CreditoTipo.class).addClass(
							CreditoARealizarHistorico.class).addClass(
							CreditoOrigem.class).addClass(
							CreditoARealizarGeral.class)

					// gcom.faturamento.consumotarifa
					.addClass(ConsumoTarifa.class).addClass(
							ConsumoTarifaVigencia.class).addClass(
							ConsumoTarifaCategoria.class).addClass(
							ConsumoTarifaFaixa.class)
							
					// gcom.faturamento.debito
					.addClass(DebitoFaixaValore.class)
					
					// gcom.faturamento.autoinfracao
					.addClass(AutoInfracaoSituacao.class)
					.addClass(AutosInfracao.class)
					.addClass(AutosInfracaoDebitoACobrar.class)
					.addClass(FaturaItemHistorico.class)
					.addClass(HistogramaAguaEconomiaSemQuadra.class)
					.addClass(HistogramaAguaLigacaoSemQuadra.class)
					.addClass(HistogramaEsgotoLigacaoSemQuadra.class)
					.addClass(ContaComunicado.class)
					.addClass(ContaComunicadoQuadra.class)
					.addClass(ContaComunicadoRota.class)
					.addClass(ContaComunicadoSetor.class)
					.addClass(ContaComunicadoFaturamentoGrupo.class)	
					
					// *************************************//
					// CLASSES DO PACOTE gcom.micromedicao //
					// *************************************//
					.addClass(Rota.class).addClass(RateioTipo.class).addClass(
							ImovelTestesMedicaoConsumo.class)
					.addClass(ItemContratoServicoTipo.class)		
					// gcom.micromedicao.hidrometro
					.addClass(HidrometroCapacidade.class).addClass(
							Hidrometro.class).addClass(
							HidrometroMotivoBaixa.class).addClass(
							HidrometroClasseMetrologica.class).addClass(
							HidrometroMarca.class).addClass(
							HidrometroMovimentacao.class).addClass(
							HidrometroMotivoMovimentacao.class).addClass(
							HidrometroLocalArmazenagem.class).addClass(
							HidrometroSituacao.class).addClass(
							HidrometroDiametro.class)
							.addClass(HidrometroRelojoaria.class)
							.addClass(
							HidrometroInstalacaoHistorico.class).addClass(
							HidrometroLocalInstalacao.class).addClass(
							HidrometroTipo.class).addClass(
							HidrometroProtecao.class).addClass(
							HidrometroMovimentado.class).addClass(
							Leiturista.class).addClass(
							ArquivoTextoRoteiroEmpresa.class).addClass(
							RoteiroEmpresa.class).addClass(
							ServicoTipoCelular.class).addClass(
							MovimentoRoteiroEmpresa.class)
							.addClass(ItemServico.class)
							.addClass(ContratoEmpresaServico.class)
							.addClass(ItemServicoContrato.class)
							.addClass(RetornoControleHidrometro.class)
							.addClass(TelemetriaLog.class)
							.addClass(TelemetriaLogErro.class)
							.addClass(TelemetriaMov.class)
							.addClass(TelemetriaMovReg.class)
							.addClass(TelemetriaRetMot.class)
							.addClass(ContratoEmpresaAditivo.class)
							.addClass(HidrometroFatorCorrecao.class)
							.addClass(HidrometroClassePressao.class)
							.addClass(MovimentoRoteiroEmpresaFoto.class)
							.addClass(HidrometroFaixaIdade.class)

					// gcom.micromedicao.leitura
					.addClass(LeituraTipo.class)
					.addClass(LeituraSituacao.class).addClass(
							LeituraFaixaFalsa.class).addClass(
							LeituraAnormalidadeLeitura.class).addClass(
							LeituraAnormalidade.class).addClass(
							LeituraFiscalizacao.class).addClass(
							LeituraAnormalidadeConsumo.class)
					// gcom.micromedicao.medicao //
					.addClass(MedicaoHistorico.class).addClass(
							MedicaoTipo.class)
					// gcom.micromedicao.consumo //
					.addClass(ConsumoHistorico.class).addClass(
							ConsumoTipo.class).addClass(
							ConsumoAnormalidade.class).addClass(
							LigacaoTipo.class).addClass(
							ResumoAnormalidadeConsumo.class).addClass(
							ResumoAnormalidadeLeitura.class).addClass(
							ConsumoHistoricoAnterior.class).addClass(
							MedicaoHistoricoAnterior.class).addClass(
							SituacaoTransmissaoLeitura.class).addClass(
							ConsumoMinimoArea.class).addClass(
							ConsumoAnormalidadeAcao.class).addClass(
							RotaAtualizacaoSeq.class )                                    
							.addClass( ReleituraMobile.class )


					// ************************************//
					// CLASSES DO PACOTE gcom.financeiro //
					// ************************************//
					.addClass(LancamentoContabil.class).addClass(
							LancamentoResumo.class).addClass(
							LancamentoResumoValorTipo.class).addClass(
							LancamentoResumoConta.class).addClass(
							LancamentoResumoContaHistorico.class).addClass(
							FinanciamentoTipo.class).addClass(
							LancamentoContabilItem.class).addClass(
							ContaContabil.class).addClass(
							LancamentoOrigem.class).addClass(
							ResumoFaturamento.class).addClass(
							LancamentoItem.class).addClass(
							LancamentoItemContabil.class).addClass(
							LancamentoTipoItem.class).addClass(
							LancamentoTipo.class).addClass(
							DevedoresDuvidososContabilParametro.class).addClass(
							ContaAReceberContabil.class).addClass(
							ValorVolumesConsumidosNaoFaturado.class).addClass(
							DocumentosAReceberResumo.class).addClass(
							ResumoReceita.class).addClass(
							FaixaDocumentosAReceber.class).addClass(
							DocumentosAReceberFaixaResumo.class).addClass(
							PerdasTipo.class).addClass(
							ParametrosPerdasOrgaoPublico.class).addClass(
							ParametrosPerdasSocietarias.class).addClass(
							ValorConsumidoNaoFaturadoParametro.class)

					// ************************************//
					// CLASSES DO PACOTE gcom.arrecadacao //
					// ************************************//
					// gcom.arrecadacao.banco

					.addClass(ResumoArrecadacao.class).addClass(Banco.class)
					.addClass(Agencia.class)
					// gcom.arrecadacao.pagamento
					.addClass(Pagamento.class)
					.addClass(PagamentoSituacao.class).addClass(
							GuiaPagamento.class).addClass(
							GuiaPagamentoHistorico.class).addClass(
							GuiaPagamentoCategoriaHistorico.class)
					.addClass(PagamentoCartaoDebito.class)
					.addClass(PagamentoCartaoDebitoItem.class)
					.addClass(SequenciaCartao.class)
					.addClass(GuiaPagamentoItem.class)
					.addClass(GuiaPagamentoItemHistorico.class)
					.addClass(GuiaPagamentoItemCategoria.class)
					.addClass(GuiaPagamentoItemCategoriaHistorico.class)
					// gcom.arrecadacao.debito
					.addClass(DebitoAutomatico.class).addClass(
							DebitoAutomaticoRetornoCodigo.class).addClass(
							DebitoAutomaticoMovimento.class).addClass(
							GuiaPagamentoCategoria.class).addClass(
							MetasArrecadacao.class)
					.addClass(DebitoAutomaticoParcelamentoCliente.class)
                    .addClass(DebitoAutomaticoMovimentoParcelamentoCliente.class)
					.addClass(DevolucaoHistorico.class)
					.addClass(DevolucaoDadosDiarios.class)
					.addClass(DebitoCarteiraMovimento.class)
					.addClass(BandeiraCartao.class)
					// *************************************//
					// CLASSES DO PACOTE gcom.operacional //
					// *************************************//
					.addClass(Bacia.class).addClass(DistritoOperacional.class)
					.addClass(DivisaoEsgoto.class).addClass(
							SistemaAbastecimento.class).addClass(
							SistemaEsgoto.class).addClass(
							SistemaEsgotoTratamentoTipo.class).addClass(
							AbastecimentoProgramacao.class).addClass(
							ManutencaoProgramacao.class).addClass(
							SetorAbastecimento.class).addClass(
							ZonaAbastecimento.class)
					.addClass(ZonaPressao.class).addClass(ProducaoAgua.class)
					// ************************************//
					// CLASSES DO PACOTE gcom.seguranca //
					// ************************************//
					// gcom.seguranca.acesso
					.addClass(AlteracaoTipo.class).addClass(UsuarioTipo.class)
					.addClass(TabelaLinhaAlteracao.class).addClass(
							TabelaLinhaColunaAlteracao.class).addClass(
							TabelaColuna.class).addClass(Tabela.class)
					.addClass(UsuarioAcao.class)
					.addClass(UsuarioFavorito.class)
					.addClass(GrupoAcesso.class)
					.addClass(UsuarioSenhaHistorico.class)
					//gcom.seguranca.parametrosistema
					.addClass(ParametroSistema.class)
					.addClass(ParametroTipo.class)
					// gcom.seguranca.transacao
					.addClass(SgbdTabela.class)
					.addClass(SgbdTabelaColuna.class).addClass(
							UsuarioSituacao.class).addClass(
							UsuarioPermissaoEspecial.class).addClass(
							UsuarioAlteracao.class).addClass(
							UsuarioGrupoRestricao.class).addClass(
							UsuarioGrupo.class).addClass(
							UsuarioAbrangencia.class).addClass(Usuario.class)
					.addClass(UsuarioBanco.class)
					.addClass(ResolucaoDiretoria.class).addClass(
							CreditoRealizadoCategoriaHistorico.class).addClass(
							CreditoARealizarCategoriaHistorico.class).addClass(
							DebitoCobradoCategoriaHistorico.class).addClass(
							DebitoACobrarCategoriaHistorico.class).addClass(
							PermissaoEspecial.class).addClass(
							AvisoDeducoes.class).addClass(AvisoBancario.class)
					.addClass(AvisoAcerto.class).addClass(
							ArrecadadorMovimentoItem.class).addClass(
							ArrecadadorMovimento.class).addClass(
							ArrecadadorContratoTarifa.class).addClass(
							ParcelamentoTipo.class).addClass(
							ParcelamentoSituacao.class).addClass(
							ParcelamentoQuantidadeReparcelamento.class)
					.addClass(ParcelamentoQuantidadePrestacao.class).addClass(
							ParcelamentoPerfil.class).addClass(
							ParcelamentoItem.class).addClass(
							ParcelamentoDescontoInatividade.class).addClass(
							ParcelamentoDescontoAntiguidade.class).addClass(
							Parcelamento.class).addClass(DocumentoTipo.class)
					.addClass(DocumentoEmissaoForma.class).addClass(
							DevolucaoSituacao.class).addClass(Devolucao.class)
					.addClass(DeducaoTipo.class).addClass(GuiaDevolucao.class)
					.addClass(GrupoFuncionalidadeOperacao.class).addClass(
							Grupo.class).addClass(
							FuncionalidadeDependencia.class).addClass(
							Funcionalidade.class).addClass(
							ParcelamentoMotivoDesfazer.class).addClass(
							PagamentoHistorico.class).addClass(
							OperacaoEfetuada.class).addClass(Operacao.class)
					.addClass(OperacaoTipo.class)
					.addClass(OperacaoTabela.class).addClass(
							RegistroCodigo.class).addClass(
							ArrecadadorContrato.class).addClass(
							Arrecadador.class).addClass(ArrecadacaoForma.class)
					.addClass(CobrancaAcao.class).addClass(
							RotaAcaoCriterio.class).addClass(
							CobrancaAcaoAtividadeComando.class).addClass(
							CobrancaCriterioLinha.class).addClass(
							CobrancaCriterio.class).addClass(
							CobrancaAtividadeComandoRota.class).addClass(
							CobrancaAtividade.class).addClass(
							CobrancaAcaoCronograma.class).addClass(
							CobrancaAcaoAtividadeCronograma.class).addClass(
							Modulo.class).addClass(ContratoDemanda.class)
					.addClass(ContratoMotivoCancelamento.class).addClass(
							CobrancaGrupoCronogramaMes.class).addClass(
							CobrancaDocumentoItem.class).addClass(
							CobrancaDocumento.class).addClass(
							ImovelSituacaoTipo.class).addClass(
							ImovelSituacao.class).addClass(ContaBancaria.class)
					.addClass(ArrecadacaoDadosDiarios.class).addClass(
							ResumoPendencia.class).addClass(
							RecebimentoTipo.class).addClass(
							ArrecadacaoContabilParametros.class).addClass(
							MotivoCorte.class).addClass(
							UnidadeProcessamento.class).addClass(
							ProcessoIniciado.class).addClass(
							ProcessoSituacao.class).addClass(
							ProcessoFuncionalidade.class).addClass(
							FuncionalidadeIniciada.class).addClass(
							FuncionalidadeSituacao.class).addClass(
							Processo.class).addClass(ProcessoTipo.class)
					.addClass(UnidadeIniciada.class).addClass(
							RelatorioGerado.class).addClass(Relatorio.class)
					.addClass(UnidadeSituacao.class).addClass(
							RamalLocalInstalacao.class).addClass(
							ParametrosDevedoresDuvidosos.class).addClass(
							ParametrosDevedoresDuvidososItem.class).addClass(
							ResumoDevedoresDuvidosos.class).addClass(
							DbVersaoBase.class).addClass(
							EnvioEmail.class).addClass(
							ResumoCobrancaAcaoEventual.class).addClass(
							ConsumoFaixaLigacao.class).addClass(
							ConsumoFaixaCategoria.class).addClass(
							ContaRevisaoFaixaValor.class).addClass(
                            OperacaoOrdemExibicao.class).addClass(
                            LigacaoEsgotoDestinoDejetos.class).addClass(
                            LigacaoEsgotoCaixaInspecao.class).addClass(
                            LigacaoEsgotoDestinoAguasPluviais.class).addClass(
                            LigacaoEsgotoEsgotamento.class).
							addClass(LigacaoAguaSituacaoConsumoTipo.class).
							addClass(LigacaoEsgotoSituacaoConsumoTipo.class).
							addClass(FonteCaptacao.class).
 							addClass(SetorFonteCaptacao.class).
 							addClass(FuncionalidadeCategoria.class).
 							addClass(TabelaAtualizacaoCadastral.class).
 							addClass(TabelaAtualizacaoCadastralSituacao.class).
 							addClass(TabelaColunaAtualizacaoCadastral.class).
							addClass(CicloMeta.class).
							addClass(Atributo.class).
							addClass(AtributoGrupo.class).
							addClass(FuncionalidadeAtributo.class).
							addClass(CicloMetaGrupo.class).
							addClass(VwImovelPrincipalCategoria.class).
							addClass(MovimentoContaImpostoDeduzido.class).
							addClass(MovimentoContaCategoriaConsumoFaixa.class).
							addClass(MovimentoContaPrefaturadaCategoria.class).
							addClass(MovimentoContaPrefaturada.class).
							addClass(MotivoNaoGeracaoDocCobranca.class).
							addClass(ImovelNaoGerado.class).
							addClass(TipoCaptacao.class).
							addClass(CobrancaDocumentoImpressao.class).
							addClass(CobrancaDocumentoControleGeracao.class).
							addClass(GrauDificuldadeExecucao.class).
							addClass(GrauRiscoSegurancaFisica.class).
							addClass(NivelPressao.class).
							addClass(GrauIntermitencia.class).
							addClass(CondicaoAbastecimentoAgua.class).
							addClass(ArquivoTextoRoteiroEmpresaDivisao.class).
							addClass(MovimentoCartaoRejeita.class).
							addClass(EmailClienteAlterado.class).
							addClass(CobrancaAcaoAtividadeComandoFiscalizacaoSituacao.class).
							addClass(CobrancaDocumentoFisc.class).
							addClass(ControleLiberacaoPermissaoEspecial.class).
							addClass(SolicitacaoAcessoSituacao.class).
							addClass(SolicitacaoAcessoGrupo.class).
							addClass(SolicitacaoAcesso.class).
							addClass(NegativacaoCriterioSituacaoEspecialCobranca.class).
							addClass(NegativacaoCriterioSituacaoCobranca.class)
										.addClass(TarifaSocialCarta.class)
					.addClass(TarifaSocialCartaDebito.class)
					.addClass(TarifaSocialComandoCarta.class)
					.addClass(TarifaSocialMotivoCarta.class)
					.addClass(GrupoPermissaoEspecial.class)
					
					.addClass(ConsultarReceitaFederal.class)
					.addClass(ParcelamentoPerfilDebitos.class)
					
					// ************************************//
					// CLASSES DO PACOTE gcom.atendimentopublico.portal //
					// ************************************//
					
					.addClass(QuestionarioSatisfacaoCliente.class)
					.addClass(AcessoLojaVirtual.class)
					
					
					// ************************************//
					// FIM DAS CLASSES DO PACOTE gcom.atendimentopublico.portal //
					// ************************************//
					
					.addClass(ServicoTerceiroAcompanhamentoServico.class)
					
					
					// ***************************************************//
					// CLASSES DO PACOTE gcom.faturamento.contratodemanda //
					// ***************************************************//
					.addClass(ContratoDemandaImovel.class)
					.addClass(ContratoDemandaMotivoEncerramento.class)
					.addClass(ContratoDemandaSituacao.class)
					.addClass(ContratoDemandaFaixaConsumo.class)
					
					// ***************************************************//
					// CLASSES DO PACOTE gcom.mobile.execucaoordemservico //
					// ***************************************************//
					.addClass(ArquivoTextoOSCobranca.class)
					.addClass(ArquivoTextoOSCobrancaCliente.class)
					.addClass(ArquivoTextoOSCobrancaItem.class)
					.addClass(ExecucaoOSCliente.class)
					.addClass(ExecucaoOSCorte.class)
					.addClass(ExecucaoOSFiscalizacao.class)
					.addClass(ExecucaoOSFoto.class)
					.addClass(ExecucaoOSOrdemServico.class)
					.addClass(ExecucaoOSSituacoesEncontradas.class)
					.addClass(ExecucaoOSVisita.class)
					.addClass(ParametrosArquivoTextoOSCobranca.class)
					.addClass(ParametrosArquivoTextoOSLocalidade.class)
					;
							
							
			configuration.setInterceptor(Interceptador.getInstancia());
			sessionFactory = configuration.buildSessionFactory();

			inicializarSessionFactoryPentaho();
		} catch (HibernateException ex) {
			ex.printStackTrace();
			throw new SistemaException(""Hibernate - Erro ao criar a SessionFactory"");
		} catch (ServiceLocatorException ex) {
			ex.printStackTrace();
			throw new SistemaException(""Hibernate - Erro ao criar a SessionFactory"");
		} finally {
			try {
				if (getDialect().toUpperCase().contains(""ORACLE"")) {
					HibernateUtil.inicializarSessionFactoryIFS();
				}
			} catch (Exception e) {
				e.printStackTrace();
			}
		}
	}

	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static Session getSession() {
		Session retorno = null;

		try {
			retorno = sessionFactory.openSession();
			//System.out.println(""inicio:""+retorno.hashCode());
			tempoSession.put(retorno.hashCode(), System.currentTimeMillis());
		} catch (HibernateException ex) {
			ex.printStackTrace();
			throw new SistemaException(""Hibernate - Erro ao criar a Session"");
		}

		return retorno;
	}

	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static StatelessSession getStatelessSession() {
		StatelessSession retorno = null;

		try {
			retorno = sessionFactory.openStatelessSession();
		} catch (HibernateException ex) {
			ex.printStackTrace();
			throw new SistemaException(""Hibernate - Erro ao criar a Session"");
		}

		return retorno;
	}

	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static StatelessSession getStatelessSessionGerencial() {
		StatelessSession retorno = null;

		try {
			retorno = sessionFactoryGerencial.openStatelessSession();
		} catch (HibernateException ex) {
			ex.printStackTrace();
			throw new SistemaException(""Hibernate - Erro ao criar a Session"");
		}

		return retorno;
	}

	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static Session getSessionGerencial() {
		Session retorno = null;

		try {
			retorno = sessionFactoryGerencial.openSession();
		} catch (HibernateException ex) {
			ex.printStackTrace();
			throw new SistemaException(
					""Hibernate - Erro ao criar a Session Gerencial"");
		}

		return retorno;
	}

	/**
	 * Retorna a sess�o do Pentaho
	 * 
	 * @return sess�o
	 */
	public static Session getSessionPentaho() {
		try {
			if(sessionFactoryPentaho == null) {
				throw new SistemaException(""Hibernate - Erro ao obter a Session Pentaho"");
			}

			return sessionFactoryPentaho.openSession();
		} catch (HibernateException ex) {
			ex.printStackTrace();
			throw new SistemaException(""Hibernate - Erro ao obter a Session Pentaho"");
		}
	}

	/**
	 * Fecha a session
	 * 
	 * @param session
	 *            Descri��o do par�metro
	 */
	public static void closeSession(Session session) {

		if (session != null) {
			try {

				//session.clear();

				
				Throwable t = new Throwable();
				StackTraceElement[] elements = t.getStackTrace();

				
					Long tempoInicialSession = tempoSession.get(session.hashCode());
					
					if (tempoInicialSession != null ) {
					
						
						Long tempoTotalSession = System.currentTimeMillis() - tempoInicialSession;
						
						String mensagem = loggerEntidadesPorConsulta(session, elements, tempoTotalSession);
						if (mensagem != null && !mensagem.trim().equals("""")) {
							log.debug(mensagem);
						}
						
				
				
					}
				session.close();
				//session = null;
			} catch (HibernateException ex) {
				throw new SistemaException(
						""Hibernate - Erro ao fechar a Session"");
			} catch (NullPointerException ex) {
				ex.printStackTrace();
				System.out.println(""Nullpointer aqui"");
				
			}

		}
	}


	private static String loggerEntidadesPorConsulta(Session session, StackTraceElement[] elements, long tempoTotalSession) {
		
		//String calleeMethod = elements[0].getMethodName();
		String callerMethodName = elements[1].getMethodName();
		String callerClassName = elements[1].getClassName();
		String callerMethodName2Level = elements[2].getMethodName();
		String callerClassName2Level = elements[2].getClassName();
		

	
		String log = """";
		Map<String, Integer> entidades = new HashMap<String, Integer>();

		for (Object a : session.getStatistics().getEntityKeys()) {

			entidades.put(((EntityKey) a).getEntityName(), session
					.getStatistics().getEntityCount());

		}

		Iterator iterator = entidades.keySet().iterator();
		while (iterator.hasNext()) {

			
			
			String nomeEntidade = (String) iterator.next();

			 
			if (log.trim().equals("""")) {
				log += "";""+callerClassName2Level + "";"" + callerMethodName2Level + "";"";
				log += callerClassName + "";"" + callerMethodName + "";"";
				log += nomeEntidade + "";"";
				log += entidades.get(nomeEntidade) + "";"" + tempoTotalSession+""; "";
			} else {
				log += "" ""+nomeEntidade + "" "";
				log += entidades.get(nomeEntidade); 
				
			}
			
			
			

		}
		
		tempoSession.remove(session.hashCode());
		
		return log;
	}

	/**
	 * Fecha a session
	 * 
	 * @param session
	 *            Descri��o do par�metro
	 */
	public static void closeSession(StatelessSession session) {

		if (session != null) {
			try {
				session.close();
			} catch (HibernateException ex) {
				throw new SistemaException(
						""Hibernate - Erro ao fechar a Session"");
			}

		}
	}

	/**
	 * M�todo que obt�m o tamanho da propriedade da classe
	 * 
	 * @param mappedClass
	 *            Nome da classe
	 * @param propertyName
	 *            Nome da propriedade da classe
	 * @return O valor de columnSize
	 */
	public static int getColumnSize(Class mappedClass, String propertyName) {
		Configuration cfg = HibernateUtil.getConfig();
		PersistentClass pClass = cfg.getClassMapping(mappedClass.getName());
		Column col = null;
		Property hibProp = null;

		try {
			hibProp = pClass.getProperty(propertyName);

			Iterator it = hibProp.getColumnIterator();

			while (it.hasNext()) {
				col = (Column) hibProp.getColumnIterator().next();
				break;
			}

		} catch (MappingException ex) {
			throw new SistemaException(""Hibernate - Erro no mapeamento"");
		}

		return col.getLength();
	}

	/**
	 * M�todo que obt�m o nome da coluna no banco da propriedade passada Caso
	 * nao tenha, retorna null
	 * 
	 * @param mappedClass
	 *            Nome da classe
	 * @param propertyName
	 *            Nome da propriedade da classe
	 * @return nome da coluna
	 */
	public static String getNameColumn(Class mappedClass, String propertyName) {
		String retorno = null;
		Configuration cfg = HibernateUtil.getConfig();
		PersistentClass pClass = cfg.getClassMapping(mappedClass.getName());
		Column col = null;
		Property hibProp = null;

		try {
			hibProp = pClass.getProperty(propertyName);

			Iterator it = hibProp.getColumnIterator();

			while (it.hasNext()) {
				col = (Column) hibProp.getColumnIterator().next();
				break;
			}

			// retorno = col.getComment();
			// if (retorno == null || """".equals(retorno)) {
			if (col == null) {
				retorno = ConstantesDescricaoBanco.get(pClass.getTable()
						.getName()
						+ ""."" + propertyName);
			} else {
				retorno = ConstantesDescricaoBanco.get(pClass.getTable()
						.getName()
						+ ""."" + col.getName());
			}
			if (retorno == null && col != null) {

				retorno = col.getName();
			}

			if (col == null) {
				retorno = null;
			}
			// }

		} catch (MappingException ex) {
			try {

				hibProp = pClass.getIdentifierProperty();
				if (hibProp.getName().equalsIgnoreCase(propertyName)) {

					Iterator it = hibProp.getColumnIterator();

					while (it.hasNext()) {
						col = (Column) hibProp.getColumnIterator().next();
						break;
					}

					// retorno = col.getComment();
					// if (retorno == null || """".equals(retorno)) {
					// retorno = col.getName();
					// }

					retorno = ConstantesDescricaoBanco.get(pClass.getTable()
							.getName()
							+ ""."" + col.getName());
					if (retorno == null) {
						retorno = col.getName();
					}
				}

			} catch (MappingException eex) {
				eex.printStackTrace();
			}
		}

		return retorno;
	}

	/**
	 * M�todo que obt�m o nome da tabela da classe passada
	 * 
	 * @param mappedClass
	 *            Nome da classe
	 * @return O String nome da tablea
	 */
	public static String getNameTable(Class mappedClass) {
		Configuration cfg = HibernateUtil.getConfig();
		PersistentClass pClass = cfg.getClassMapping(mappedClass.getName());

		String retorno = pClass.getTable().getComment();
		if (retorno == null || """".equals(retorno)) {
			retorno = ConstantesDescricaoBanco.get(pClass.getTable().getName());
			if (retorno == null) {
				retorno = pClass.getTable().getName();
			}

		}

		return retorno;
	}
	
	/**
	 * Retorna a que classe est� mapeada a tabela passada 
	 * @param tableName caminho da tabela 
	 * @return caminho da classe 
	 */
	public static String getClassName(String tableName){
		Configuration cfg = HibernateUtil.getConfig();		
		if (cfg != null){
			Iterator iter = cfg.getClassMappings();
			while ( iter.hasNext() ) {
				PersistentClass classe = (PersistentClass) iter.next();
				if (classe.getTable().getName().equals(tableName)) {
					return classe.getClassName();
				}
			}			
		}
		return null;
	}

	/**
	 * Retorna o valor de config
	 * 
	 * @return O valor de config
	 */
	public static Configuration getConfig() {

		return configuration;
	}

	/**
	 * The main program for the HibernateUtil class
	 * 
	 * @param args
	 *            The command line arguments
	 */
	public static void main(String[] args) {

		getSession();

	}


	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static StatelessSession getStatelessSessionIntegracaoSAM() {
		StatelessSession retorno = null;

		
			try {
				retorno = sessionFactoryIntegracaoSAM == null ? null : sessionFactoryIntegracaoSAM.openStatelessSession();
			} catch (HibernateException ex) {
				ex.printStackTrace();
				throw new SistemaException(""Hibernate - Erro ao criar a Session IntegracaoSAM"");
			}
		

		return retorno;
	}
	
	
	public static StatelessSession getStatelessSessionIntegracaoIFS() {
		StatelessSession retorno = null;

		
			try {
				retorno = sessionFactoryIntegracaoIFS == null ? null : sessionFactoryIntegracaoIFS.openStatelessSession();
			} catch (HibernateException ex) {
				ex.printStackTrace();
				throw new SistemaException(""Hibernate - Erro ao criar a Session Integracao IFS"");
			}
		

		return retorno;
	}
	
	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static Session getSessionIntegracaoIFS() {
		Session retorno = null;

		
			try {
				retorno = sessionFactoryIntegracaoIFS == null ? null : sessionFactoryIntegracaoIFS.openSession();
			} catch (HibernateException ex) {
				ex.printStackTrace();
				throw new SistemaException(
						""Hibernate - Erro ao criar a Session Integracao IFS"");
			}
		
		return retorno;
	}

	/**
	 * Retorna o valor de session
	 * 
	 * @return O valor de session
	 */
	public static Session getSessionIntegracaoSAM() {
		Session retorno = null;

		
			try {
				retorno = sessionFactoryIntegracaoSAM == null ? null : sessionFactoryIntegracaoSAM.openSession();
			} catch (HibernateException ex) {
				ex.printStackTrace();
				throw new SistemaException(
						""Hibernate - Erro ao criar a Session IntegracaoSAM"");
			}
		
		return retorno;
	}
	
	public static String getDialect(){
		String retorno = """";
		retorno = configuration.getProperty(""hibernate.dialect"");		
		return retorno;
	}
	
	/**
	 * Seta as propriedades do configurationGerencial e do configuration de acordo com o arquivo xml de propriedades HibernateBaseProperties 
	 * 
	 * @author Paulo Diniz
	 * @date 27/11/2011
	 * 
	 * @return
	 */
	private static void verificaBaseDadosTipo() {
		try {
			File fXmlFile = new File(""HibernateBaseProperties.xml"");
			DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();
			DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();
			Document doc = dBuilder.parse(fXmlFile);
			doc.getDocumentElement().normalize();
			
			NodeList nodeList = (NodeList) doc.getElementsByTagName(""properties"");
			Node properties = nodeList.item(0);
			String base = """";
		    if (properties.getNodeType() == Node.ELEMENT_NODE) {
		    	
		    	base = Util.getTagValue(""base"", (Element) properties);
			   
		    }
			
			if (base != null && !base.equals("""") && (base.equals(""Oracle"") || base.equals(""Postgres""))) {
				
				String datasource = Util.getTagValue(""connection-datasource"", (Element) properties);
				String dialect = Util.getTagValue(""dialect"", (Element) properties);
				String release_mode = Util.getTagValue(""connection-release-mode"", (Element) properties);
		
				if( base.equals(""Postgres"")){
					configurationGerencial.setProperty(""hibernate.connection.datasource"", ""java:/PostgresGerencialDS"");

				} else {
					configurationGerencial.setProperty(""hibernate.connection.datasource"", datasource);
					
				}
				configurationGerencial.setProperty(""hibernate.connection.release_mode"", release_mode);
				configurationGerencial.setProperty(""hibernate.dialect"",dialect);
				
				configuration.setProperty(""hibernate.connection.datasource"", datasource);
				configuration.setProperty(""hibernate.connection.release_mode"", release_mode);
				configuration.setProperty(""hibernate.dialect"",dialect);
				
			}else{
				//� setado Postgres como Default
				configurationGerencial.setProperty(""hibernate.connection.datasource"",""java:/PostgresGerencialDS"");
				configurationGerencial.setProperty(""hibernate.connection.release_mode"", ""after_transaction"");
				configurationGerencial.setProperty(""hibernate.dialect"",""org.hibernate.dialect.PostgreSQLDialect"");
				
				configuration.setProperty(""hibernate.connection.datasource"",""java:/PostgresDS"");
				configuration.setProperty(""hibernate.connection.release_mode"", ""after_transaction"");
				configuration.setProperty(""hibernate.dialect"",""org.hibernate.dialect.PostgreSQLDialect"");
				
			}
		} catch (Exception e) {

			e.printStackTrace();
			
			//� setado Postgres como Default
			configurationGerencial.setProperty(""hibernate.connection.datasource"",""java:/PostgresGerencialDS"");
			configurationGerencial.setProperty(""hibernate.connection.release_mode"", ""after_transaction"");
			configurationGerencial.setProperty(""hibernate.dialect"",""org.hibernate.dialect.PostgreSQLDialect"");
			
			configuration.setProperty(""hibernate.connection.datasource"",""java:/PostgresDS"");
			configuration.setProperty(""hibernate.connection.release_mode"", ""after_transaction"");
			configuration.setProperty(""hibernate.dialect"",""org.hibernate.dialect.PostgreSQLDialect"");
		}
	}
	
	/**
	 * [RM6365] - 21/11/2011 - Bruno Barros - Grava��o das altera��es no banco de dados por usu�rio
	 * [UC1252] - Alterar Usu�rio Logado no Banco de Dados
	 * 
	 * [FS-0002] - Trocar o usu�rio da base
	 * 
	 * @author Th�lio Ara�jo
	 * @since 22/11/2011
	 * 
	 * @param idUsuario
	 * @param loginUsuario
	 * @return UsuarioBanco
	 * @throws ErroRepositorioException
	 */
	public static int alterarSessaoDaFabrica(String user, String password, String empresa) {
		int mensagemRetorno = 0;
		try {
			configurationUser = new Configuration();
			if(empresa.equals(SistemaParametro.EMPRESA_COMPESA)){
				configurationUser.setProperty(""hibernate.connection.datasource"",""java:/OracleDS"");
				configurationUser.setProperty(""hibernate.connection.release_mode"", ""after_transaction"");
				configurationUser.setProperty(""hibernate.dialect"",""org.hibernate.dialect.Oracle9Dialect"");
			}else{
				configurationUser.setProperty(""hibernate.connection.datasource"",""java:/PostgresDS"");
				configurationUser.setProperty(""hibernate.connection.release_mode"", ""after_transaction"");
				configurationUser.setProperty(""hibernate.dialect"",""org.hibernate.dialect.PostgreSQLDialect"");
			}
			configurationUser.setInterceptor(Interceptador.getInstancia());
			Iterator<?> classMappingsConfigurationIterator = configuration
					.getClassMappings();
			while (classMappingsConfigurationIterator.hasNext()) {
				RootClass classe = (RootClass) classMappingsConfigurationIterator
						.next();
				configurationUser.addClass(classe.getMappedClass());
			}
			configurationUser
					.setProperty(""hibernate.connection.username"", user);
			configurationUser.setProperty(""hibernate.connection.password"",
					password);
			
			
			sessionFactory = configurationUser.buildSessionFactory();
			mensagemRetorno = UsuarioBanco.MENSAGEM_SUCESSO;
		} catch (Exception ex) {
			ex.printStackTrace();
			mensagemRetorno = UsuarioBanco.MENSAGEM_ERRO;
			sessionFactory = configuration.buildSessionFactory();
		}
		return mensagemRetorno;
	}
	
	/**
	 * [RM6365] - 21/11/2011 - Bruno Barros - Grava��o das altera��es no banco de dados por usu�rio
	 * [UC1252] - Alterar Usu�rio Logado no Banco de Dados
	 * 
	 * [FS-0002] - Trocar o usu�rio da base
	 * 
	 * @author Th�lio Ara�jo
	 * @since 22/11/2011
	 * 
	 * @param idUsuario
	 * @param loginUsuario
	 * @return UsuarioBanco
	 * @throws ErroRepositorioException
	 */
	public static void alterarSessaoDaFabricaParaPadrao() {
		try {
			sessionFactory = configuration.buildSessionFactory();
		} catch (Exception ex) {
			ex.printStackTrace();
		}
	}
	
	/**
	 * [RM 4201] Bloquear vers�o batch para IP pr� cadastrado
	 * 
	 * M�todo que verifica se o ip do servidor possui
	 * autoriza��o para rodar batch
	 * 
	 * @author Raimundo Martins
	 * @date 31/07/2012 
	 * */
	
	/*public static boolean autorizadoBatch(){
		boolean retorno = false;	
		try{
			SistemaParametro sisp = (SistemaParametro) getSession().createCriteria(SistemaParametro.class).uniqueResult();
			InetAddress ip = InetAddress.getLocalHost();			
			if(ip.getHostAddress()!=null && sisp.getIpAutorizadoBatch() !=null &&
			  !ip.getHostAddress().trim().equals("""") && !sisp.getIpAutorizadoBatch().trim().equals("""") &&
			   ip.getHostAddress().equals(sisp.getIpAutorizadoBatch()))
				retorno = true;
		}catch(Exception ex){
			ex.printStackTrace();
		}		
		return retorno;
	}*/
	
}
",java
"/*
 * Problem Statement: https://www.hackerrank.com/challenges/piling-up/copy-from/181700435
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <assert.h>
#include <ctype.h>
#include <limits.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <time.h>

/*START OF CODE-TEMPLATE*/

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

// Constant Macros.
#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Calculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

// Error-Handling Macros.
#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, (expected_return_val)); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0)

// Initialisation Macros.
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '\0', (bytes))

// Mathematical Macros.
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) / 2) + (start)

// Bit-Manipulation Macros.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

/*END OF CODE-TEMPLATE*/

static bool check_decreasing_order(int*, const int);
static bool check_stack_possible(const int*, const int);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        int n;
        if(1 != scanf(""%d"", &n)) {
            SCANF_READ_ERROR(1);
        }
        assert(n > 0);
        int *const cube_side_lengths = calloc((size_t) n, sizeof*cube_side_lengths);
        if(!cube_side_lengths) {
            MEMORY_ALLOCATION_FAILED_ERROR(cube_side_lengths, (size_t) n * sizeof*cube_side_lengths);
            exit(0);
        }
        for(int i = 0; i < n; ++i) {
            if(1 != scanf(""%d"", cube_side_lengths + i)) {
                SCANF_READ_ERROR(1);
            }
        }
        printf(""%s\n"", check_stack_possible(cube_side_lengths, n) ? ""Yes"" : ""No"");
        free(cube_side_lengths);
    }
    return EXIT_SUCCESS;
}

static bool check_decreasing_order(int *sequence, const int n) {
    bool is_decreasing_order = true;
    for(int i = 1; i < n; ++i) {
        if(sequence[i - 1] < sequence[i]) {
            is_decreasing_order = false;
            break;
        }
    }
    free(sequence);
    return is_decreasing_order;
}

static bool check_stack_possible(const int *cube_side_lengths, const int n) {
    int *const stacked_cubes = calloc((size_t) n, sizeof*stacked_cubes);
    if(!stacked_cubes) {
        MEMORY_ALLOCATION_FAILED_ERROR(stacked_cubes, (size_t) n * sizeof*stacked_cubes);
        exit(0);
    }
    for(int i = 0, start = 0, end = n - 1; start <= end; ) {
        if(cube_side_lengths[start] > cube_side_lengths[end]) {
            stacked_cubes[i++] = cube_side_lengths[start++];
            continue;
        }
        stacked_cubes[i++] = cube_side_lengths[end--];
    }
    return check_decreasing_order(stacked_cubes, n);
}
",c
"/*
 *  Problem Statement: Program to compute the GCD of two numbers using only one statement.
 *  Author: striker
*/

#include <stdio.h>
#include <stdlib.h>
#include <assert.h>

typedef long long ll_t;
typedef unsigned long long ull_t;

#define SCANF_READ_ERROR(exp_return) fprintf(stderr, ""Line Number: %u: scanf() read error. Expected return value: %d\n"", __LINE__, (exp_return)); exit(1)

static ll_t compute_gcd(ll_t, ll_t);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    assert(test > 0);
    while(test--) {
        ll_t a, b;
        if(2 != scanf(""%lld%lld"", &a, &b)) {
            SCANF_READ_ERROR(2);
        }
        printf(""%lld\n"", compute_gcd(a, b));
    }
    return EXIT_SUCCESS;
}

static ll_t compute_gcd(ll_t a, ll_t b) {
    return !b ? a : b == 1LL ? b : compute_gcd(b, a % b);
}
",c
"#include <stdio.h>
#include <stdlib.h>

struct node{
    int data;
    struct node *left;
    struct node *right;
};

struct node *newrec, *root, *a, *b;

void insert(int x){
    newrec = (struct node *)malloc(sizeof(struct node));
    newrec -> data = x;
    newrec -> left = NULL;
    newrec -> right = NULL;
    
    if(root == NULL){
        root = newrec;
    }
    else{
        a = b = root;
        while(a!=NULL){
            b = a;
            if(x <= a->data){
                a = a->left;
            }else{
                a = a->right;
            }
        }
        if(x<=b->data){
            b->left = newrec;
        }else{
            b->right = newrec;
        }
    }
}

void delete(int x){
    a = b = root;
    while(a!=NULL || a->data != x){
        b = a;
        if(x <= a->data){
            a = a->left;
        }else{
            a = a->right;
        }
    }
    if(a==NULL){
        printf(""\n Element not found!"");
    }
    // element to be delete is pointed by a
    // parent of element to be delete is pointed by b
    else if(a->left != NULL && a->right == NULL){
        // if it is root node
        if(x == root->data){
            root = a->left;
        }else{
            if(b->left == a){
                b->left = a->left;
            }else{
                b->right = a->left;
            }
        }
    }
    else if(a->left == NULL && a->right != NULL){
       if(root->data == x){
           root = a->right;
       }else{
           if(b->left == a){
               b -> left = a->right;
           }else{
               b -> right = a->right;
           }
       }
    }
    else if(a->left == NULL && a->right == NULL){
        if(root->data == x){
            root = NULL;
        }else{
            if(b->left == a){
                b->left = NULL;
            }else{
                b->right = NULL;
            }
        }
    }
    else if(a->left !=NULL && a->right != NULL){
        struct node *c;
        c = a->right;
        while(c->left != NULL){
            c = c -> left;
        }
        c->left = a->left;
        if(root == a){
            root = root-> right;
        }else{
            if(b->left == a){
                b->left = a->right;
            }else{
                b->right = a->right;
            }
        }
    }
}

void inorder(struct node *p){
    if(p!=NULL){
        inorder(p->left);
        printf(""%d, "", p->data);
        inorder(p->right);
    }
}

void preorder(struct node *p){
    if(p!=NULL){
        printf(""%d, "", p->data);
        preorder(p->left);
        preorder(p->right);
    }
}

void postorder(struct node *p){
    if(p!=NULL){
        postorder(p->left);
        postorder(p->right);
        printf(""%d, "", p->data);
    }
}

void distroy(){
    root = NULL;
    printf(""\n Tree is destroyed!"");
}

void main(void) {
    insert(100);
    insert(50);
    insert(150);
    insert(25);
    insert(75);
    insert(125);
    insert(175);
    printf(""\n Inorder traversal: "");
    inorder(root);
    printf(""\n Preorder traversal: "");
    preorder(root);
    delete(75);
    printf(""\n Postorder traversal: "");
    postorder(root);
    distroy();
}
",c
/home/runner/.cache/pip/pool/15/59/91/e229622a3722873302c25a11d45d896304992bd3f87ff86f2112c74834,c
"#include <stdio.h>
#include <string.h>

int main () {
    char ch1[101],ch3;
    char ch2[101];

    int i=0,j;

    gets(ch1);
    gets(ch2);

    j = strlen(ch1) - 1;

    for( ; i<j ; i++,j--){
        ch3 = ch1[j];
        ch1[j] = ch1[i];
        ch1[i] = ch3;
    }

    if(!(strcmp(ch1,ch2))) printf(""YES"");
    else printf(""NO"");

    return 0;
}
",c
"#include <stdio.h>

int partition(int a[], int l, int r){
    int i =l, j= r, x=a[l], temp;
    while(i<j){
        while(a[i]<=x && i<=r){
            i++;
        }
        while(a[j]>x){
            j--;
        }
        if(i<j){
            temp = a[i];
            a[i] = a[j];
            a[j] = temp;
        }
    }
    temp = a[l];
    a[l] = a[j];
    a[j] = temp;
    return j;
}

int quick_sort(int a[], int l, int r){
    if(l!=r){
        int p = partition(a, l, r);
        quick_sort(a, l, p-1);
        quick_sort(a, p+1, r);
    }
    
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call quick sort
    // 0, l, r
    quick_sort(a, 0, 5);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c
"/*
 * Problem Statement: Refer to the readme.md file.
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d\n"", __LINE__, return_val); exit(0)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

static void display_list(int[], const int, const char *const);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    if(1 == scanf(""%d"", &test)) {
        if(test < 1) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(test, test value cannot be 0 or -ve);
            exit(0);
        }
        while(test--) {
            int n, k;
            if(2 == scanf(""%d%d"", &n, &k)) {
                int sequence[n];
                for(register int i = 0; i < n; ++i) {
                    scanf(""%d"", &sequence[(i + k) % n]);
                }
                display_list(sequence, n, "" "");
                printf(""\n"");
            } else {
                SCANF_READ_ERROR(2);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static void display_list(int sequence[], const int n, const char *const delimeter) {
    printf(""%d"", sequence[0]);
    for(register int i = 1; i < n; ++i) {
        printf(""%s%d"", delimeter, sequence[i]);
    }
}
",c
"/*  Problem Statement: https://www.spoj.com/problems/BINSTIRL/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<string.h>
#include<assert.h>

const uint32_t compute_stirling_number_of_second_kind(uint32_t,uint32_t);

int main(void) {
    uint32_t test;
    scanf(""%""SCNu32, &test);
    assert(test > 0 && test < 201);
    while(test--) {
        uint32_t n,m;
        scanf(""%""SCNu32""%""SCNu32, &n,&m);
        assert((n > 0 && n < 1000000001) && (m > 0 && m < 1000000001));
        printf(""%""PRIu32""\n"", compute_stirling_number_of_second_kind((n + 1),(m + 1)));
    }
    return EXIT_SUCCESS;
}

const uint32_t compute_stirling_number_of_second_kind(uint32_t n,uint32_t m) {
    uint8_t *const data_storage = calloc((m + 1),sizeof(uint8_t));
    data_storage[0] = 1;
    for(uint32_t i = 0; i < n; ++i) {
        for(int32_t j = (m - 1); j >= 0; --j) {
            if(j > i) {
                data_storage[j] = 0;
            } else if(i > 0 && j == 0) {
                data_storage[j] = 0;
            }
            else if(j == i) {
                data_storage[j] = 1;
            } else {
                data_storage[j] = (((j % 2) * (data_storage[j] % 2)) + (data_storage[j - 1] % 2)) % 2;
            }
        }
    }
    uint32_t ans = data_storage[m - 1];
    free(data_storage);
    return ans;
}",c
"/*
 * Problem Statement: https://onlinejudge.org/index.php?option=com_onlinejudge&Itemid=8&category=3&page=show_problem&problem=36
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

/* ANSI C 5.3.0 - GNU C Compiler doesn't have following GCC functions defined.
// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).
*/

#define MAX_SIZE 10000

static ll_t compute_maximum_cycle_length(ll_t, ll_t);
static void swap_data(ll_t *const, ll_t *const);
static ll_t compute_cycle_length(ll_t);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    ll_t start, end;
    while(EOF != scanf(""%lld%lld"", &start, &end)) {
        printf(""%lld %lld %lld\n"", start, end, compute_maximum_cycle_length(start, end));
    }
    return EXIT_SUCCESS;
}

static ll_t compute_maximum_cycle_length(ll_t start, ll_t end) {
    static ll_t cache[MAX_SIZE];
    if(start > end) {
        swap_data(&start, &end);
    }
    ll_t max_cycle_length = 0;
    for(; start <= end; ++start) {
        if(!cache[start - 1]) {
            cache[start - 1] = compute_cycle_length(start);
        }
        if(max_cycle_length < cache[start - 1]) {
            max_cycle_length = cache[start - 1];
        }
    }
    return max_cycle_length;
}

static void swap_data(ll_t *const a, ll_t *const b) {
    if(a != b) {
        *a = (*a) ^ (*b);
        *b = (*a) ^ (*b);
        *a = (*a) ^ (*b);
    }
}

static ll_t compute_cycle_length(ll_t n) {
    ll_t cycle_length = 1;
    while(1 != n) {
        ++cycle_length;
        if(n % 2) {
            n = (3 * n) + 1;
            continue;
        }
        n >>= 1;
    }
    return cycle_length;
}
",c
"#include <stdio.h>

int main () {
    int a,b,c;
    char atto1[10][10]= {""zero"",""one"",""two"",""three"",""four"",""five"",""six"",""seven"",""eight"",""nine""};
    char atto2[10][10]= {""ten"",""eleven"",""twelve"",""thirteen"",""fourteen"",""fifteen"",""sixteen"",""seventeen"",""eighteen"",""nineteen""};
    char atto3[ 8][10]= {""twenty"", ""thirty"", ""forty"", ""fifty"", ""sixty"", ""seventy"", ""eighty"", ""ninety""};

    scanf(""%d"", &a);
    b=a/10;

    if (b==0) printf(""%s"", atto1[a]);
    else if(b==1) printf(""%s"", atto2[a-10]);
    else {
        c = a%10;
        if(!c) printf(""%s"", atto3[b-2]);
        else {
            printf(""%s"", atto3[b-2]);
            printf(""-"");
            printf(""%s"", atto1[c]);
        }
    }


    return 0;
}

",c
"/*  Problem Statement: https://www.spoj.com/problems/ACODE/
 *  Author: striker
*/

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

#define MAX_STRING_LENGTH 50001
#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr. ""Line number: %u: Constraints not satisfied for the <%s> variable i.e. %s\n"", __LINE__, #variable, #constraints)

enum alphabet_mapping {A = 1, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z};

static ull_t compute_number_of_decodings(char[]);

int main(void) {
    /*
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    */
    while(true) {
        char encoded_data[MAX_STRING_LENGTH];
        scanf(""%s"", encoded_data);
        if(!strcmp(encoded_data, ""0"")) {
            break;
        }
        printf(""%llu\n"", compute_number_of_decodings(encoded_data));
    }
    return EXIT_SUCCESS;
}

static ull_t compute_number_of_decodings(char encoded_data[]) {
    int data_len = strlen(encoded_data);
    ull_t cache_solutions[data_len];
    memset(cache_solutions, 0, data_len * sizeof(ull_t));
    for(int end = data_len - 1, i = 0; end >= 0; --end, ++i) {
        if(end == data_len - 1) {
            if('0' == encoded_data[end]) {
                cache_solutions[i] = 0;
            } else {
                cache_solutions[i] = 1;
            }
        } else {
            int valid_num = ((encoded_data[end] - '0') * 10) + encoded_data[end + 1] - '0';
            if('0' != encoded_data[end]) {
                cache_solutions[i] = cache_solutions[i - 1];
                if(valid_num >= J  && valid_num <= Z) {
                    if(end == data_len - 2) {
                        cache_solutions[i]++;
                    } else {
                        cache_solutions[i] += cache_solutions[i - 2];
                    }
                }
            }
        }
    }
    return cache_solutions[data_len - 1];
}

",c
"//
// Created by luozhen on 2018/2/28.
//

#ifndef CODEFORCES_MEDIAN_OF_TWO_SORTED_ARRAYS_H
#define CODEFORCES_MEDIAN_OF_TWO_SORTED_ARRAYS_H

#endif //CODEFORCES_MEDIAN_OF_TWO_SORTED_ARRAYS_H

//There are two sorted arrays nums1 and nums2 of size m and n respectively.
//
//Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).
//
//Example 1:
//nums1 = [1, 3]
//nums2 = [2]
//
//The median is 2.0
//Example 2:
//nums1 = [1, 2]
//nums2 = [3, 4]
//
//The median is (2 + 3)/2 = 2.5


",c
"#include <stdio.h>

int main (void) {
    int atto[4],i,j,k,l=0,m=0,n=0;

    scanf(""%d %d %d %d"", &atto[0],&atto[1],&atto[2],&atto[3]);

    // bubble sort
    for(i=0; i<4; i++) {
        for(j=i+1; j<4; j++) {
            if(atto[i]<atto[j]) {
                k=atto[i];
                atto[i]=atto[j];
                atto[j]=k;
            }
        }
    }

    for(i=0; i<2; i++) {
        if(atto[i] < atto[i+1]+atto[i+2]) l++;
        else if(atto[i] == atto[i+1]+atto[i+2]) m++;
        else n++;
    }

    if(l>0) printf(""TRIANGLE"");
    else if(m>0) printf(""SEGMENT"");
    else printf(""IMPOSSIBLE"");

    return 0;
}
",c
"/*  Problem Statement: Refer to the readme.md in this directory.
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<stdbool.h>
#include<string.h>
#include<assert.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

static const bool check_sorted(const int *const,unsigned int);
static void merge_sort_int_sequence(int *const,unsigned int,unsigned int);
static void merge_int_sequence(int *const,unsigned int,unsigned int,unsigned int);
static void rearrange_int_sequence(int *const,unsigned int);
static void display_sequence(const int *const,unsigned int);

int main(void) {
    unsigned int n;
    // printf(""Enter the length of the sequence\n"");
    scanf(""%u"", &n);
    assert(n > 0);
    int sequence[n];
    // printf(""Enter the sequence\n"");
    for(unsigned int i = 0; i < n; ++i) {
        scanf(""%d"", &sequence[i]);
    }
    if(!check_sorted(sequence,n)) {
        merge_sort_int_sequence(sequence,0,(n - 1));
    }
    rearrange_int_sequence(sequence,n);
    // printf(""Sequence after re-arrangement\n"");
    display_sequence(sequence,n);
    return EXIT_SUCCESS;
}

static const bool check_sorted(const int *const data,unsigned int n) {
    bool is_sorted = true;
    for(unsigned int i = 0; i < (n - 1); ++i) {
        if(data[i] > data[i + 1]) {
            is_sorted = false;
            break;
        }
    }
    return is_sorted;
}

static void merge_sort_int_sequence(int *const data,unsigned int start,unsigned int end) {
    if(start < end) {
        unsigned int mid = ((end - start) >> 1) + start;
        merge_sort_int_sequence(data,start,mid);
        merge_sort_int_sequence(data,(mid + 1),end);
        merge_int_sequence(data,start,mid,end);
    }
}

static void merge_int_sequence(int *const data,unsigned int start,unsigned int mid,unsigned int end) {
    unsigned left_size = (mid - start) + 1;
    int left_data[left_size];
    memmove(left_data,&data[start],(sizeof(int) * left_size));
    unsigned right_size = end - mid;
    int right_data[right_size];
    memmove(right_data,&data[mid + 1],(sizeof(int) * right_size));
    for(unsigned int k = start, i = 0, j = 0; k <= end; ++k) {
        if(i == left_size) {
            data[k] = right_data[j++];
        } else if(j == right_size) {
            data[k] = left_data[i++];
        } else if(left_data[i] < right_data[j]) {
            data[k] = left_data[i++];
        } else {
            data[k] = right_data[j++];
        }
    }
}

static void rearrange_int_sequence(int *const data,unsigned int n) {
    unsigned int even_count,odd_count;
    even_count = odd_count = 0;
    for(unsigned int i = 0; i < n; ++i) {
        if(data[i] & 1) {
            ++odd_count;
        } else {
            ++even_count;
        }
    }
    int even_number_sequence[even_count],odd_number_sequence[odd_count];
    for(unsigned int i = 0, j = 0, k = 0; (i < n && j <= odd_count && k <= even_count); ++i) {
        if(data[i] & 1) {
            odd_number_sequence[j++] = data[i];
        } else {
            even_number_sequence[k++] = data[i];
        }
    }
    bool even_odd = false;
    for(unsigned int i = 0, j = 0, k = 0; k < n; ++k) {
        if(i == even_count) {
            data[k] = odd_number_sequence[j++];
        } else if(j == odd_count) {
            data[k] = even_number_sequence[i++];
        } else if(!k) {
            if(even_number_sequence[i] < odd_number_sequence[j]) {
                data[k] = even_number_sequence[i++];
                even_odd = true; 
            } else {
                data[k] = odd_number_sequence[j++];
            }
        } else if(!even_odd) {
            if(k & 1) {
                data[k] = even_number_sequence[i++];
            } else {
                data[k] = odd_number_sequence[j++];
            }
        } else {
            if(k & 1) {
                data[k] = odd_number_sequence[j++];
            } else {
                data[k] = even_number_sequence[i++];
            }
        }
    }
}

static void display_sequence(const int *const data,unsigned int n) {
    for(unsigned int i = 0; i < n; ++i) {
        printf(""%d "", data[i]);
    }
    printf(""\n"");
}",c
"#include <stdio.h>

int main () {
    long long int i,j,m,l[1000];
    int k,n,o;

    scanf(""%I64d"", &i);
    j=i;

    for(n=0,o=0; i ;n++) {
        for(k=0 ; j ; j=j/10) k++;
        for(m=0; k ; k-- ) {
            m = (m*10)+1;
            printf(""%d\n"",m);
        }

        if (i>m) {
            i= i-m;
            l[n]=m;
            o++;
        }
    }

    printf(""%d\n"",m);
    for(n=0 ; l[n]; n++) {
        printf(""%d "", l[n]);
    }


    return 0;
}
",c
"#include <stdio.h>

int main (void) {

    long long int n,m,a,i,j;
    scanf(""%I64d %I64d %I64d"",&n, &m ,&a);

    if(n%a==0)i=n/a;
    else i=(n/a)+1;

    if(m%a==0)j=m/a;
    else j=(m/a)+1;


    printf(""%I64d"", i*j);

    return 0;
}
",c
"#include<stdio.h>

int selection_sort(int a[], int n){
    int i, j, temp, min, p;
    for(i=0; i<=n-2; i++){
        min = a[i], p=i;
        for(j=i+1; j<=n-1; j++){
            if(a[j]<min){
                min = a[j];
                p = j;
            }
        }
        temp = a[i];
        a[i] = a[p];
        a[p] = temp;
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    selection_sort(a, 6);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c
"#ifndef WIYATA_CODEFORCES_REORDER_H
#define WIYATA_CODEFORCES_REORDER_H

char const* reorder(unsigned n, unsigned a[n], unsigned m);

#endif /* WIYATA_CODEFORCES_REORDER_H */
",c
"/*
 * Problem Statement: https://www.spoj.com/problems/FENCE1/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

int main(void) {
    while(true) {
        int l;
        if(1 != scanf(""%d"", &l)) {
            SCANF_READ_ERROR(1);
        }
        if(!l) {
            break;
        }
        printf(""%0.2f\n"", (l * l) / (2 * PI));
    }
    return EXIT_SUCCESS;
}
",c
"#include <stdio.h>

int main (void) {
    char str[200001];

    long long int a, b, c=0, d=0, e;

    scanf(""%I64d"", &a);
    gets(str);
    gets(str);

    for(b=0; b<a; b++) {
        if(str[b]=='1') c++;
        else d++;
    }


    if(c>d) printf(""%I64d\n"",c-d);
    else printf(""%I64d\n"",d-c);

    return 0;
}
",c
"#include <stdio.h>
#include <string.h>

int main () {
    char str1[10] = ""CODEFORCES"";
    char str2[100];

    int i=0,j=0,k=0;

    scanf(""%s"", str2);

    if(strcmp(str1,str2)) {
        for( ; i<10; i++) {
            for( ; j<101 ; j++) {
                if(str1[i] == str2[j]) {
                    k++;
                    break;
                }
            }
        }
        if(k == 10) printf(""YES"");
        else printf(""NO"");
    }

    else printf(""NO"");

    return 0;
}
",c
"//
// Created by luozhen on 2017/12/22.
//

#ifndef CODEFORCES_A131_H
#define CODEFORCES_A131_H

#endif //CODEFORCES_A131_H

//A. cAPS lOCK
//time limit per test0.5 second
//memory limit per test256 megabytes
//inputstandard input
//outputstandard output
//wHAT DO WE NEED cAPS LOCK FOR?
//
//Caps lock is a computer keyboard key. Pressing it sets an input mode in which typed letters are capital by default. If it is pressed by accident, it leads to accidents like the one we had in the first passage.
//
//Let's consider that a word has been typed with the Caps lock key accidentally switched on, if:
//
//either it only contains uppercase letters;
//or all letters except for the first one are uppercase.
//In this case we should automatically change the case of all letters. For example, the case of the letters that form words ""hELLO"", ""HTTP"", ""z"" should be changed.
//
//Write a program that applies the rule mentioned above. If the rule cannot be applied, the program should leave the word unchanged.
//
//Input
//The first line of the input data contains a word consisting of uppercase and lowercase Latin letters. The word's length is from 1 to 100 characters, inclusive.
//
//Output
//Print the result of the given word's processing.
//
//Examples
//input
//cAPS
//output
//Caps
//input
//Lock
//output
//Lock
//
",c
"struct Circle : Point {
    double r;
    Circle(double x = 0, double y = 0, double r = 0) : Point(x, y), r(r) {}
    Circle(Point p, double r) : Point(p), r(r) {}
    
    bool contains(Point p) { return (*this - p).len() <= r + EPS; }
};

// Find common tangents to 2 circles
// Tested:
// - http://codeforces.com/gym/100803/ - H
// Helper method
void tangents(Point c, double r1, double r2, vector<Line> & ans) {
    double r = r2 - r1;
    double z = sqr(c.x) + sqr(c.y);
    double d = z - sqr(r);
    if (d < -EPS)  return;
    d = sqrt(fabs(d));
    Line l((c.x * r + c.y * d) / z,
            (c.y * r - c.x * d) / z,
            r1);
    ans.push_back(l);
}
// Actual method: returns vector containing all common tangents
vector<Line> tangents(Circle a, Circle b) {
    vector<Line> ans; ans.clear();
    for (int i=-1; i<=1; i+=2)
        for (int j=-1; j<=1; j+=2)
            tangents(b-a, a.r*i, b.r*j, ans);
    for(int i = 0; i < ans.size(); ++i)
        ans[i].c -= ans[i].a * a.x + ans[i].b * a.y;

    vector<Line> ret;
    for(int i = 0; i < (int) ans.size(); ++i) {
        bool ok = true;
        for(int j = 0; j < i; ++j)
            if (areSame(ret[j], ans[i])) {
                ok = false;
                break;
            }
        if (ok) ret.push_back(ans[i]);
    }
    return ret;
}

// Circle & line intersection
// Tested:
// - http://codeforces.com/gym/100803/ - H
vector<Point> intersection(Line l, Circle cir) {
    double r = cir.r, a = l.a, b = l.b, c = l.c + l.a*cir.x + l.b*cir.y;
    vector<Point> res;

    double x0 = -a*c/(a*a+b*b),  y0 = -b*c/(a*a+b*b);
    if (c*c > r*r*(a*a+b*b)+EPS) return res;
    else if (fabs(c*c - r*r*(a*a+b*b)) < EPS) {
        res.push_back(Point(x0, y0) + Point(cir.x, cir.y));
        return res;
    }
    else {
        double d = r*r - c*c/(a*a+b*b);
        double mult = sqrt (d / (a*a+b*b));
        double ax,ay,bx,by;
        ax = x0 + b * mult;
        bx = x0 - b * mult;
        ay = y0 - a * mult;
        by = y0 + a * mult;

        res.push_back(Point(ax, ay) + Point(cir.x, cir.y));
        res.push_back(Point(bx, by) + Point(cir.x, cir.y));
        return res;
    }
}

// helper functions for commonCircleArea
double cir_area_solve(double a, double b, double c) {
    return acos((a*a + b*b - c*c) / 2 / a / b);
}
double cir_area_cut(double a, double r) {
    double s1 = a * r * r / 2;
    double s2 = sin(a) * r * r / 2;
    return s1 - s2;
}
// Tested: http://codeforces.com/contest/600/problem/D
double commonCircleArea(Circle c1, Circle c2) { //return the common area of two circle
    if (c1.r < c2.r) swap(c1, c2);
    double d = (c1 - c2).len();
    if (d + c2.r <= c1.r + EPS) return c2.r*c2.r*M_PI;
    if (d >= c1.r + c2.r - EPS) return 0.0;
    double a1 = cir_area_solve(d, c1.r, c2.r);
    double a2 = cir_area_solve(d, c2.r, c1.r);
    return cir_area_cut(a1*2, c1.r) + cir_area_cut(a2*2, c2.r);
}

// Check if 2 circle intersects. Return true if 2 circles touch
bool areIntersect(Circle u, Circle v) {
    if (cmp((u - v).len(), u.r + v.r) > 0) return false;
    if (cmp((u - v).len() + v.r, u.r) < 0) return false;
    if (cmp((u - v).len() + u.r, v.r) < 0) return false;
    return true;
}

// If 2 circle touches, will return 2 (same) points
// If 2 circle are same --> be careful
// Tested:
// - http://codeforces.com/gym/100803/ - H
// - http://codeforces.com/gym/100820/ - I
vector<Point> circleIntersect(Circle u, Circle v) {
    vector<Point> res;
    if (!areIntersect(u, v)) return res;
    double d = (u - v).len();
    double alpha = acos((u.r * u.r + d*d - v.r * v.r) / 2.0 / u.r / d);

    Point p1 = (v - u).rotate(alpha);
    Point p2 = (v - u).rotate(-alpha);
    res.push_back(p1 / p1.len() * u.r + u);
    res.push_back(p2 / p2.len() * u.r + u);
    return res;
}
",c
"#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#define MAX 5

struct vertex{
    char lable;
    int visited;
};

int queue[MAX];
int front = 0;
int rear = -1;

struct vertex * vertices[MAX];
int adjmatrix[MAX][MAX];
int vertexcount = 0;

void insert(int data){
    queue[++rear] = data;
}

int delete(){
    return queue[front++];
}

bool isQueueEmpty(){
    return front == -1;
}

void addVertex(char data){
    struct vertex * v = (struct vertex *) malloc(sizeof(struct vertex));
    v->lable = data;
    v->visited = false;
    vertices[vertexcount++] = v;
}

void addEdge(int start, int end){
    adjmatrix[start][end] = 1;
    adjmatrix[end][start] = 1;
}

void displayVertex(int vertexIndex) {
   printf(""%c "",vertices[vertexIndex]->lable);
}

int getadjecentVertex(int vertexIndex){
    for(int i = 0; i<vertexcount; i++) {
      if(adjmatrix[vertexIndex][i] == 1 && vertices[i]->visited == false)
         return i;
    }
    return -1;
}

void breadthFirstSearch() {
   int i;

   vertices[0]->visited = true;

   displayVertex(0);   

   //insert vertex index in queue
   insert(0);
   int unvisitedVertex;

   while(!isQueueEmpty()) {
      int tempVertex = delete();   
      while((unvisitedVertex = getadjecentVertex(tempVertex)) != -1) {    
         vertices[unvisitedVertex]->visited = true;
         displayVertex(unvisitedVertex);
         insert(unvisitedVertex);               
      }
   }   

   //queue is empty, search is complete, reset the visited flag        
   for(i = 0;i<vertexcount;i++) {
      vertices[i]->visited = false;
   }    
}

int main() {
   int i, j;

   for(i = 0; i<MAX; i++){
        for(j = 0; j<MAX; j++){
           adjmatrix[i][j] = 0;
        }
   }

   addVertex('S');   // 0
   addVertex('A');   // 1
   addVertex('B');   // 2
   addVertex('C');   // 3
   addVertex('D');   // 4
 
   addEdge(0, 1);    // S - A
   addEdge(0, 2);    // S - B
   addEdge(0, 3);    // S - C
   addEdge(1, 4);    // A - D
   addEdge(2, 4);    // B - D
   addEdge(3, 4);    // C - D
	
   printf(""\nBreadth First Search: "");
   
   breadthFirstSearch();

   return 0;
}
",c
"#include <stdio.h>

int main (void) {
    int i,j,k,l,m,n=0;
    int art[100],art2[100];

    scanf(""%d %d"", &i, &j);

    for(k=0; k<i ; k++){
        scanf(""%d"", &art[k]);
        art2[k]=art[k];
    }


    // sort
    for(k=0; k<i; k++) {
        for(l=k+1; l<i; l++) {
            if(art[k]>art[l]){
                m=art[k];
                art[k]=art[l];
                art[l]=m;
            }
        }
    }

    for(k=0,m=0,l=0; l<i ;k++, l++) {
        if(art[k]+ m <= j) {
            m = m+ art[k];
            n++;
        }
        else break;
    }

    printf(""%d\n"", n);


    for(k=0,m=0,l=0,n=0; l<i ;k++, l++) {
        if(art[k]+ m <= j) {
            for(n=0; n<i; n++){
                if(art2[n]== art[k]) {
                    printf(""%d "", n+1);
                    art2[n]=-1;
                    break;
                }
            }
            m = m+ art[k];
        }
        else break;
    }

    return 0;
}
",c
"#include <stdio.h>

int bubble_sort(int a[], int l){
    for(int i=l-2; i>=0; i--){
        for(int j=0; j<=i; j++){
            if(a[j]>a[j+1]){
                int temp = a[j];
                a[j] = a[j+1];
                a[j+1] = temp;
            }
        }
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call bubble sort
    bubble_sort(a, 6);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c
"//
// Created by luozhen on 2017/7/25.
//

#ifndef CODEFORCES_VASYA_AND_SHIFTS_H
#define CODEFORCES_VASYA_AND_SHIFTS_H

#endif //CODEFORCES_VASYA_AND_SHIFTS_H

//Vasya has a set of 4n strings of equal length, consisting of lowercase English letters ""a"", ""b"", ""c"", ""d"" and ""e"".
// Moreover, the set is split into n groups of 4 equal strings each. Vasya also has one special string a of the same length,
// consisting of letters ""a"" only.
//
//Vasya wants to obtain from string a some fixed string b, in order to do this, he can use the strings from his set
// in any order. When he uses some string x, each of the letters in string a replaces with the next letter in alphabet
// as many times as the alphabet position, counting from zero, of the corresponding letter in string x. Within this
// process the next letter in alphabet after ""e"" is ""a"".
//
// For example, if some letter in a equals ""b"", and the letter on the same position in x equals ""c"", then the letter
// in a becomes equal ""d"", because ""c"" is the second alphabet letter, counting from zero. If some letter in a equals ""e"",
// and on the same position in x is ""d"", then the letter in a becomes ""c"". For example, if the string a equals ""abcde"",
// and string x equals ""baddc"", then a becomes ""bbabb"".
//
//A used string disappears, but Vasya can use equal strings several times.
//
//Vasya wants to know for q given strings b, how many ways there are to obtain from the string a string b using the
// given set of 4n strings? Two ways are different if the number of strings used from some group of 4 strings is different.
// Help Vasya compute the answers for these questions modulo 109 + 7.
//
//Input
//The first line contains two integers n and m (1 ≤ n, m ≤ 500) — the number of groups of four strings in the set, and
// the length of all strings.
//
//Each of the next n lines contains a string s of length m, consisting of lowercase English letters ""a"", ""b"", ""c"", ""d""
// and ""e"". This means that there is a group of four strings equal to s.
//
//The next line contains single integer q (1 ≤ q ≤ 300) — the number of strings b Vasya is interested in.
//
//Each of the next q strings contains a string b of length m, consisting of lowercase English letters ""a"", ""b"", ""c"", ""

int vas_solution(){

}",c
"#include <stdio.h>

int main (void) {
    double c,b,d=0;
    int a;

    scanf(""%d"",&a);
    c=a*100.0;
    for(; a; a--) {
        scanf(""%lf"", &b);
        d=d+b;
    }

    printf(""%.12f"", d/c*100.0);

    return 0;
}
",c
"/*  Problem Statement: https://www.spoj.com/problems/HANGOVER/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<stdbool.h>
#include<assert.h>

uint16_t find_min_cards(double);

int main(void) {
    double card_len;
    while(true) {
        fscanf(stdin,""%lf"",&card_len);
        if(card_len == 0.00) break;
        assert(card_len > 0.00 && card_len < 5.21);
        fprintf(stdout,""%""PRIu16"" card(s)\n"",find_min_cards(card_len));
    }
    return 0;
}

uint16_t find_min_cards(double card_len) {
    double nthterm = 0.00;
    uint16_t no_of_cards = 0;
    for(uint16_t i=1;nthterm<card_len;++i) {
            nthterm += (1/(double)(i+1));
            ++no_of_cards;
    }
    return no_of_cards;
}
",c
"#include <stdio.h>

int main (void) {
    int i;
    long long int cord1, cord2, axxh=-1000000000, axyh=-1000000000, axxl=1000000000, axyl=1000000000;

    scanf(""%d"", &i);

    for( ; i ; i--) {
        scanf(""%I64d %I64d"", &cord1, &cord2);
        if(cord1 > axxh) axxh=cord1;
        if(cord1 < axxl) axxl=cord1;
        if(cord2 > axyh) axyh=cord2;
        if(cord2 < axyl) axyl=cord2;
    }

    axxh = axxh - axxl;
    if(axxh<0) axxh = axxh*(-1);

    axyh = axyh - axyl;
    if(axyh<0) axyh = axyh*(-1);

    if(axxh<axyh) axxh=axyh;

    printf(""%I64d"", axxh*axxh);

    return 0;
}
",c
"/*  Problem Statement: Program to compute matrix-multiplication of two matrices of different dimensions.
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)

#define CONSTRAINTS_NOT_SATISFIED(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the <%s>, i.e. %s\n"", __LINE__, #variable, constraints)

static int** take_input_matrix(const size_t, const size_t);
static void display_matrix(int* *const, const size_t, const size_t);
static int** matrix_multiplication(int* *const, const size_t, const size_t, int* *const, const size_t);
static void free_memory(int* *const, const size_t);

int main(void) {
    int matrix_A_rows, matrix_A_cols, matrix_B_rows ,matrix_B_cols; // Dimensions of the matrix
    scanf(""%d%d"", &matrix_A_rows, &matrix_A_cols);
    if(matrix_A_rows < 1 || matrix_A_cols < 1) {
        CONSTRAINTS_NOT_SATISFIED(matrix_A, ""Dimensions of matrix cannot be -ve"");
        exit(0);
    }
    int* *const matrix_A = take_input_matrix(matrix_A_rows, matrix_A_cols);
    if(!matrix_A) {
        MEMORY_ALLOCATION_FAILED_ERROR(matrix_A, matrix_A_rows * matrix_A_cols * sizeof(**matrix_A));
        exit(0);
    }
    scanf(""%d%d"", &matrix_B_rows, &matrix_B_cols);
    if(matrix_B_rows < 1 || matrix_B_cols < 1) {
        CONSTRAINTS_NOT_SATISFIED(matrix_B, ""Dimensions of matrix cannot be -ve"");
        exit(0);
    }
    int* *const matrix_B = take_input_matrix(matrix_B_rows, matrix_B_cols);
    if(!matrix_B) {
        MEMORY_ALLOCATION_FAILED_ERROR(matrix_B, matrix_B_rows * matrix_B_cols * sizeof(**matrix_B));
        exit(0);
    }
    printf(""Matrix-A:\n"");
    display_matrix(matrix_A, matrix_A_rows, matrix_A_cols);
    printf(""Matrix-B:\n"");
    display_matrix(matrix_B, matrix_B_rows, matrix_B_cols);
    if(matrix_A_cols == matrix_B_rows) {
        int* *const result_matrix = matrix_multiplication(matrix_A, matrix_A_rows, matrix_A_cols, matrix_B, matrix_B_cols);
        if(!result_matrix) {
            MEMORY_ALLOCATION_FAILED_ERROR(result_matrix, matrix_A_rows * matrix_B_cols * sizeof(**result_matrix));
            exit(0);
        }
        printf(""Result-Matrix:\n"");
        display_matrix(result_matrix, matrix_A_rows, matrix_B_cols);
        free_memory(matrix_A, matrix_A_rows);
        free_memory(matrix_B, matrix_B_rows);
        free_memory(result_matrix, matrix_A_rows);
    } else {
        fprintf(stderr, ""Line number: %u: Matrix multiplication cannot be performed beacause matrix_A_cols != matrix_B_rows.\n"", __LINE__);
        exit(0);
    }
    return EXIT_SUCCESS;
}

static int** take_input_matrix(const size_t nrows, const size_t ncols) {
    int* *const matrix = calloc(nrows, sizeof(*matrix));
    if(matrix) {
        for(unsigned int i = 0; i < nrows; ++i) {
            matrix[i] = calloc(ncols, sizeof(**matrix));
            if(matrix[i]) {
                for(unsigned int j = 0; j < ncols; ++j) {
                    scanf(""%d"", &matrix[i][j]);
                }
            } else {
                MEMORY_ALLOCATION_FAILED_ERROR(matrix[i], ncols * sizeof(**matrix));
                return NULL;
            }
        }
    }
    return matrix;
}

static void display_matrix(int* *const matrix, const size_t nrows, const size_t ncols) {
    for(unsigned int i = 0; i < nrows; ++i) {
        for(unsigned int j = 0; j < ncols; ++j) {
            printf(""%5d"", matrix[i][j]);
        }
        printf(""\n"");
    }
}

static int** matrix_multiplication(int* *const matrix_A, const size_t matrix_A_rows, const size_t matrix_A_cols, int* *const matrix_B, const size_t matrix_B_cols) {
    int* *const result_matrix = calloc(matrix_A_rows, sizeof(*result_matrix));
    if(result_matrix) {
        for(unsigned int i = 0; i < matrix_A_rows; ++i) {
            result_matrix[i] = calloc(matrix_B_cols, sizeof(**result_matrix));
            if(!result_matrix[i]) {
                MEMORY_ALLOCATION_FAILED_ERROR(result_matrix[i], matrix_B_cols * sizeof(**result_matrix));
                return NULL;
            }
        }

        for(unsigned int i = 0; i < matrix_A_rows; ++i) {
            for(unsigned int j = 0; j < matrix_B_cols; ++j) {
                for(unsigned int k = 0; k < matrix_A_cols; ++k) {
                    result_matrix[i][j] += (matrix_A[i][k] * matrix_B[k][j]);
                }
            }
        }
    }
    return result_matrix;
}

static void free_memory(int* *const matrix, const size_t nrows) {
    for(unsigned int i = 0; i < nrows; free(matrix[i]), ++i);
    free(matrix);
}
",c
/home/runner/.cache/pip/pool/fc/d7/db/b5f480926fc0ebbba68d1d6811bf7246704be449d303be9fbd022e3559,c
"#include <stdio.h>

int n = 7;
int stack[10];
int top = -1;

void push(int x){
    if(top==n){
        printf(""\n Stak is overflow!"");
    }
    else{
        top++;
        stack[top] = x;
    }
}

void pop(){
    if(top==-1){
        printf(""\n Stack is underflow"");
    }else{
        printf(""\n Element to be delete:%d"", stack[top]);
        top--;
    }
}

void distroy(){
    top= -1;
    printf(""\n Stack is destroyed!"");
}

void display(){
    if(top==-1){
        printf(""\n Stack is underflow"");
    }else{
        printf(""\n stack elements:"");
        for(int i=0; i<=top; i++){
            printf(""%d "", stack[i]);
        }
    }
}
void main(void) {
    display();
    push(1);
    push(2);
    push(3);
    push(4);
    display();
    pop();
    display();
    distroy();
}


// ===== OUTPUT =====
//  Stack is underflow
//  stack elements:1 2 3 4 
//  Element to be delete:4
//  stack elements:1 2 3 
//  Stack is destroyed!
",c
"/*
 * Problem Statement: https://www.hackerrank.com/challenges/handshake/problem
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <ctype.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        ll_t n;
        if(1 != scanf(""%lld"", &n)) {
            SCANF_READ_ERROR(1);
        }
        printf(""%lld\n"", (n * (n - 1)) >> 1);
    }
    return EXIT_SUCCESS;
}
",c
/home/runner/.cache/pip/pool/08/30/ed/c1a576d43da762dca99cc433c6fbe9669713bc8b3c399e8a0dad60e2dd,c
"/*
 * Cryptographic API.
 *
 * RIPEMD-320 - RACE Integrity Primitives Evaluation Message Digest.
 *
 * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC
 *
 * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License as published by the Free
 * Software Foundation; either version 2 of the License, or (at your option)
 * any later version.
 *
 */
#include <crypto/internal/hash.h>
#include <linux/init.h>
#include <linux/module.h>
#include <linux/mm.h>
#include <linux/types.h>
#include <asm/byteorder.h>

#include ""ripemd.h""

struct rmd320_ctx {
	u64 byte_count;
	u32 state[10];
	__le32 buffer[16];
};

#define K1  RMD_K1
#define K2  RMD_K2
#define K3  RMD_K3
#define K4  RMD_K4
#define K5  RMD_K5
#define KK1 RMD_K6
#define KK2 RMD_K7
#define KK3 RMD_K8
#define KK4 RMD_K9
#define KK5 RMD_K1

#define F1(x, y, z) (x ^ y ^ z)		/* XOR */
#define F2(x, y, z) (z ^ (x & (y ^ z)))	/* x ? y : z */
#define F3(x, y, z) ((x | ~y) ^ z)
#define F4(x, y, z) (y ^ (z & (x ^ y)))	/* z ? x : y */
#define F5(x, y, z) (x ^ (y | ~z))

#define ROUND(a, b, c, d, e, f, k, x, s)  { \
	(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \
	(a) = rol32((a), (s)) + (e); \
	(c) = rol32((c), 10); \
}

static void rmd320_transform(u32 *state, const __le32 *in)
{
	u32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee, tmp;

	/* Initialize left lane */
	aa = state[0];
	bb = state[1];
	cc = state[2];
	dd = state[3];
	ee = state[4];

	/* Initialize right lane */
	aaa = state[5];
	bbb = state[6];
	ccc = state[7];
	ddd = state[8];
	eee = state[9];

	/* round 1: left lane */
	ROUND(aa, bb, cc, dd, ee, F1, K1, in[0],  11);
	ROUND(ee, aa, bb, cc, dd, F1, K1, in[1],  14);
	ROUND(dd, ee, aa, bb, cc, F1, K1, in[2],  15);
	ROUND(cc, dd, ee, aa, bb, F1, K1, in[3],  12);
	ROUND(bb, cc, dd, ee, aa, F1, K1, in[4],   5);
	ROUND(aa, bb, cc, dd, ee, F1, K1, in[5],   8);
	ROUND(ee, aa, bb, cc, dd, F1, K1, in[6],   7);
	ROUND(dd, ee, aa, bb, cc, F1, K1, in[7],   9);
	ROUND(cc, dd, ee, aa, bb, F1, K1, in[8],  11);
	ROUND(bb, cc, dd, ee, aa, F1, K1, in[9],  13);
	ROUND(aa, bb, cc, dd, ee, F1, K1, in[10], 14);
	ROUND(ee, aa, bb, cc, dd, F1, K1, in[11], 15);
	ROUND(dd, ee, aa, bb, cc, F1, K1, in[12],  6);
	ROUND(cc, dd, ee, aa, bb, F1, K1, in[13],  7);
	ROUND(bb, cc, dd, ee, aa, F1, K1, in[14],  9);
	ROUND(aa, bb, cc, dd, ee, F1, K1, in[15],  8);

	/* round 1: right lane */
	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[5],   8);
	ROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[14],  9);
	ROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[7],   9);
	ROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[0],  11);
	ROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[9],  13);
	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[2],  15);
	ROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[11], 15);
	ROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[4],   5);
	ROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[13],  7);
	ROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[6],   7);
	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[15],  8);
	ROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[8],  11);
	ROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[1],  14);
	ROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[10], 14);
	ROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[3],  12);
	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);

	/* Swap contents of ""a"" registers */
	tmp = aa; aa = aaa; aaa = tmp;

	/* round 2: left lane"" */
	ROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);
	ROUND(dd, ee, aa, bb, cc, F2, K2, in[4],   6);
	ROUND(cc, dd, ee, aa, bb, F2, K2, in[13],  8);
	ROUND(bb, cc, dd, ee, aa, F2, K2, in[1],  13);
	ROUND(aa, bb, cc, dd, ee, F2, K2, in[10], 11);
	ROUND(ee, aa, bb, cc, dd, F2, K2, in[6],   9);
	ROUND(dd, ee, aa, bb, cc, F2, K2, in[15],  7);
	ROUND(cc, dd, ee, aa, bb, F2, K2, in[3],  15);
	ROUND(bb, cc, dd, ee, aa, F2, K2, in[12],  7);
	ROUND(aa, bb, cc, dd, ee, F2, K2, in[0],  12);
	ROUND(ee, aa, bb, cc, dd, F2, K2, in[9],  15);
	ROUND(dd, ee, aa, bb, cc, F2, K2, in[5],   9);
	ROUND(cc, dd, ee, aa, bb, F2, K2, in[2],  11);
	ROUND(bb, cc, dd, ee, aa, F2, K2, in[14],  7);
	ROUND(aa, bb, cc, dd, ee, F2, K2, in[11], 13);
	ROUND(ee, aa, bb, cc, dd, F2, K2, in[8],  12);

	/* round 2: right lane */
	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[6],   9);
	ROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[11], 13);
	ROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[3],  15);
	ROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[7],   7);
	ROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[0],  12);
	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[13],  8);
	ROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[5],   9);
	ROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[10], 11);
	ROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[14],  7);
	ROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[15],  7);
	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[8],  12);
	ROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[12],  7);
	ROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[4],   6);
	ROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[9],  15);
	ROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[1],  13);
	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);

	/* Swap contents of ""b"" registers */
	tmp = bb; bb = bbb; bbb = tmp;

	/* round 3: left lane"" */
	ROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);
	ROUND(cc, dd, ee, aa, bb, F3, K3, in[10], 13);
	ROUND(bb, cc, dd, ee, aa, F3, K3, in[14],  6);
	ROUND(aa, bb, cc, dd, ee, F3, K3, in[4],   7);
	ROUND(ee, aa, bb, cc, dd, F3, K3, in[9],  14);
	ROUND(dd, ee, aa, bb, cc, F3, K3, in[15],  9);
	ROUND(cc, dd, ee, aa, bb, F3, K3, in[8],  13);
	ROUND(bb, cc, dd, ee, aa, F3, K3, in[1],  15);
	ROUND(aa, bb, cc, dd, ee, F3, K3, in[2],  14);
	ROUND(ee, aa, bb, cc, dd, F3, K3, in[7],   8);
	ROUND(dd, ee, aa, bb, cc, F3, K3, in[0],  13);
	ROUND(cc, dd, ee, aa, bb, F3, K3, in[6],   6);
	ROUND(bb, cc, dd, ee, aa, F3, K3, in[13],  5);
	ROUND(aa, bb, cc, dd, ee, F3, K3, in[11], 12);
	ROUND(ee, aa, bb, cc, dd, F3, K3, in[5],   7);
	ROUND(dd, ee, aa, bb, cc, F3, K3, in[12],  5);

	/* round 3: right lane */
	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[15],  9);
	ROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[5],   7);
	ROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[1],  15);
	ROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[3],  11);
	ROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[7],   8);
	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[14],  6);
	ROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[6],   6);
	ROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[9],  14);
	ROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[11], 12);
	ROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[8],  13);
	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[12],  5);
	ROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[2],  14);
	ROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[10], 13);
	ROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[0],  13);
	ROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[4],   7);
	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);

	/* Swap contents of ""c"" registers */
	tmp = cc; cc = ccc; ccc = tmp;

	/* round 4: left lane"" */
	ROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);
	ROUND(bb, cc, dd, ee, aa, F4, K4, in[9],  12);
	ROUND(aa, bb, cc, dd, ee, F4, K4, in[11], 14);
	ROUND(ee, aa, bb, cc, dd, F4, K4, in[10], 15);
	ROUND(dd, ee, aa, bb, cc, F4, K4, in[0],  14);
	ROUND(cc, dd, ee, aa, bb, F4, K4, in[8],  15);
	ROUND(bb, cc, dd, ee, aa, F4, K4, in[12],  9);
	ROUND(aa, bb, cc, dd, ee, F4, K4, in[4],   8);
	ROUND(ee, aa, bb, cc, dd, F4, K4, in[13],  9);
	ROUND(dd, ee, aa, bb, cc, F4, K4, in[3],  14);
	ROUND(cc, dd, ee, aa, bb, F4, K4, in[7],   5);
	ROUND(bb, cc, dd, ee, aa, F4, K4, in[15],  6);
	ROUND(aa, bb, cc, dd, ee, F4, K4, in[14],  8);
	ROUND(ee, aa, bb, cc, dd, F4, K4, in[5],   6);
	ROUND(dd, ee, aa, bb, cc, F4, K4, in[6],   5);
	ROUND(cc, dd, ee, aa, bb, F4, K4, in[2],  12);

	/* round 4: right lane */
	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[8],  15);
	ROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[6],   5);
	ROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[4],   8);
	ROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[1],  11);
	ROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[3],  14);
	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[11], 14);
	ROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[15],  6);
	ROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[0],  14);
	ROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[5],   6);
	ROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[12],  9);
	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[2],  12);
	ROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[13],  9);
	ROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[9],  12);
	ROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[7],   5);
	ROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[10], 15);
	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);

	/* Swap contents of ""d"" registers */
	tmp = dd; dd = ddd; ddd = tmp;

	/* round 5: left lane"" */
	ROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);
	ROUND(aa, bb, cc, dd, ee, F5, K5, in[0],  15);
	ROUND(ee, aa, bb, cc, dd, F5, K5, in[5],   5);
	ROUND(dd, ee, aa, bb, cc, F5, K5, in[9],  11);
	ROUND(cc, dd, ee, aa, bb, F5, K5, in[7],   6);
	ROUND(bb, cc, dd, ee, aa, F5, K5, in[12],  8);
	ROUND(aa, bb, cc, dd, ee, F5, K5, in[2],  13);
	ROUND(ee, aa, bb, cc, dd, F5, K5, in[10], 12);
	ROUND(dd, ee, aa, bb, cc, F5, K5, in[14],  5);
	ROUND(cc, dd, ee, aa, bb, F5, K5, in[1],  12);
	ROUND(bb, cc, dd, ee, aa, F5, K5, in[3],  13);
	ROUND(aa, bb, cc, dd, ee, F5, K5, in[8],  14);
	ROUND(ee, aa, bb, cc, dd, F5, K5, in[11], 11);
	ROUND(dd, ee, aa, bb, cc, F5, K5, in[6],   8);
	ROUND(cc, dd, ee, aa, bb, F5, K5, in[15],  5);
	ROUND(bb, cc, dd, ee, aa, F5, K5, in[13],  6);

	/* round 5: right lane */
	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[12],  8);
	ROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[15],  5);
	ROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[10], 12);
	ROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[4],   9);
	ROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[1],  12);
	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[5],   5);
	ROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[8],  14);
	ROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[7],   6);
	ROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[6],   8);
	ROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[2],  13);
	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[13],  6);
	ROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[14],  5);
	ROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[0],  15);
	ROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[3],  13);
	ROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[9],  11);
	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);

	/* Swap contents of ""e"" registers */
	tmp = ee; ee = eee; eee = tmp;

	/* combine results */
	state[0] += aa;
	state[1] += bb;
	state[2] += cc;
	state[3] += dd;
	state[4] += ee;
	state[5] += aaa;
	state[6] += bbb;
	state[7] += ccc;
	state[8] += ddd;
	state[9] += eee;

	return;
}

static int rmd320_init(struct shash_desc *desc)
{
	struct rmd320_ctx *rctx = shash_desc_ctx(desc);

	rctx->byte_count = 0;

	rctx->state[0] = RMD_H0;
	rctx->state[1] = RMD_H1;
	rctx->state[2] = RMD_H2;
	rctx->state[3] = RMD_H3;
	rctx->state[4] = RMD_H4;
	rctx->state[5] = RMD_H5;
	rctx->state[6] = RMD_H6;
	rctx->state[7] = RMD_H7;
	rctx->state[8] = RMD_H8;
	rctx->state[9] = RMD_H9;

	memset(rctx->buffer, 0, sizeof(rctx->buffer));

	return 0;
}

static int rmd320_update(struct shash_desc *desc, const u8 *data,
			 unsigned int len)
{
	struct rmd320_ctx *rctx = shash_desc_ctx(desc);
	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);

	rctx->byte_count += len;

	/* Enough space in buffer? If so copy and we're done */
	if (avail > len) {
		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
		       data, len);
		goto out;
	}

	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
	       data, avail);

	rmd320_transform(rctx->state, rctx->buffer);
	data += avail;
	len -= avail;

	while (len >= sizeof(rctx->buffer)) {
		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
		rmd320_transform(rctx->state, rctx->buffer);
		data += sizeof(rctx->buffer);
		len -= sizeof(rctx->buffer);
	}

	memcpy(rctx->buffer, data, len);

out:
	return 0;
}

/* Add padding and return the message digest. */
static int rmd320_final(struct shash_desc *desc, u8 *out)
{
	struct rmd320_ctx *rctx = shash_desc_ctx(desc);
	u32 i, index, padlen;
	__le64 bits;
	__le32 *dst = (__le32 *)out;
	static const u8 padding[64] = { 0x80, };

	bits = cpu_to_le64(rctx->byte_count << 3);

	/* Pad out to 56 mod 64 */
	index = rctx->byte_count & 0x3f;
	padlen = (index < 56) ? (56 - index) : ((64+56) - index);
	rmd320_update(desc, padding, padlen);

	/* Append length */
	rmd320_update(desc, (const u8 *)&bits, sizeof(bits));

	/* Store state in digest */
	for (i = 0; i < 10; i++)
		dst[i] = cpu_to_le32p(&rctx->state[i]);

	/* Wipe context */
	memset(rctx, 0, sizeof(*rctx));

	return 0;
}

static struct shash_alg alg = {
	.digestsize	=	RMD320_DIGEST_SIZE,
	.init		=	rmd320_init,
	.update		=	rmd320_update,
	.final		=	rmd320_final,
	.descsize	=	sizeof(struct rmd320_ctx),
	.base		=	{
		.cra_name	 =	""rmd320"",
		.cra_flags	 =	CRYPTO_ALG_TYPE_SHASH,
		.cra_blocksize	 =	RMD320_BLOCK_SIZE,
		.cra_module	 =	THIS_MODULE,
	}
};

static int __init rmd320_mod_init(void)
{
	return crypto_register_shash(&alg);
}

static void __exit rmd320_mod_fini(void)
{
	crypto_unregister_shash(&alg);
}

module_init(rmd320_mod_init);
module_exit(rmd320_mod_fini);

MODULE_LICENSE(""GPL"");
MODULE_AUTHOR(""Adrian-Ken Rueegsegger <ken@codelabs.ch>"");
MODULE_DESCRIPTION(""RIPEMD-320 Message Digest"");
MODULE_ALIAS_CRYPTO(""rmd320"");
",c
"#include <stdio.h>
int main (void) {
    char ch1;
    long long int nA=0, nI=0, nF=0, count;

    scanf(""%I64d"", &count);
    scanf(""%c"", &ch1);

    while( count ) {
        scanf(""%c"", &ch1);
        if(ch1=='A') nA++;
        else if(ch1== 'I') nI++;
        else nF++;

        count--;
    }

    if(nI > 1) printf(""0"");
    else if(nI==1) printf(""1"");
    else printf(""%d"", nA);

    return 0;
}
",c
"/*  * Program to generate the test-cases for the problem: https://www.spoj.com/problems/COINS/
    * Program is based on command-line arguments which takes a filename as an argument.
    * Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<time.h>
#include<assert.h>

#ifdef _WIN32
    #include<Windows.h>
#else
    #include<unistd.h>
#endif

typedef unsigned long long ull_t;
ull_t MAX_LIMIT = 100;

int main(int argc,char *const argv[]) {
    srand(time(NULL));
    if(argc == 2) {
        FILE *test_file = fopen(argv[1],""w"");
        if(test_file) {
            sleep(1);
            srand(time(NULL));
            for(int i = 0; i < 10; ++i) {
                fprintf(test_file,""%llu\n"",(rand() % MAX_LIMIT));
            }
            fclose(test_file);
        } else {
            fprintf(stderr,""File not opened successfully\n"");
            return EXIT_FAILURE;
        }
    } else {
        fprintf(stderr,""Insufficient or More number of command line arguments\n"");
        return EXIT_FAILURE;
    }
    return EXIT_SUCCESS;
}",c
"#include <stdio.h>
#include <stdlib.h>
#include ""ml.h""

int  iunique(int y[], int n, int **values)
     /*
       extract unique values from a vector y of n integers.
       
       Return value: the number of unique values on success, 0 otherwise.
     */
{
  int nvalues=1;
  int i,j;
  int addclass;
  int *indx;

  if(!(*values=ivector(1))){
    fprintf(stderr,""iunique: out of memory\n"");
    return 0;
  }
    
  (*values)[0]=y[0];
  for(i=1;i<n;i++){
    addclass=1;
    for(j=0;j<nvalues;j++)
      if((*values)[j]==y[i])
        addclass=0;
    if(addclass){
      if(!(*values=(int*)realloc(*values,(nvalues+1)*sizeof(int)))){
	fprintf(stderr,""iunique: out of memory\n"");
	return 0;
      }
      (*values)[nvalues++]=y[i];
    }
  }

  if(!(indx=ivector(nvalues))){
    fprintf(stderr,""iunique: out of memory\n"");
    return 0;
  }

  isort(*values,indx,nvalues,SORT_ASCENDING);

  if(free_ivector(indx)!=0){
    fprintf(stderr,""iunique: free_ivector error\n"");
    return 0;
  }

  return nvalues;
}


int  dunique(double y[], int n, double **values)
     /*
       extract unique values from a vector y of n doubles.
       
       Return value: the number of unique values on success, 0 otherwise.
     */
{
  int nvalues=1;
  int i,j;
  int addclass;
  int *indx;

  if(!(*values=dvector(1))){
    fprintf(stderr,""dunique: out of memory\n"");
    return 0;
  }
    
  (*values)[0]=y[0];
  for(i=1;i<n;i++){
    addclass=1;
    for(j=0;j<nvalues;j++)
      if((*values)[j]==y[i])
        addclass=0;
    if(addclass){
      if(!(*values=(double*)realloc(*values,(nvalues+1)*sizeof(double)))){
	fprintf(stderr,""dunique: out of memory\n"");
	return 0;
      }
      (*values)[nvalues++]=y[i];
    }
  }

  if(!(indx=ivector(nvalues))){
    fprintf(stderr,""iunique: out of memory\n"");
    return 0;
  }

  dsort(*values,indx,nvalues,SORT_ASCENDING);

  if(free_ivector(indx)!=0){
    fprintf(stderr,""iunique: free_ivector error\n"");
    return 0;
  }

  return nvalues;
}
",c
"#include <stdio.h>

int n = 7;
int queue[10];
int front = -1;
int rear = -1;

void insert(int x){
    if(front==-1){
        front = rear = 0;
        queue[rear] = x;
    }else{
        rear++;
        queue[rear] = x;
    }
}

void delete(){
    if(front == -1){
        printf(""\n Queue is underflow"");
    }else{
        printf(""\n element to be delete: %d"", queue[front]);
        front++;
    }
}

void display(){
     if(rear == -1){
        printf(""\n Queue is underflow"");
    }else{
        printf(""\n element of queue are:"");
        for(int i=front; i<=rear; i++){
            printf(""%d "", queue[i]);
        }
    }
}

void destroy(){
    front = -1;
    rear = -1;
    printf(""\n Queue is destroyed"");
}
void main(void) {
    display();
    insert(1);
    insert(2);
    insert(3);
    insert(4);
    display();
    delete();
    display();
    destroy();
}

// ====OUTPUT====
//  Queue is underflow
//  element of queue are:1 2 3 4 
//  element to be delete: 1
//  element of queue are:2 3 4 
//  Queue is destroyed
",c
"#include <stdio.h>

int main () {
    char ch[201];
    int i,j,k=0,l=0,m=0,n;

    scanf(""%s"", ch);

    for(i=0; ch[i]; i++ ) {
        if(ch[i]=='1') k++;
        else if(ch[i]=='2') l++;
        else if(ch[i]=='3') m++;
    }

    n=2*(k+l+m)-1;

    for (i=0; n; i=i+2,n-- ) {
        if(k) {
            ch[i]='1';
            k--;
        }
        else if(l) {
            ch[i]='2';
            l--;
        }
        else ch[i]='3';
    }

    printf(""%s"", ch);

    return 0;
}
",c
"#include <stdio.h>
#include <stdlib.h>

struct node
{
    int data;
    struct node *next;
}; 

struct node *newrec, *first, *last, *temp; 

void insert_beg(int x){
    newrec = (struct node*)malloc(sizeof(struct node));
    newrec->data = x;
    if(first == NULL){
        first = last = newrec;
        newrec->next = NULL;
    }
    else{
        newrec->next = first;
        first = newrec;
    }
}

void insert_end(int x){
    newrec = (struct node*)malloc(sizeof(struct node));
    newrec -> data = x;
    if(first == NULL){
        first = last = newrec;
        newrec -> next = NULL;
    }else{
        last -> next = newrec;
        newrec ->next = NULL;
        last = newrec;
    }
}

void insert_pos(int x, int p){
    newrec = (struct node *)malloc(sizeof(struct node));
    newrec -> data = x;
    if(first==NULL){
        first = last = newrec;
        newrec -> next = NULL;
    }else{
        temp = first;
        for(int i=1; i<p-1; i++){
            temp = temp->next;
        }
        newrec->next = temp->next;
        temp->next = newrec;
    }
}

void del_beg(){
    if(first == NULL){
        printf(""linkedlist is underflow"");
    }else{
        printf(""Element to be delete: %d \n"", first->data);
        if(first == last){
            first = last = NULL;
        }else{
            first = first->next;
        }
    }
}

void del_end(){
    if(first == NULL){
        printf(""linkedlist is underflow"");
    }else{
        printf(""Element to be delete: %d \n"", last->data);
        if(first == last){
            first = last = NULL; 
        }else{
            temp = first;
            while(temp->next!=last){
                temp = temp->next;
            }
            last = temp;
            last -> next = NULL;
            
        }
    }
}

void del_pos(int p){
    if(first == NULL){
        printf(""linkedlist is underflow"");
    }else{
        if(first==last){
            printf(""Element to be delete: %d \n"", first->data);
            first = last = NULL;
        }else{
            temp = first;
            for(int i=1; i<p-1; i++){
                temp=temp->next;
            }
            printf(""Element to be delete: %d \n"", temp->next->data);
            temp->next = temp->next->next;
        }
    }
}

void display(){
    if(first==NULL){
        printf(""Linked list is underflow"");
    }else{
        temp = first;
        printf(""Content of linkedlist:"");
        while(temp!= NULL){
            printf(""%d "", temp->data);
            temp = temp -> next;
        }
    }
    printf(""\n"");
}

void destroy(){
    first = last = NULL;
    printf(""linkedlist is destroyed! \n"");
}

void main(void) {
    display();
    insert_beg(3);
    display();
    insert_beg(2);
    display();
    insert_beg(1);
    display();
    insert_end(4);
    display();
    insert_end(5);
    display();
    insert_beg(0);
    display();
    insert_pos(8,3);
    display();
    insert_pos(10,2);
    display();
    del_beg();
    display();
    del_end();
    display();
    del_pos(4);
    display();
    destroy();
    display();
}

// ===========OUTPUT=============
// Linked list is underflow
// Content of linkedlist:3 
// Content of linkedlist:2 3 
// Content of linkedlist:1 2 3 
// Content of linkedlist:1 2 3 4 
// Content of linkedlist:1 2 3 4 5 
// Content of linkedlist:0 1 2 3 4 5 
// Content of linkedlist:0 1 8 2 3 4 5 
// Content of linkedlist:0 10 1 8 2 3 4 5 
// Element to be delete: 0 
// Content of linkedlist:10 1 8 2 3 4 5 
// Element to be delete: 5 
// Content of linkedlist:10 1 8 2 3 4 
// Element to be delete: 2 
// Content of linkedlist:10 1 8 3 4 
// linkedlist is destroyed! 
// Linked list is underflow
",c
"/*  Problem Statement: https://www.spoj.com/problems/FIBOSUM/
 *  Author: striker
*/

#include<stdio.h>
#include<stdlib.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

enum matrix_dimensions {nrows = 2, ncols = 2};

#define MOD (1000000000 + 7)
#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line nubmer: %u: Constraints not satisfied for <%s> variable i.e. %s\n"",  __LINE__, #variable, #constraints)

static ll_t nth_fibonacci(ll_t);
static void matrix_exponentiation(ll_t [][ncols], ll_t);
static void matrix_multiplication(ll_t [][ncols], ll_t [][ncols]);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    scanf(""%d"", &test);
    if(test < 1 || test > 1000) {
        CONSTRAINTS_OUT_OF_BOUND_ERROR(test, 1 <= test <= 1000);
        exit(0);
    }
    while(test--) {
        int n, m;
        scanf(""%d%d"", &n, &m);
        if(n < 0 || n > 1000000000) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n, 0 <= n <= 10^9);
            exit(0);
        }
        if(m < 0 || m > 1000000000) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(m, 0 <= m <= 10^9);
            exit(0);
        }
        if(n > m) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n < m, n should be less than m);
            exit(0);
        }
        if(!(n == m)) {
            ll_t fibo_sum = ((nth_fibonacci(m + 2) - 1) - (nth_fibonacci((n - 1) + 2) - 1)) % MOD;
            if(fibo_sum < 0) {
                fibo_sum += MOD;
            }
            printf(""%lld\n"", fibo_sum);
        } else {
            printf(""%lld\n"", nth_fibonacci(n) % MOD);
        }
    }
    return EXIT_SUCCESS;
}

static ll_t nth_fibonacci(ll_t n) {
    if(!n) {
        return 0;
    } else if(1 == n) {
        return 1;
    }
    ll_t result_matrix[][ncols] = {{1, 0}, {0, 1}}; //Identity Matrix.
    matrix_exponentiation(result_matrix, n - 1);
    return result_matrix[0][0];
}

static void matrix_exponentiation(ll_t result_matrix[][ncols], ll_t n) {
    ll_t transformation_matrix[][ncols] = {{1, 1}, {1, 0}}; // Transformation Matrix.
    while(n) {
        if(n & 1) {
            matrix_multiplication(result_matrix, transformation_matrix);
        }
        matrix_multiplication(transformation_matrix, transformation_matrix);
        n >>= 1;
    }
}

static void matrix_multiplication(ll_t matrix_A[][ncols], ll_t matrix_B[][ncols]) {
    ll_t a = ((matrix_A[0][0] * matrix_B[0][0]) % MOD + (matrix_A[0][1] * matrix_B[1][0]) % MOD) % MOD;
    ll_t b = ((matrix_A[0][0] * matrix_B[0][1]) % MOD + (matrix_A[0][1] * matrix_B[1][1]) % MOD) % MOD;
    ll_t c = ((matrix_A[1][0] * matrix_B[0][0]) % MOD + (matrix_A[1][1] * matrix_B[1][0]) % MOD) % MOD;
    ll_t d = ((matrix_A[1][0] * matrix_B[0][1]) % MOD + (matrix_A[1][1] * matrix_B[1][1]) % MOD) % MOD;
    matrix_A[0][0] = a;
    matrix_A[0][1] = b;
    matrix_A[1][0] = c;
    matrix_A[1][1] = d;
}
",c
,c
"/*  Problem Statement: https://www.hackerrank.com/contests/projecteuler/challenges/euler002/problem or https://projecteuler.net/problem=2
 *  Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<string.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the <%s> variable i.e. %s\n"", __LINE__, #variable, #constraints)
#define INITIALIZE_DATA(variable, bytes) memset(variable, 0, (bytes))

static ull_t compute_even_fibonacci_sum(const ull_t);

int main(void) {
    /*
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    */
    int test;
    scanf(""%d"", &test);
    if(test < 1 || test > 100000) {
        CONSTRAINTS_OUT_OF_BOUND_ERROR(test, 1 <= test <= 10^5);
        exit(0);
    }
    while(test--) {
        ull_t n;
        scanf(""%llu"", &n);
        if(n < 1 || n > 40000000000000000) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n, 10 <= n <= 4 * 10^16);
            exit(0);
        }
        printf(""%llu\n"", compute_even_fibonacci_sum(n));
    }
    return EXIT_SUCCESS;
}

static ull_t compute_even_fibonacci_sum(const ull_t n) {
    ull_t sub_problem_1_sol = 2, sub_problem_2_sol = 8;
    ull_t even_sum = sub_problem_1_sol;
    while(sub_problem_2_sol <= n) {
        even_sum += sub_problem_2_sol;
        ull_t temp = sub_problem_2_sol;
        sub_problem_2_sol = 4 * sub_problem_2_sol + sub_problem_1_sol;
        sub_problem_1_sol = temp;
    }
    return even_sum;
}
",c
"#include <stdio.h>
#include <stdlib.h>

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        while(test--) {
            long long int n;
            if(1 == scanf(""%lld"", &n)) {
                long long int total_triangle = (n * (n + 2) * ((n << 1) + 1)) / 8;
                printf(""%lld\n"", total_triangle);
                continue;
            }
        }
    }
    return EXIT_SUCCESS;
}
",c
"/*
 * Problem Statement: Refer to the readme.md file.
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

static void rearrange_zeroes(int *const, const int);
static void display_sequence(const int *const, const int, const char *const);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    scanf(""%d"", &test);
    while(test--) {
        int n;
        scanf(""%d"", &n);
        if(n < 1) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(n, size of array cannot be 0 or -ve);
            exit(0);
        }
        int *const sequence = calloc(n, sizeof*sequence);
        if(sequence) {
            for(int i = 0; i < n; ++i) {
                scanf(""%d"", sequence + i);
            }
            rearrange_zeroes(sequence, n);
            display_sequence(sequence, n, "" "");
            free(sequence);
        } else {
            MEMORY_ALLOCATION_FAILED_ERROR(sequence, n * sizeof*sequence);
            exit(0);
        }
    }
    return EXIT_SUCCESS;
}

static void display_sequence(const int *const data, const int n, const char *const delimiter) {
    printf(""%d"", data[0]);
    for(int i = 1; i < n; ++i) {
        printf(""%s%d"", delimiter, data[i]);
    }
    printf(""\n"");
}

static void rearrange_zeroes(int *const data, const int n) {
    int index = 0;
    for(int i = 0; i < n; ++i) {
        if(data[i]) {
            data[index++] = data[i];
        }
    }
    while(index < n) {
        data[index++] = 0;
    }
}
",c
/home/runner/.cache/pip/pool/9f/36/73/a5473c01f4edc3e20d47728ec5c8f1f69cb355433c3a1b2b747d9d3bfc,c
"#include <stdio.h>

int main (void) {
    int atto[1000];
    int a, b, c=0;

    scanf(""%d"", &a);
    for(b=0; b<a; b++) scanf(""%d"", &atto[b]);

    while(atto[0] != 0) {
        for(b=0; b<a ; b++) {
            if(b%2 == 1 && atto[b]==0) atto[b]= a-1;
            else if (b%2==1) atto[b]--;
            else if (atto[b]== a-1) atto[b]=0;
            else atto[b]++;
        }
    }

    for(b=0; b<a; b++) {
        if(atto[b]==b) c=1;
        else {
            c=0;
            break;
        }
    }

    if(c==1) printf(""YES\n"");
    else printf(""No\n"");

    return 0;
}
",c
"/*  Problem Statement: https://www.codechef.com/ZCOPRAC/problems/ZCO12001
    Author: striker
*/

#include <stdio.h>
#include <stdlib.h>
#include <inttypes.h>
#include <assert.h>

int main(void) {
    int32_t n;
    scanf(""%""SCNd32, &n);
    assert(n > 1 && n < 100001);
    uint8_t *const bracket_sequence = calloc((size_t) n, sizeof(uint8_t));
    if(bracket_sequence) {
        int32_t open_cnt, max_depth, number_of_symbols, max_number_of_symbols;
        int32_t index_depth, index_max_symbols;
        index_depth = index_max_symbols = -1;
        open_cnt = max_depth = number_of_symbols = max_number_of_symbols = 0;
        for(int32_t i = 0; i < n; ++i) {
            scanf(""%""SCNu8, &bracket_sequence[i]);
            assert(bracket_sequence[i] > 0 && bracket_sequence[i] < 3);
            ++number_of_symbols;
            if(bracket_sequence[i] == 1) {
                ++open_cnt;
                if(open_cnt > max_depth) {
                    max_depth = open_cnt;
                    index_depth = i;
                }
            } else {
                --open_cnt;
                if(!open_cnt) {
                    if(number_of_symbols > max_number_of_symbols) {
                        max_number_of_symbols = number_of_symbols;
                        index_max_symbols = (i - (max_number_of_symbols - 1));
                    }
                    number_of_symbols = 0;
                }
            }
        }
        printf(""%""PRIu32"" %""PRIu32"" %""PRIu32"" %""PRIu32""\n"", max_depth, (index_depth + 1), max_number_of_symbols, (index_max_symbols + 1));
        free(bracket_sequence);
    } else {
        fprintf(stderr,""Not able to allocate %lu bytes of memory\n"", (n * sizeof(uint8_t)));
    }
    return 0;
}
",c
"// Max External: startup.c
// T.Place - 9/4/2001, 1/8/2002
// A simple Max object to put all tap.tools' objects into the new object list & post some info

#include ""ext.h""				// Required for all Max external objects

void *this_class;			// Required. Global pointing to this class 

typedef struct startup		// Data structure for this object 
{
	Object	p_ob;		// Must always be the first field; used by Max 
} Startup;

		
// Prototypes for methods: need a method for each incoming message
void	*startup_new(long value);			// object creation method  
void	startup_free(Startup *startup);	// free method

/*********************************************************/
//Main() Function

void main(void)			//main receives a copy of the Max function macros table 
{	
	// set up our class: create a class definition 
	setup((t_messlist **)&this_class, (method)startup_new, (method)startup_free, (short)sizeof(Startup), 0L, A_DEFLONG, 0);

	addmess((method)inspector_open, ""info"", A_CANT, 0);		// bind method for opening the license window

	finder_addclass(""SuperCollider Lib"", ""sc.CombN"");
	finder_addclass(""SuperCollider Lib"", ""sc.LFPulse"");
	finder_addclass(""SuperCollider Lib"", ""sc.LFSaw"");
	finder_addclass(""SuperCollider Lib"", ""sc.midicps"");
	finder_addclass(""SuperCollider Lib"", ""sc.SinOsc"");
	finder_addclass(""SuperCollider Lib"", ""sc.WhiteNoise"");
	finder_addclass(""SuperCollider Lib"", ""sc.Xline"");
	
//	finder_addclass(""Tap.Tools"", ""tap.metro"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.prime"");
	finder_addclass(""Tap.Tools"", ""tap.random"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.sieve"");					// add object to new-object list

	finder_addclass(""Tap.Tools"", ""tap.1pole-lp~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.allpole~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.anticlick~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.auto_thru~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.avg~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.bink~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.crossfade~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.decibels~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.diff~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.elixir~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.fft-list~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.fft-normalize~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.lp-comb~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.lpc~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.noise~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.pan~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.polar~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.quantize~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.radians~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.rms~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.scale~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.sift~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.split~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.typecheck~"");			// add object to new-object list

	finder_addclass(""Tap.Tools"", ""tap.5comb~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.adapt~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.decay_calc"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.deviate~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.fft~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.filterbank~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.gate~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.ifft~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.Lchange"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.limiter~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.loadbang"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.normalizer~"");			// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.nr~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.shift~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.sustain~"");				// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.thru~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.verb~"");					// add object to new-object list
	finder_addclass(""Tap.Tools"", ""tap.vocoder~"");				// add object to new-object list	
	finder_addclass(""Tap.Tools"", ""tap.vocoderlite~"");			// add object to new-object list	
	
	post(""Tap.Tools MSP"");						// Print to the Max Window...
	post(""    Objects for Max/MSP by Tim Place"");
	post(""    Version 0.95"");
	post(""    Copyright � 1999-2002 by Silicon Prairie Intermedia"");
	post(""    http://www.sp-intermedia.com"");
	post(""    Use \""Get Info\"" on any object to view its license"");
}


/*********************************************************/
//Object Creation Function

void *startup_new(long value)
{
	Startup *startup;
	startup = (Startup *)newobject(this_class);	// create the new instance and return a pointer to it 
	return(startup);						// must return a pointer to the new instance 
}


/*********************************************************/
//Bound to input Functions

// free method
void startup_free(Startup *startup)
{
	notify_free((t_object *)startup);
}",c
"#include <stdlib.h>
#include <stdio.h>
#include <string.h>

int main(int argc, char *argv[])
{
	char banner[100] = """";
			
	scanf(""%s"", banner);
	
	char codeforces[] = ""CODEFORCES"";
	int len = strlen(codeforces); // Although we know it's 10
	
	int i;
	int index = 0;
	int achieved = 0;
	int status = 0;
	
	for (i = 0; i < strlen(banner); i++)
	{
		if (index == len && achieved != 0) // CODEFORCES already completed but still iterating; reset index with achieved data
			index = achieved; // index resetted, but must continue checking current letter
		
		if (banner[i] == codeforces[index])
		{
			if (status == 1)
			{
				status = 2;
			}				
			index++;
		}	
		else //if (banner[i] != codeforces[index])
		{
			if (status == 0) // 1st error. save accumulated data
			{
				achieved = index;
				status = 1;
			}
			else if (status == 2) // Another error, reset index by loading achieved data
			{
				index = achieved;
				status = 1;
			}
		}
	}

	if (status == 0 && index == len) // Ideal case, received word is CODEFORCES
		printf(""YES\n"");	
	else if (status == 1 && achieved == len) // Completed CODEFORCES but got a substring after
		printf(""YES\n"");
	else if (status == 2 && index == len) // Got a substring but ended completing CODEFORCES
		printf(""YES\n"");
	else
		printf(""NO\n"");

	return 0;
}
",c
/home/runner/.cache/pip/pool/7f/f7/36/674c7000a4c978add160c229d5d817615f10c9e3b15202a4321b78aa4a,c
"/*  Problem Statement: https://www.hackerrank.com/challenges/maximum-element/problem
    Author: striker.
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<assert.h>

struct link_list {
    uint32_t data;
    struct link_list *next;
};
typedef struct link_list link_list_t;

link_list_t* make_node(uint32_t d);
void push_data(link_list_t*,link_list_t**);
void pop_data(link_list_t**);
link_list_t* peek_data(link_list_t**);
void delete_stack(link_list_t**);

int main(void) {
    uint32_t n;
    link_list_t *stack_1_head,*stack_2_head;
    scanf(""%""SCNu32,&n);
    assert(n > 0 && n < 100001);
    stack_1_head = stack_2_head = NULL;
    while(n--) {
        uint32_t type;
        scanf(""%""SCNu32,&type);
        assert(type > 0 && type < 4);
        switch(type) {
            uint32_t x;
            case 1:
                scanf(""%""SCNu32,&x);
                assert(x > 0 && x < 1000000001);
                push_data(make_node(x),&stack_1_head);
                if((!stack_2_head) || ((peek_data(&stack_2_head))->data) <= x) {
                    push_data(make_node(x),&stack_2_head);
                }
                break;
            case 2:
                if(stack_1_head && stack_2_head) {
                    if((peek_data(&stack_1_head)->data) == (peek_data(&stack_2_head)->data)) {
                        pop_data(&stack_2_head);
                    }
                    pop_data(&stack_1_head);
                } else {
                    if(!stack_1_head) {
                        fprintf(stderr,""Fist-stack is empty!\n"");
                    }
                    if(!stack_2_head) {
                        fprintf(stderr,""Second-stack is empty!\n"");
                    }
                }
                break;
            case 3:
                if(stack_2_head) {
                    printf(""%""PRIu32""\n"",(peek_data(&stack_2_head)->data));
                } else {
                    fprintf(stderr,""Second-stack is empty!\n"");
                }
                break;
            default:
                fprintf(stderr,""Entered query-type is not valid!\n"");
                break;
        }
    }
    if(stack_1_head) {
        delete_stack(&stack_1_head);
    }
    if(stack_2_head) {
        delete_stack(&stack_2_head);
    }
    return 0;
}

link_list_t* make_node(uint32_t d) {
    link_list_t *node = malloc(sizeof(link_list_t));
    if(node) {
        (node->data) = d;
        (node->next) = NULL;
    } else {
        fprintf(stderr,""Node not created successfully!\n"");
    }
    return node;
}

void push_data(link_list_t *node,link_list_t **head) {
    if(*head) {
        (node->next) = (*head);
        (*head) = node;
    } else {
        (*head) = node;
    }
}

void pop_data(link_list_t **head) {
    if(*head) {
        link_list_t *temp = (*head);
        (*head) = (*head)->next;
        free(temp);
    } else {
        fprintf(stderr,""Stack is empty!\n"");
    }
}

link_list_t* peek_data(link_list_t **head) {
    if(*head) {
        return (*head);
    } else {
        fprintf(stderr,""Stack is empty!\n"");
        return NULL;
    }
}

void delete_stack(link_list_t **head) {
    if(*head) {
        link_list_t *temp = (*head);
        while(temp) {
            (*head) = (*head)->next;
            free(temp);
            temp = *head;
        }
    } else {
        fprintf(stderr,""Stack is already empty!\n"");
    }
}",c
"/*  Problem Statement: https://www.spoj.com/problems/AE00/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<math.h>
#include<assert.h>

uint32_t find_number_rectangles(uint16_t);

int main(void) {
    uint16_t n; // number of square of side-length 1.
    scanf(""%""SCNu16,&n);
    assert(n > 0 && n < 10001);
    printf(""%""PRIu32""\n"",find_number_rectangles(n));
    return 0;
}

uint32_t find_number_rectangles(uint16_t n) {
    uint32_t ans = n;
    uint32_t n_rows = floor(sqrt(n));
    for(uint16_t i=2;i<=n_rows;ans += (n/i),++i);
    ans -= ((n_rows * (n_rows-1)) >> 1);
    return ans;
}
",c
"#include <stdio.h>
#include <ctype.h>

int main () {
    char str1[101],str2[202];
    int i,j;


    for(i=0; i<101 ; i++) str1[i]=0;
    for(j=0; j<202 ; j++) str2[j]=0;

    scanf(""%s"", str1);

    for(i=0; str1[i]; i++) str1[i]= tolower(str1[i]);

    for(i=0,j=0; str1[i] ; i++) {
        if(str1[i]=='a' || str1[i]=='o' || str1[i]=='y' || str1[i]=='e' || str1[i]=='u' || str1[i]=='i' );
        else {
            str2[j]='.';
            j++;
            str2[j]= str1[i];
            j++;
        }
    }

    printf(str2);



    return 0;
}
",c
"#include <stdio.h>

int main (void) {
	int num;
	int sec[num];
	int i=0;
	int flag=0;
	
	scanf(""%d"", &num);
	
	for( ;i<num; i++) scanf(""%d"", &sec[i]);
	
	for(i=1; i<num; i++) {
		if(sec[0]==sec[i]) {
			flag++;
			sec[0]++;
		}
		else if(sec[0]<sec[i]) {
			int temp=sec[i]-sec[0];
			
			if(temp%2) flag+=((temp/2)+1);
			else flag+=(temp/2);
			
			sec[0]+=(flag-sec[0]);
		}
	}
	
	printf(""%d\n"", flag);

	return 0;
}
",c
"#include<stdio.h>
#include<stdlib.h>

#define MODULUS 10

static int compute_last_digit(int, int);

int main(void) {
	int test;
	scanf(""%d"", &test);
	while(test--) {
		int a, b;
		scanf(""%d%d"", &a, &b);
		printf(""%d\n"", compute_last_digit(a, b));
	}
	return EXIT_SUCCESS;
}

static int compute_last_digit(int base, int exponent) {
	int result;
	if(!base) {
		result = 0;
	} else if(!exponent) {
		result = 1;
	} else {
		result = 1;
		while(exponent) {
			if(exponent & 1) {
				result = (result * (base)) % MODULUS;
			}
			base = (base * base) % MODULUS;
			exponent >>= 1;
		}
	}
	return result;
}
",c
"//
// Created by luozhen on 2017/8/25.
//

#ifndef CODEFORCES_BLOCK_ALI_H
#define CODEFORCES_BLOCK_ALI_H

#endif //CODEFORCES_BLOCK_ALI_H
#include <stdio.h>
#include <math.h>
#include <stdlib.h>

int Get(int n){
    int x;
    // do something
    int sq = sqrt(n * 2.0) - 1;
//    if(n == sq)
//        return n;
    while(sq * (sq + 1) / 2 < n){
        sq += 1;
    }
    printf(""sq:%d"", sq);
    x = n - sq * (sq - 1) / 2;
    return x % 10;
}

int block_main()
{
    int n;
    scanf(""%d"",&n);
    n += 1;
    int x;
    // do something
    int sq = sqrt(n * 2.0) - 1;
    while(sq * (sq + 1) / 2 < n){
        sq += 1;
    }
    x = n - sq * (sq - 1) / 2;
    printf(""%d"",x%10);
}",c
"#include <stdio.h>

int main (void)
{
    int dime;
    int i,j,k;
    char ch;

    scanf(""%d"", &dime);

    if(!(dime%2)) printf(""%d\n"", (dime*dime)/2 );
    else printf(""%d\n"", ((dime*dime)/2)+1);

    for(i=0, k=0; i<dime; i++) {
        for(j=0 ; j<dime; j++){
            if(!(k%2)) printf(""C"");
            else printf(""."");
            k++;
        }
        if(!(dime%2)) k--;
        printf(""\n"");
    }

    return 0;
}
",c
"/**
 * Author: Simon Lindholm
 * License: CC0
 * Source: Codeforces
 * Description: Given $a[i] = \min_{lo(i) \le k < hi(i)}(f(i, k))$ where the (minimal) optimal $k$ increases with $i$, computes $a[i]$ for $i = L..R-1$.
 * Status: tested on http://codeforces.com/contest/321/problem/E
 * Time: O((N + (hi-lo)) \log N)
 */
#pragma once

struct DP { // Modify at will:
	int lo(int ind) { return 0; }
	int hi(int ind) { return ind; }
	ll f(int ind, int k) { return dp[ind][k]; }
	void store(int ind, int k, ll v) { res[ind] = pii(k, v); }

	void rec(int L, int R, int LO, int HI) {
		if (L >= R) return;
		int mid = (L + R) >> 1;
		pair<ll, int> best(LLONG_MAX, LO);
		rep(k, max(LO,lo(mid)), min(HI,hi(mid)))
			best = min(best, make_pair(f(mid, k), k));
		store(mid, best.second, best.first);
		rec(L, mid, LO, best.second+1);
		rec(mid+1, R, best.second, HI);
	}
	void solve(int L, int R) { rec(L, R, INT_MIN, INT_MAX); }
};
",c
"#include <stdio.h>

int main () {
    char str1[] = ""hello"";
    char str2[101];

    int i=0,j=0,k=0;

    gets(str2);

    while(str1[i] && str2[j]) {
        if(str1[i]==str2[j]) {
            i++;
            k++;
        }
        j++;
    }

    if(k==5) printf(""YES"");
    else printf(""NO"");

    return 0;
}
",c
"//
// Created by luozhen on 2018/7/9.
//

#ifndef CODEFORCES_VECTOR_H
#define CODEFORCES_VECTOR_H

#endif //CODEFORCES_VECTOR_H
",c
"//
// Created by luozhen on 2018/5/4.
//

#ifndef CODEFORCES_LIB_H
#define CODEFORCES_LIB_H

#endif //CODEFORCES_LIB_H

struct ListNode {
    int val;
    ListNode *next;
    ListNode(int x) : val(x), next(NULL) {}
};


ListNode* createList(int* a, int n){
    ListNode* list = new ListNode(0), *res = list;
    for(int i=0; i<n; i++){
        res->next = new ListNode(0);
        res->next->val = a[i];
        //cout << res->next->val << "" "";
        res = res->next;
    }
    return list->next;
}

void showList(ListNode* ls){
    cout << ""show list:"" << endl;
    ListNode* p = ls;
    while(p){
        cout << p->val << "" "";
        p = p->next;
    }
    cout << endl;
}

",c
/home/runner/.cache/pip/pool/71/bb/0d/dcb93d1e4c33afd73ec8e3f6c44060d7f9a5d57ee7c003035b11a3cdcf,c
"/*
 * Problem Statement: https://www.hackerrank.com/contests/projecteuler/challenges/euler008/problem
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

static ll_t compute_largest_product(char[], const int);

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        while(test--) {
            getchar_unlocked();
            int n, k;
            if(2 == scanf(""%d%d"", &n, &k)) {
                getchar_unlocked();
                char number[n + 1];
                if(fgets(number, n + 1, stdin)) {
                    char *enter_char_loc = strchr(number, '\n');
                    if(enter_char_loc) {
                        *enter_char_loc = '\0';
                    }
                    printf(""%lld\n"", compute_largest_product(number, k));
                }
            } else {
                SCANF_READ_ERROR(2);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static ll_t compute_largest_product(char number[], const int digits) {
    int tot_digit = (int) strlen(number);
    ll_t max_product = 0;
    for(register int i = 0; i <= tot_digit - digits; ++i) {
        ll_t curr_product = 1;
        for(register int j = i, digit_limit = i + digits; j < digit_limit; ++j) {
            curr_product *= (number[j] - '0');
        }
        if(curr_product > max_product) {
            max_product = curr_product;
        }
    }
    return max_product;
}
",c
"#include <stdio.h>

int main (void) {
    int a, b, c,d,e,f;


    scanf(""%d"", &a);

    for(b=a+1,c=1; b ; c++,b--) {
        for(d=b-1; d; d--) printf(""  "");
        for(d=c-1,e=0; d; d--,e++) printf(""%d "",e);
        for(d=c; d>1 ; d--,e--) printf(""%d "",e);

        printf(""0\n"");
    }

    for(b=a; b; b--) {
        for(d=a-b+1; d; d--) printf(""  "");
        for(d=b-1,e=0; d; d--,e++ )printf(""%d "",e);
        for(d=b-1; d; d-- )printf(""%d "",d);

        printf(""02\n"");
    }



    return 0;
}
",c
"#include <stdlib.h>
#include <stdio.h>
#include <string.h>

int main(int argc, char *argv[])
{
	char banner[100] = """";
			
	scanf(""%s"", banner);
	
	char codeforces[] = ""CODEFORCES"";
	int len = strlen(codeforces); // Although we know it's 10
	
	int i;
	int index = 0;
	int achieved = 0;
	int status = 0;
	
	for (i = 0; i < strlen(banner); i++)
	{
		if (index == len && achieved != 0) // CODEFORCES already completed but still iterating; reset index with achieved data
			index = achieved; // index resetted, but must continue checking current letter
		
		if (banner[i] == codeforces[index])
		{
			if (status == 1)
			{
				status = 2;
			}				
			index++;
		}	
		else //if (banner[i] != codeforces[index])
		{
			if (status == 0) // 1st error. save accumulated data
			{
				achieved = index;
				status = 1;
			}
			else if (status == 2) // Another error, reset index by loading achieved data
			{
				index = achieved;
				status = 1;
			}
		}
	}

	if (status == 0 && index == len) // Ideal case, received word is CODEFORCES
		printf(""YES\n"");	
	else if (status == 1 && achieved == len) // Completed CODEFORCES but got a substring after
		printf(""YES\n"");
	else if (status == 2 && index == len) // Got a substring but ended completing CODEFORCES
		printf(""YES\n"");
	else
		printf(""NO\n"");

	return 0;
}
",c
"#include<Windows.h>
#include""APITransfer.h""
#include""CommandManager.h""
#include""InlineCommand.h""


int RegisterInlineCommand()
{
	pBOIT_COMMAND Command_qwq = RegisterCommand(L""qwq"", CmdMsg_qwq_Proc, L""����"", BOIT_MATCH_FULL);
	AddCommandAlias(Command_qwq, L""pwp"");
	AddCommandAlias(Command_qwq, L""qaq"");
	RegisterCommand(L""èè"", CmdMsg_cat_Proc, L""����èè��"", BOIT_MATCH_FULL);
	RegisterCommand(L""����"", CmdMsg_meow_Proc, L""����èè��"", BOIT_MATCH_FULL);
	
	RegisterCommand(L""boast"", CmdMsg_boast_Proc, L""��ţ��(�����еĹ���)"", BOIT_MATCH_FULL);
	RegisterCommandEx(L""run"", CmdMsg_run_Proc, CmdEvent_run_Proc, L""���д���"", BOIT_MATCH_PARAM);
	RegisterCommand(L""savecode"", CmdMsg_savecode_Proc, L""�������"", BOIT_MATCH_PARAM);
	RegisterCommand(L""runcode"", CmdMsg_runcode_Proc, L""���б���Ĵ���"", BOIT_MATCH_PARAM);
	RegisterCommand(L""showcode"", CmdMsg_showcode_Proc, L""��ʾ����"", BOIT_MATCH_PARAM);
	RegisterCommandEx(L""oier"", CmdMsg_oier_Proc,CmdEvent_oier_Proc, L""��ѯ OIer ��Ϣ"", BOIT_MATCH_PARAM);
	pBOIT_COMMAND Command_cf = RegisterCommandEx(L""cf"", CmdMsg_codeforces_Proc, CmdEvent_codeforces_Proc, L""��ѯ CF ��Ϣ"", BOIT_MATCH_PARAM);
	AddCommandAlias(Command_cf, L""codeforce"");
	AddCommandAlias(Command_cf, L""codeforces"");

	RegisterCommandEx(L""luogu"", CmdMsg_luogu_Proc, CmdEvent_luogu_Proc, L""��ѯ�����Ϣ"", BOIT_MATCH_PARAM);

	RegisterCommand(L""help"", CmdMsg_help_Proc, L""������Ϣ"", BOIT_MATCH_PARAM);
	RegisterCommand(L""q&amp;a"", CmdMsg_q_and_a_Proc, L""�����ʴ�"", BOIT_MATCH_FULL);
	RegisterCommand(L""admin"", CmdMsg_admin_Proc, L""����Ⱥ����bot����"", BOIT_MATCH_PARAM);
	RegisterCommand(L""about"", CmdMsg_about_Proc, L""����"", BOIT_MATCH_FULL);
	RegisterCommand(L""��Ǯ"", CmdMsg_donate_Proc, L""???"", BOIT_MATCH_FULL);
	RegisterCommand(L""version"", CmdMsg_version_Proc, L""�鿴boit�汾"", BOIT_MATCH_FULL);
	RegisterCommand(L""stop"", CmdMsg_stop_Proc, L""�ر�BOIT"", BOIT_MATCH_FULL);

	return 0;
}",c
"#include <stdio.h>

int main () {
    int a;
    scanf(""%d"",&a);

    if(a%4==0)printf(""YES"");
    else if(a%2==0) {
        if(a/2 > 1) printf(""YES"");
        else printf(""NO"");
    }
    else printf(""No"");

    return 0;
}
",c
"#include <stdio.h>

int main (void) {
    int i,j,k,l=0;
    int prime[] ={
     2 ,     3   ,   5  ,    7    , 11 ,    13  ,   17   ,  19  ,   23 ,    29 ,
     31  ,   37  ,   41   ,  43  ,   47 , 0
    };


    scanf(""%d %d"", &i, &j);

    for(k=0; k<15; k++) {
        if(prime[k]==i) {
            if(prime[k+1]==j) {
                printf(""YES\n"");
                l=1;
            }
            else break;
        }
    }

    if(l==0) printf(""NO\n"");

    return 0;
}
",c
"#include <stdio.h>
#include <conio.h>

int main (void) {
    char str1[27],ch1;
    char str2[100][100];
    int row, column,i,j,m,n=0,l;

    scanf(""%d %d"", &row, &column);
    scanf(""%c"",&ch1);
    scanf(""%c"",&ch1);

    for(i=0; i<row; i++){
        for(j=0; j<column; j++) str2[i][j]=getche();
    }

    for(i=0; i<row ;i++){
        for(j=0; j<column; j++){
            if(str2[i][j-1] == ch1 || str2[i][j+1] == ch1 || str2[i-1][j] == ch1 || str2[i+1][j] == ch1 ) {
                if(str2 != '.') {
                    for(l=0,m=1; l<27; l++) {
                        if(str1[l]== str2[i][j]) {
                            m=0;
                            break;
                        }
                    }
                    if(m=1) {
                        str1[n]= str2[i][j];
                        n++;
                    }
                }
            }
        }
    }

    printf(""%d"",n);

    return 0;
    }
",c
/home/runner/.cache/pip/pool/5b/29/74/8a9caccc72a8b5e2d7d2ea33d3e7c8e178dfef43bf9a8910099024a39e,c
"/**
 * Author: User adamant on CodeForces
 * Source: http://codeforces.com/blog/entry/12143
 * Description: For each position in a string, computes p[0][i] = half length of
 *  longest even palindrome around pos i, p[1][i] = longest odd (half rounded down).
 * Time: O(N)
 * Status: Fuzz-tested
 */
#pragma once

void manacher(const string& s) {
	int n = sz(s);
	vi p[2] = {vi(n+1), vi(n)};
	rep(z,0,2) for (int i=0,l=0,r=0; i < n; i++) {
		int t = r-i+!z;
		if (i<r) p[z][i] = min(t, p[z][l+t]);
		int L = i-p[z][i], R = i+p[z][i]-!z;
		while (L>=1 && R+1<n && s[L-1] == s[R+1])
			p[z][i]++, L--, R++;
		if (R>r) l=L, r=R;
}}
",c
/home/runner/.cache/pip/pool/31/aa/28/6720c63b52d353b450486ff4870a8bf8dc5b4cdc0cd314917156ae8628,c
"#include <stdio.h>

int main (void) {
    long long int n;
    int k,w,a=0,i=0;

    scanf(""%d %I64d %d"",&k,&n,&w);

    for(i=k; a<w ; i = i+k, a++) n = n-i;

    if(n>0) printf(""0\n"");
    else printf(""%d\n"", n*(-1));

    return 0;
}
",c
"    #include<stdio.h>  
     int main()    
    {    
    int n,r,sum=0,temp;    
    printf(""enter the number="");    
    scanf(""%d"",&n);    
    temp=n;    
    while(n>0)    
    {    
    r=n%10;    
    sum=sum+(r*r*r);    
    n=n/10;    
    }    
    if(temp==sum)    
    printf(""armstrong  number "");    
    else    
    printf(""not armstrong number"");    
    return 0;  
    }   
",c
"/*  Problem Statement: https://www.spoj.com/problems/PIHU1/
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<stdbool.h>
#include<assert.h>

const bool check_sorted(uint32_t *const,uint16_t);
void merge_sort(uint32_t *const,uint16_t,uint16_t);
void merge_data(uint32_t *const,uint16_t,uint16_t,uint16_t);
const bool is_representation_possible(uint32_t *const,uint16_t,uint32_t);

int main(void) {
    uint8_t test;
    scanf(""%""SCNu8, &test);
    assert(test > 0);
    while(test--) {
        uint16_t n;
        scanf(""%""SCNu16, &n);
        uint32_t *const data = calloc(n,sizeof(uint32_t));
        if(data) {
            for(uint16_t i = 0; i < n; ++i) {
                scanf(""%""SCNu32, &data[i]);
            }
            uint32_t p;
            scanf(""%""SCNu32, &p);
            if(!check_sorted(data,n)) {
                merge_sort(data,0,(n - 1));
            }
            printf(""%s"", (is_representation_possible(data,n,p) ? ""YES\n"" : ""NO\n""));
            free(data);
        } else {
            fprintf(stderr,""Not able to allocate %lu bytes of memory\n"", (n * sizeof(uint32_t)));
        }
    }
    return EXIT_SUCCESS;
}

const bool check_sorted(uint32_t *const data,uint16_t n) {
    bool is_sorted = true;
    for(uint32_t i = 0; i < (n - 1); ++i) {
        if(data[i] > data[i + 1]) {
            is_sorted = false;
            break;
        }
    }
    return is_sorted;
}

void merge_sort(uint32_t *const data,uint16_t start,uint16_t end) {
    if(start < end) {
        uint16_t mid = ((end - start) >> 1) + start;
        merge_sort(data,start,mid);
        merge_sort(data,(mid + 1),end);
        merge_data(data,start,mid,end);
    }
}

void merge_data(uint32_t *const data,uint16_t start,uint16_t mid,uint16_t end) {
    uint16_t left_size = (mid - start) + 1;
    uint32_t *const left_list = calloc(left_size,sizeof(uint32_t));
    if(left_list) {
        for(uint16_t i = 0; i < left_size; ++i) {
            left_list[i] = data[start + i];
        }
    } else {
        fprintf(stderr,""Not able to allocate %lu bytes of memory to left-list\n"", left_size * sizeof(uint32_t));
    }
    uint16_t right_size = end - mid;
    uint32_t *const right_list = calloc(right_size,sizeof(uint32_t));
    if(right_list) {
        for(uint32_t j = 0; j < right_size; ++j) {
            right_list[j] = data[(mid + 1) + j];
        }
    } else {
        fprintf(stderr,""Not able to allocate %lu bytes of memory to right-list\n"", right_size * sizeof(uint32_t));
    }
    for(uint16_t k = start, i = 0,j = 0; k <= end; ++k) {
        if(i == left_size) {
            data[k] = right_list[j];
            ++j;
        } else if(j == right_size) {
            data[k] = left_list[i];
            ++i;
        } else if(left_list[i] < right_list[j]) {
            data[k] = left_list[i];
            ++i;
        } else {
            data[k] = right_list[j];
            ++j;
        }
    }
    free(left_list);
    free(right_list);
}

const bool is_representation_possible(uint32_t *const data,uint16_t n,uint32_t p) {
    bool is_possible = false;
    for(uint16_t i = 0; i < (n - 2); ++i) {
        if(data[i] >= p) {
            continue;
        }
        uint32_t s = p - data[i];
        for(uint16_t start = (i + 1), end = (n - 1); start < end;) {
            if(data[start] + data[end] == s) {
                // printf(""Ai: %""PRIu32"" Aj: %""PRIu32"" Ak: %""PRIu32""\n"", data[start],data[end],(p - s));
                is_possible = true;
                break;
            } else if(data[start] + data[end] > s) {
                --end;
            } else {
                ++start;
            }
        }
        if(is_possible) {
            break;
        }
    }
    return is_possible;
}",c
"#ifndef _CODEFORCES_H

int Codeforces_1157C1();
void Codeforces_1157A();
int Codeforces_1157E();
int Codeforces_1169B();
int Codeforces_2A();
int Codeforces_4B();
int Codeforces_4C();
int Codeforces_1B();

#endif // !_CODEFORCES_H



",c
"//
// Created by luozhen on 2017/12/21.
//

#ifndef CODEFORCES_A281_H
#define CODEFORCES_A281_H

#endif //CODEFORCES_A281_H

//A. Word Capitalization
//time limit per test2 seconds
//memory limit per test256 megabytes
//inputstandard input
//outputstandard output
//Capitalization is writing a word with its first letter as a capital letter. Your task is to capitalize the given word.
//
//Note, that during capitalization all the letters except the first one remains unchanged.
//
//Input
//A single line contains a non-empty word. This word consists of lowercase and uppercase English letters. The length of the word will not exceed 103.
//
//Output
//Output the given word after capitalization.
//
//Examples
//input
//ApPLe
//output
//ApPLe
//input
//konjac
//output
//Konjac



",c
"/*
 * Problem Statement: https://www.spoj.com/problems/IITKWPCA/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

#define MAX_STRING_LENGTH 10002

typedef struct node {
    char *word;
    struct node *next;
} node_t;

static int compute_niceness_value(char*);
static node_t * makenode_list(char[]);
static void insert_node_list(node_t*, node_t*);
static bool search_data_list(const node_t*, char[]);
static int compute_list_length(node_t*);

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        getchar_unlocked();
        while(test--) {
            char sentence[MAX_STRING_LENGTH];
            if(fgets(sentence, MAX_STRING_LENGTH, stdin)) {
                char *const enter_char_loc = strchr(sentence, '\n');
                if(enter_char_loc) {
                    *enter_char_loc = '\0';
                }
                printf(""%d\n"", !strchr(sentence, ' ') ? 1 : compute_niceness_value(sentence));
            } else {
                fprintf(stderr, ""Line number: %u: Not able to read the string from stdin.\n"", __LINE__);
                exit(0);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static node_t * makenode_list(char data[]) {
    node_t *new_node = malloc(sizeof*new_node);
    if(new_node) {
        new_node->word = data;
        new_node->next = NULL;
    } else {
        MEMORY_ALLOCATION_FAILED_ERROR(new_node, sizeof*new_node);
        exit(0);
    }
    return new_node;
}

static void insert_node_list(node_t *traverse_ptr, node_t *new_node) {
    for(; traverse_ptr->next; traverse_ptr = traverse_ptr->next);
    traverse_ptr->next = new_node;
}

static bool search_data_list(const node_t *traverse_ptr, char search_data[]) {
    bool is_present = false;
    for(; traverse_ptr; traverse_ptr = traverse_ptr->next) {
        if(!strcmp(traverse_ptr->word, search_data)) {
            is_present = true;
            break;
        }
    }
    return is_present;
}

static int compute_list_length(node_t *traverse_ptr) {
    int list_length = 0;
    for(node_t *del_node = traverse_ptr; traverse_ptr; ++list_length) {
        traverse_ptr = traverse_ptr->next;
        free(del_node->word);
        free(del_node);
        del_node = traverse_ptr;
    }
    return list_length;
}

static int compute_niceness_value(char *sentence) {
    node_t *head_ptr = NULL;
    char *start_loc = sentence;
    unsigned long int whitespace_count, read_char_count;
    whitespace_count = read_char_count = 0;
    for(register int i = 0; sentence[i]; ++i) {
        if(sentence[i] == ' ') {
            ++whitespace_count;
            if(read_char_count && whitespace_count == 1) {
                char *token = calloc((size_t) (1 + read_char_count), sizeof*token);
                if(token) {
                    memcpy(token, start_loc, (read_char_count * sizeof*token));
                    token[read_char_count] = '\0';
                    read_char_count = 0;
                    if(!head_ptr) {
                        head_ptr = makenode_list(token);
                        continue;
                    }
                    if(!search_data_list(head_ptr, token)) {
                        insert_node_list(head_ptr, makenode_list(token));
                        continue;
                    }
                    free(token);
                } else {
                    MEMORY_ALLOCATION_FAILED_ERROR(token, 1 + read_char_count * sizeof*token);
                    exit(0);
                }
            }
            continue;
        }
        whitespace_count = 0;
        ++read_char_count;
        if(read_char_count == 1) {
            start_loc = sentence + i;
        }
    }
    if(read_char_count) {
        char *token = calloc((size_t) (1 + read_char_count), sizeof*token);
        if(token) {
            token[read_char_count] = '\0';
            memcpy(token, start_loc, read_char_count * sizeof*token);
            if(!search_data_list(head_ptr, token)) {
                insert_node_list(head_ptr, makenode_list(token));
            } else {
                free(token);
            }
        } else {
            MEMORY_ALLOCATION_FAILED_ERROR(token, 1 + read_char_count* sizeof*token);
        }
    }
    return compute_list_length(head_ptr);
}
",c
"#include <stdio.h>

int main () {

    long long int number, height, procLength;
    long long int temp=0;
    long long int totalTime = 0;
    long long int load = 0;


    scanf(""%I64d %I64d %I64d"", &number, &height, &procLength);

    while(number--) {

        scanf(""%I64d"", &temp);

        if(load+temp > height) {

            int key = height - load;
            key = temp - key;

            if( key%procLength ) key += (procLength - (key%procLength));
            totalTime += (key/procLength);

            if(load < key) load = 0;
            else load -= key;
            load += temp;
        }
        else {
            load += temp;
            continue;
        }

    }

    if(load > 0) {

        totalTime += (load/procLength);
        if(load%procLength) totalTime++;
    }

    printf(""%I64d\n"", totalTime);

    return 0;
}
",c
"/*  Problem Statement: https://www.hackerrank.com/contests/core-intra/challenges/clock-hands/problem
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<inttypes.h>
#include<string.h>
#include<math.h>
#include<assert.h>

#define MAX_LENGTH 6

static double compute_angle_between_hands(const uint8_t,const uint8_t);

int main(void) {
    uint8_t test;
    scanf(""%""SCNu8, &test);
    assert(test > 0 && test < 11);
    while(test--) {
        char time[MAX_LENGTH];
        scanf(""%s"", time);
        uint8_t len = strlen(time) + 1;
        char *buffer = calloc(sizeof(char),len);
        snprintf(buffer,len,""%s"",time);
        uint8_t hr = atoi(__strtok_r(buffer,"":"",&buffer));
        uint8_t min = atoi(__strtok_r(NULL,"":"",&buffer));
        assert(min >= 0 && min < 61);
        if(min == 60) {
            min = 0;
            hr += 1;
        }
        if(hr > 12 && hr < 25) {
            hr %= 12;
        }
        assert(hr >= 0 && hr < 13);
        double angle_between_hands = compute_angle_between_hands(hr,min);
        if(floor(angle_between_hands) == angle_between_hands) {
            printf(""%""PRIu8""\n"", (int)(angle_between_hands));
        } else {
            printf(""%0.1lf\n"", angle_between_hands);
        }
    }
    return EXIT_SUCCESS;
}

static double compute_angle_between_hands(const uint8_t hr,const uint8_t min) {
    double hr_angle,min_angle;
    hr_angle = (30 * hr) + (0.5 * min);
    min_angle = 6 * min;
    double angle_between_hands = 0.0;
    angle_between_hands = fabs(hr_angle - min_angle);
    if(angle_between_hands > 180) {
        angle_between_hands = 360 - angle_between_hands;
    }
    return angle_between_hands;
}",c
"/*
 * Problem Statement: https://www.linkedin.com/posts/gcnit_projecteuler-code-coding-activity-6636246267817226240-5lgK
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d\n"", __LINE__, return_val); exit(0)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

// Solution to the problem starts from below.

#define TOTAL_PRIMES 78498
#define LIMIT 1000001

unsigned int prime_number[TOTAL_PRIMES];

static void generate_primes(void);

int main(void) {
    int test;
    if(1 == scanf(""%d"", &test)) {
        generate_primes(); // Generate all the primes upto given n i.e. 10^5.
        while(test--) {
            int n;
            if(1 == scanf(""%d"", &n)) {
                printf(""%d\n"", prime_number[n - 1]); // After generating the prime, you can calculate the nth prime in O(1) time.
            } else {
                SCANF_READ_ERROR(1);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

static void generate_primes(void) {
    bool sieve_table[LIMIT];
    memset(sieve_table, 1, LIMIT * sizeof(bool)); // Initialise every location of sieve_table array to true.
    // Sieve of Eratosthenes algorithm.
    sieve_table[0] = sieve_table[1] = false; // As 0 and 1 are not prime numbers.
    for(register ll_t i = 2, k = 0; i < LIMIT; ++i) {
        if(sieve_table[i]) {
            prime_number[k++] = i;
            for(register ll_t j = i * i; j < LIMIT; j += i) {
                sieve_table[j] = false;
                continue;
            }
        }
    }
}
",c
"#include <stdio.h>
#include <string.h>

int main () {
    int i,j;
    char str1[101];

    scanf(""%d"", &i);

    for(; i; i--) {
        for (j=0; j<101; j++ ) {
            str1[j]=0;
        }
        scanf(""%s"", str1);
        j=strlen(str1);

        if (j>10) printf(""%c%d%c\n"", str1[0],j-2, str1[j-1]);
        else {
            printf(""%s"", str1);
            printf(""\n"");
        }
    }

    return 0;
}
",c
"/*
 * Problem Statement: https://www.spoj.com/problems/BYTESM2
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <ctype.h>
#include <limits.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <time.h>

/*START OF CODE-TEMPLATE*/

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

/*END OF CODE-TEMPLATE*/

static int compute_maximum_element(const int *const, const int);
static int compute_maximum_path_cost(int **const, const int, const int);
static void free_dynamic_memory(int **const, const int);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        int nrows, ncols;
        if(2 == scanf(""%d%d"", &nrows, &ncols)) {
            int **const matrix = calloc((size_t) nrows, sizeof*matrix);
            if(!matrix) {
                MEMORY_ALLOCATION_FAILED_ERROR(matrix, (size_t) nrows * sizeof*matrix);
                exit(0);
            }
            for(int i = 0; i < nrows; ++i) {
                matrix[i] = calloc((size_t) ncols, sizeof**matrix);
                if(!matrix[i]) {
                    MEMORY_ALLOCATION_FAILED_ERROR(matrix[i], (size_t) ncols * sizeof**matrix);
                    exit(0);
                }
                for(int j = 0; j < ncols; ++j) {
                    if(1 != scanf(""%d"", &matrix[i][j])) {
                        SCANF_READ_ERROR(1);
                    }
                }
            }
            printf(""%d\n"", compute_maximum_path_cost(matrix, nrows, ncols));
            free_dynamic_memory(matrix, nrows);
            continue;
        }
        SCANF_READ_ERROR(2);
    }
    return EXIT_SUCCESS;
}

static int compute_maximum_element(const int *const sequence, const int n) {
    int max_value = 0;
    for(int i = 0; i < n; ++i) {
        if(sequence[i] > max_value) {
            max_value = sequence[i];
        }
    }
    return max_value;
}

static int compute_maximum_path_cost(int **const matrix, const int nrows, const int ncols) {
    if(nrows == 1 && ncols == 1) {
        return matrix[0][0];
    }
    if(nrows == 1) {
        return compute_maximum_element(matrix[0], ncols);
    }
    if(ncols == 1) {
        int value_sum = 0;
        for(int i = 0; i < nrows; ++i) {
            value_sum += matrix[i][0];
        }
        return value_sum;
    }
    int *cost_matrix, *temp_matrix;
    cost_matrix = calloc((size_t) ncols, sizeof*cost_matrix);
    if(!cost_matrix) {
        MEMORY_ALLOCATION_FAILED_ERROR(cost_matrix, (size_t) ncols * sizeof*cost_matrix);
        exit(0);
    }
    temp_matrix = calloc((size_t) ncols, sizeof*temp_matrix);
    if(!temp_matrix) {
        MEMORY_ALLOCATION_FAILED_ERROR(temp_matrix, (size_t) ncols * sizeof*temp_matrix);
        exit(0);
    }
    for(int j = 0; j < ncols; ++j) {
        cost_matrix[j] = matrix[0][j];
    }
    for(int i = 1; i < nrows; ++i) {
        for(int j = 0; j < ncols; ++j) {
            if(!j) {
                temp_matrix[j] = FIND_MAX(cost_matrix[j] + matrix[i][j], cost_matrix[j + 1] + matrix[i][j]);
                continue;
            }
            if(j == ncols - 1) {
                temp_matrix[j] = FIND_MAX(cost_matrix[j] + matrix[i][j], cost_matrix[j - 1] + matrix[i][j]);
                continue;
            }
            temp_matrix[j] = FIND_MAX(FIND_MAX(cost_matrix[j - 1] + matrix[i][j], cost_matrix[j] + matrix[i][j]), cost_matrix[j + 1] + matrix[i][j]);
        }
        for(int j = 0; j < ncols; ++j) {
            cost_matrix[j] = temp_matrix[j];
        }
    }
    int max_cost = compute_maximum_element(cost_matrix, ncols);
    free(cost_matrix);
    free(temp_matrix);
    return max_cost;
}

static void free_dynamic_memory(int **const matrix, const int nrows) {
    for(int i = 0; i < nrows; ++i) {
        free(matrix[i]);
    }
    free(matrix);
}
",c
"#include <stdio.h>

int main () {
    int pass,plane,i=0;
    int seat[1000];

    for(i=0; i<100; i++) seat[i]=0;

    scanf(""%d %d"", &pass, &plane);

    for( i=0 ; i < plane ; i++) scanf(""%d"", &seat[i]);

    // min earning
    for()

    return 0;
}
",c
"/*
 * Problem Statement: https://leetcode.com/problems/number-of-steps-to-reduce-a-number-to-zero/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d\n"", __LINE__, return_val); exit(0)
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

static int number_of_steps(int);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    if(1 == scanf(""%d"", &test)) {
        if(test < 1) {
            CONSTRAINTS_OUT_OF_BOUND_ERROR(test, test value cannot be 0 or -ve);
            exit(0);
        }
        while(test--) {
            int n;
            if(1 == scanf(""%d"", &n)) {
                if(n < 0) {
                    CONSTRAINTS_OUT_OF_BOUND_ERROR(n, n cannot be 0 or -ve);
                    exit(0);
                }
                printf(""%d\n"", number_of_steps(n));
            } else {
                SCANF_READ_ERROR(1);
            }
        }
    } else {
        SCANF_READ_ERROR(1);
    }
    return EXIT_SUCCESS;
}

/*
 * Function which needs to be written on Leet-Code.
*/

static int number_of_steps(int n) {
    if(n && !(n & (n - 1))) {
        return 1 + log2(n);
    }
    int nsteps = 0;
    while(n) {
        ++nsteps;
        if(n && !(n & (n - 1))) {
            nsteps += log2(n);
            break;
        }
        if(!(n % 2)) {
            n >>= 1;
            continue;
        }
        n -= 1;
    }
    return nsteps;
}
",c
"/*
 * Problem Statement: https://leetcode.com/explore/featured/card/top-interview-questions-easy/92/array/727/
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <ctype.h>
#include <limits.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <time.h>

/*START OF CODE-TEMPLATE*/

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d_t;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.
#define GOLDEN_RATIO 1.618033988749895 // Number of digits(15).

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define SCANF_READ_ERROR(expected_return_val) fprintf(stderr, ""Line number: %u: scanf() read error!\nExpected-Return-Value: %d.\n"", __LINE__, expected_return_val); exit(0)
#define STREAM_LINK_ERROR(file_path, stream_name) fprintf(stderr, ""Line number: %u: Stream Link Error! Not able to link <%s> file to <%s> stream.\n"", __LINE__, #file_path, #stream_name); exit(0);
#define INITIALISE_INT_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define INITIALISE_CHAR_CONTAINER_ZERO(container, bytes) memset(container, '0', (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

// The below function macros refers to the GCC functions for doing computation directly on the bit-level of a number.
#define COMPUTE_SET_BITS(number) __builtin_popcountll(number) // Returns the number of set-bits in number (unsigned long long).
#define COMPUTE_PARITY(number) __builtin_parityll(number) // Returns the parity of the number (unsigned long long) i.e. True if 1's are odd else False.
#define COUNT_LEAD_ZEROES(number) __builtin_clzll(number) // Returns the count of lead zeroes before first set-bit from MSB in number (unsigned long long).
#define COUNT_TRAIL_ZEROES(number) __builtin_ctzll(number) // Return the count of trailing zeroes in number(unsigned long long).

/*END OF CODE-TEMPLATE*/

static int remove_duplicates(int *const, const int);

int main(void) {
    int test;
    if(1 != scanf(""%d"", &test)) {
        SCANF_READ_ERROR(1);
    }
    while(test--) {
        int n;
        if(1 != scanf(""%d"", &n)) {
            SCANF_READ_ERROR(1);
        }
        int *const sequence = calloc((size_t) n, sizeof*sequence);
        if(!sequence) {
            MEMORY_ALLOCATION_FAILED_ERROR(sequence, (size_t) n * sizeof*sequence);
            exit(0);
        }
        for(int i = 0; i < n; ++i) {
            if(1 != scanf(""%d"", sequence + i)) {
                SCANF_READ_ERROR(1);
            }
        }
        const int limit = remove_duplicates(sequence, n);
        for(int i = 0; i < limit; ++i) {
            printf(""%d "", sequence[i]);
        }
        printf(""\n"");
        free(sequence);
    }
    return EXIT_SUCCESS;
}

static int remove_duplicates(int *const sequence, const int n) {
    if(!n) {
        return 0;
    }
    int index = 0, i = 1;
    for(; i < n; ++i) {
        if(sequence[index] != sequence[i]) {
            sequence[++index] = sequence[i];
        }
    }
    return 1 + index;
}
",c
"#include <stdio.h>

int main (void) {
    char str1[51],changer;
    int stu, time, count=0,i;

    scanf(""%d %d"", &stu, &time);

    gets(str1);
    gets(str1);

    for ( ; time ; time--) {
        for(i=0 ; str1[i]; i++ ) {
            if(str1[i]== 'B' && str1[i+1]=='G') {
                changer= str1[i];
                str1[i]= str1[i+1];
                str1[i+1]= changer;
                i++;
            }
        }
    }

    printf(str1);

    return 0;
}
",c
"#include <stdio.h>

int main (void) {
    int a, b, c, e1,e2,e3,e4,e5,e6,sum=0;

    scanf(""%d %d %d"", &a, &b,&c);

    e1=a + b + c;
    e2=a * b * c;
    e3=a + b * c;
    e4=a * b + c;
    e5=(a + b)* c;
    e6=a * (b+c);


    if (e1>sum) sum = e1;
    if (e2>sum) sum = e2;
    if (e3 >sum) sum = e3;
    if (e4 >sum) sum = e4;
    if (e5 >sum) sum = e5;
    if (e6>sum) sum = e6;

    printf(""%d"", sum);

    return 0;
}
",c
/home/runner/.cache/pip/pool/9c/c7/c8/bdea484861437b13eb3189792d6b5d9ade94cbd4ca3f31780556b2c362,c
"/*
 * Problem Statement: https://github.com/strikersps/Competitive-Programming/blob/master/Other-Programs/Best-Pair/readme.md
 * Author: striker
 *
 * Copyright 2020 striker
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <limits.h>
#include <time.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

typedef struct Point2D {
    int x, y;
} point_2d;

#define MOD (1000000000 + 7) // Prime Number
#define PI 3.141592653589793 // Number of digits(15) of Pi which JPL uses for Interplanetary Caculations.

#define MEMORY_ALLOCATION_FAILED_ERROR(variable, bytes) fprintf(stderr, ""Line number: %u: Not able to allocate <%lu> bytes of memory to <%s> variable.\n"", __LINE__, (bytes), #variable)
#define CONSTRAINTS_OUT_OF_BOUND_ERROR(variable, constraints) fprintf(stderr, ""Line number: %u: Constraints not satisfied for the variable <%s>, i.e. %s.\n"", __LINE__, #variable, #constraints)
#define INITIALISE_CONTAINER_ZERO(container, bytes) memset(container, 0, (bytes))
#define FIND_MAX(a, b) (a) > (b) ? (a) : (b)
#define FIND_MIN(a, b) (a) < (b) ? (a) : (b)
#define FIND_MID(start, end) (((end) - (start)) >> 1) + (start)

static bool check_sorted(const ll_t *const, const int);
static void merge_sort(ll_t *const, const int, const int);
static void merge_data(ll_t *const, const int, const int, const int);

int main(void) {
    #ifndef ONLINE_JUDGE
        freopen(""test-cases/test-case-1.in"", ""r"", stdin);
        freopen(""test-cases/test-case-1.out"", ""w"", stdout);
    #endif
    int test;
    scanf(""%d"", &test);
    while(test--) {
        int n;
        scanf(""%d"", &n);
        ll_t *const data = calloc(n, sizeof*data);
        if(data) {
            for(int i = 0; i < n; ++i) {
                scanf(""%lld"", &data[i]);
            }
            if(!check_sorted(data, n)) {
                merge_sort(data, 0, n - 1);
            }
            printf(""%lld\n"", FIND_MAX((data[0] * data[1]), (data[n - 1] * data[n - 2])));
            free(data);
        } else {
            MEMORY_ALLOCATION_FAILED_ERROR(data, n * sizeof*data);
            exit(0);
        }
    }
    return EXIT_SUCCESS;
}

static bool check_sorted(const ll_t *const data, const int n) {
    bool is_sorted = true;
    for(int i = 0; i < (n - 1); ++i) {
        if(data[i] > data[i + 1]) {
            is_sorted = false;
            break;
        }
    }
    return is_sorted;
}

static void merge_sort(ll_t *const data, const int start, const int end) {
    if(start < end) {
        const int mid = FIND_MID(start, end);
        merge_sort(data, start, mid);
        merge_sort(data, mid + 1, end);
        merge_data(data, start, mid, end);
    }
}

static void merge_data(ll_t *const data, const int start, const int mid, const int end) {
    const int left_size = (mid - start) + 1;
    ll_t *const left_data = calloc(left_size, sizeof*left_data);
    if(left_data) {
        memcpy(left_data, &data[start], left_size * sizeof*data);
    } else {
        MEMORY_ALLOCATION_FAILED_ERROR(left_data, left_size * sizeof*left_data);
        exit(0);
    }
    const int right_size = end - mid;
    ll_t *const right_data = calloc(right_size, sizeof*right_data);
    if(right_data) {
        memcpy(right_data, &data[mid + 1], right_size * sizeof*data);
    } else {
        MEMORY_ALLOCATION_FAILED_ERROR(right_data, right_size * sizeof*right_data);
        exit(0);
    }
    for(int i = 0, j = 0, k = start; k <= end;) {
        if(i == left_size) {
            data[k++] = right_data[j++];
        } else if(j == right_size) {
            data[k++] = left_data[i++];
        } else if(left_data[i] < right_data[j]) {
            data[k++] = left_data[i++];
        } else {
            data[k++] = right_data[j++];
        }
    }
    free(left_data);
    free(right_data);
}
",c
"#include <stdio.h>

int main () {
    int m,n,a;

    scanf(""%d %d"", &m, &n);

    a= m*n;
    printf(""%d"", a/2);

    return 0;
}
",c
"#include <stdio.h>

void simple_merge(int a[], int f, int s, int t){
    int i=f, j=s, k=-1;
    int temp[20];
    while(i<=s-1 && j<=t){
        if(a[i]>a[j]){
            k++;
            temp[k] = a[j];
            j++;
        }
        else{
            k++;
            temp[k] = a[i];
            i++;
        }
    }
    if(i>s-1){
        for(int w=j; w<=t; w++){
            k++;
            temp[k] = a[w];
        }
    }else{
        for(int w=i; w<=s-1; w++){
            k++;
            temp[k] = a[w];
        }
    }
    for(int w=0; w<=k; w++){
        a[f+w] = temp[w];
    }
}


int merge_sort(int a[], int l, int r){
    int mid = (l+r)/2;
    if(l!=r){
        merge_sort(a, l, mid);
        merge_sort(a, mid+1, r);
        simple_merge(a, l, mid+1, r);
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call merge sort
    // a, 0, n-1
    merge_sort(a, 0, 5);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c
"#include <stdio.h>
#include <math.h>

int main () {

    long long int a,b;
    int i=0,j,k,m,n=0;

    scanf(""%I64d"", &a);

    for ( b=a ; b ; ) {
        b = b/10;
        i++;
    }

    for(j=1; j<i; j++) {
        for(k=1, m=1; k<=j; k++) {
            m= m*2;
        }
        n=n+m;
    }


    if(a%((i-1)*10)==4) n = n+1;



    printf(""%d"", n);

    return 0;
}
",c
/home/runner/.cache/pip/pool/3f/e6/07/8e3d971384a2b610643f00e04a13b11969d548d51783bda1f0ede4a5bb,c
"/*  Problem Statement: Refer the readme.md file.
    Author: striker
*/

#include<stdio.h>
#include<stdlib.h>
#include<assert.h>

typedef unsigned long long ull_t;
typedef long long ll_t;

void take_input(size_t *const,size_t);
size_t* transform_list(size_t *const,size_t);
void display_list(size_t *const,size_t);

int main(void) {
    int test;
    printf(""Enter the number of test-cases\n"");
    scanf(""%d"",&test);
    assert(test > 0);
    while(test--) {
        size_t n;
        printf(""Enter the length of the sequence\n"");
        scanf(""%lu"",&n);
        assert(n > 0);
        // Assumption: All the numbers in the sequence are positive, and zero is not allowed.
        size_t *const data = calloc(n,sizeof(size_t));
        if(data) {
            printf(""Enter the data into the sequence\n"");
            take_input(data,n);
            size_t *const transformed_list = transform_list(data,n);
            display_list(transformed_list,n);
            free(transformed_list);
            free(data);
        } else {
            fprintf(stderr,""Memory not allocated to *data pointer!\n"");
        }
    }
    return 0;
}

void take_input(size_t *const data,size_t n) {
    for(size_t i = 0; i < n; ++i) {
        scanf(""%lu"",&data[i]);
        assert(data[i] != 0);
    }
}

size_t* transform_list(size_t *const data,size_t n) {
    ull_t cummulative_product = 1;
    size_t *left_list = calloc(n,sizeof(size_t));
    if(left_list) {
        for(size_t i = 0; i < n; ++i) {
            cummulative_product *= data[i];
            left_list[i] = cummulative_product;
        }
    } else {
        fprintf(stderr,""Memory not allocated to *left-list pointer!\n"");
    }
    cummulative_product = 1;
    size_t *right_list = calloc(n,sizeof(size_t));
    if(right_list) {
        for(int i = (n - 1); i >= 0; --i) {
            cummulative_product *= data[i];
            right_list[i] = cummulative_product;
        }
    } else {
        fprintf(stderr,""Memory not allocated to the *right-list pointer!\n"");
    }
    size_t *transformed_list = calloc(n,sizeof(size_t));
    for(size_t i = 0; i < n; ++i) {
        if(!i) {
            transformed_list[i] = right_list[i + 1];
        } else if(i == (n - 1)) {
            transformed_list[i] = left_list[i - 1];
        } else {
            transformed_list[i] = right_list[i + 1] * left_list[i - 1];
        }
    }
    free(left_list);
    free(right_list);
    return transformed_list;
}

void display_list(size_t *const data,size_t n) {
    for(size_t i = 0; i < n; ++i) {
        printf(""%lu "",data[i]);
    }
    printf(""\n"");
}",c
"#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#define MAX 5

struct vertex{
    char lable;
    bool visited;
};

// graph variables
struct vertex *vertices[MAX];
int adjencencymatrix[MAX][MAX];
int vertexcount = 0;

// stack variables
int stack[MAX];
int top = -1;

// stack functions
void push(int x){
    stack[++top] = x;
}

int pop(){
    return stack[top--];
}

int peek(){
    return stack[top];
}

bool isstackempty(){
    return(top==-1);    
}

// graph functions
void addVertex(char x){
    struct vertex *v = (struct vertex *)malloc(sizeof(struct vertex));
    v -> lable = x;
    v -> visited = false;
    vertices[vertexcount++] = v;
}

void addEdge(int start, int end){
    adjencencymatrix[start][end] = 1;
    adjencencymatrix[end][start] = 1;
}

void displayvertex(int vertexindex){
    printf(""%c "", vertices[vertexindex]->lable);
}

int getadjecentvertex(int vertexindex){
    int i;
    for(i = 0; i<vertexcount; i++){
        if(adjencencymatrix[vertexindex][i]==1 && vertices[i]->visited == false){
            return i;
        }
    }
    return -1;
}

void depthFirstSearch(){
    int i;
    vertices[0] -> visited = true;
    displayvertex(0);
    push(0);
    
    while(!isstackempty()){
        //get the unvisited vertex of vertex which is at top of the stack
        int unvisited = getadjecentvertex(peek());
        
        //no adjacent vertex found
        if(unvisited == -1){
            pop();
        }
        else{
            vertices[unvisited]->visited = true;
            displayvertex(unvisited);
            push(unvisited);
        }
    }
    
    //stack is empty, search is complete, reset the visited flag
    for(i=0; i< vertexcount; i++){
        vertices[i]->visited = false;
    }
}


int main(void) {
	// your code goes here
	int i, j;
	for(i=0; i<MAX; i++){
	    for(j=0; j<MAX; j++){
	        adjencencymatrix[i][j] = 0;
	    }
	}
	
    addVertex('S');   // 0
    addVertex('A');   // 1
    addVertex('B');   // 2
    addVertex('C');   // 3
    addVertex('D');   // 4

    addEdge(0, 1);    // S - A
    addEdge(0, 2);    // S - B
    addEdge(0, 3);    // S - C
    addEdge(1, 4);    // A - D
    addEdge(2, 4);    // B - D
    addEdge(3, 4);    // C - D
    
    printf(""Depth First Search: "");
    depthFirstSearch(); 
    
	return 0;
}
",c
/home/runner/.cache/pip/pool/b1/f1/24/af2dfcb60045573c8d5ce046fc5f178745f3a09d3ec9c46395165d5bc0,c
"#include <stdio.h>

int insertion_sort(int a[], int n){
    for(int i=0; i<=n-1; i++){
        int j = i;
        int x = a[i];
        while(j>0 && a[j-1]>x){
            a[j] = a[j-1];
            j--;
        }
        a[j] = x;
    }
}

void main(){
    int a[10] = {1, 8, 2, 9, 7, 5};
    // call insertion sort
    insertion_sort(a, 6);
    printf(""Array: "");
    for(int i=0; i<6; i++){
        printf(""%d "", a[i]);
    }
}
",c
/home/runner/.cache/pip/pool/38/73/b9/76ff73884011b57db0d953c3a011f352b37b0e83c5125b5ed3d47d2bd7,c
